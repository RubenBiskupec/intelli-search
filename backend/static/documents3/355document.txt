TELKOMNIKA Telecommunication, Computing, Electronics and Control

Vol. 18, No. 6, December 2020, pp. 3041~3049

ISSN: 1693-6930, accredited First Grade by Kemenristekdikti, Decree No: 21/E/KPT/2018

DOT: 10.12928/TELKOMNIKA.v1 816.17300 O 3041

Towards better performance: phase congruency based face

recognition

Muthana H. Hamd, Rabab A. Rasool
Computer Engineering Department, Al-Mustansiriyah University, Iraq

Article Info ABSTRACT

Article history: Phase congruency is an edge detector and measurement of the significant
feature in the image. It is a robust method against contrast and illumination

Received May 16, 2020 variation. In this paper, two novel techniques are introduced for developing a

Revised Jun 6, 2020 low-cost human identification system based on face recognition. Firstly, the

Accepted Jul 20, 2020 valuable phase congruency features, the gradient-edges and their associated

angles are utilized separately for classifying 130 subjects taken from three face
databases with the motivation of eliminating the feature extraction phase. By
Keywords: doing this, the complexity can be significantly reduced. Secondly, the training
process is modified when a new technique, called averaging-vectors is
developed to accelerate the training process and minimizes the matching time
to the lowest value. However, for more comparison and accurate evaluation,

Face recognition
Feature detection

Gradient three competitive classifiers: Euclidean distance (ED), cosine distance (CD),
Orientation and Manhattan distance (MD) are considered in this work. The system
Phase congruency performance is very competitive and acceptable, where the experimental

results show promising recognition rates with a reasonable matching time.

This is an open access article under the CC BY-SA license.

Corresponding Author:

Muthana H. Hamd,

Department of Computer Engineering,
University of Al Mustansiriyah,

Baghdad, Iraq.

Email: dr.muthana@uomustansiriyah.edu.iq

1. INTRODUCTION

Phase congruency (PC) is an accurate approach for features detection which unlike traditional edge
detectors, that search for points of maximum gradients, the phase congruency searches for the ordered
spectrums in a frequency domain. It provides a contrast and an illumination invariant method of edge detection.
These significant PC features: the local-orientations and their associated phases have inspired a new vision for
designing a low-cost biometric system like face recognition based on those PC features only, which means
there is no more demand for employing feature extraction phase in the design plan. In the meantime, feature
extraction is a dimension reduction process by which an original dataset is reduced to be more convenient
groups. Also, it is a vital operation in the machine learning process for building features that: facilitate the
speed of learning, saving time, and phase generalization. It is usually the step that the classification process
comes after. Hereby, cancelling this step resulted in a large-size feature vector causing unwanted delay time in
the training and matching process. So, this work, introduces a new technique for manipulating this urgent
status, it depends on the determining the mean feature vector for training datasets, so the matching or
classification process will be implemented in one-to-one relation instead of one-to-many. This paper is
organized as follows, a literature review for the most related works are presented in section 2, while, the
theoretical part of the phase congruency approach and its types is illustrated in section 3. The methodology of

Journal homepage: http://journal.uad.ac.id/index.php/TELKOMNIKA
3042 O ISSN: 1693-6930

this work is explained in section 4. Section 5 demonstrates the experimental system results, and finally,
section 6 summarizes the most important aspects and issues in this work.

2. LITERATURE REVIEW

In [1, 2] used wavelets and universal threshold value over a wide class of images. The calculation for
the one-dimensional (1-D) signal was extended to 2-D images, also it is argued that high-pass filter can be used
to obtain image information at different scales. In 2007, [3, 4] proposed a face recognition technique aimed at
improving the recognition accuracies of the faces that are affected due to varying illuminations, partial
occlusions and varying expressions. H. Ragb and V. K. Asari [5], presented a descriptor based on the phase
congruency concept, called histogram of oriented phase (HOP) used to depict and represent the human objects
more efficiently than the gradient-based approach especially those images exposed to the illumination and
contrast variations. N. D. Rao presented a novel face recognition technique. The modular kernel Eigen spaces
approach implemented on the phase congruency images to localize nonlinear feature selection procedure for
overcoming the bottlenecks of illumination variations, partial occlusions, expression variations as in [6]. S.
Alavi in [7] developed a two-dimensional multi-scale phase congruency (2D-MSPC) software for detecting
and evaluation of image features. Many parameters are appropriately tuned for optimal image features
detection, these parameters are optimized for maximum and minimum moments. The design in [8] proposed a
modified algorithm of phase congruency to locate image features using the Hilbert transform. The local energy
is obtained by convoluting original image with two operators of removing direct current (DC) component over
the current window and the 2-D Hilbert transform respectively. The local energy is divided with the sum of
Fourier amplitude of the current window to retrieve the value of PC [9-11]. A novel decision-level fusion
method is developed by [12] on several AR sets to improve face recognition. PC feature maps are utilized
instead of intensities to make the recognition process invariant to contrast and illumination in an image.
A combination of Gabor wavelets (GW) and PC was developed by [13] for face recognition system, first,
the PC was applied to the ORL face image, then the spatial frequency information was obtained using the set
of Gabor-filters. The initial results without using of principal component analysis (PCA) method showed 98%
recognition rate. Upon using the PCA, the recognition rate was still retained by 98%. Also, the recognition rate
was reduced to 96% using GW and PCA methods only. Combinations of PCA, modular PCA (MPCA),
modular subspace PCA (MPPCA), and neighbourhood module PCA (NMPCA) were applied on the significant
PC features of AR database. The PC approach could improve the recognition accuracy by 10% for some
combination like NMPCA [14]. A distinct wavelength PC (DWPC) and log-Gabor filters were proposed for
matching a visible and infrared image, the PC theory was utilized to determine PC images with affluent and
intrinsic image features for noisy or complex intensity-change images [15].

3. PHASE CONGRUENCY MEASURMENTS

Some problems of incomplete edges and contours because of the changes in the local illumination and
hence an inadequate selective threshold is handled by [2] when a high-level technique is considered to
accommodate useful data and reject redundant information. Three types of PC based frequency domain
operations that considered a phase in their operating are presented as follows [16-18]:

3.1. Fourier components based measure

In this type, a one-dimension phase congruency at some location point x is defined as congruency
function. Features are detected by founding the Fourier components that have a maximum phase as explained
in (1) [ 1, 2].

dulFp, | cos(@,, (x) ~ eu)

PC(x) = MAXG (x)E[ 0,21 |] ( y |Fp | (1)

where: %u(*)and 9,.(*) are the local and mean phase angles of the frequency component FPu at x The aim is
to maximize (1) by maximizing the weighted mean amplitude for local phase angle for all considered Fourier

points of D(x), Hereby, phase congruency is a rather difficult quantity to be computed, as finding, where
phase congruency is a maximum, is approximately equivalent finding where the weighted variance of local
phase angles relative to the weighted average local phase is a minimum [19-21 ].

3.2. One-dimension wavelet-based measure
The phase congruency in (1) is sensitive to the noise and it is not well localized because the measure
changes with the difference in phase, not in the small responses or magnitude IFpul itself, so for @ ~ zero,

TELKOMNIKA Telecommun Comput El Control, Vol. 18, No. 6, December 2020: 3041 - 3049
TELKOMNIKA Telecommun Comput El Control O 3043

2

Y / 2 explains how phase difference affects the weighted magnitudes IFPul. So, an alternative
approach is needed to find maximum local energy as phase congruency is directly proportional to it. [19]
improved the phase congruency performance when 1-D Wavelet is applied to define a measure for PC with
the presence of noise. The components, F(x) and H(x) are obtained by convolving the quadrature filters with
the signal. In order to determine the phase information and local frequency in the signal, logarithmic Gabor
functions are used to obtain a non-zero DC component in the filtered signal. If J(x) is a signal and “" and
Mn denote the even symmetric and odd symmetric components of the log Gabor function at a scale n,
the amplitude and phase in the transformed domain can be obtained as :

A, = Ve,(x)? + 0, (x)? (2)

®, = tan! (° (x) e, ()) (3)

the cos(@) ~ 1-

where &») and °@) are the even and odd responses of quadrature pair of filters. The response vector is
illustrated in (4).

[en (x), On (x) = L(x) * MZ, I(x) * M7] (4)

So, F(x) and H(x) can be obtained from (5) and (6).

FO) =) en @) 5)

n

H(@®) =) 0 (0) 6)

n

All Fourier amplitudes they are computed at point x, are very small, then a small positive constant, ¢ (between
0 and 1) is added to the denominator to overcome the division by zero problem. The final phase congruency
formula is given by (8).

Where E(x) = ./ F(x)? + H(x)? (7)

_ E(x)
PC(x) = yA, +é (8)

3.3. Two-dimensions log-gabor-based measure

Frequency domain, wavelets, and convolution are three repetitively terms within phase congruency
subject where a new notation called frequency domain Gabor wavelet using different functions was presented.
The extension of frequency domain considerations to the 2D image was developed by [18, 20, 22] by
convolving set of frequency-domain constructed filters with an image. So the construction of Fourier domain
filter like log-Gabor function is very suitable as it has complementary spreading functions and singularity at
DC frequency. Starting from the low-pass Gaussian filter has a transfer function defined in (9).

(0-9)?
e 202 (9)

 

6,,0) =
g( 0 ) V2n0,

where,

99 , 8: are the orientation and angle of the local orientation respectively

0; ‘controls the spreading around the orientation 9% the Laplace of Gaussian (log) and Gabor band-pass filter
(g) have spreading function /9 (@, @n) with m different scales and k different orientations as defined in (10).

0 w= 0
_ Cogl@/ @n))?
Ig(@, ®m) = , 2(log(f))? (10)
Jomo. wt#O0
TO;

Towards better performance: phase congruency based face recognition (Muthana H. Hamd)
3044. O ISSN: 1693-6930

where, ” >» m ‘are the scale and the center frequency at this scale respectively, ‘controls bandwidth at this

_k
scale, B= "/ ®m. The functions combination will result 2D filter 12D which works at different scales and
orientations as in (11) [23, 24]. So, the convolution of this filter with the image J (x, y) delivers the phase
congruency measurement after inversion the Fourier transformation as in (12) and (13) [25 - 28].

12Dg(w, Wm , 0,8) = g(0,9) X Ig(o, Wm ) (11)

E(M)xy =3 1 U2Dg(@, Om 19,9 )xy * Ixy (12)

|>M_,E(m),.y |

PC, , ==
YM _|ECm),y| +e

(13)

4. METHODOLOGY

For more investigations and accurate decision, different image sources and qualities are considered for
evaluation the system performance [29]. Three facial databases are considered in this work, they are Aletx and Robert
(AR), visible and thermal paird face database (VIS-TH), olivetti research laboratory (ORL). Table 1 explains some
attributes of those databases. The MATLAB code in [21] is utilized with its experimental optimum parameters to
detect the PC local-orientations and their associated local-phases for facial images. Figure 1 is an example of an ORL
image with its two features matrices: the gradient-edges and their associated angles.

Table 1. Face databases

 

Database Subjects Training images Samples Dimension
AR 50 5 250 120x165
ORL 40 8 320 112x92

VIS-CH 40 10 400 1920x1080

     

Original image PC edges

Figure |. Phase congruency features: gradient-edges and gradient-angles for ORL image

4.1. Averaging-vectors training

An averaging-vectors procedure is applied to reduce the long-time needed in the matching process caused
by the large-size feature vector. By implementing this modification, matching operations will be reduced to
the number of classes instead of (training images = no. of classes) for each test image, as explained in (14).

MBT =2ico” (14)

n

4.2. Classification

For wide comparison, three classifiers ED, MD, and CD are applied simultaneously to calculate
the recognition accuracies for three face databases at different distance measures. The system accuracy is
computed at equal error rate (EER) value which reflects the maximum system performance when the false
acceptance rate (FAR) equals to the false rejection rate (FRR) as explained in 15. The error distance between
x andy with m+J/ length can be described in (16-18) [30-34].

TELKOMNIKA Telecommun Comput El Control, Vol. 18, No. 6, December 2020: 3041 - 3049
TELKOMNIKA Telecommun Comput El Control O 3045

(FAR + FRR)

Accuracy Rate = (1 — ; ) (15)

— Euclidean distance
The ED is the straight-line distance between two points in Euclidean space, with this distance,
Euclidean space becomes a metric space [35].

ED = > Ve —y,)2 (16)
i=0

— Manhattan distance

The MD between two items is the sum of the differences of their corresponding coordinates, it is
measured along axes at right angles in contrast to Eucledian distance which consider a straight (diagonal) line
to measure the differences. The formula for the distance between two points 1s,

m

MD = ) |x,-y (17)

i=0

— Cosine distance

Cosine similarity is a measure of similarity between two non-zero vectors, it is defined to equal
the cosine of the angle between them. It is thus a judgment of orientation and not magnitude: two vectors with
the same orientation have a cosine similarity of 1, two vectors oriented at 90° relative to each other have
a similarity of 0, and two vectors diametrically opposed have a similarity of -1, independent of their magnitude.
The complement of the cosine similarity is as follows:

vio Xi Vi
CD = 1 —-——ti (18)

m

2 m 2
i=o~%i + V Li=0 Vi

5. EXPERIMANTAL RESULTS

It is rarely found work that matches the proposed design having the same PC features, databases, and
classifiers. However, [13] ran its recognition system using a combined PC/Gabor wavelet method with ORL
database, it satisfied highest recognition rate at 98%, also, it obtained 96% recognition accuracy using PC/PCA
method. The results of [14] were too modest, 1t achieved only 52.7% using PC/PCA method and 72.5% using
the MPPCA method. Those accuracy results were classified by radial basis function NNs for AR database.
Also, the matching of infrared and visible images using DWPC and log-Gabor filters improved the recognition
accuracy by 50% as [15] approved that. Most biometric systems do not include the run-time result in their
calculations, as their systems are not designed to run for real-time applications. However, our proposed design
needs to compare the run-time of the averaging-vectors and Normal methods for the purposes of evaluation.
The recognition accuracies are tabulated into Table 2 and Table 3 depending on the averaging-vectors based
classification and normal based classification respectively.

Table 2. Phase congurency performance using averaging-vectors classification
Accuracy (edges, angles) %

Database Euclidean Manhattan Cosine Run Time (Sec. )
AR (79.6, 96.2) (82. 7,92.8) (94.5, 91.5) (10, 10.7)
ORL (80.9, 81.1) (81.5, 82.6) (89.9, 82.1) (5.9, 9.1)

VIS-TH 66.9, 83.3 68.4, 80.9 95.0, 76.2 33.1, 35

Table 3. Phase congurency performance using normal classification
Accuracy (edges, angles) %

Database Euclidean Manhattan Cosine Run Time (Sec.) Euclidean
AR (83.8, 88.9) (88.3, 96.3) AR (83.8, 88.9)
ORL (85.5,78.4) (85.8, 91.8) ORL (85.5,78.4 )
VIS-TH (84.3, 86.2) (87.6, 93.6) | VIS-TH (84.3, 86.2)

Towards better performance: phase congruency based face recognition (Muthana H. Hamd)
3046 O ISSN: 1693-6930

5.1. Averaging-vectors based classification

From Table 2, the CD measurement satisfied maximum recognition rates (94.5, 89.9, 95) for AR,
ORL, and VIS-TH datasets respectively. These results belong to the gradient-edge feature, while the gradient-
angle feature achieved maximum recognition rates (96.2, 83.3) using ED for AR and VIS-TH datasets
respectively. The MD measurement achieved only 82.6 using ORL dataset. The maximum performance
(96.2%) is then registered for ED measure using the local-phase feature. The run-time for this maximum
performance is 10.7 sec.

5.2. Normal-based classification

From Table 3, the CD measurement and the local-orientation satisfied maximum recognition rates (95.5,
89.3, 94.7) for AR, ORL, and VIS-TH respectively, while the local-phase feature satisfied maximum rates of (96.3,
91.8, 93.6) for AR, ORL, and VIS-TH respectively. The maximum performance (96.3%) is then registered for MD
measure with the local-phase feature. The run-time for this maximum performance is (420 sec. = 7 min.). Hereby,
the maximum recognition accuracies for the two classification methods are obtained from the local-phase
(gradient-angle) features. Figures 2 to 13, provide more details about the performance of each dataset with respect
to the classifier and matching method. It is noticeable that the system run-time based on the averaging-vectors is
highly less than Normal e.g.; the maximum accuracy rates and their associated run-times are (96.2%, 10.7 sec.) and
(96.3%, 7 min.) w.r.t Table 1 and Table 2 respectively. That means, the averaging-vector classification is ~ 39.25
times faster than Normal-classification and moreover, the maximum accuracy rates for both tables have belonged to
the gradient-angle feature and not gradient-edge feature.

 

95r T T T T T T T T T 7 100

 

 

 

 

Euclidean
Manhaten
Cosine

 

Euclidean
Manhaten
Cosine

90 + 95 F

 

 

 

 

 

 

 

 

 

 

85 + 90 5
85 F

80 7

      

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

  

 

 

¢ 5 75}
8 70 | 3
< x aob
65
65 5
60 60 +
55 5 55+
50 1 1 1 1 1 1 1 1 50 1 1 1 1 1 1 1
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
Threshold Threshold
Figure 2. AR accuracy of gradient-edges and Figure 3. AR accuracy of gradient-edges and
averaging-vector matching normal matching
100 T T T T T T T T T 100
Euclidean Euclidean
95 7 Manhaten 95 fF Manhaten
Cosine Cosine
90 [- 90
85 [- 85 L
> 80 fF > 80 fF
© ©
8 TOP 3 75+
< 70} fc aot
65 [- 65
60 + 60 F
55 | 55 b
50 1 1 1 1 1 1 1 50 1 1 1 1 1 1 1 1 1
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
Threshold Threshold
Figure 4. AR accuracy of gradient-angles and Figure 5. AR accuracy of gradient-angles and
averaging-vectors matching normal matching

TELKOMNIKA Telecommun Comput El Control, Vol. 18, No. 6, December 2020: 3041 - 3049
TELKOMNIKA Telecommun Comput El Control

 

 

 

 

 

 

 

 

90 1 T 1
Euclidean

B54 Manhaten
Cosine

80

757

Accuracy
oO |
ol oO
T T

oD
oO
T

55 5

 

 

50 1 1 1 1 1 1 1 1 1

0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1

Threshold

Figure 6. ORL accuracy of gradient-edges and
averaging-vectors matching

 

85° T T T T T T T T T

 

 

Euclidean
Manhaten

80 Cosine

 

 

 

75

Accuracy
~
oO

om
o

60

55

 

 

 

50
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1

Threshold

Figure 8. ORL accuracy of gradient-angles and
averaging-vector matching

 

 

 

 

 

 

 

 

 

 

100 T T T T T T T T T
Euclidean
95 fF Manhaten
Cosine
90 +
85/5

80 F

Accuracy
N
oOo
T

707

60 fF

 

 

 

 

50 1 1 1 1
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9

Threshold

Figure 10. VIS-TH accuracy of gradient-edges and

averaging-vector matching

Accuracy

Accuracy

Accuracy

 

90 T T T T T T T

  
 
  

 

 

Euclidean
Manhaten
Cosine

 

85 5

 

 

 

 

80 fF 7

60 F 7

55 F J

  

 

 

     

50 !
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
Threshold

Figure 7. ORL accuracy of gradient-edges and
normal matching

 

95 r T T T 1 1 t t t T 5

 

 

Euclidean
Manhaten
Cosine

 

 

 

 

 

85 5

80 5

65 F

60 F

 

 

 

50 | | | |
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1

Threshold

Figure 9. ORL accuracy of gradient-angles and
normal matching

 

  
 
 
 
      

 

 

 

 

 

 

 

95 T T T T T T T mal
Euclidean

90 + Manhaten 7
Cosine

85

80

75

70

65

60

55

 

      

 

0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
Threshold

50

Figure 11. VIS-TH accuracy of gradient-edges and

normal matching

Towards better performance: phase congruency based face recognition (Muthana H. Hamd)
3048 O ISSN: 1693-6930

 

 

o
oa

85

 

 

 

Euclidean Euclidean
Manhaten Manhaten
80 7 Cosine | Cosine

 

 

©
jo)
T

 

 

 

 

 

 

 

 

 

©
ol
T

757 7

Accuracy
©) N
o oO
T T
1 1
Accuracy
N ~N oo
oO o oO
T T T

oD
ol
T

nD
oO
T

55 7 7

Oo
oa
T

   

 

 

 

 

 

 

50

oa
oO

0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
Threshold Threshold

Figure 12. VIS-TH accuracy of gradient-angles and _- Figure 13. VIS-TH accuracy of gradient-angles and
averaging-vector matching normal matching

6. CONCLUSION

This paper implemented a human identification system with low-complexity design consideration.
The phase congruency features: the gradient-edge and its associated angle were utilized individually in constructing
two competitive face recognition systems. The highest recognition accuracy registered by the averaging-vectors
based classification was 96.2% in 10.7 sec., in contrast to the Normal based classification which needs 7 min. to
reach 96.3% of accuracy rate. The experimental results showed that the averaging-vectors classification scored
competitive recognition rates against Normal based classification, likewise, the angel-based feature satisfied
excellent accuracy rates comparing with the edge-based feature. Moreover, the averaging-vectors technique still has
the lowest matching-time advantage over the Normal. Therefore, the novelty aspects of this work succeeded in
providing new contribution in the optimization field such as design complexity and training/matching time.

ACKNOWLEDGEMENTS
The sincere thanks and gratitude to Al Mustansiriyah university.for the support and encourgment,
https://uomustansiriyah.edu.iq/

REFERENCES

[1] P. Kovesi, "Image Features from Phase Congruency," The MIT Press, Quarterly Journal, vol. 1, no. 3, 1999.

[2] M.S. Nixon,and A. S. Aguado, “Feature Extraction and Image Processing for Computer,” Third edition, ISBN: 978-
0-123-96549-3, 2012

[3] S. Gundimada and V. K Asari, "A Novel Neighborhood Defined Feature Selection on Phase Congruency Images for
Recognition of Faces with Extreme Variations," /nternational Journal of Computer and Information Engineering, vol.
1, no. 7, 2007

[4] Kusuma, et al., “Face Recognition Against Varying Lighting Conditions using Oriented Phase Congruency Image
Features,” conferance proceeding, vol. 88, pp 115-22, 2016.

[5] H. Ragb and V. K. Asari, "Histogram of Oriented Phase (HOP): A New Descriptor Based on Phase Congruency",
Proceedings Volume 9869, Mobile Multimedia/Image Processing, Security, and Applications, 2016.

[6] N. D. Rao, et al., "Face Recognition by Phase Congruency Modular Kernel Principal Component Analysis," Int. J.
Elec & Elecn. Eng & Telcomm., vol. 6, no. 2, pp. 30-36, 2017.

[7] S. Alavi and Y. Zhang, "Phase Congruency Parameter Optimization for Enhanced Detection of Image Features for
both Natural and Medical Applications," arXiv: 1705.02102v1, 2017.

[8] K. Wang and P. Xiao, "Image feature detection from phase congruency based on two-dimensional Hilbert transform,"
Pattern Recognition Letters, vol. 32, no. 15, pp. 2015-2024, 2011.

[9] Mashhadi and P. Sheikholharam, “A Novel Feature Vector in the Fused Space of Gabor Magnitude and Gabor Phase
for Face Recognition,” Journal of Computational Intelligence and Electronic Systems, vol. 3, no. 4, pp. 244-255, 2014

[10] Jisi K. J., et al., "Phase Congruency based Multimodal Image Fusion using Adaptive Histogram in NSCT Domain,"
International Journal of Engineering Research & Technology, vol. 3, no 19, 2015.

[11] A. M. Gintautas, et al., “Multiresolution image fusion: Phase congruency for spatial consistency assessment,” JSPRS
Technical Commision VII Symposium - 100 Years ISPRS, Vienna, Austria, pp. 383-388, 2010.

[12] S. Gundimada, et al., “Face recognition in multi-sensor images based on a novel modular feature selection technique,”
Information Fusion, vol. 11, no. 2, pp. 124-132, 2010.

TELKOMNIKA Telecommun Comput El Control, Vol. 18, No. 6, December 2020: 3041 - 3049
TELKOMNIKA Telecommun Comput El Control O 3049

[13] E. Bezalel and U. Efron, “Efficient face recognition method using a combined phase congruency/Gabor wavelet
technique,” Optical Information Systems III, vol. 5908, 2005.

[14] S. Gundimada, "Neighborhood Defined Feature Selection Strategy for Improved Face Recognition in Different Sensor
Modalitie," Electrical & Computer Engineering Theses & Disssertations, Old Dominion University, 2007.

[15] X. Liu and J. Li, J. Pan, "Feature Point Matching Based on DistinctWavelength Phase Congruency and Log-Gabor
Filters in Infrared and Visible Images," Sensors, vol. 19, no. 19, pp. 1-20, 2019.

[16] Y. W. K. Zoetgnande, et al., "Sub-Pixel Matching Method for Low-Resolution Thermal Stereo Images,"
arXiv: 1912.00138v1 [cs.CV], 2019.

[17] P. Kovesi, ”’Edges are not just steps,” Proceedings of the Fifth Asian Conference on Computer Vision, 2002.

[18] P. Kovesi, " Phase Congruency Detects Corners and Edges," Proc. ViIth Digital Image Computing: Techniques and
Applications, 2003.

[19] P. Kovesi, “A dimensionless measure of edge signifcance from phase congruency calculated via wavelets,” First New
Zealand Conference on Image and Vision Computing, pp. 87-94, 1993.

[20] Y. C. See, et al.,"Investigation of face recognition using Gabor filter with random forest as learning framework," JEEE
Region 10 Conference, 2017

[21] P. Kovesi, "MATLAB and Octave Functions for Computer Vision and Image Processing". [Online]. Available:
https://www.peterkovesi.com/matlabfns/

[22] Z. Zhu, et al., "A Phase Congruency and Local Laplacian Energy Based Multi-Modality Medical Image Fusion
Method in NSCT Domain," JEEE Access, vol. 7, pp. 20811-20824, 2019.

[23] I. Glazistov, et al., "Sharpening Image Details Using Local Phase Congruency Analysis," Conference: 2018 IS&T
International Symposium on Electronic Imaging, Burlingame, California USA, 2018.

[24] I. Nafornita, "Feature extraction through cross-phase congruency for facial expression analysis," /nternational Journal
of Pattern Recognition and Artificial Intelligence, vol. 23, no. 03, pp. 617-635, 2009.

[25] M. H. Hamd and R. Rasool, ’Optimized multimodal biometric system based fusion technique for human
identification,” Bulletin of Electrical Engineering and Informatics, vol. 9, no. 6, 2020.

[26] A. Essa and V. K Asari, “Local directional pattern of phase congruency features for illumination invariant face
recognition,” Proceedings of SPIE - The International Society for Optical Engineering, 2014.

[27] H. Mokhtari, et al/., "Performance Comparison of Face Recognition Algorithms based on face image Retrieval,"
Research Journal of Recent Sciences, vol. 2, no. 12, pp. 65-73, 2013.

[28] Y. C. See and N. M. Noor, "Integrating Complete Gabor Filter to The Random Forest Classification Algorithm for
Face Recognition," Journal of Engineering Science and Technology, vol. 14, no. 2, pp. 859-874, 2019.

[29] The Database of Faces, “AT&T Laboratories Cambridge,”. [Online]. Available: — http://cam-
orl.co.uk/facedatabase.html

[30] Z. Fu, et al., "HOMPC: A Local Feature Descriptor Based on the Combination of Magnitude and Phase Congruency
Information for Multi-Sensor Remote Sensing Images," Remote Sensing, vol. 10, no. 8, 2018.

[31] Y. Ye, et al., "A local phase based invariant feature for remote sensing image matching," JSPRS Journal of
Photogrammetry and Remote Sensing, vol. 142, pp. 205-221, 2018.

[32] J. Mei, et al., "Multi-focus Image Fusion Framework Using Total Variation and Phase Congruency," 20/8 IEEE 4th
International Conference on Computer and Communications, 2018.

[33] B. Lakshmi and K. Jayanthi, “Edge Enhancement of Liver CT Images Using Non-Subsampled Shearlet Transform
Based Multislice Fusion,” 20/7 International Conference on Wireless Communications, Signal Processing and
Networking, 2017.

[34] B. Sadou, et al, "No Reference Image Quality Assessment: Feature Fusion Using Relevance Vector Machine,"
The 5th Int. Conference on Electrical Engineering — Boumerdes, Boumerdes, Algeria, October 29-31, 2017.

[35] Z. Huang, et al., "Multi-View Face Database Recognition Using Phase Congruency and SVM Classifier,"
International Conference on Computer and Electrical Engineering, 2008.

Towards better performance: phase congruency based face recognition (Muthana H. Hamd)
