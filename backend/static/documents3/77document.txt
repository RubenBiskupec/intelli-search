A.Qaffas et al. Smart Learning Environments (2020) 7:14 S ma rt Lea ‘aa ng F nvi ronme nts
https://doi.org/10.1186/s40561-020-0117-y

RESEARCH Oy else =e

Towards an optimal personalization ®
strategy in MOOCs

updates
Alaa A.Qaffas', Kaouther Kaabi*, Rustam Shadiev? ® and Fathi Essalmi'*

 

 

* Correspondence: rustamsh@gmail.
com

3 : .
School of Education Science, Lee .
Nanjing Normal University, Nanjing, Several successful initiatives have resulted from the OER movement. One of them is

China Massive Open Online Courses (MOOCs) which is a popular learning mode as it offers

Full list of author information is an affordable and flexible way to learn. However, the evolution of the MOOCs has

avallable at the end of the article some challenges. One of the major problems of MOOCs is the diversity of learners
and the need to personalize the content as well as the way of delivering it. The
origin of this problem is the one size does not fit all. In fact, learners have different
characteristics such as their learning styles, levels of knowledge, and so on. The
selection of the most suitable parameters (set of complementary learners’
characteristics) to be considered in learner's profile is not easy in the presence of a
considerable number of learners in MOOCs. One reason is because a course can be
attended by many learners with varied profiles from different regions of the world.
This plurality of learner profiles makes it important to develop content that can meet
the needs and objectives of each learner in MOOCS. Our solution to solve this
problem consists of personalizing the content of MOOC for each learner. We
propose a new approach which allows to optimize the selection of the
personalization parameters and to apply the appropriate personalization strategy,
based on a classification algorithm. The proposed approach aims to improve the
retention rate and the quality of learning in MOOCs. This approach is validated by
experiments which test its success when applied to many combinations of strategies
and learner profiles.

Abstract

Keywords: Online learning, OER, MOOCs, Personalization strategies, Retention,
Classification algorithm, Learner characteristics, Educational games

 

Introduction
According to the United Nations Educational, Scientific and Cultural Organization
(UNESCO), global investments in Open Educational Resources (OER) are needed for
the purpose of improving access to education. OER term was created at the 2002
UNESCO Forum on the impact of open courseware (UNESCO, 2011). Open education
is anchored both in the history of new education and the experiences of free schools,
such as the Summerhill School in England with the focus of the promoting their use of
OER: we pass resources to practices; one way to say that the provision of these re-
sources was not enough to ensure its use (D’Antoni, 2009).

By definition, educational resources are educational materials, in the form of presen-
tation, video, etc. accessible through the Internet under license. A very famous example
of organization that develops open educational resources is the Khan-academy,

. © The Author(s). 2020 Open Access This article is distributed under the terms of the Creative Commons Attribution 4.0 International
GQ) Springer Open License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium,
— provided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and
indicate if changes were made.
A.Qaffas et al. Smart Learning Environments (2020) 7:14 Page 2 of 18

established in 2006. It is a no-profit organization whose mission is to provide free edu-
cation for all around the world (Khan Academy, 2006).

The demand for training is increasing in higher education. For example, in Africa,
the number of students is increased from 200,000 in 1970 to 5,000,000 in 2014, an in-
crease of 9% per year (Bateman, P, & Moon, 2012) so we can talk here about the
growth of numbers and massiveness of students.

Recently another movement, not far from OER, Massive Open Online Course
(MOOC) is one of the modalities of the e-learning. It is indeed a course distributed
digitally. It was one of the dominant events in the world of higher education in 2012
(Caramel, 2015). In addition, in massive open online courses, open learning has raised
new challenges. For instance, a problem of retention in online courses and retention in
MOOCs should be carefully considered (Koller, Ng, & Chen, 2013). Data analysis and
observations of (Khalil et al., 2014) show the most significant factors that cause a high
attrition rate of MOOCs; lack of time, lack of motivation of learners, lack of interactiv-
ity in MOOCs, lack of knowledge and skills.

Each learner is unique, has individual potential and learn differently including the
learning from his/her peers. The common characteristics of using educational games
are that they allows learners to be active, reflective and engaged. Furthermore, educa-
tional games allow learners to learn individually or in group. They allow also to collect
rich traces about the learners which help in the process of learners modeling and
personalization of courses.

The Massif attribute is common in MOOCs and massive games. In MOOCs, Many
thousands, even tens or hundreds of thousands of learners can register. But beyond the
numbers, it is a new experience that is offered to MOOC participants. Just like the
massive character of some online games (like the famous World of Warcraft) which
allow discovering the players behaviors, such as emulation and building teams. Also,
the relationship between MOOCs and educational games has revolutionized the con-
tacts, relationships between students and the way to recommend information and
knowledge. The MOOCs dimension makes it possible to develop a mutual aid that al-
lows some to learn better by helping their peers, by questioning more freely, or to solve
together an enigma that will allow everyone to progress in their learning.

The use of open educational game may be a solution to enhance the motivation of
learners and the interactivity in MOOCs. Also, educational games help in solving many
problems such as arithmetic, sorting and searching. We can even program computers
to have supernatural abilities in solving skills (Amory et al., 1999). Also we can get
computers to play some board games better than any human being. For most learners,
computer games have become a major part of their lives. Using games for learning
would be a good manner to encourage learners to learn with fun. In this paper, we
focus in the engineering side: creating games that apply in MOOCs and that help to
learn.

The questions we asking here is: How can we optimize the retention rate in MOOCs?
This question directs as to two sub-questions: (1) What is the optimal personalization
strategy in MOOCs. (2) Haw using educational games in MOOCs to enhance the
learners’ retention rate?

This study examines the problem of students who failed their MOOCs; it also pro-
vides strategies that can be implemented to increase the overall retention rate of
A.Qaffas et al. Smart Learning Environments (2020) 7:14 Page 3 of 18

students. Our objective is to automatically select the appropriate personalization strat-
egy in MOOCs. Our approach improves the retention rate by personalizing the learning
according to the appropriate personalization strategy in MOOCS. In order to achieve
our goal, we use the K-means algorithm to classify the learners based on their traces
when they play open (open source) educational games. In fact, educational games have
high interactivity level and allow to collect rich traces about the players. This will allow
selecting the appropriate strategy for personalizing MOOCS to each group of learners.
This is done to minimize the number of students’ groups and decrease the complex
combinations of personalization parameters.

The rest of the paper is organized as follows. Related works section contextualizes
the contribution by analyzing the researches on e-learning personalization. Proposed
solutions for optimizing the personalization strategy section, introduces our approach
for the selection of appropriate personalization strategy in MOOCs. Validation method
section presents the experimentation method, the participants, the procedure and the
instruments. Results and interpretation section describes and discusses the experimen-
tation results. Finally, Discussion, conclusion and future research section presents the

conclusion and gives an overview of future works.

Related works
This section presents works related to e-learning personalization and MOOCs. Besides,

it explains the e-learning personalization.

MOOCs personalization

Personalization in MOOCs in a global way, personalization is to change the behavior
and characteristics of a system according to the user who interacts with it. The
customization proposed to a specific user is based on his/her profile. The profile of a
user contains information that characterizes him/her and it is the instantiation of the
user model. Personalization in MOOCs is a well-established research topic that is be-
coming increasingly important. Several definitions and explanations have been pro-
posed to present the personalization in the educational setting. In (Verpoorten et al.,
2009), personalization is defined as the automatic structuring of learning paths to meet
the needs of the learner. In particular, (Baguley et al., 2014) describes individual learn-
ing as the adaptation of pedagogy, curricula and learning environments to meet the
learning needs and styles of each learner. The personalization of learning environments
aims to change the traditional perspective of teacher-centered teaching into a learner-
centered perspective. Klasnja-Milicevic et al. (2017) defines the aspects that can be per-
sonalized in a learning environment: (1) the content delivered to learners during the
learning process, (2) the presentation and order in which the content is presented and

(3) the method used to evaluate learners.

E-learning and MOOCs personalization approach
Researchers presented several approaches for the e-learning and MOOCs
personalization (Essalmi, Ayed, Jemni, Graf, et al., 2015). Table 1 presents examples of

personalization approaches in e-learning and MOOCs.
A.Qaffas et al. Smart Learning Environments (2020) 7:14

Table 1 Examples of personalization approaches for the E-learning and MOOCs

 

 

Researchers E-learning/MOOCs Description

(Essalmi et al., E-learning personalization: A new approach The approach presents metrics for the

2015) for the personalization of e-learning scenar- analysis of e-learning personalization strat-
ios based on two levels. egies based on their feasibility and success

when applied to a large number of learning
objects and learners’ characteristics.

(Gilbert Paquette MOOCs personalization: Competency-based Regarding the criteria to be taken into

et al, 2015) personalization for massive online learning = account in the recommendations of
contents, various constraints were defined in
the personalization of the MOOCs. Among
these, we cite: resources that respect the
level of knowledge of the learner.

(Essalmi, Ayed, E-learning personalization: Generalized The proposed solution is a step to federate

Jemni, Kinshuk, & metrics for the analysis of e-learning the research efforts on the E-learning

Graf, 2010) personalization strategies personalization by integrating and combin-
ing the personalization parameters.

(Carlos Alario- MOOCs personalization: Adaptive planner for Designing an application designed to guide

Hoyos et al., facilitating the management of tasks in learners who have a lack of skills and

2014) MOOCs learning habits to read the most of the

content of MOOCs. The work presents the
main component of the application which is
the adaptive planner.

(Naveen Bansal. © MOOCs personalization: Adaptive Regarding the criteria to be taken into

2013) recommendation system for MOOC account in the recommendations of
contents, various constraints were defined in
the personalization of the MOOCs. Among
these, we cite: the resources that respect the
preferences of the learner

 

(Gutiérrez-Rojas = = MOOCs personalization: Towards an It helps the user to find the most relevant

et al., 2015) outcome-based discovery and filtering of elements for him from a certain sets of
MOOCs using MOOC rank information in the MOOCs

(Nishikant MOOCs personalization: A case study on The type of customization implemented in

Sonwalkar, 2013) pedagogy framework and scalable cloud MOOC adaptation
architecture

(Ayse Saliha MOOCs personalization: A Critical Literature = The importance of providing social platforms
Sunar et al. 2015) Review for learners to reinforce their interactions
with course content.

 

 

There are others approaches which provide learners with recommendations in
MOOCs. This is the case for example of the solution presented by (Gutiérrez-Rojas,
2015) to help learners achieving their learning objectives of the MOOCs. The learner
model contains the MOOCs already followed by the learner. This information is re-
trieved by asking the learner an explicit/her. This is done based on the assessments that
have been assigned in the current MOOC and on a similarity calculation with the
others MOOCs. In (Iftene, 2016), a recommendation system is proposed in the form of
a conversational agent that recommends MOOCs.

Some personalization strategies are being identified to increase retention rates in
MOOCs and online learning. These research works aim to improve the quality of open
education. In this paper, we examine the problem of learners who failed their MOOCs;
we also provide an optimal strategy that can be implemented to increase the overall re-

tention rate of learners.

E-learning personalization strategy
The e-learning personalization strategy involves students in deciding their own learning
process, as we'll discuss below. This teaches the students vital skills that will serve them

Page 4 of 18
A.Qaffas et al. Smart Learning Environments (2020) 7:14 Page 5 of 18

throughout their lives. For example, Sharing in goal-setting helps students develop mo-
tivation and reliability. Also, engaging in self-assessment helps students develop self-
reflective abilities. In addition, the personalized learning strategies are ways that
learners use to acquire, integrate and remember the knowledge they are taught (Essalmi
et al., 2010).

There is an important number of personalization strategies (Essalmi et al., 2010). For
example, if we have N concepts included in a course and if we assume that each
personalization parameter includes K different characteristics of the learner (Essalmi,
Ayed, & Jemni, 2007). In this case, the teacher responsible for the course must prepare
N * K learning scenarios if he/she consider only one personalization parameter. Taking
the example of personalization parameter learner’s Felder—Silverman learning style
which includes the learners’ characteristics: {Sensing / Intuiting, Visual / Verbal, Active
/ Reflective and Sequential / Global} (Felder & Silverman, 1989). For N=19 and K =4;
19*4 = 76 different learning scenarios.

The problem of selecting the personalization parameters becomes more complex with
the increase of the number of students in MOOCs. In the same context, (Essalmi et al.,
2015) we need a multi-parameters personalization approach to combine several
personalization parameters including the pedagogical approach. This multi-parameters
combination combined with the massive number of learners represents an important
issue in MOOCs.

Parameters of personalization
Our purpose is to personalize the MOOCs for motivating the students and enhancing
their attention. There is an important number of personalization systems using differ-
ent personalization parameters (Chorfi & Jemni, 2004; Essalmi et al., 2007, 2010, 2015).
Each of them aims generating a personalized course, according to a set of learners’
characteristics.

Table 2 presents a set of personalization parameters as well as their potential values
reported in the literature and used by teachers for personalizing their courses.

Proposed solutions for optimizing the personalization strategy
This section presents our architecture to optimize the selection of personalization strat-
egy in MOOCs. It presents also a clustering algorithm used to apply our approach.

MOOCs personalization system
In this sub-section, we present our architecture for the MOOCs personalization strat-
egy. The presented architecture focuses on the analysis of the personalization strategy.
Figure 1 presents a general of the personalization strategy system; it contains an easy
and uncomplicated user interface used to better communicate with the teacher. The
system requests information from the Database component when it’s needed. The
Database stores all the information about the traces which are used to evolve the user
profile. Then, the classification algorithm is applied and the appropriate personalization
strategy is generated.
The principle is simple in the Fig. 1: learners will play open (free of use and could be
modified as open software) educational games, during which all their actions will be
A.Qaffas et al. Smart Learning Environments

(2020) 7:14 Page 6 of 18

Table 2 Examples of values for the personalization parameters (Essalmi et al., 2010)

 

Personalization
parameter

Set of values

 

Learner's level of
knowledge

Learner personality
Kolb learning cycle

Honey—Mumford
learning style

Felder—Silverman
learning style

La Garanderie learning
style

Motivation level
Navigation Preference

Cognitive traits

Pedagogical approach

{beginner, intermediate, advanced} (Chorfi & Jemni, 2004)

{Introvert, Extrovert, sensing, intuitive} (Celli et al. 2016)
{Converger, Diverger, Assimilator, Accommodator} (Milosevic et al., 2006)

{activist, reflector, theorist, pragmatist} (Honey & Mumford, 1986)

{sensing, intuiting} {visual, verbal}{active, reflective} {sequential, global} (Felder &
Silverman, 1989)

{competitive, cooperative, access on the avoidance, participative, dependant,
independent} (La Garanderie, 1993)

{low, moderate, high} (Milosevic et al., 2006)
{breadth-first, depth-first} (Stash, Cristea, & De Bra, 2006)

{low working memory capacity, high working memory capacity} {low inductive
reasoning ability, high inductive reasoning ability} {low information processing speed,
high information processing speed} {Low associative learning skills, high associative
learning skills.} (Kinshuk & Graf, 2007)

{objectivist, competencies based, collaborative} (Essalmi et al., 2007)

 

traced. Favor to the traces of learners’ interactions with the platform, the learners’ profiles

can be generated. Our application based on k-Means algorithm classifies the learners and

select the appropriate personalization strategy. It is possible to automatically determine

for each learner new activities and new paths, according to the information contained in

his profile. Then, the cycle will be able to begin again, since new traces will be generated

by the learners when they play new educational games. For each learner, the system gen-

erates activities that correspond to his/her characteristics (learner profile).

 

: Qo
=

Learners

 
 
 
  
   

Creation listsjof activities

Fig. 1 Proposed architecture of the MOOCs personalization strategy

Modeling

Profile

PaCman Game 1,2

MOOC PLATFORM

e Show the best
personalization
strategy.
Personalize activities
for the learner.

  
 

  
   

  

Personalize

     

Analyze learner profile.
Optimize a personalization
pedagogic strategy.

   
    
 
 
   
 

Classification of parameters:

  
 

K-means algorithm

 
 

 
A.Qaffas et al. Smart Learning Environments (2020) 7:14 Page 7 of 18

The objective of our approach is to automatically optimize the personalization strategy
for each learner. One of the challenges that MOOCs will have to meet is providing per-
sonalized paths for learners, in order to better attend the course. In order to respond to
this major issue of personalization in the field of MOOCs, we have proposed a complete
model of MOOCs personalization. Our approach is based on the follow-up of the
learners, and analyzes of their traces in order to build new learning path for each student.

In the first step, the learners play the educational game. The players must be con-
nected with the application by different logins and passwords. Thereafter, they play a
game presented in the system such as Pacman mini games versions (action and puzzle).
Then, the players can respond to QCM presented in the game. The traces such as the
choices of the player for any games and his/her path were collected and recorded in a
MySQL database already connected to these mini-games.

The second step represents the traces classification. We apply the unsupervised clas-
sification K-Means algorithm, which classifies the players in groups based on their simi-
lar traces. The classification results will be visualized as a graph. Players with the
common characteristics are assigned to the same group and players with different char-

acteristics are placed in different groups.

The process of optimizing the personalization strategy in MOOCs is presented in the Fig. 2.

 
   
 

Play games and answer to the
questions

 
 
   
 

Extract different characteristics
of learner parameters

    

Stage 1 : Regroupement
of

Collect traces

  
 

Learners

  
 

Of learners

 

   

Applicate the k-means algorithm
classification

 
  
 

i

Get learners groups according to

      

their parameters

Apply the classification
algorithm on groups
Identification of groups
Show the result by teacher

Fig. 2 Process of personalization strategy optimization in MOOCs

  
   

 
   

Stage 2 : Identification of

Groups

 

 

 
A.Qaffas et al. Smart Learning Environments (2020) 7:14 Page 8 of 18

System of trace extraction

In the context of the main question addressed by this paper (How can we optimize the re-
tention rate in MOOCs?), our first sub-question is: What is the optimal personalization
strategy in MOOCs. To answer to this sub-question, our contribution consists in proposing
an approach based on the analysis of the learner’s trace for recommending courses that
takes into consideration both the learner’s characters and his/her preferences. Trace-based
systems have been used as the main brick in a recommendation model (Develay, 1996),
which makes it possible to use all the information collected on a learner to show him/her
the activities to follow in order to succeed in the process of learning. A good recommenda-

tion also requires a good definition of the profile of the learner (Salomon, 1992).

K-means algorithm and its application on traces of open educational games

In unsupervised classification algorithms, unsorted information can be grouped accord-
ing to similarities and differences even if no categories are provided. Partitioning data is
an important task in data analysis; it divides a set of data into several subsets, these
subsets are named clusters (Ng, Jordan, & Weiss, 2002). In the clustering problem (Lar-
ose, 2005) a set of unmarked data is given and we want the algorithm to automatically
aggregate it into coherent or clustered subsets consistent for us.

K-means defined by McQueen is one of the simplest automatic data classification al-
gorithms. K-means is the most used clustering algorithm (MacQueen, 1967). The main
idea is to choose randomly a set of centers fixed a priori and to iteratively seek the opti-
mal partition. Each individual is assigned to the nearest center. After having assigned
all the data, the average of each group is calculated, and constitutes the new representa-
tives of the groups. These groups are ideally characterized by a strong internal similar-
ity and a strong dissimilarity between the members of different groups (Kogan, 2007).
When a stable state is reached and no group of data changes, the algorithm is stopped.
The k-means algorithm is popular due to its simplicity and its ability to process large
datasets (Kogan, 2007). The pseudo code of the K-means algorithm applied for stu-
dents’ classification based on their traces in open educational games is as follows:

Input: Set of N data, denoted by x = learners {1...N},
characters = {1, 2, 3..20}, Number of groups desired.
Output: A partition of K {Cl groups, C2 groups ..and Ck
groups};

Begin

Randomly generate K centers as Ck;

Repeat
2) Assignment: generate a new partition by

assigning each object to the group whose center
is closest;

x; EC, if Vj Xi —LUk| = min|x; —L]

With wk the centers (mean vector of centroid) of
class K;
3) Representation: Calculate the centers
associated with the new partition; wel/N sum xi

Until convergence of the algorithm to a= stable
partition (no change) ;
End.
A.Qaffas et al. Smart Learning Environments (2020) 7:14 Page 9 of 18

In addition, (Ruwet & Haesbroeck, 2012) are determined the classification efficiency
of the k-means rule classification efficiencies of the logistic discriminations. In the fol-
lowing graph we present a simple example of k-means (red points are centroids, and

blue points are students):
We note that to receive the k means algorithm is applicable in our classification; we

adapted this algorithm when implementation to some modification. The main idea in
Fig. 3 is to choose at k the number of characteristics a set of fixed centers a priori and
to search iteratively for the optimal partition. For example, each student is assigned to
the nearest center. After assigning all the data that the average of each group is calcu-
lated, it constitutes the new representatives of the groups. The algorithm is stopped
when the algorithm is stable and no group of data changes.

The implementation is divided in two parts: in the first part, two open educational
games have been implemented. The first game is an educational version of the Pacman
game in the form of puzzle. It allows the learners to benefit from the drag and drop
technology, in an amusing way. In fact, it allows the learners to construct a program
step by step. The second game is a learning version of Pacman game (Khenissi et al.,
2012). It is considered as an action game. It keeps the learners moving and involved in
order to conduct Pacman correctly. The learners’ choices for any path in their two
games are automatically saved in a Database. Thereafter, the learners will answer to the
Felder-Silverm Learning Style Models (FSLSM) questionnaire. It contains questions
corresponding to each of the four dimensions of the FSLSM. The aim of the question-
naire is to determine the learning style preferred by each learner.

The second part is the implementation of the k-means algorithm for the student clas-
sification based on their traces collected during the use of the educational games.

Figure 4 presents the main interface of menu web application which is available in
http://www.applicatione-learning.ovh/en, where many alternatives are displayed accord-
ing to the learners’ preferences, such as play games, QCM. The display of the learners

group could be used only by teachers.

PT
PUTT
TINT TTT

ye]
|
it
iz
iva
a a
TN
| 4
a

 

 

Fig. 3 Example of results k-means algorithm
A.Qaffas et al. Smart Learning Environments (2020) 7:14 Page 10 of 18

 

  
 
 

Common elements

c Form elements
i 1
Pacman Simple Game Pacman Action Game

   

 

Fig. 4 Menu of the Web application for playing open educational games

  

The first part presents the game scenario, the goal of this game is to teach the SQL

database language in the form of questions that allows the player to choose only one
answer for each question. When Pacman eats a gold kiwi, a question is visualized. The
player answers the question and the correct answer is displayed.

In the second part, when the player ends the game, he/she will answer to the ques-
tion his/her traces are saved in the database.

When learner is playing an open educational game, his/her traces are followed. Cur-
rently, we have two open educational games.

— The first one is an educational version of PacMan action game which is presented
in the Fig. 5.

— The second is an educational version of PacMan puzzle game which is presented in
the Fig. 6.

This action game PacMan 1 is an advanced Pacman game composed by three levels.

Then, this simple game PacMan 2 is the classic pacman game in which we add some
learning scenarios.

As long as game integration in MOOCs is further supported by researchers (Huangx-

ing Zeng, 2016), they realize that games can inspire learners by increasing productivity,

 

 

Fig. 5 Educational version of PacMan action game
A.Qaffas et al. Smart Learning Environments (2020) 7:14 Page 11 of 18

 

I

—
L

Fig. 6 Educational version of PacMan puzzle game

 

 

and conduct research on creativity. With a clever integration of the study of the
MOOC game, it will undoubtedly bring significant innovation and development to the
teaching of educational computerization accordingly.

In addition, the online educational game is developed as an educational website using
the game elements in MOOCs to make it more interactive for users. Therefore, the im-
plementation of the game elements in MOOCs increases the user motivation, improves
engagement during the learning process, and allows users to use the MOOCs for long

time.

Validation method
In order to verify the validity of the proposed solution we conduct the following

experimentation.

Participants and procedure

Fifty-seven learners from the Raccada secondary School in Kairouan in the field of
computer science has participated in the experiment. They are from different educa-
tional levels (2nd-year secondary and 3nd-year secondary of computer branch); learners
are the ages between 15 and 18 years. They are grouped randomly into the control
group and the experimental group; 27 learners (17 girls, 1Oboys) in the control group
and 30 learners (19 girls, 11 boys) in the experimental group. The learners of the two
groups were requested to answer the pre-test given by the same teacher using paper
and pencil. The given pre-test was composed of questions that allow a question that al-
lows testing the learner’s knowledge. Then, the control group learned through the trad-
itional method (reading) and the experimental group learned through the learning
games. Then, the post-test which focus on evaluating the student’s level of knowledge
is used.

Here it is important to mention that during the experimentation faced a major prob-
lem of material; classroom computers didn’t work properly and there were no internet
connection to play the game online. Under these circumstances, I found myself obliged
to give my own laptop to students to use one by one, which was a waste of precious
time and energy. In addition, the experiments are conducted in a high school and in
A.Qaffas et al. Smart Learning Environments (2020) 7:14 Page 12 of 18

the field of computer science and since most of the existing MOOCs are university-
level courses, so the experimentation is adapted to the secondary level for that we adapt
this experimentation, by introducing the MOOC and making a quick explanation of it
for the learners,

Instruments

In order to verify the validity of the hypothesis: the classification of learners minimizes
the complexity of personalization parameters problem, we use the following
instruments:

We have used pre and post-tests which focus on verifying student’s level of know-
ledge. After answering the pre-test, the 30 students of experiment group played the
educational games. The 27 control group students learned by using text containing the
same information presented in the games.

The results of the post-test will make the research team know whether or not the
MOOCs, as well as the process learning, is useful. Our research team has the following
two hypotheses:

e H1: The proposed process of personalization learning with MOOC makes students
learn better.

e H2: The traditional learning makes students learn better.

To identify the appropriate personalization parameter, learners had to answer the
Index of Learning Styles (ILS) which is a questionnaire containing 44 questions, 11
questions corresponding to each of the four dimensions of the Felder-Silverm learning
style models (FSLSM). The Index of Learning Styles (ILS) is a questionnaire which is
validated and presented in the literature (Felder & Silverman, 1989).

Also, the learners had to answer the questionnaire of the Technology Acceptance
Model (TAM) which includes 20 questions evaluating the learner’s satisfaction. The re-
alized TAM has 20 items (ranging from 5 for “strongly agree” to 1 for “strongly dis-
agree”). In fact, to obtain a valid and reliable questionnaire, it should have at least three
items for each variable. Specifically, students of the experimental group were requested
to answer to the TAM questionnaire. It includes instances of the 5 items for Usefulness
(U) and the 5 items for Ease of Use (EOU). It includes also instances of the 5 items for
attitude toward using the system (ATT) and the 5 items for behavioral intention to use
the system (INT) presented in (Davis, 1989).

This study used also a test of learners’ preferences. The preference’ values were
divided into three groups, namely prefer, neutral, and do not prefer to use the

game.

The learners of the two groups were requested to answer the pre and post-tests given
by the same teacher using paper and pencil. Additionally, both groups had the same
amount of time to play. In the classroom pre-test and post-test, learners had to re-
sponse to the post-test in order to evaluate the effectiveness of each learning method.
We have integrated an implementation of the K-means algorithm in our system; it uses
as input the number of students with their traces. The output is groups of students

with maximum intra-class similarity.
A.Qaffas et al. Smart Learning Environments (2020) 7:14 Page 13 of 18

Results and interpretation
This section presents the experiment results.

Pre-test and post test results

In this sub-section, the comparison of students’ results in the pre-test and the post-test
was used to draw conclusions about the educational games effectiveness compared to
the simple traditional learning method. We calculate the averages of students’ scores
on the pre-test and the post-test. These averages show that, in average, students of the
experimental and control groups have similar levels of knowledge before starting the
experimentation (12.91 for the experimental group and 11.90 for the control group).
However, after the experimentation, the level of the students in the experimental group
is greater than the level of the students in the control group (10.86 for the experimental
group and 10.22 for the control group). Table 3 presents the average of learners score
in pre-test and post-test:

From Table 3 we can conduct two observations: The average score of the experiment
group who has used the educational games is superior than the average score of the
control group who has learned with the classical method, although both groups have
approximately the same average in the pre-test. We note also that the post-test was
more difficult than the pre-test. This explains the fact that the average scores in the
post-test is not good.

In Table 4 above, results for the two groups are presented. As we can observe, there
is a difference between the learning outcomes presented by the two groups. However,
is this difference significant? To answer this question, ANOVA test (see Table 4) is
used.

Two hypotheses are discussed. HO: there is no significant difference between the con-
trol and the experimental groups. H1: there is a significant difference between the two
groups. After running the ANOVA test, we obtained the results presented in Table 4.

The alpha value is 0, 05. Furthermore, p-value = 0.00000000231 < alpha = 0.05. So, HO
is rejected and we conclude that there is a significant difference between the two
groups.

Also, we used the t-tests to analyze data by comparing the two groups. We have two
hypotheses.

HO: There is no significant difference between the learning outcomes in the two
groups (Control and experimental groups).
H1: There is a significant difference between the learning outcomes in the control and

experimental groups (Table 5).

We observe that the experiment group has a significant progression of gained know-
ledge compared to the control group when the learners of the two groups had all an

Table 3 Average of learners score

Experimental Group Control Group
Pre-Test 12,91 11,90
Post-Test 10,86 10,22

 

 
A.Qaffas et al. Smart Learning Environments

Table 4 ANOVA test outputs: single factor

(2020) 7:14

 

Summary
Groups Count Sum Average Variance
Experiment group 30 5,95 0457692319 0022735882
Control group 2/7 0,99 0,066 0,007611429
ANOVA
Source of Variation SS Df Ms F P-value F crit
Between Groups 1378134934 2 0,689067467 = 35,11342037 ~—-0,00000000231 3,24481361
Within groups 0,745713846 54 0,0196240
49

Total 2,12384878 56

 

approximate average in the pre-test. So, the experimentation shows that the use of
games in MOOCs is more efficient and useful than traditional methods of learning.

Technology acceptance results

To calculate the level of acceptance of the educational games, the experimental group
answered to the technology acceptance model (TAM) questionnaires. We have adapted
the Technology Acceptance Model (TAM) (Masrom, 2007); since it is considered as
the most used model for the validation of the information systems. Table 7 presents
the averages and medians of the learner satisfaction.

Furthermore, to prove the reliability of the questionnaire, we use Cronbach’s alpha
coefficient. It is a statistic used to measure the internal reliability of the asked ques-
tions. Its value is between 0 and 1 and it is considered as acceptable from 0.7.

Two participants from the experiment group did not reply to the totality of the given
questionnaire, hence, the corresponding responses were eliminated. The final valid
sample therefore includes 55 students.

Table 6 displays the results of reliability analysis. All constructs have acceptable mea-
sures of reliability since their values exceed 0.7.

A reliable TAM questionnaire with four constructs and 20 items is determined to
measure students’ attitude toward the developed educational game.

Table 7 presents the averages and medians of the learner satisfaction.

Table 5 The results of t-test comparing experiment group and control group t-Test: two-sample
assuming equal variances

 

Experiment group Control group

 

Mean 0,457,692,319 0,066
Variance 0,022735882 0,007611429
Observations 30 27
Pooled Variance 0,014591953

Hypothesized Mean 0

Df 26

T Stat 8,557,100,381

P(T < =t) one-tail 0,00000000244

T critical one-tail 1,705,61 7,901

P(T < =t) two-tail 0,00000000489

T critical two-tail 2,055,529,418

 

Page 14 of 18
A.Qaffas et al. Smart Learning Environments (2020) 7:14 Page 15 of 18

Table 6 Reliability analysis results of the proposed TAM

 

 

Construct Item number Overall Cronbach's alpha
Usefulness (U) 5 0.728
Ease of Use (EOU). 5 0.719
Attitude toward using the system (ATT) 5 0.705
Intention to use the system (INT) 5 0.720

 

Table 7 shows that the average and median values for the TAM questionnaires are
near to 5 which mean that the learners were satisfied with using the educational games.

Classification of students and interpretation
Figure 7 presents the results of applying the K-means algorithm for classifying students
in MOOCs.

In the Fig. 7, the dots that have the same colors present the students who have similar
characters and they are in the same group. The K-Means algorithm allows to aggregate
the data into coherent groups of learners. Groups are ideally characterized by strong in-
ternal similarity and strong dissimilarity between members of different groups of learners.

The results displayed at the Table 3 showed that the learners benefited from the open
educational games which represents a fun way for learning and a learning which has a
positive impact on learning outcome. Table 7 shows that learners are satisfied with the
open educational games. Furthermore, the Fig. 7 shows that the k-means algorithm
could be used to classify students in MOOCs.

Discussion, conclusion and future research

This section discusses the obtained results and their similarities with other research
work regarding the preferences on using the web application including open educa-
tional games. The uses of personalization parameters and k-means algorithm are also
discussed.

The obtained results showed that learners have positive attitudes towards using the
educational versions of PacMan-game. These results are similar to the results of recent
studies (Khenissi et al., 2012, 2016); in wish the personalization of learning games ac-
cording to learning styles is discussed.

The k-means algorithm is implemented to classify students. This allows
personalization parameters to be used for personalizing the open educational games.

When we need to personalize MOOCs, the question is: which personalizing parame-
ters we have to use?

Assume that we have to consider all the personalization parameters for personalizing
open content to massive learners.

This proposition aims to apply a large number of personalization parameters for

personalization MOOCs. Consequently, the combination of personalization parameters

Table 7 Averages and medians of learner's satisfaction

U EOU ATT INT
Average 48 45 4.34 4.32
Median 4 4 4 4

 

 
A.Qaffas et al. Smart Learning Environments (2020) 7:14 Page 16 of 18

 

 

 

K-means classification
0.30 @ Group 0
™ @ Group 1
®@ Group 2
0.45 @ Group 3
@ Group 4
@ Group 5
e
0.00 Group 6
@ Group 7
@ Centroids
¢ Initial means
0 45
-0,90
-1,8814673 -1,2543115 -0.6271558 0,0000000 06271558
Fig. 7 A classification of learner in MOOCs

 

will be more complex. The generated learning scenarios have to fit all the characteris-
tics of the learners. This problem is discussed in (Essalmi et al., 2010) in the E-learning
context. We have integrated two components to minimize the complexity of this prob-
lem. The first one is the open educational games which allow to model the learners im-
plicitly. This will allow to avoid the huge task of learners when they answer to many
explicit questionnaires about their level of knowledge, motivation, learning styles and
so on. The second component is the classification algorithm (k-mean in our case)
which allows classifying learners and then help teachers to select the personalization
parameters and combine them flexibly to define different personalization strategies.

The proposed open educational games combined with the classification algorithm
could constitute a solution to improve the learners’ retention in MOOCs. For instance,
the open educational games help learners to enjoy at the time of learning. Also, the
classification algorithm allows personalizing learning according to the learners’ profiles.

This study aims to improve personalization in MOOCs. It is proposed for individual-
izing the interactions with students and for improving their retention rate in MOOCs.
Optimized personalization strategies enhance the learning process and help the teacher
to select the appropriate combination of personalization parameters in MOOCs.

The open educational games (educational version of PacMan action game and educa-
tional version of PacMan puzzle game) bring a great learning experience and solicit differ-
ent skills and abilities. They provide the learner with basic learning needs by providing
pleasure, motivation and creativity. Also, these open educational games allow collecting
learners’ traces and then classifying them. The results of the experimentation showed that
the proposed system could help learners, improves their skills and quality of learning.

Future directions of this research could focus on the generalization of our e-learning
system to support different MOOCs and satisfy different needs of teachers. Further-
more, it is possible to test others classification algorithms in MOOCs.

This study still has some limitations, where the evaluation of the MOOCs platform has
not been well completed. The prototype is developed as an educational website using
gamification elements to make this site more interactive for users. Thus, the level of suc-
cess and effectiveness of the proposed game elements has not been proven. Therefore, in
the next study, the prototype of the MOOCs platform will be tested both by direct use
and by collecting student feedbacks to analyze the performance of the platform.
A.Qaffas et al. Smart Learning Environments (2020) 7:14 Page 17 of 18

Acknowledgements
Not available.

Authors’ contributions

AAQ and KK conceived and designed the study, collected data and analyzed it, and drafted the manuscript. RS
interpreted data and reviewed and edited the manuscript. FE participated in the study design, supervised the research
team, and reviewed and edited the manuscript. All authors read and approved the final manuscript.

Funding
Not available.

Availability of data and materials
The datasets generated and analyzed during the current study are not publicly available but will be provided by the
corresponding author on reasonable request.

Competing interests
The authors declare that they have no competing interests.

Author details

‘Management Information Systems Department, College of Business, University of Jeddah, Jeddah, Saudi Arabia.
*Higher Institute of Computer Science and Management of Kairouan (ISIGK), University of Kairouan, Kairouan, Tunisia.
°School of Education Science, Nanjing Normal University, Nanjing, China. “The Research Laboratory of Technologies of
Information and Communication & Electrical Engineering (LaTICE), Higher School of Sciences and Technologies of
Tunis (ESSTT), University of Tunis, Tunis, Tunisia.

Received: 16 October 2019 Accepted: 5 February 2020
Published online: 28 April 2020

References

Alan A., Kevin N., Jacky V., Claudia A. (1999). The use of computer games as an educational tool: identification of appropriate
game types and game elements, British Educational Communications and Technology Agency, Pages 311-321.

Baguley, D.M., Danaher, P.A., Davies, A., Jones, J.K., Matthews, KJ., Midgley, W., Arden, C.H., George-Walker, L.D. (2014).
Educational learning and development: Building and enhancing capacity. Springer.

Bateman, P., Lane, A., & Moon, B. (2012). An emerging typology for analyzing OER initiatives. In Proceedings of Cambridge
2012: Innovation and impact - Openly collaborating to enhance education, OCW Consortium and SCORE, Cambridge, UK,
April 16-18 2012 (pp. 19-28). Milton Keynes: The Open University.

Caramel, L. (2015). African universities see their future in MOOC.

Carlos Alario-Hoyos, Mar Pérez-Sanagustin, Dave Cormier, Carlos and Delgado-Kloos. Proposal for a Conceptual Framework
for Educators to Describe and Design MOOCs, Journal of Universal Computer Science, (2014).

Celli, F., Ghosh, A,, Alam, F., & Riccardi, G. (2016). In the mood for sharing contents: Emotions, personality and interaction
styles in the diffusion of news. Information Processing & Management, 52(1), 93-98.

Chorfi, H., & Jemni, M. (2004). Perso: Towards an adaptive e-learning system. Journal of Interactive Learning Research, 15(4),
433.

D’Antoni, S. (2009). Open educational resources: Reviewing initiatives and issues. Open Learning: The Journal of Open,

Distance and e-Learning Volume 24, 2009 - Issue 1: Open Educational Resources, pages 3-10.

Davis, F. D. (1989). Perceived usefulness, perceived ease of use, and user acceptance of information technology. MIS Quarterly,

319-340.

Develay, La transfert de connaissances en formation initiale et en formation continue: actes du colloque organisé a

'Université Lumiére Lyon 2, 29 septembre-2, (1996).

Essalmi, F., Ayed, L. J. B.,, & Jemni, M. (2007). A multi-parameters personalization approach of learning scenarios. In The 7th IEEE

international conference on advanced learning technologies, Niigata, Japan (pp. 90-91).

Essalmi, F., Ayed, L. J. B., Jemni, M., Kinshuk, & Graf, S. (2010). A fully personalization strategy of E-learning scenarios.

Computers in Human Behavior, 26(4), 581-591.

Essalmi, F., Ayed, L. J. B.,, Jemni, M., Graf, S., et al. (2015). Generalized metrics for the analysis of e-learning personalization

strategies. Computers in Human Behavior, 48, 310-322.

Felder, R. M., & Silverman, L. K. (1989). Learning and teaching styles in engineering education. Engineering Education, 78, 674-
681.

Gilbert Paquette, MarifoDelia, Rogozan Michel and Léonard. Competency-based personalization for massive online learning,
Smart Learning Environments, (2015).

Gutiérrez-Rojas. (2015). Towards an outcome-based discovery and filtering of MOOCs using MOOT rank. In Proceedings of the
second MOOC European stakeholders summit (pp. 50-57).

G Le Bouedec, A La Garanderie, Les Etudes doctorales en sciences de |'éducation: contribution 4 un accompagnement
personnalisé des mémoires et des théses,164 p, (1993).

Honey & Mumford; The manual of learning styles”, Maidenhead, Berkshire. P. Honey, Ardingly House, (1986).

Huang, Z. H., & Qi, L. (2017). Formulating an n-person noncooperative game as a tensor complementarity problem.
Computational Optimization and Applications, 66(3), 557-576.

Iftene, A. (2016). MOOC Buddy: a chatbot for personalized learning with MOOCs. In RoCHI-International conference on human-
computer interaction. 1.91.

Khalil, H., & Ebner, M. (2014). MOOCs completion rates and possible methods to improve retention. In Proceedings of world
conference on educational multimedia, hypermedia and telecommunications 2014 (pp. 1236-1244).

Khan Academy, (Khan Academy, 2006) available at URL http://www.khan-academy.fr/.

 

 

 
A.Qaffas et al. Smart Learning Environments (2020) 7:14 Page 18 of 18

Khenissi, M. A., Essalmi, F., & Jemni, M. (2012). Toward the personalization of learning games according to learning styles.

Khenissi, M. A., Essalmi, F., Jemni, M., Kinshuk, Graf, S., & Chen, N.-S. (2016). Relationship between learning styles and genres of
games. Computers in Human Behavior, 101, 1-4.

Kinshuk & Graf. Considering cognitive traits and learning styles to open web based learning to a larger student community”,
in Proceedings of Bibliography 52 the International Conference on Information and Communication Technology and
Accessibility (ICTA 2007), Hammamet, Tunisia, pp. 21-26, (2007).

Klasnja-Milicevicn, A,, Vesin, B., lvanovic, M., Budimac, Z. and Jain, L.C. (2017). Personalization and adaptation in e-learning
systems. In E-learning systems (pp. 21-25). Intelligent Systems Reference Library book series (ISRL, volume 112)..

Kogan, J. (2007). Introduction to clustering large and high-dimensional data. Cambridge: Cambridge University Press.

Koller, D, Ng, A, & Chen, Z. (2013). Retention and intention in massive open online courses: In depth, student retention E-learning
massive open online course (MOOC).

Larose, D. T. (2005). Discovering knowledge in data: An introduction to data mining. Hoboken: Wiley.

MacQueen, J. (1967). Some methods for classification and analysis of multivariate observations. In Proceedings of 5th Berkeley
symposium on mathematics, statistics and probability (Vol. 1, pp. 281-298).

Masrom, M. (2007). Technology acceptance model and E-learning. In 12th international conference on education,Cruise Tourism
& Innovation: Improving passengers’ experiences and safety, Sultan Hassanal Bolkiah Institute of Education, Universiti Brunei
Darussal.

Milosevic, D., Brkovic, M., & Bjekic, D. (2006). Designing lesson content in adaptive learning environments. International
Journal of Emerging Technologies in Learning (JET), 1(2).

Naveen Bansal; ADAPTIVE RECOMMENDATION SYSTEM FOR MOOC, Department of Computer Science and Engineering
Indian Institute of Technology, Bombay, (2013).

Nishikant Sonwalkar. The first adaptive MOOC: A case study on pedagogy framework and scalable cloud Architecture—Part |,
Founder and Managing Director, Synaptic Global Learning, LLC and Adjunct Professor of Physics, University of
Massachusetts, Boston, Massachusetts, (2013).

Ng, Y., Jordan, M. |, & Weiss, Y. (2002). On spectral clustering: Analysis and an algorithm. In Neural information processing
systems (Vol. 14).

Ruwet & Haesbroeck, Classification performance resulting from a 2-means, Journal of Statistical Planning and Inference, -
Elsevier, (2012).

Salomon, Le destin technologique, editions Balland, 331 pages, (1992).

Stash, N., Cristea, A. |, & De Bra, P. (2006). Adaptation to learning styles in e-learning: Approach evaluation.

UNESCO. Guidelines for Open Educational Resources (OER) in higher education, IEEE Transactions on Education, UNESCO
Publication, (2011).

Verpoorten, D., et al. (2009). Personalisation of learning invirtual learning environments. In Learning in the synergy of multiple
disciplines (pp. 52-66).

 

 

Publisher’s Note

Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.

 

Submit your manuscript to a SpringerOpen”®
journal and benefit from:

> Convenient online submission

> Rigorous peer review

> Open access: articles freely available online
> High visibility within the field

> Retaining the copyright to your article

 

Submit your next manuscript at > springeropen.com

 

 
