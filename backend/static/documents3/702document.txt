Underwood et al. Applied Network Science
https://doi.org/10.1007/s41 109-020-00293-z

(2020) 5:62

Applied Network Science

RESEARCH Open Access

Motif-based spectral clustering of
weighted directed networks

Check for
updates

 

William G. Underwood!" ©, Andrew Elliott?* and Mihai Cucuringu!?”

 

*Correspondence:
wgu2@princeton.edu;
mihai.cucuringu@stats.ox.ac.uk
'Department of Statistics, University
of Oxford, 24-29 St. Giles, Oxford,
OX1 3LB, UK

>The Alan Turing Institute, British
Library, 96 Euston Road, London
NW1 2DB, UK

Full list of author information is
available at the end of the article

D) Springer Open

Abstract

Clustering is an essential technique for network analysis, with applications in a diverse
range of fields. Although spectral clustering is a popular and effective method, it fails to
consider higher-order structure and can perform poorly on directed networks. One
approach is to capture and cluster higher-order structures using motif adjacency
matrices. However, current formulations fail to take edge weights into account, and thus
are somewhat limited when weight is a key component of the network under study.
We address these shortcomings by exploring motif-based weighted spectral clustering
methods. We present new and computationally useful matrix formulae for motif
adjacency matrices on weighted networks, which can be used to construct efficient
algorithms for any anchored or non-anchored motif on three nodes. In a very sparse
regime, our proposed method can handle graphs with a million nodes and tens of
millions of edges. We further use our framework to construct a motif-based approach
for clustering bipartite networks.

We provide comprehensive experimental results, demonstrating (i) the scalability of
our approach, (ii) advantages of higher-order clustering on synthetic examples, and (iii)
the effectiveness of our techniques on a variety of real world data sets; and compare
against several techniques from the literature. We conclude that motif-based spectral
clustering is a valuable tool for analysis of directed and bipartite weighted networks,
which is also scalable and easy to implement.

Keywords: Motif, Spectral clustering, Weighted network, Directed network,
Community detection, Graph Laplacian, Bipartite network

 

1 Introduction

Networks are ubiquitous in modern society; from the internet and online blogs to protein
interactions and human migration, we are surrounded by inherently connected struc-
tures (Kolaczyk and Csardi 2014). The mathematical and statistical analysis of networks
is therefore an important area of modern research, with applications in a diverse range
of fields, including biology (Albert 2005), chemistry (Jacob and Lapkin 2018), physics
(Newman 2008) and sociology (Adamic and Glance 2005).

A common task in network analysis is that of clustering (Schaeffer 2007). Network clus-
tering refers to the partitioning of a network into “clusters’, so that nodes in each cluster
are similar (in some sense), while nodes in different clusters are dissimilar. For a review
© The Author(s). 2020 Open Access This article is licensed under a Creative Commons Attribution 4.0 International License,
which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate
credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were
made. The images or other third party material in this article are included in the article’s Creative Commons licence, unless
indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons licence and your

intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly
from the copyright holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0/.
Underwood et al. Applied Network Science (2020) 5:62 Page 2 of 41

of approaches, see for example (Fortunato 2010) or (Fortunato and Hric 2016). Spec-
tral methods for network clustering have a long and successful history (Cheeger 1969;
Donath and Hoffman 1972; Guattery and Miller 1995), and have become increasingly
popular in recent years. These techniques exhibit many attractive properties including
generality, ease of implementation and scalability (Von Luxburg 2007); in addition to
often being amenable to theoretical analysis by using tools from matrix perturbation the-
ory (Stewart and Sun 1990). However, traditional spectral methods have shortcomings,
particularly involving their inability to consider higher-order network structures (organi-
zations above the level of individual nodes and edges), which have become of increasing
interest in recent years (Rosvall et al. 2014; Benson et al. 2016; Benson et al. 2018); and
their insensitivity to edge directions! (Cucuringu et al. 2019b). Such weaknesses can lead
to unsatisfactory results, especially when considering directed networks. Motif-based
spectral methods have proven more effective for clustering directed networks on the basis
of higher-order structures (Tsourakakis et al. 2017), with the introduction of the motif
adjacency matrix (MAM) (Benson et al. 2016). While weights can be important in net-
work clustering (Newman 2004), to the best of our knowledge, these motif-based methods
have not been comprehensively investigated on weighted networks. Thus, in this paper,
we focus on extending these methods to the family of weighted directed networks.

Contribution In this paper, we explore motif-based spectral clustering methods with
a focus on addressing these shortcomings by generalizing motif-based spectral meth-
ods to weighted directed networks. Our main contributions include a collection of new
matrix-based formulae for MAMs on weighted directed networks, and a motif-based
approach for clustering bipartite networks. We also provide computational analysis of our
approaches, demonstrations of scalability and comprehensive experimental results, both
from synthetic data (variants of stochastic block models) and from real world network
data. Finally, we provide a thoroughly tested, scalable implementation of our proposed
matrix-based MAM formulae in both Python and R, which can be found at https://github.

com/wgunderwood/motifcluster.

Paper layout Our paper is organized as follows. In Section 2, we describe our graph-
theoretic framework which provides a natural model for real world weighted directed
networks and weighted bipartite networks. In Section 3 we develop our methodology,
and state and prove new matrix-based formulae for MAMs. We explore the com-
putational complexity of our approaches and demonstrate their scalability on sparse
graphs. In Section 4 we explore the performance of our approaches on several synthetic
examples. We demonstrate the utility of considering weight and higher-order struc-
ture, and compare against non-weighted and non-higher-order methods. In Section 5,
we apply our methods to real world data sets, demonstrating that they can uncover
interesting divisions in weighted directed networks and in weighted bipartite net-
works. We compare our performance to standard methods and highlight our ability
to avoid misclassification. Finally, in Section 6 we present our conclusions and discuss

future work.

 

1 Although there are some spectral approaches which do consider edge direction e.g. (Rohe et al. 2016; Satuluri and
Parthasarathy 2011).
Underwood et al. Applied Network Science (2020) 5:62 Page 3 of 41

2 Framework

In this section, we give notation and definitions for our graph-theoretic framework, with
the aim of being able to define our weighted generalizations of motif adjacency matrices in
Section 3. The motif adjacency matrix (Benson et al. 2016) is the central object in motif-
based spectral clustering, and serves as a similarity matrix for spectral clustering. In an
unweighted MAM M, the entry Mj is proportional to the number of motifs of a given
type that include both of the vertices i and j.

Notation Graph notation is notoriously inconsistent in the literature; in this work, a
graph is a triple G = (V,€,W) where V is the vertex set, E C {(if:ij € Vi Fj} is
the edge set and W: E — (0,00) is the weight map. A graph G’ = (V’,€’) is a sub-
graph of a graph G = (V,€) (write G’ < G)if VW’ C Vand €’ C E. It is an induced
subgraph (write G’ < G) if further €' = EN (V’ x VY’). A graph G’ = (V’,E’) is iso-
morphic to a graph G = (V,€) (write G’ = G) if there exists a bijection g: VY’ > VY
with (u,v) € E' <=> (¢(u),¢(V)) € E. An isomorphism from a graph to itself is
called an automorphism. Where it is not relevant or understood from the context, we may
sometimes omit the weight map W.

As we are considering directed weighted graphs, it is convenient to consider five indi-
cator matrices that capture the different possible relationships between pairs of nodes,
namely the directed indicator matrix J, the single-edge indicator matrix J;, the double-
edge indicator matrix Jy, the missing-edge indicator matrix Jo, and the vertex-distinct

indicator matrix Jp:

Jy = MUG p € €},
Js)ij = (Gj) € E and Gi) € €},
Ja) = Gf) € € and (j,i) € €},
Jo)j = NG) € € and (j,i) ¢ E andi Fj},
Ong = Hi Aj},

 

where I is an indicator function. Furthermore, we consider the following three weighted
adjacency matrices, corresponding to directed edges, single edges, and double edges,

respectively:

Gy = WG) UGA € €},
(Gj = WGP) GS) € € and Gi) € €},
(Gay = (WGA) + WG i))) Gs) € E and (i) € E}.

We can extend to the setting of undirected graphs by constructing a new graph, where
each undirected edge is replaced by a bi-directional edge.

Definition 1 (Motifs and anchor sets) A motif is a pair (M,A) where M = (Vu, Em)
is a (weakly) connected graph with Vy, = {1,...,m} for some small m > 2, and an anchor
set is A C Vy with |A| > 2. If A 4 Vu, we say the motif is anchored, and if A= Vn
we say it is simple. We say that H is a functional instance of M inG if M =H < G, and
we say that H is a structural instance of M inG if M =H < G. When an anchor set is
Underwood et al. Applied Network Science (2020) 5:62 Page 4 of 41

not given, it is assumed that the motif is simple. Figure 1 shows all the simple motifs (up to

isomorphism) on at most three vertices.

Structural instances occur when an exact copy of the motif is present in the graph: i.e.
edges present (resp. not present) in the motif are present (resp. not present) in the graph.
Functional instances are less restrictive, and occur when the motif is present in a graph,
but potentially with extra edges.

Anchor sets (Benson et al. 2016) can be thought of as the set of locations in a motif
that we consider important for the motif structure. For example we could consider the
2-path motif Mg, and try to cluster together nodes which appear at the start or end of
a 2-path, but maybe not in the middle. Then we can define the anchor set as the subset
of motif vertices which should not be separated. In Mo, the start and end vertices would
correspond to A = {1,3} (Fig. 1). Anchor sets are crucial for defining the collider and
expander motifs given in Section 3.2.

Finally, we require one additional definition before we can state our generalization of
MAMs to weighted networks.

Definition 2 (Anchored pairs) Let G be a graph and (M, A) a motif. Suppose H is an
instance of M in G. Define the anchored pairs of the instance H as

ACH) := {{¢ (i), dG)}:ij € A, i Fj, b is an isomorphism from M to H} .

This is the set of pairs of vertices for which both vertices lie in the image of the motif’s
anchor set, under some isomorphism from the motif to the instance.

3 Methodology

In this section we detail our methods for motif-based spectral clustering of weighted
directed networks. Firstly we define our weighted generalizations of motif adjacency
matrices (MAMs) (Definition 3.1). We further provide computationally useful formu-
lae for weighted MAMs (Proposition 3.1), and discuss their applications to clustering

 

@)

© ©
@—-® @—-@ /\ /\ /\
6-—@® @-@ G--O

Mz, (single) Ma (double) My, My M3

® ® ® ® ®
JN S\ S\N S\N
O-—® C—O G-O O-O 6 @

Me M7, Ms

® ® ® ® ®
f\ S\ S\N S\ LN
©, © 6 © © © 6 & 6 @

Fig. 1 All simple directed motifs on at most three vertices

 

 

 
Underwood et al. Applied Network Science (2020) 5:62 Page 5 of 41

(Section 3.3). Finally we present a complexity analysis of our method for computing
weighted MAMs (Proposition 3.3), and empirically demonstrate the scalability of our
approach (Section 3.4).

3.1 Weighted motif adjacency matrices

Generalizing unweighted measures to weighted networks is non-trivial and application-
dependent, and there are typically many possible valid choices. For example, see the
approaches for motif weighting proposed by (Onnela et al. 2005) and (Benson et al. 2018).
It is often helpful to first consider the generalization of the measure to multi-edges (New-
man 2004). We can then view positive integer-weighted edges as multi-edges, and extend
to positive real-weighted edges in a natural way.

Thus, we begin by considering the weight to place on a motif which contains multi-
edges. A first option might be to consider the minimum number of multi-edges lying on
any edge of the motif. This would capture the number of fully edge-disjoint instances
of the motif. Another option would be to count the number of unique instances of the
motif (possibly counting individual edges more than once), giving the total weight as the
product of the number of multi-edges between each pair of nodes in the instance. Alter-
natively, as a compromise between these two schemes, we might consider the number of
distinct motifs present, were the multi-edges distributed evenly among all the edges in the
motif (allowing fractional edges for simplicity). This gives the arithmetic mean weighting
scheme which is used in Onnela et al. (2005); Benson et al. (2018); Mora et al. (2018) and
Simmons et al. (2019).

As an illustrative example of how this choice can affect clustering, Fig. 2 shows how
different motif weighting schemes prefer to divide a network in different ways. Here, we
treat the undirected edges as bi-directional edges and consider the fully-connected trian-
gle motif M4. The “minimum” approach has no preference between Cut 1 and Cut 2, with
all motifs having a weight of 1, and in this example is equivalent to the simple unweighted
case. However the “mean” weighting approach (which, up to a scaling factor, is equivalent
to summing the edge weights) prefers Cut 1 (cutting motifs of mean-weight 2 and 1 rather

 

Cut 1 Cut 2

02-6
Q——-

Fig. 2 An example illustrating that different weighting schemes prefer different motif cuts: the four triangles
have mean-weights of 2, 1, : and 2, and product-weights of 6, 1,3 and 3 respectively whereas the minimum
edge weight in each triangle is 1. Thus, the minimum formulation cannot distinguish between the cuts,
whereas, under the mean formulation Cut 1 gives a cut of size 9, and Cut 2 gives a cut of size 10. On the other
hand, under the product formulation, Cut 1 gives a cut of size 7, and Cut 2 gives a cut of size 6. Hence the
mean formulation prefers Cut 1 and product formulation prefers Cut 2

    

 

 

 

 
Underwood et al. Applied Network Science (2020) 5:62 Page 6 of 41

than 3 and 3), while the “product” approach prefers Cut 2 (cutting motifs of product-
weight 3 and 3 rather than 6 and 1). Further, although they ostensibly concern bipartite
networks, Section 4.5 exhibits some of the effects of different weighting schemes on the
performance of motif-based clustering, and Section 5.3 provides real world motivation
for using mean-weighted motifs.

Each of these approaches has merits. The “minimum” approach might be natural when
dealing with flow networks, where low-count multi-edges could indicate bottlenecks or
points of unreliability. The “product” approach is useful if we want to consider each pos-
sible set of edges to be a separate entity, while the “mean” approach is appropriate if we
consider the motif to be a single object and wish to count the total number of edges it
contains, perhaps as some notion of capacity.

When considering weighted edges however, these approaches have some mathematical
differences, particularly in how they handle the presence of large weights. For example,
suppose that a graph contains just a few heavy edges. Were two of these heavy edges to
appear together in a motif instance, the product formulation would assign a very large
total weight to that instance, possibly completely dominating any other instances. On
the other hand, using the mean formulation ensures that the total weight of any instance
remains on the same scale as the individual edge weights. By taking the minimum edge
weight, it may be that the heavy edges do not contribute to any motif weights at all.

With these points in mind, and following (Mora et al. 2018) and (Simmons et
al. 2019), we use the “mean-weighted” approach in this paper, defining the weight
of a motif instance by its average (mean) edge weight. We acknowledge that other
weighting schemes may be more appropriate in some circumstances’. For example,
(Onnela et al. 2005) introduces several weighting schemes related to the geometric and
arithmetic means of the edge weights. Further, these are special cases of the generalized
p-means weighting scheme detailed by Benson et al. (2018).

Now that we have chosen a motif weighting scheme, we can define our weighted gen-
eralizations of motif adjacency matrices. We note that while a weighted extension was
considered by Wang et al. (2018), in this paper we provide the first thorough exploration,
including computational analysis, fast software implementations and comprehensive real
world and synthetic experiments.

Definition 3.1 (Weighted motif adjacency matrices) Let G = (V,E, W) be a weighted
graph on n vertices and let (M,.A) be a motif. The functional and structural (mean-
weighted) motif adjacency matrices (MAMs) of size n x n of (M,.A) in G are given

by
UNC 1 oe
Mi" = — > Iftsjhe AG}? We),
eM SF<c ecb
1
MyM := —— JS" If fij}e AGD} Yo Wee).
Em MEZH<G ecb

When W = 1 and M is simple, the (functional or structural) MAM entry My (i ¥ j)
simply counts the (functional or structural) instances of M in G containing i and j. When

M is not simple, Mj; counts only those instances with anchor sets containing both i and j.

 

For convenience our software package implements three weighting schemes: product, mean and a scheme which
ignores the weights.
Underwood et al. Applied Network Science (2020) 5:62

MAMs are always symmetric, since the only dependency on (i, /) is via the unordered set
{i,j}. In order to state Proposition 3.1, we need one more definition.

Definition 3.2 (Anchored automorphism classes) Let (M,.A) be a motif. Let Sy, be the
set of permutations on Vy, = {1,...,m} and define the anchor-preserving permutations
SuA = {o € Spy: {1,m} C o(A)}. Let ~ be the equivalence relation defined on § yy, by:
o~t eT!
are the quotient set Sy, 4 :=SM,A / ~,

o is an automorphism of M. Finally the anchored automorphism classes

The motivation for this definition of anchored automorphism classes is as follows: sup-
pose we are looking for instances of (M,.A) in G which contain nodes i and j. We set
k, =iandk,, = j (where m is the number of nodes in the motif — note we could use any
two fixed indices instead of 1 and m here), and choose some other nodes {ko,..., kj,—1}.
We want to find all mappings of vertices in M to our chosen vertices in G by u b> key
such that (i) vertices in A are mapped to i and j, and (ii) mappings which correspond to
the same instance are not counted more than once. These conditions are precisely the

same as requiringo € Sy, 4.

Proposition 3.1 (MAM formula) Let G = (V,€,W) be a graph with vertex set
VY = {1,...,n} and let (M, A) be a motif on m vertices. For any i,j € V and with ky = i,
km = Jj, the functional and structural MAMs of (M, A) in G are given by

unc 1 unc func
Mi — IEn| » > k,o Gig , (1)

oes A {ko,..4km—1}CV
1
StTUC __ Struc struc
Mi a IEm| > S Jigs Gio , (2)
oES NA {ko,..4km—1}CV

Unc
k,o
structural) instance on the m-tuple of distinct vertices k = (kj,...,km) in G, under the

where is equal to one (and zero otherwise) if M appears as a functional (likewise for

mapping u+> ky; and in that case, Gun is the average edge weight of that instance:

UsIC
Ke = | ]On)koukov [ Pecuskor | [ad ke uskov »
0 EN Ed,

EM
func _
Gio a > Gkowkov + S (Ga) keruskov ,
s d
EM Et

StYUC ,__
Ig = [ [Oo )keuskrv [ [Os)kouskor ] [Gad keuskov’

0 ’
£4, EM EM
Ge = (Gs )kcuskov + (GA) kowkev ,
; d
EX EM

and the summations and products are over the missing edges, single edges and double edges

of M as follows:
EN = {(u,v):1<u<v<m:(u,v) €En, (Vu) € En},
E\y = {Uv):l1<u<v<m:(uv)€ Eu (vu) €Eu},

EL s—f(wv):1<u<v<m:(uv) € Eu, (yu) € En}.

Proof See Proof B.1. O

Page 7 of 41
Underwood et al. Applied Network Science (2020) 5:62 Page 8 of 41

3.2 Motif adjacency matrices for bipartite graphs

We also extend our formulation to weighted bipartite networks, by considering certain 3-
node anchored motifs. These are used to create separate similarity matrices for each part
of a bipartite graph.

Definition 3.3 A bipartite graph is a directed graph where the vertices can be parti-
tioned as V = S UD, such that every edge starts in S and ends in D. We refer to S as the
source vertices and to D as the destination vertices.

Our method for clustering bipartite graphs uses two anchored motifs; the collider and
the expander (Fig. 3). For both motifs the anchor set is A = {1,3}. These motifs are useful
for bipartite clustering because when restricted to the source or destination vertices, their
MAMs are the adjacency matrices of the weighted projections (Chessa et al. 2014) of the
graph G (Proposition 3.2). In particular they can be used as similarity matrices for the
source and destination vertices respectively. Note that if a bipartite graph is connected,

then so are the projections onto its source or destination vertices.

Proposition 3.2 (Colliders and expanders in bipartite graphs) Let G = (V,€,W) be
a directed bipartite graph. Let Meoy and Mexpa be the structural or functional MAMs of
Moy and Mexpa respectively in G. Then

1
(Meo =i AID, 5[WGKH)+WG%)], (3)
Gk Ghee
1
(Mexpa)ij = Mi # j} dX 5 LW) + WK) (4)
(kd, Ee
Proof See Proof B.2. O

We note that there are other options available for constructing projections of weighted
bipartite graphs, such as the approach in (Stram et al. 2017), which, similarly to our frame-
work, uses sums of edge weights over shared neighbors. Another relevant line of work is
that of (Zha et al. 2001), who proposed a certain minimization problem on the bipartite
graph, showing that an approximation solution could be obtained via a partial singular
value decomposition of a suitably scaled edge weight matrix.

 

@ Q
J/\ JS \
6 © 6 @

M coll M expa

Fig. 3 The collider and expander motifs.

 

 

 
Underwood et al. Applied Network Science (2020) 5:62 Page 9 of 41

3.3 Clustering the motif adjacency matrix

A motif adjacency matrix can be construed as a general pairwise similarity measure, and
as such, can be analyzed directly as a new weighted undirected graph. Following (Benson
et al. 2016), one of the most interesting applications is identifying higher-order clusters
with spectral methods, leveraging the fact that the similarity is based on motifs.

To extract clusters, we use a standard approach from the literature on spectral cluster-
ing, based on the spectrum of the random-walk Laplacian, followed by k-means++ (see
Appendix C). To this end, we need to define two parameters: / is the number of random-
walk Laplacian eigenvectors to use, and k is the number of clusters for k-means++
(see Algorithm 1). We detail our approach for general directed weighted networks in
Algorithm 2, and for weighted bipartite networks in Algorithm 3.

3.3.1 Cluster evaluation

When ground-truth clustering is available, we compare it to our recovered clustering
using the Adjusted Rand Index (ARI) (Hubert and Arabie 1985). The ARI between two
clusterings has expected value 0 under random cluster assignment, and maximum value
1 denoting perfect agreement between the clusterings. A larger ARI indicates a more
similar clustering, and hence closer to the ground truth.

3.3.2 Connected components

In order for spectral clustering to produce nontrivial clusters from a graph, it is neces-
sary to restrict the graph to its largest connected component. When forming MAMs,
even if the original graph is (weakly or strongly) connected, there is no guarantee that
the (symmetric) MAM is connected too. Hence we restrict the MAM to its largest con-
nected component before spectral clustering is applied. While this may initially seem to
be a flaw with motif-based spectral clustering (since some vertices may not be assigned to
any cluster), in fact it can be useful: we only attempt to cluster vertices which are in some
sense “well connected” to the rest of the graph. This can result in fewer misclassifications
than with traditional spectral clustering, as seen in Section 5.2, where we also investigate
MAM regularization as an alternative strategy for dealing with disconnected MAMs.

3.3.3 Motif choice

The selection of a motif is essentially equivalent to selecting a similarity measure between
nodes in the network, as the (i,j)th entry in the MAM corresponds to the similarity
between nodes i and j used for our clustering procedure. This selection can be impor-
tant, as we will see in Section 4.4, where the choice of motif can have a significant impact
on the clusters obtained. For motif selection, considerations for weighted networks are
largely similar to those for unweighted networks. Thus much of this discussion will mir-
ror that of (Benson et al. 2016), although we will highlight the areas where weight may
cause deviations.

The first criterion for motif selection is the application domain. This may involve
choosing motifs which are related to specific features of the application domain, essen-
tially specializing the similarity measure to the task at hand. For example, in several
fields, some motifs may be more relevant or have very different properties; e.g. the feed
forward structure in biological networks (Mangan and Alon 2003), various triadic struc-
tures in sociology (Wasserman et al. 1994), or the motif M5 in food web networks
(Benson et al. 2016). For weighted networks the procedure is very similar, but care must
Underwood et al. Applied Network Science (2020) 5:62 Page 10 of 41

be taken to simultaneously select a motif and a weighting scheme (Section 3.1), in order
to capture the similarity measure of interest.

Again following (Benson et al. 2016), in the case where there is no application domain
guidance, more principled methods for motif choice are also available. For example, sweep
profiles (Shi and Malik 2000) or their motif-coherence counterparts (Benson et al. 2016)
can be used to identify motifs which give more clearly distinguished clusters. In the
weighted case, these methods require weighted generalizations of the appropriate quan-
tities. We give an example of the application of weighted generalizations of these sweep
profiles to real world data in Section 5.2. Finally, one could consider every motif (or a
subset of motifs) and then explore each in turn. We demonstrate this approach in our
migration experiment in Section 5.1, where we plot the geographic spread of our clusters
and then validate on a subset of motifs by considering the cut imbalance ratio scores.

3.3.4 Functional vs. structural MAMs

There is also a choice of whether to use functional or structural MAMs for motif-based
clustering, and their different properties make them suitable for different circumstances.
Firstly, note that 0 < Mg < uyene for all i,j €¢ V. This implies that the largest connected
component of M!""° is always at least as large as that of M‘"°, meaning that sometimes
more vertices can be assigned to a cluster by using functional MAMs. However, structural
MAMs are more discerning about finding motifs, since they require both “existence” and

“non-existence” of edges.

3.4 Computational analysis

For motifs on at most three vertices, we provide two fast and potentially parallelizable
matrix-based procedures for computing weighted MAM«s: one for dense regimes and one
for sparse regimes. In this section, we explore and demonstrate the scalability of these two

approaches.

3.4.1 Dense approach

First, Proposition 3.3 bounds the number of matrix operations required to compute a
weighted MAM, for a motif on at most three vertices, using our dense formulation. In
practice, additional symmetries of the motif often allow computation with even fewer
matrix operations (Appendix A).

Proposition 3.3 (Complexity of MAM formula) Let G be a (weighted, directed) graph
on n vertices, and suppose that the n x n directed adjacency matrix G of G is known. Then,
computing the adjacency and indicator matrices and calculating a MAM, for a motif on
at most three vertices, using Eqs. (1) and (2) in Proposition 3.1, involves at most 18 matrix
multiplications, 22 entry-wise multiplications and 21 additions of n x n matrices.

Proof See Proof B.3. O

Thus as we have a fixed bound on the number of each operation for any motif, and
as each operation is performed on a matrix of the same size, our approach scales with
the largest complexity of these operations. In dense matrices, element-wise products and
additions are O(n) and naive matrix multiplication is O(?). Therefore, in a naive imple-
mentation for a graph on n vertices, the overall complexity of our dense approach is
Underwood et al. Applied Network Science (2020) 5:62 Page 11 of 41

O(n*), and the memory requirement is O(n’). We note that somewhat faster algorithms
are available for multiplication of large dense matrices, such as the O(n*!) algorithm
given by Strassen (1969).

A list of functional MAM formulae for our dense approach, for all simple motifs on at
most three vertices, as well as for the collider and expander motifs (used in Section 3.2), is
given in Table 5 in Appendix 6. These formulae are generalizations of those stated in Table
S6 in the supplementary materials of (Benson et al. 2016) (a list of structural MAMs for
triangular motifs in unweighted graphs). Note that the functional MAM formula for the
two-vertex motif M, yields the symmetrized adjacency matrix M = G + G', which can
be used for traditional spectral clustering (Appendix C1), as in (Meila and Pentney 2007).

3.4.2 Sparse approach

Real world networks are often sparse (Leskovec and Krevl 2014), and operations with
sparse matrices are significantly faster: in sparse matrices with b non-zero entries,
element-wise products and additions are O(b), and matrix multiplications are O(bn).
Therefore, we give a slightly different approach with a better computational running time
(Section 3.4.3) on sparse graphs, which can extend to graph sizes that are infeasible for
our dense approach.

For motifs on at most three vertices, the formulae in Propsition 3.1 are simply sums of
terms of the form A o (BC), where A, B and C are adjacency or indicator matrices, and o
represents the entry-wise (Hadamard) product. If the directed graph has vertices and b
edges, then most of the adjacency and indicator matrices have at most b non-zero entries.
For these matrices, we can compute the (possibly dense) matrix BC in O(bn) time, and
then the matrix A o (BC) in O(n?) time. Summing them together is also done in O(n’)
time.

However, when considering motifs with missing edges, we use the dense indicator
matrices Jo and Jy. This is problematic as now the term BC can contain a dense matrix,
which can be an issue both for computational reasons* and more importantly, for memory

requirements. To address this, we rewrite these two matrices as

In =1-TZ,
Jo=1—-(U 4h +3) +Ja)

where 1 is a matrix of 1s, and expand out the resulting formulae. Element-wise and
matrix products with 1 and J are at most O(n”) so are computationally simple, and do
not require generating dense matrices. This allows scaling simply using standard linear
algebra libraries.

For sparse graphs the key limitation of this approach is in fact not CPU, but memory
(RAM) as while B and C might be sparse, BC may not be. The worst case density of BC
for B and C indicator matrices of a connected graph is n? (e.g. a star graph).” However,

 

3By exploiting sparsity the sums and element-wise products could be faster than O(n), but as the complexity is
dominated by the matrix multiplication, we do not explore this further.

4 Although there are sparse-dense matrix multiplication algorithms that address this.

>See https://math.stackexchange.com/questions/1042096/bounds- of- sparse- matrix- multiplication.
Underwood et al. Applied Network Science (2020) 5:62 Page 12 of 41

in practice the density is often substantially lower than this, allowing our approaches to
scale to very large graphs (Section 3.4.3).

3.4.3 Empirical computational speed

In this section, we demonstrate the scalability of our two approaches to computing
MAMs. We showcase the running times of four different random graph ensembles. For
the first two ensembles, we use the directed Erdés-Rényi (ER) model (Erdos et al. 1959)
in which each directed edge between n nodes exists independently with probability p. We
consider two regimes, a very sparse regime (p = 1) and a less sparse regime (p = 100),
For the last two ensembles, we use the undirected Barabasi-Albert (BA) model (Barabasi
and Albert 1999). In this model, the graph is initialized with m nodes, and n — m nodes
are then added sequentially, with each node connecting to m previously placed nodes,
and with probability of connection proportional to the current degree of each previously
placed node, resulting in a graph with a skewed (power-law) degree distribution. We again
consider two regimes, a very sparse regime (m = 10) and a less sparse regime (m = 100).
In each of these four ensembles, the expected number of edges in the graph scales as O(n).

We measure the performance of computing a functional MAM for a representative
sample of motifs: one triangle motif M,, the 2-star Mg, and a motif with a bi-directional
edge, M11. We do not include the time taken to generate the graph in either the sparse or
the dense matrix form. To make this a fair test, we use an optimized Python environment
from the Data Science Virtual Machine image on an E64s v3 Azure virtual machine with
64 vCPUs and 432 GiB of RAM.

The results are summarized in Fig. 4. In the denser graphs (ER: p = 0 BA: m = 100),
we note that for smaller graphs (i.e for 7 less than ~ 10*) the dense approach tends to
perform as well as, and in many cases exceeds, the performance of the sparse approach,
highlighting the advantage of using this approach in denser graphs. For graphs above this
size and graphs in the sparser regime (ER: p = 10 BA: m = 10), the sparse approach
outperforms, handling graphs with over a million nodes and tens of millions of edges.
In the less sparse regime (ER: p = 100 BA: m = 100), we consider graphs of size up to
n = 10° nodes and of order 10’ edges, for which our sparse approach takes less than 102
seconds for the ER model, and around 10° seconds for the BA model.

We note that the time required for each method is roughly constant across most of the
tested motifs. The exception is the sparse approach for M1, which takes substantially
less time than the other motifs in both of the ER regimes. We believe this to be related
to the bi-directional edge in Mj, (not present in Mj, or Ms), which is rare in sparse
ER graphs, heavily reducing the amount of computation required. This is not seen in the
undirected BA graphs, where bi-directional edges are much more common, resulting in a
similar level of performance across all tested motifs in this regime. The various scenarios
we experimented with highlight the fact that our approach is highly scalable to very large
sparse graphs, including those with skewed degree sequences which often arise in real
world applications.

4 Applications to synthetic data

To validate our method, we consider three synthetic data sets as examples. We selected
each example to highlight a different aspect of our approach and to demonstrate
the advantages of considering a weighted higher-order clustering measure. Example 1
Underwood et al. Applied Network Science (2020) 5:62 Page 13 of 41

 

 

Timing results for the sparser regime ER(n, a) Timing results for the less sparse regime ER(n, 100)

Time (s)
Time (s)

  

10° 104 10°

Timing results for the sparser regime BA(n, 10) Timing results for the less sparse regime BA(n, 100)

Time (s)

Time (s)

  

103 104 10°
n nm

Fig. 4 Run time for our two approaches. Top: Erddés-Rényi (ER) graph ensembles. Bottom: Barabasi-Albert
yn — 10 BA. mm —

(BA) graph ensembles. The left panels show very sparse graphs (ER: p = —, BA: m = 10) and the right panels

show less sparse graphs (ER: p = 100 BA: m = 100). We average over five repeats, and error bars are one

sample standard deviation

 

 

 

 

 

demonstrates the importance of taking the edge weights into account when performing
higher-order clustering; Example 2 shows the value of higher-order clustering, demon-
strating that clustering using different motifs can yield different insights into the same
data; and finally, Example 3 demonstrates the value of our bipartite clustering scheme for
detecting structures in weighted bipartite networks.

4.1 Directed stochastic block models

For these tests we use weighted and unweighted directed stochastic block models
(DSBMs), a broad class of generative models for directed graphs (Nowicki and Snijders
2001). An unweighted DSBM is characterized by a block count k, a list of block sizes
(nj)K_1, and a connection matrix F e€[0,1]k**. We define the cumulative block sizes
1; = ia nj, and the total graph size n = nj. These are used to construct the group
allocations g; = min{r : n* > i}, and finally a graph G is generated with adjacency matrix

entries

Gi = Ber(Fg,g,) ltt Aj}, (5)

with all Bernoulli random variables sampled independently. A weighted DSBM is
constructed in a similar manner (see for example (Mariadassou et al. 2010) and
(Aicher et al. 2014)), but also requires a weight matrix A €[0,00)***, In this case, the
weighted adjacency matrix entries are generated by the following mixture model

Gi = Ber(Fg,g) « Poi(Ag,g) «Ili 4 j}, (6)

with all Bernoulli and Poisson random variables sampled independently. Note that the
Bernoulli variable now no longer directly corresponds to edge existence, since there
is always a non-zero chance of the Poisson variable being zero, which sets Gj = 0
and thus removes the edge. We assume a DSBM is unweighted unless stated other-
wise. We evaluate performance using the Adjusted Rand Index (ARI) (Rand 1971), as in
Section 3.3.1.
Underwood et al. Applied Network Science (2020) 5:62 Page 14 of 41

4.2 Bipartite stochastic block models

We define the unweighted bipartite stochastic block model (BSBM) with source block
count ks, destination block count kp, source block sizes (ni, 5S, destination block sizes
(ni), and bipartite connection matrix Fy €[0, 1]‘s*kD as the unweighted DSBM with

block count k = ks +kp, block sizes (ni), = Gost (nip), and connection matrix

0 F
F=({- °).
00
A weighted BSBM with bipartite weight matrix Ap €[0,00)*S**? can similarly be con-

OA
structed by using a weighted DSBM with weight matrix A = 00 p ) Note that this is

a generalization of the model in (Florescu and Perkins 2016).

4.3 Example 1

In this example we demonstrate the advantages of taking edge weights into account when
detecting higher-order structures. We compare Algorithm 2 with two clusters (kK = 2)
and two eigenvectors (J = 2), against two standard approaches. The first comparison is
random-walk spectral clustering using a symmetrized weighted matrix, which captures
the ability of non-motif-based methods to uncover the underlying structure. This is equiv-
alent to Algorithm 2 with motif /,. Secondly, we compare against our own motif-based
approaches, but with all edge weights set to 1, similar to the formulation of (Benson et al.
2016).

To demonstrate the advantages of our approach, we consider an example for which (i) a
higher-order structure is present, and (ii) weight is important in the structure. Construct-
ing higher-order structures in a stochastic block model is challenging, as by definition all
the edges are independent. Thus the block structure in a DSBM with strongly connected
blocks is captured by density rather than by the existence of motifs (although these are
correlated).

To this end, we construct clusters that consist of several blocks, and introduce a higher-
order structure between blocks of the same cluster. For this example, we use two clusters
(Fig. 5 (upper panel)), each one consisting of two blocks each of size 100, for a total of
n = 400 nodes. Each cluster (VP, Vr) and VP, yO 1) consists of two blocks with
strong uni-directional (probability py = 0.25) connections with potentially large weights
(Poisson with mean w)). The two clusters are then linked by weaker inter-block con-
nections with potentially smaller weights (Poisson with mean 50). By design, this model
has strong heavy-weighted uni-directional structures, and is thus well captured by Mg
and M10, both of which capture uni-directional structure. Thus, following (Benson et al.
2016) rather than focusing on an individual motif, we use the sum of both MAMs.

The lower panel of Fig. 5 displays the results for functional motifs (structural
motifs in Appendix D). As our procedure only clusters the largest connected MAM
component, we compute ARI over this component. For w,; = _ 50, all edges
have the same expected weight, and thus the performances of weighted and non-
weighted motifs are equal. In the mid-range of weights (50 < w , < 90), our
approach outperforms both of the others, indicating the advantages of accounting for
weights.

Finally, for large weights (w; > 90), we are (on average) slightly outperformed by Mg,
the symmetrized weighted adjacency matrix, although the error bars are overlapping. One
Underwood et al. Applied Network Science (2020) 5:62 Page 15 of 41

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

   

 

0 QO |0.125}0.125 0 0 | 50 | 50
r : Ix
0 0 0 0 0 0 0 0
——
an
0.8
0.6
oo
<q
0.4
0.2 —+— Msg t+ Mio
—— Msg +Myjo no weight
0.0 + Ms:
50 60 70 80 90 100 110 120
W1
Fig. 5 Top: DSBM parameters for Example 1. We note that the DSBM has been constructed to favor
weighted motifs. The left and middle panels display the connection matrix and weight matrix (Eq. 6). In the
right panel, a schematic diagram of the structure, blocks of the same color belong to the same cluster and
larger arrows represent connections with higher probabilities and larger edge weights. Bottom: Exploring
the performance of MAMs based on Mg and Mig on the model in the upper panel. Each block contains 100
nodes. We compare both to the unweighted case, and to the symmetrized case. We perform 100 repeats,
and error bars are one sample standard deviation

 

 

 

possible reason for this is that while using Msg and M)o gives a strong signal, it also
introduces noise when motifs with heavy and non-heavy weighted edges span clusters.

The pattern on structural motifs is similar (Fig. 16 in Appendix D), with two key differ-
ences: first, the non-weighted motifs have a larger ARI (~ 0.7 vs. © 0.3), and second, the
weighted motif equals or outperforms M,;. We hypothesize the following possible reason
for this phenomenon: in this model, motifs on three nodes which span clusters can form
triangles, whereas those within clusters cannot (due to the probability-0 connections).
Hence versions of the non-triangle motifs Mg and Mj are able to filter out some of the
noise described in the previous paragraph, leading to better performance.

Finally, we note that this example has been designed to highlight the advantages of our
motifs; and several other structures were considered which do not have this property.
When applying this to real world data, it is important to consider the correct motif to use,

as discussed in Section 3.3.3.

4.4 Example 2

In the second example, we explore the value of higher-order clustering, by demonstrating
that clustering using different motifs can give different albeit potentially equally valu-
able insights. We showcase this with two experiments. First, we consider the case where,
due to the construction of the network, certain motifs are better at detecting the under-
lying structure in different parameterization regimes. Second, expanding on our first

example, we consider a DSBM where, by construction, the network does not have strong
Underwood et al. Applied Network Science (2020) 5:62 Page 16 of 41

densely connected blocks, and thus different motifs highlight distinct and equally relevant
groupings in the network.

4.4.1 Experiment 1
For the first experiment, we use the DSBM with k = 2, 1, = nz = 100 (son = 200) and
0.2
F= 7
0.05 0.2
We test the performance of Algorithm 2 across a few structural motifs with parameters

) as depicted in the upper panel of Fig. 6.

k =1=2 on this model (functional motifs in Appendix D). It can be seen that the motifs
perform well in different regions, with MM, outperforming other methods in the regime
0.3 < qi < 0.7, and also performing well outside this range. For large values of qi, motif
Mog performs best. For lower values of qi, Mz has a slightly higher average ARI, although
the difference is within the standard errors. This altogether demonstrates the impor-
tance of selecting the right motif. Furthermore, we compare against M,, the symmetrized
weighted adjacency matrix, and each presented motif outperforms this baseline.

We also observe an artifact in this plot: for certain motifs, the performance drops
away at qi = 0 (triangles) and at q,; = 1 (all motifs). For these parameter values, the
MAM becomes entirely disconnected, with each of the two groups in its own connected
component. As our clustering scheme only considers the largest connected component
(Section 3.3.2), we then obtain an ARI of 0. In real world graphs, we would recommend
investigating all reasonably large connected components or, depending on the application,
employing some form of regularization (see Section 5.2).

We note that there is a bi-modality with certain motifs, notable with Mo performing

well for small and large values of qi, a feature not present within the functional motifs

 

 

 

 

 

1.0

0.8

0.6

ARI

0.4

0.2

 

0.0

0.0 0.2 0.4 0.6 0.8 1.0
qd
Fig.6 Top: DSBM parameters for Example 2 Experiment 1. Left panel, the connection matrix for this model
(Eq. 5). Right panel, a schematic diagram of the structure: larger arrows represent connections with higher
probabilities. Bottom: Performance on this benchmark using structural MAMs. We compare with standard
symmetrization M;. We perform 100 repeats, and error bars are one sample standard deviation

 

 

 
Underwood et al. Applied Network Science (2020) 5:62 Page 17 of 41

(Fig. 17). We believe this is due to the fact that structural motifs act as a filter: with high
values of qj, it is difficult to form 2-paths (Mo) between groups without also forming

triangular motifs, which would not contribute towards a structural MAM.

4.4.2 Experiment 2

In this experiment, we demonstrate the ability of MAMs to uncover different structures.
We construct a DSBM with 8 groups of size 100 (7 = 800) with block structure given by
the diagram in the left panel of Fig. 7: we place edges which match the block structure
with probability 0.5 (ie. F,, = 0.5 if there is an arrow from a to b in the diagram), and
0.0001 otherwise, in order to maintain connectivity.

Following Example 1, in this DSBM we do not have the usual strongly connected groups:
in fact, each group has a close to zero probability (0.0001) of within-group connections.
Thus, while there are clearly 8 groups with unique connection patterns, there does not
exist a “correct” division of the nodes into densely connected groups, but rather, different
motifs highlight different structures.

We display the results of using functional motifs with Algorithm 2 with k = / = 2
in Fig. 7 (structural results are similar in Fig. 18). Each column represents the structure
uncovered by one of the motifs. For robustness, we perform the experiment on 100 repli-
cates, and place the resulting partitions side by side in each column. For each motif, the
columns are sorted within block in order to promote contiguity of the colors across each
block.

We observe that (by design) this graph has 3 different clusterings, highlighted by dif-
ferent motifs. First, Mg (a 2-star with the edges pointing outwards (Fig. 1)). Each pair of
connected blocks is connected by this motif. However, there is a much stronger connec-
tion when this motif is part of the higher-order structure. Thus, when we cluster using
Meg, we obtain two consistent clusters consisting of {V1, V2, V4} and {Vs5, V7, Vg}, each of
which is united by this motif at a block level. The remaining blocks without this block

 

Vg
@) »
Ve
——
@) »
—
Ve

Y

 

Ms Mg Mio Ms Mz, (8,3)

Fig. 7 Left: Diagram of the block structure for Example 2 Experiment 2: edges in the diagram are present
with probability 0.5, all other edges are present with probability 0.0001 (including edges within blocks).
Right: The detected groups found by each method, with k = 2 and/ = 2, with the exception of the last
column which has k = 8,/ = 3. We test 100 replicates and present the results as columns in the plot. The
nodes are ordered by block, and colors represent the group allocations in a given block for each motif-based
method. We order replicates (i.e. columns) within each motif to highlight similarities, the columns are sorted
within block in order to promote contiguity of the colors across each block. While the clustering assignments
may contain some errors, the results are relatively robust across replicates

 

 

 
Underwood et al. Applied Network Science (2020) 5:62 Page 18 of 41

level structure (V3 and Ye) are then essentially randomly placed into one of the two clus-
ters, giving the behavior observed in Fig. 7. We observe a similar structure with the other
motifs: Mg (a 2-path) splits the graph into the two groups characterized by their 2-paths,
{V1, V2, V3, Vs} and {V4, Ve, V7, Vg}; and finally Myo (a 2-star with the edges pointing
inwards) splits the graph into the two clusters based on this structure, namely, {V1, V4, Vo}
and {V3, Vs, Vs} (with a similar behavior to Mg for the remaining blocks). Thus, we con-
clude that our MAMs can obtain very different and equally valid structures in the same
graph.

Finally, we compare with M, which is equivalent to clustering with G+ G!. Under sym-
metrization, this graph is a ring of indistinguishable blocks. Therefore, the best possible
division is to arbitrarily divide the ring into two roughly equal-sized pieces. Considering
Fig. 7, we observe this behavior with many different divisions, and no pair of blocks is
consistently placed within the same cluster. For completeness we also compare against
My, with k = 8 and 1 = 3, which divides the network into the 8 blocks of the under-
lying DSBM. Although this is a specially constructed example, it highlights the different
equally valid structures that can be uncovered, emphasizing the importance of consider-
ing the correct motif (see Section 3.3.3) and demonstrating the value of this procedure
above standard spectral clustering.

4.5 Example 3
In our final example, we demonstrate clustering the source vertices of bipartite networks,
using the collider motif as in Algorithm 3. Clustering the destination vertices with the
expander motif is exactly analogous (by simply reversing edge directions), so we do not
demonstrate it explicitly. Note also that in bipartite graphs, all instances of the collider or
expander motifs are structural, so we need not compare functional and structural MAMs.
We illustrate this with two experiments. In the first one, we show that in certain net-
works, edge weights are important for our collider method to perform well. In the second
experiment, we compare against an alternative method for clustering weighted bipartite
networks, showing that under certain conditions, our collider method performs better.

4.5.1 Experiment 1

This example illustrates the advantages of using weights for bipartite clustering. We

use a weighted BSBM with block counts ks = kp = 2, block sizes nk = ns =
1 9 oo, . . 0.15 0.1 oo,
Np = Np = 100, bipartite connection matrix Fy = 01 01s)’ and bipartite

W 1 50
50 wy
been constructed so that vertices in S; are slightly more likely to connect to vertices

weight matrix Ap = ( ) where w is a varying parameter. This network has

in D than to vertices in D2, and vice versa for Sy. This makes the source vertex clus-
ters Sj and S2 weakly distinguishable when not considering edge weights. However,
the edge weights exhibit the same preferences, and this effect becomes stronger as w
increases.

We test the performance of Algorithm 3 for clustering the source vertices (using the
collider motif), with parameters ks = /]s = 2 on this model. We compare the results
against those obtained by ignoring the edge weights. Fig. 8 shows that the weights in this
model allow the structure to be recovered well when the weighting effect is large enough.
Underwood et al. Applied Network Science (2020) 5:62 Page 19 of 41

 

 

 

0.15| 0.1 wi | 50 (s)—>(2:)
fy = Ap = ><

0.1 |0.15 50 | wi (3 )—>(?.)

0.8 —-+— Weighted
—— Unweighted

 

 

 

 

 

 

 

 

 

 

0.6
= 04
me
0.0
90 60 70 80 90 100 110 120
Wy)

Fig.8 Top: BSBM parameters for Example 3 Experiment 1. Left panel is the connection matrix, middle panel
is the weight matrix (see Eq. 6 and Section 4.2 for details), and right panel is a schematic diagram of the
structure. Bottom: performance of our bipartite collider method with and without edge weights. We
perform 100 repeats, and error bars are one sample standard deviation

 

 

 

4.5.2 Experiment 2

In this final experiment, we show the advantages of using the collider motif over simply
clustering using the matrix AA', where A €[0,00)!°!*!! is the weighted bipartite adja-
cency matrix of the graph (Chessa et al. 2014). We use a weighted BSBM with block counts

ks = 2,kp = 3, block sizes nk = ns = Np = nz, = nd, = 200, bipartite connection
0.9 0.3 0 w, 10

matrix Fy = , and bipartite weight matrix Ap = ' , where w is
0 0.3 0.9 0 lw

a varying parameter.

This model has been constructed such that vertices in S; are more likely to be con-
nected to D, than to D2, and similarly vertices in Sp are more likely to be connected to D3
than to D2. However, the weights show a reverse preference (for w; < 1, as in our model),
with larger weights assigned to the lower-probability edges. Note that in this regime where
weights are small, there is a significant probability of the Poisson weight variables being
zero, removing edges which might otherwise have had a high probability of existing.

The results are shown in Fig. 9, which illustrates that our collider method (Algorithm 3
with ks = ls = 2) is better at distinguishing the source vertex clusters S, and Sz com-
pared to the method based on AA!. Although it must be made clear that the model
has been specifically constructed to do this, and that this effect occurs only for a lim-
ited parameter set, it gives an example of the different behavior observed when using
a product-based weight formulation (Section 3.1). We explore this further in real world
data in Section 5.3. For our collider method, the expected similarity between two source
vertices in the same cluster directly depends on w, while the expected similarity between
two source vertices in different clusters is fixed. Hence for large enough values of wj,
our collider method performs well. However, for the AA! method, the expected similar-

ity between two source vertices in the same cluster depends on w% (since AA! contains
Underwood et al. Applied Network Science (2020) 5:62 Page 20 of 41

 

= ao leal o= Se
0 103) 0.9 O |] 1 | w (sa
*@)

 

 

 

 

 

 

 

 

 

 

 

—}— Collider motif
1.0 —+— AA! method

   

0.8
re 0.6
<
0.4
0.2
0.0
0.06 0.08 0.10 0.12 0.14
Wy

Fig.9 Top: BSBM parameters for Example 3 Experiment 2. Left panel is the connection matrix, middle panel
is the weight matrix (see Eq. 6 and Section 4.2 for details), right panel is a diagram of the block structure, with
arrow widths representing connection probabilities. Bottom: performance of our bipartite collider method
vs. clustering based on AA. We perform 100 repeats, and error bars are one sample standard deviation

 

 

 

squared edge weights), which in this model is small (as w; < 1). Hence the AA' method
does not perform so well on this model.

5 Applications to real world data

This section details the results of our proposed methodology on a number of directed
networks arising from real world data sets. We show that weighted edges and motif-
based clustering allow various structures to be uncovered in migration data with the
US-MIGRATION network, while the US-POLITICAL-BLOGS network demonstrates how
motif-based methods can control misclassification error for weakly-connected vertices,
how sweep profiles can be used to select a motif, and how regularization can affect
clustering. Finally, we consider the bipartite territory-to-language network, UNICODE-
LANGUAGES, and show that when using our bipartite clustering method, mean-weighted
motifs can produce more desirable clusters than their unweighted or product-weighted

counterparts.

5.1 US-MIGRATION network

The first data set is the US-MIGRATION network (U.S. Census Bureau 2002), consisting
of data collected during the US Census in 2000. Vertices represent the 3075 counties in 49
contiguous states (excluding Alaska and Hawaii, and including the District of Columbia).
The 721432 weighted directed edges represent the number of people migrating from
county to county, capped at 10000 (the 99.9th percentile) to control large entries, as in
(Cucuringu et al. 2019b).
Underwood et al. Applied Network Science (2020) 5:62 Page 21 of 41

We test the performance of Algorithm 2 with three selected motifs: M;, M6 and Mog
(see Fig. 1). M, gives a spectral clustering method with naive symmetrization. Mg rep-
resents a pair of counties exchanging migrants, with both also receiving migrants from a
third. Mo is a path of length two, allowing counties to be deemed similar if they both lie
on a heavy-weighted 2-path in the migration network. These motifs give a representative
sample, including a triangle and a non-triangle motif, and results with the other motifs
(both functional and structural) can be found in Figs. 19 and 20 in Appendix E.

Figure 10 plots maps of the US, with counties colored by the clustering obtained using
Algorithm 2 with k = / = 7. The top row shows clusterings from the unweighted graph,
while those in the bottom row are from the weighted graph. The advantage of using
weighted graphs is clear, with the clustering showing better spatial coherence (compared
with the fragmented blue clusters produced by the unweighted graph). Furthermore, as
suggested in Section 3.3.3, the different motifs induce different similarity measures, and
thus uncover distinct structures. For example, weighted Mg. and Mog both allocate a clus-
ter to the southern states of Mississippi, Alabama, Georgia and Tennessee, while weighted
M; identifies the northern states of Michigan and Wisconsin. Also, weighted Mg favors a
larger “central” region, which includes significant parts of Colorado, Oklahoma, Arkansas
and Illinois.

It is also interesting to investigate the cut imbalance ratio (Appendix C4) (Cucuringu
et al. 2019b) associated with these clusters. For each pair of clusters, it measures the
imbalance of migration flow from one to the other. Figure 11 indicates, for each method,
the first (resp. second) pair of clusters which exhibit the largest (resp. second largest)
cut imbalance ratio, with migration mostly occurring from the red counties to the blue
counties. We note that the domestic migration report from this census (U.S. Census
Bureau 2003) states that the South had the most in-migration and out-migration, with
in-migration accounting for over 60% of the region’s total. In Fig. 11, this is only consis-
tently observed (by coloring the South blue) when using weighted three-node motifs. The
report also states that out-migration accounts for over 64% of migration involving the
Northeast, and this is witnessed only by the motif Mg (by coloring the Northeast red). It
is also worth mentioning that the pattern of flow from Northeast to South uncovered by

 

 

Weighted Unweighted
NOD OF BP WN FR

 

Fig. 10 Motif-based clusterings of the US-MIGRATION network, for various functional motifs. Each county
(node) is colored by its cluster allocation. Top row: clusterings from the unweighted graph. Bottom row:
clusterings from the weighted graph. M, corresponds to using the symmetrized adjacency matrix

 

 

 
Underwood et al. Applied Network Science (2020) 5:62 Page 22 of 41

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

a
5.
Disa
oO
O
YH
&
OD
oe
OC ox
28
ct oF
- =
S
Oo
O
©
Tr
a
oS
OC,
Ow &
O &
45
S
OO
— wH
O °S3
= Ss
oT
S
O
O
©
WN
Fig. 11 Cut imbalance for functional motif-based clusterings of the US-MIGRATION network, for various
motifs. For each method, the pairs of clusters with largest and second largest cut imbalance ratio are colored,
with most migration flow occurring from red to blue. Top two rows: clusterings from the unweighted
graph. Bottom two rows: clusterings from the weighted graph. M, corresponds to using the symmetrized
adjacency matrix

 

 

 

Mg on the unweighted graph (top pair) and the weighted graph (second pair) bears sig-
nificant resemblance to the topmost imbalanced structure uncovered by the HERM-SYM
algorithm in Fig. 16 within (Cucuringu et al. 2019b).

Figure 12 displays the full cut imbalance ratio matrices (Appendix C4) associated with
each method. The (i,j)th matrix entry is positive if there is more migration flow from
cluster i to cluster 7 than from cluster j to cluster i (yielding an antisymmetric matrix),
and a value of +1/2 indicates uni-directional flow. We see that weighted Me. and Mo
produce clear “stripes” of blue and red in the matrices, where they identify clusters which
have more imbalanced migration. This again highlights the ability of weighted motifs to

uncover hidden structures (in this case corresponding to large-scale migration patterns).

5.2 US-POLITICAL-BLOGs network
The US-POLITICAL-BLOGS network (Adamic and Glance 2005) consists of data collected
two months before the 2004 US election. Vertices represent blogs, and are labeled by
their political leaning (“liberal” or “conservative”). Weighted directed edges represent the
number of citations from one blog to another. After restricting to the largest connected
component, there are 536 liberal blogs, 636 conservative blogs (total 1222) and 19024
edges. The network is plotted in Fig. 13.

Firstly we use sweep profiles (Shi and Malik 2000) with a few selected motifs to moti-

vate the use of motif-based clustering on this network. To construct a sweep profile, we
Underwood et al. Applied Network Science

(2020) 5:62

Page 23 of 41

 

M,

1 0 0.03 0.01 0.04 0.01 —0.04 —0.01
+, 2 0.03 0 0 001 —0.03 0 —0.03
oO
Y
B 3-001 0 0 0 0.01 —0.07 —0.02

a
O 4 —0.04-0.01 0 0 —0.05 —0.06 —0.03

ort

5 0.01 0.03 —0.01 0.05 0 —0.04 0.05

O%
SH
Gy 6 0.04 0 0.07 0.06 0.04 0 —0.04

Unweighted

7 0.01 0.03 0.02 0.03 —0.05 0.04 0
12 3 4 5 6 7
To cluster
1 0 0.01 0.01 —0.05 —0.01 —0.01 0.02
$4 2 -0.01 0 ~—0.01 —0.04 —0.01 —0.02 —0.05

wm 3 -0.01 0.01 0 001 0 002 0

luste

Od 0.05 0.04 0.01 0 0.03 —0.02 0.06

5 0.01 0.01 0 —0.03 0 —0.02 0.03

From

6 0.01 0.02 0.02 0.02 0.02 0 —0.02

Weighted

7 —0.02 0.05 0 —0.06 —0.03 0.02 0

12 3 4 5 6 7
To cluster

symmetrized adjacency matrix

 

1 0 0.05 000 NEB 002 0.03 —0.05

$2 0.05 0 0.01 0 0.02 0 —0.05
£

g 3 0.09 0.01 0 0.06 0.05 0.05 —0.03

S 4 013 0 01 0.06 0.07
5 5 0.02 0.02 ly 0 0.02 0.03
Fa 6 -0.03 0 —0.05 0.06 —0.02 0 on

7 0.05 0.05 0.03 —0.07 —0.03 0.1 0

12 3 4 5 6 7
To cluster

0 0 004/098) 002 0 —0.02

0 0 —0.01 0.07 —0.04 0 —0.06

0.04 0.01 0 0

oO 0.02 0.04 0 0.1 0

0.02 —0.01

0.02 0.01

me Wo NY fF

TU

From cluster

a

0 0 —0.02 0.05 —0.02 0 —0.07

7 0.02 0.06 0.01 BIS) oon 0.07 0

12 3 4 5 6 7
To cluster

Fig. 12 Cut imbalance ratio matrices for functional motif-based clusterings of the US-MIGRATION network, for
various motifs. Entry (i,/) is positive if most of the flow is in the direction i — /. Top row: clusterings from the
unweighted graph. Bottom row: clusterings from the weighted graph. Ms; corresponds to using the

Mog

1 0 0.01 0.05 0.06 0.03 0.01 —0.01
$1 2 0.01 0 0.06 —0.02 —0.05 —0.01 —0.04
oO
YY
M3 0.05 0.06 0 0.06 0.02 0.05 0.01
5
ee
O 4 —0.06 0.02 —0.06 0 —008 0 —007
& 5 0.03 0.05 0.02 0.08 0 0.02 0.06
es 6 0.01 0.01 -0.05 0 002 0 —0.07

7 0.01 0.04 —0.01 0.07 —0.06 0.07 0

12 3 4 5 6 7
To cluster
1 0 0.01 —0.01! 0.1 0.02 —0.04 0.02
s, 2 -0.01 0 0.02 0.01 —0.03 —0.01 —0.04
o
YY
DN 3 0.01 0.02 0.09 0.03 —0.03 0.02

5
oH
S 4 ol or a

5 0.02 0.03 —0.03 0.1 0 —0.01 0.04

From

6 0.04 0.01 0.03 0.07 0.01 0 —0.03

7 0.02 0.04 —0.02 0.08 —0.04 0.03 0

12 3 4 5 6 7
To cluster

 

 

order the vertices according to the first non-trivial eigenvector of the random-walk Lapla-

cian, and select a splitting point based on minimizing an objective function; in this case

the Ncut score (see Appendix C). Figure 14 exhibits visibly sharper minima for motifs

Mz and Mg than for M, (which corresponds to traditional spectral clustering), indicat-

ing that motif-based methods can produce more well-defined clusters (for the vertices

contained in the largest connected component of the MAM) than traditional methods on

this network.

In fact, traditional two-cluster spectral clustering performs very poorly on this net-

work, with one of the clusters containing just four vertices (circled in Fig. 13), which

are very weakly connected to the rest of the graph. However, motif-based clustering per-

forms significantly better. As discussed in Section 3.3.2, our framework tries to reduce

the misclassification error by only clustering the nodes which are in the largest connected

component of the MAM, and are therefore in some sense well connected to the graph. In

 

. ® Liberal

various motifs

 

@ Conservative

 

1.0
M, M2 7
Ms ae = & eMe <7 Ms; Ms
Ma Mi3 .
0.8 Mr Mi Ms
0.6
a
<
0.4
. 0.2
Ms
0.0 e
400 600 800 1000 1200
Number of clustered vertices

Fig. 13 Left: the US-POLITICAL-BLOGs network. Right: ARI score against number of clustered vertices, across

 

 
Underwood et al. Applied Network Science (2020) 5:62 Page 24 of 41

 

0.5 0.5 0.5

0.4 0.4 0.4
2 g 5
8 0.3 8 0.3 8 0.3
3 3 3
oC oO oC
Z, 0.2 Z, 0.2 Z, 0.2

0.1 0.1 0.1

Ms; M3 Ms
0.0 0.0 0.0
0 200 400 600 800 1000 1200 0 100 =200 300 400 500 600 0 200 400 600 800 1000 1200
Splitting point Splitting point Splitting point

Fig. 14 Sweep profiles for different motifs on the US-POLITICAL-BLOGS network. M, corresponds to using the
symmetrized adjacency matrix

 

 

 

this dataset, the choice of motif determines the trade-off between the number of vertices
assigned to clusters, and the accuracy of those clusters (see Fig. 13 for a plot of ARI score
against number of vertices clustered). For example, motif Mg clusters 1197 vertices with
an ARI of 0.82, while the more strongly connected M, only clusters 378 vertices, with an
improved ARI of 0.92. This is because the largest connected component of the MAM will
be smaller for more strongly-connected motifs such as M4.

To explore the classification performance of our reduced clustering method, we com-
pare its effectiveness with other approaches from the literature. Table 1 gives the ARI,
number of clustered vertices, normalized mutual information (NMI) (Nguyen et al. 2009),
and percentage error for various motifs on this network. We note that both of the motifs
Mz3 and Mg outperform the NMI score of 0.72 given by the degree-corrected stochastic
blockmodel in (Karrer and Newman 2011), and improve on the percentage error of 4.66%
given by the normalized spectral clustering procedure in (Li 2017), at the expense of not
assigning every vertex to a cluster.

We further compare our proposed method to an alternative approach for dealing with
disconnected vertices; namely regularization. We follow the method suggested by (Joseph
et al. 2016) and (Zhang and Rohe 2018) using the regularized Laplacian Lr, = I — (D+
tI)~!(G+11/n), where 1 is a matrix of all ones and t is a tuning parameter. Table 2 shows
how using this regularized Laplacian with t ~ d (the mean weighted vertex degree),
can improve the ARI performance of traditional (top row) and motif-based (second and
third rows) spectral clustering while still assigning all of the vertices to clusters. However
this regularization method is unable to reach the ARI scores of over 0.9 achieved by our
proposed method of motif-based clustering on the largest connected component of the
MAM (Table 1). Furthermore, regularization is sensitive to the choice of tuning parameter
t, and the default setting of t = d suggested by (Zhang and Rohe 2018) and (Qin and
Rohe 2013) performs rather poorly here.

Table 1 Performance of motif-based clustering on the US-POLITICAL-BLOGS network

 

 

Motif ARI Number of clustered vertices NMI Percentage error
M, 0.00 1222 0.00 48.2%
M3 0.90 586 0.83 2.6%

Me 0.84 1160 0.75 4.1%

 
Underwood et al. Applied Network Science (2020) 5:62 Page 25 of 41

Table 2 ARI scores for regularized traditional and motif-based spectral clustering on the
US-POLITICAL-BLOGS network

 

 

5 10 5 2 1 0.5 0.2 0.1 0.05 002 0.01 0005 0.002 0.001
M; 008 014 028 036 049 O81 O80 081 O81 082 082 0.00 0.00
M3 0.00 000 001 O02 004 O10 O14 O17 024 025 0.25 0.00 0.00
Msg 005 007 O13 028 O49 O58 062 O65 O71 075 0.80 0.80 0.80

 

5.3. UNICODE-LANGUAGES bipartite network

The UNICODE-LANGUAGES network (KONECT: The Koblenz Network Collection 2019)
is a bipartite network consisting of data collected in 2014 on languages spoken around the
world. Source vertices are territories, and destination vertices are languages. Weighted
edges from territory to language indicate the number of inhabitants (GeoNames 2019)
in that territory who speak the specified language. After removing territories with fewer
than one million inhabitants, and languages with fewer than one million speakers, there
are 155 territories, 270 languages and 705 edges remaining. We then restrict the net-
work to its largest connected component, and in doing so remove the territories of Laos,
Norway and Timor-Leste, and the languages of Lao, Norwegian Bokmal and Norwegian
Nynorsk. We test Algorithm 3 with parameters ks = 15 = kp = /p = 6 on this network
(such that each cluster in Table 3 contains at least 1% of the world’s population), compar-
ing three different motif weighting schemes: unweighted motifs, mean-weighted motifs
and product-weighted motifs, as in Section 3.1. For the source vertices, Fig. 15 plots maps

of the world with territories colored by the recovered clustering.

Table 3 Clustering the territories from the UNICO

collider motif

 

DE-LANGUAGES network using the mean-weighted

 

 

 

 

Cluster 1 Cluster 2 Cluster 3 Cluster 4 Cluster 5 Cluster 6
India Iran Mexico Russia China Japan
United States DR Congo Colombia Ukraine Indonesia S. Korea
Brazil Afghanistan Argentina Uzbekistan Vietnam N. Korea
Pakistan Saudi Arabia Peru Belarus Malaysia

Bangladesh Syria Venezuela Tajikistan Taiwan

Nigeria Céte d'Ivoire Ecuador Kyrgyzstan Cambodia

Philippines Burkina Faso Guatemala Turkmenistan Hong Kong

Ethiopia Niger Cuba Georgia Singapore

Germany Mali Bolivia Moldova Panama

Egypt Senegal Paraguay Latvia Mongolia

Turkey Tunisia El Salvador Estonia

Thailand Chad Nicaragua

France Guinea Costa Rica

United Kingdom — Somalia Uruguay

Italy Burundi Eq. Guinea

Myanmar Haiti

South Africa Benin

Spain Azerbaijan

Tanzania Togo

Kenya Libya

|Cluster 1| = 87 |Cluster 2| = 29 |Cluster 3] = 15 |Cluster 4| = 11 |Cluster 5] = 10 |Cluster 6] = 3

 
Underwood et al. Applied Network Science (2020) 5:62 Page 26 of 41

 

 

 

 

1

2

3

4

5

6

NA

1

2

3

4

Oo

6

NA

1

2

3

4

Oo

6

NA

Product—weighted

Fig. 15 Clustering the territories from the UNICODE-LANGUAGES network, using the collider motif. Top:
clustering the unweighted graph. Middle: motifs weighted using mean edge weight. Bottom: motifs
weighted using product of edge weights

 

Focusing first purely on the clusters produced by mean-weighted motifs, we observe
balanced clusters with good spatial coherence (middle panel in Fig. 15), from which
some language groups can be easily recognized. The top 20 territories (by population)
in each cluster for this mean-weighted scheme are given in Table 3. Cluster 1 is by far
the largest cluster, and includes a wide variety of territories. Cluster 2 contains sev-
eral Persian-speaking and African French-speaking territories, while Cluster 3 mostly
captures Spanish-speaking territories in the Americas. Cluster 4 includes the Slavic terri-
tories of Russia and some of its neighbors. Cluster 5 covers China, Hong Kong, Mongolia
and some of South-East Asia. Cluster 6 is the smallest cluster and contains only Japan and
the Koreas.
Underwood et al. Applied Network Science (2020) 5:62 Page 27 of 41

For the destination vertices, we present the six clusters obtained by Algorithm 3 with
mean-weighted motifs. Table 4 contains the top 20 languages (by number of speakers) in
each cluster. Cluster 1 is the largest cluster and contains some European languages and
dialects of Arabic. Cluster 2 is also large and includes English, as well as several South
Asian languages. Cluster 3 consists of many indigenous African languages. Cluster 4 cap-
tures languages from South-East Asia, mostly spoken in Indonesia and Malaysia. Cluster 5
identifies several varieties of Chinese and a few other Central and East Asian languages.
Cluster 6 captures more South-East Asian languages, this time from Thailand, Myanmar
and Cambodia.

Next, we return to the source vertices (territories) and compare the mean-weighted
scheme with the unweighted and product-weighted schemes, as illustrated in Fig. 15.
Unlike the mean-weighted approach, the unweighted partition fails to identify the
Chinese-speaking territories, which is likely to be related to the fact that this scheme
is unable to account for the large number of speakers in China. Further, it does not
identify Mexico and Argentina with other Spanish-speaking territories in the Americas.
Finally, the product-weighted motifs make no distinctions at all between territories in the
Americas, Africa and Western Europe, and instead identify a few much smaller clusters.

6 Conclusion and future work

Contribution We have introduced generalizations of MAMs to weighted directed
graphs and presented new matrix-based formulae for calculating them, which are easy to
implement and scalable. By leveraging the popular random-walk spectral clustering algo-
rithm, we have proposed motif-based techniques for clustering both weighted directed

Table 4 Clustering the languages from the UNICODE-LANGUAGES network using the mean-weighted
expander motif

 

 

 

Cluster 1 Cluster 2 Cluster 3 Cluster 4 Cluster 5 Cluster 6
Spanish English Swahili Indonesian Chinese Thai
Arabic Hindi Kinyarwanda Javanese Wu Chinese N.E. Thai
Portuguese Bengali Somali Malay Korean Khmer
French Urdu Luba-Lulua Sundanese Xiang Chinese N. Thai
Russian Punjabi Kikuyu Madurese Hakka Chinese S. Thai
Japanese Telugu Congo Swahili Minangkabau Minnan Chinese = Shan
German Marathi Luyia Betawi Gan Chinese Pattani Malay
Turkish Vietnamese Ganda Balinese Kazakh

Persian Tamil Luo Buginese Uighur

Italian Lahnda Sukuma Banjar Sichuan Yi

Egyptian Arabic Filipino Kalenjin Achinese Mongolian

Polish Gujarati Lingala Sasak Zhuang

Nigerian Pidgin Kannada Nyankole Makasar Tibetan

Ukrainian Pushto Gusii Lampung Api

Dutch Malayalam Kiga Rejang

Algerian Arabic Oriya Soga

Moroccan Arabic Burmese Luba-Katanga

Hausa Bhojpuri Meru

Azerbaijani Amharic Teso

Uzbek Oromo Nyamwezi

|Cluster 1] = 120 |Cluster2}=90 |Cluster3}=25 |Cluster4/=15 = |Cluster5|=13 |Cluster 6] = 7

 
Underwood et al. Applied Network Science (2020) 5:62 Page 28 of 41

graphs and weighted bipartite graphs. We demonstrated using synthetic data examples
that accounting for edge weights and higher-order structure can be essential for good
cluster recovery in directed and bipartite graphs, and that different motifs can uncover
different but equally insightful clusters. Applications to real world networks have shown
that weighted motif-based clustering can reveal a variety of different structures, and
that it can reduce misclassification rate, performing favorably in comparison with other
methods from the literature.

Future work There are limitations to our proposed methodology, which raise a number
of research avenues to explore. While our matrix-based formulae for MAMs are sim-
ple to implement and scalable, there is scope for further computational improvement.
As mentioned in (Benson et al. 2016), fast triangle enumeration algorithms (Demeyer et
al. 2013; Wernicke 2006; Wernicke and Rasche 2006) may offer superior performance at
scale for triangular motifs, but MAMs for motifs with missing edges are inherently denser.
The implementation could also be optimized to further exploit any sparsity structures in
the network, rather than relying on general-purpose linear algebra libraries. More recent
work on combinatorial graphlet counting (Ahmed et al. 2015) or vertex orbit counting
(Pashanasangi and Seshadhri 2020) could also potentially yield further computational
improvements. Another shortcoming of our matrix-based formulae is that, unlike motif
detection algorithms such as FANMOD (Wernicke and Rasche 2006), they do not eas-
ily extend to motifs on four or more vertices. While we believe that this extension is in
principle possible using tensor operations rather than matrix operations, it is currently
beyond the scope of the work.

We have seen that choosing the correct motif for clustering a network can play a crucial
role (Section 4.4), and while we have suggested some methods for doing so (Section 3.3.3),
it may be that other techniques can also be used to guide the motif selection process.
We would also be interested in seeing more approaches to dealing with disconnected
MAMs, perhaps involving some criterion for when a connected component is “large
enough” to be worth keeping, or a deeper exploration of regularization methods for motif-
based spectral clustering. Extensions to our methodology could involve further analysis
of the differences between functional and structural MAMs, between different types of
Laplacians (Von Luxburg 2007), or between different weighted stochastic graph models,
perhaps following an exponential family method (Aicher et al. 2013). Also, connections
between motif-based clustering and hypergraph partitioning (Li and Milenkovic 2017; Li
and Milenkovic 2018; Veldt et al. 2020) would be worth further investigation.

Further experimental work would also be interesting. We would like to explore the util-
ity of our framework on additional real data, and suggest that collaboration networks such
as (Leskovec and Krevl 2007), transportation networks such as the airports network in
(Frey and Dueck 2007), and bipartite preference networks such as (Clauset et al. 2007)
could be interesting. Direct comparison of results with other state-of-the-art clustering
methods from the literature could also be insightful; suitable benchmarks for perfor-
mance include the Hermitian matrix-based clustering method in (Cucuringu et al. 2019b),
the Motif-based Approximate Personalized PageRank (MAPPR) in (Yin et al. 2017), and
TECTONIC from (Tsourakakis et al. 2017). Other established and fast methods from the
literature on directed networks include SAPA (Satuluri and Parthasarathy 2011) and DI-
SIM (Rohe et al. 2016), which respectively perform a degree-discounted symmetrization;
Underwood et al. Applied Network Science (2020) 5:62 Page 29 of 41

and a combined row and column clustering into four sets using the concatenation of the
left and right singular vectors.

Further potential extensions of our work pertain to the detection of overlapping clus-
ters, allowing nodes to belong to multiple groups (Li et al. 2016), to the detection of
core—periphery structures in directed graphs (Elliott et al. 2019a), as well as implications
for existing methods on network comparison (Wegner et al. 2018), anomaly detection in
directed networks (Elliott et al. 2019b), and ranking from a sparse set of noisy pairwise
comparisons (Cucuringu 2016). Furthermore, incorporating our pipeline into deep learn-
ing architectures is another avenue worth exploring, building on the recent MOTIFNET
architecture (Monti et al. 2018), a graph convolutional neural network for directed graphs,
or SIGAT (Huang et al. 2019), another recent graph neural network which incorporates
graph motifs in the context of signed networks which contain both positive and negative

links (Cucuringu et al. 2019a).

Appendix A: Motif adjacency matrix formulae

We give explicit matrix-based formulae for mean-weighted motif adjacency matrices M
for all simple motifs M on at most three vertices, along with the anchored motifs M oj
and Mexpa. Entry-wise (Hadamard) products are denoted by o. Table 5 gives our dense
formulation of functional MAMs. For the dense formulation of structural MAMs, simply
replace Jy, J, and G with Jo, J;, and G, respectively. For the sparse formulation of functional
MAMs, replace J, with 1—J, and expand and simplify the expressions as in Section 3.4. For
the sparse formulation of structural MAMs, replace J and G with J, and G, respectively.
Also replace Jo with 1 — + J), where J = J, + I + Ja, and expand and simplify the

expressions.

Appendix B: Proofs

Proof B.1 (Proposition 3.1, MAM formula) Consider Eg. 1. We sum over functional
instances M = H < G such that {i,j} € A(H). This is equivalent to summing over
{ko,.-.sKm—-1} © Vando € Sy, 4, such that k, are all distinct and

(u,v) €EM => (Kowkov) € E. (f) (7)

This is because the vertex set {ko,...,k,,—-1} C V indicates which vertices are present
in the instance H, and o describes the mapping from V,, onto those vertices: u b> kgy.
We take o € Sy, , to ensure that {i,j} € A(H) (since i = ky, j = k,), and that instances
are counted exactly once. The condition (7) is to check that H is a functional instance of

M in G. Hence
1
Mgr = = Y- If{fi ¢ AAD} > Wee)
MI MzH<g ecéH
1
== YL YE Mkvalldistinet, ()) }) WO.
lEm| (ka, -okin-1} 0554, 4 ecEy

For the first term, by conditioning on the types of edge in Eyy:
Underwood et al. Applied Network Science

Table 5 Dense formulation of mean-weighted functional motif adjacency matrices

(2020) 5:62

Page 30 of 41

 

 

 

 

Motif C C’ iunc
Mz, G+Gl
Ma Gq
My J. 0 UG) + J 0(G) +G!oW) 3(C+C)
J¥ 0 UgG) + J" 0 (Ga) + Gl 0 UJ)
M2 + J 0 UGqy) + J! © (Gg) + Gl © (Wy) 5(C+C')
+ Jy o UG) +Jg0(G) + Ggo VU)
Jo UgGg) + Jo (Gag) + Go Uasa)
M3 + Jg 0 UgG) + Jg o (GgJ) + Gg o UdJ) 2(C+C')
+ Jg o UGg) + Jg o (Gla) + Gg o Wa)
M4 Jg.0 UaGa) + Ja 0 (GaJa) + Ga © Uda) aC
Jo (UG) +Jo(G) +GoWU/
Ms +JoUG')+Jo(G')+GoW/) t(c+C)
t+Jo(J'G+Jo(GU)+Go(V)
Me Jo UGg) + Jo (Gilg) + Go Wg) +Jg 0 U'G) Gyo U1) 7(C+C1+C)
Jg 0 UG') + Jg 0 (GJ) 7,
My; Jo UgG) + Jo (GgJ) + Go UgJ) + 7(C+C'+C)
+ Gg o WU)
Meg Jo(Gn) + Go Wn) Jno I'G) + Jn 0 (GTI) 5(c+C'+C)
Jo UnG!) + Go Uns") + Jn 0 UG) -
+ In o (GJ) +J0 (Gn) + Go Jy)
Myo Jo UnG) + Go UpJ) Jn 0 UG") + Jn 0 (GJ) 5(c+c'+C)
Jg 0 (Gn) + Gg o Wn) + Jn o UaG) _
My) 3 (C +C )
+ Jno (Gg/) + J 0 (GgIn) + Go Un)
Jg 0 UnG) + Gg o Uns) + Jn o UGg) _
M2 3 (C+ C )
+ Jy o (Gg) +J0 UnGg) + Go Ung)
M33 Jg 0 (GgJn) + Gg © Uddin) + In 0 UgGa) 7 (C+C')
Meo Jn 0 UG") 5(C+C')
Mexps Jn 0 UG) 5(C+C')

 

I {k, all distinct, (+)} = | | Mkou 4 kov}

Assuming {k,, all distinct, (+)}, the second term is

0
EM

x [ [ MKoukov) € &}

EM

x | | Mkow kor) € E and(kev, kou) € E}

d
EM

= [ [On) Keruskor | route: [ [Gad kouskor
ay, EM EKY

__ func
ko *
Underwood et al. Applied Network Science (2020) 5:62 Page 31 of 41

>) We) = 2 W ((kou Kov)) + >| (W((Kow kov)) + W (kos kou)))

ecEy Ev,
= -¥ Gkowkov + 2G key
_ -func
~~ ape

as required. For Eq. 2, we simply change (7+) to (+) to check that an instance is a structural

instance
(u,v) € EM <> (Koy kev) € € (+)

Now for the first term, the following holds true

I {k,, all distinct, (£)} = I] Itkew Kev) € E and(keys key) € €}
EN
x | | Mkou kov) € E and(kov,kou) ¢ €}
EM
x I] I{(KousKov) € E and(Key, Kou) € E}
EN
= | [Uo dkoukov | [Osdkoukor | [|Oakouskor
EN EM EN
_— struc

ko

Assuming {k;,, all distinct, (+)}, the second term is given by

Yd) We) =) Whos kov)) + > (W((Kow Kov)) + W((kovs Kou)))

ecExy EX Eq,
=) (Gs)ksukov + > (Ga) keuskov
EX Eq,
= Ge

Proof B.2 (Proposition 3.2, Colliders and expanders in bipartite graphs) Consider Eq. 3
and the collider motif M, oy. Since G is bipartite, Miunc — Meer =: M¢ou, and by Table 5,
Meoll = Jn Oo en + GJ"). Hence

1 T T
(Mooll) ij = 5 Uni JG +G/ ji

Ii £ j} ~ 5 (Tix Gx + Girlix)

keV
1
=li4#j})- SIGH GK € EF LWGH) + WK)
keV
= li 4) D3 [Wig k) + WG) .
uk Pree

Similarly for the expander motif Mexpa = y J,0 J'G + G'J), which yields Eq. (4):
Underwood et al. Applied Network Science (2020) 5:62 Page 32 of 41

esa) gt Tr,
(Mexpa)ij — 5 Uni J G+G ij
1
=IiAAD) 5(WKdD) +WKK/)].

keS
(k,i) (kK j)EE

Proof B.3 (Proposition 3.3, Complexity of MAM formula) Suppose m < 3 and consider
M"C, The adjacency and indicator matrices of G are given by

(1) J=l{G > 0}, (5) Jn = TUnxn = 0},
(2) Jo=WG+G' =O0}oh, (6) Ja=JoJ",
(3) Js=J—Ja, (7) G;=Gokj,,

(4) Ga=(G+G')oJg,

and computed using four additions and four element-wise multiplications. fiance is a

product of at most three factors, and Gyunc contains at most three summands, thus

func -func
S J k,o Gk oc
knEV
is expressible as a sum of at most three matrices, each of which is constructed with at most
one matrix multiplication (where {k,;,kos} 4 {i,j}) and one entry-wise multiplication
(where {k;, kas} = {i,j}). This is repeated for eacho € Sy, , (at most six times) and the

results are summed. Calculations are identical for MS"™"°.

Appendix C: Spectral clustering
We provide a summary of traditional random-walk spectral clustering and show how it
applies to motif-based clustering.

Overview of spectral clustering

For an undirected graph, the objects to be clustered are the vertices of the graph, and a
similarity matrix is provided by the graph’s adjacency matrix G. To cluster directed graphs,
the adjacency matrix must first be symmetrized, perhaps by considering G + G' (Meila
and Pentney 2007). This symmetrization ignores information about edge direction and
higher-order structures, and can lead to poor performance (Benson et al. 2016). Spectral
clustering consists of two steps. Firstly, eigendecomposition of a Laplacian matrix embeds
the vertices into R’. The & clusters are then extracted from this space.

Graph laplacians

The Laplacians of an undirected graph are a family of matrices which play a central role in
spectral clustering. While many different graph Laplacians are available, we focus on just
the random-walk Laplacian, for reasons concerning objective functions, consistency and
computation (Von Luxburg et al. 2004; Von Luxburg 2007). The random-walk Laplacian
of an undirected graph G with (symmetric) adjacency matrix G is given by

Lew i= 1—D'G,

where J is the identity and Dj := yj Gj is the diagonal matrix of weighted degrees.
Underwood et al. Applied Network Science (2020) 5:62 Page 33 of 41

Graph cuts
Graph cuts provide objective functions which we seek to minimize while clustering the
vertices of a graph.

Definition 3.4 Let G be a graph. Let P,,..., Px be a partition of V. Then the normalized
cut (Shi and Malik 2000) of G with respect to P\,..., Px is

l k

Neutg(P1,...) PR) = 5 d

cut(P;, P;)
vol(P;)

where cut(P;, P;) := ueP;, veV\P; Gyy and vol(P;) := yueP; Duu-

Note that more desirable partitions have a lower Ncut value; the numerators penal-
ize partitions which cut a large number of heavily weighted edges, and the denominators
penalize partitions which have highly imbalanced cluster sizes. It can be shown (Von
Luxburg 2007) that minimizing Ncut over partitions P),...,P, is equivalent to find-
ing the cluster indicator matrix H € R”** minimizing Tr (H'(D —G)H ) subject to
Ay = vol(P,)~2 I{v; < Pj} (hy), and H'DH = I. Solving this problem is in general NP-
hard (Wagner and Wagner 1993). However, by dropping the constraint (+) and applying
the Rayleigh Principle (Liittkepohl 1996), we find that the solution to this relaxed prob-
lem is that H contains the first k eigenvectors of L-w as columns (Von Luxburg 2007). In
practice, to find k clusters it is often sufficient to use only the first / < k eigenvectors of
Lrw.

Cut imbalance ratio
Given a partition of a directed graph, cut imbalance ratio gives a notion of flow imbalance
between each pair of clusters.

Definition 3.5 Let G be a graph. Let P\,..., Px be a partition of V. Then the cut
imbalance ratio (Cucuringu et al. 2019b) of G from P; to P; is

1 cut(P;, Pj) — cut(P;, Pi)
2 cut(P;, P;) + cut(P;, Pi)

where cut(P;, Pj) := D ueP i, veP; Guy.

CIRg (Pi, Pj) =

The cut imbalance ratio takes values in [-4; S| with positive values indicating more
flow from P; to P; and negative values indicating more flow from P; to Pj. The cut
imbalance ratio matrix is the antisymmetric k x k matrix with (i,j)th entry equal to

CIRg (Pi; Pj).

Cluster extraction

Once Laplacian eigendecomposition has been used to embed the data into R’, the clusters
may be extracted using a variety of methods. We propose k-means++ (Arthur and Vassil-
vitskii 2007), a popular clustering algorithm for data in R’, as an appropriate technique.
It aims to minimize the within-cluster sum of squares, based on the standard Euclidean
metric on R’. This makes it a reasonable candidate for clustering spectral data, since
the Euclidean metric corresponds to notions of “diffusion distance” in the original graph
(Nadler et al. 2006).
Underwood et al. Applied Network Science (2020) 5:62 Page 34 of 41

Random-walk spectral clustering

Algorithm 1 gives random-walk spectral clustering (Von Luxburg 2007), which takes a
symmetric connected adjacency matrix as input. We drop the first column of H (the first
eigenvector of L,w) since although it should be constant and uninformative, numerical
imprecision may give unwanted artifacts. It is worth noting that although the relaxation
used in Appendix C.3 is reasonable and often leads to good approximate solutions of the
Ncut problem, there are cases where it performs poorly (Guattery and Miller 1998). The
Cheeger inequality (Chung 2005) gives a bound on the error introduced by this relaxation.

Motif-based random-walk spectral clustering

Algorithm 2 gives motif-based random-walk spectral clustering. The algorithm forms
a motif adjacency matrix, restricts it to its largest connected component, and applies
random-walk spectral clustering (Algorithm 1) to produce clusters. The most computa-
tionally expensive part of Algorithm 2 is the calculation of the MAM using a formula from
Table 5, as noted by (Benson et al. 2016) for their unweighted MAMs. The complexity of
this is analyzed in Section 3.4.

Bipartite spectral clustering

Algorithm 3 gives our procedure for clustering a bipartite graph. The algorithm uses the
collider and expander motifs to create similarity matrices for the source and destination
vertices respectively (as in Section 3.2), and then applies random-walk spectral clustering
(Algorithm 1) to produce the partitions.

 

Algorithm 1: Random-walk spectral clustering
Input: Symmetric adjacency matrix G, number of clusters k, dimension /
Output: Partition P),..., Px
1 function RWSpectClust (G,k,/):

Construct the weighted degree matrix Dj <— i Gi
Construct the random-walk Laplacian matrix Lry < 1 — D-!G
Let H have the first / eigenvectors of L;w as columns
Drop the first column of H
Run k-means++ on the rows of H with k clusters to produce 7,..., Px
return 7),..., Px

Algorithm 2: Motif-based random-walk spectral clustering

Input: Graph G, motif M, number of clusters k, dimension /
Output: Partition P),..., Px
1 function MotifRWSpectClust (G,M,k,1):
Construct the motif adjacency matrix M of the graph G with motif M

Let M be M restricted to its largest connected component, C
P1,..., Pe < RWSpectClust (M, k,1)
return ?,..., Px

 
Underwood et al. Applied Network Science (2020) 5:62

 

     
 

1.0
0.8
0.6
a
<x
0.4
0.2 Ms + Mio
—— Msg + Myo no weight
0.0 + MM;
50 60 70 80 90 100 110 120
Wy)
Fig. 16 Exploring the performance of structural MAMs based on Mg and Mig on Example 1 (see Fig. 5). Each
block contains 100 nodes. We compare both to the unweighted case, and to the symmetrized case. We
perform 100 repeats, and error bars are one sample standard deviation

 

 

 

Appendix D: Additional synthetic results
In this section we present additional results for some of our synthetic experiments.

Example 1 In Fig. 16 we present the results for structural motifs, to complement the
functional motifs presented in the main paper. We note that when we consider structural
motifs, the unweighted motifs perform better but are still outperformed by our weighted
method.

Example 2 — Experiment 1 In Fig. 17 we present the results for the functional motifs
for Example 2 Experiment 1. As noted in the main paper, our approaches outperform the
baseline, but we do not observe the same bi-modal structure, with M1, outperforming all
approaches for q, < 0.6, and without the recovery in performance for high values of q1.

Example 2 — Experiment 2 In Fig. 18 we present the structural version of Example 2

Experiment 2. We observe the same structures as we observe for the functional version,

Algorithm 3: Bipartite random-walk spectral clustering

Input: Bipartite graph G, source clusters ks, destination clusters kp, source
dimension /s, destination dimension /p
Output: Source partition S),...,S,,, destination partition D),..., Dx,
1 function BipartiteRWSpectClust (G,ks,kp,ls,lp):
Construct the collider motif adjacency matrix M,oy of the graph G
Construct the expander motif adjacency matrix Mexpa of the graph G

Meo < Meou[S; S] ; [> restrict rows and columns of M,o to S

Mexpa <- Mexpal D, PI ; > restrict rows and columns of Mexpa to D
Sj,...,Skg <—RWSpectClust (Moo, ks, ls)

Di, ee ey Dkp < RWSpectClust (Mexpa; Kp, lp)

return Sj,...,S,, and Dj,...,Dxp

 

Page 35 of 41
Underwood et al. Applied Network Science (2020) 5:62 Page 36 of 41

 

 

1.0 —— M,
| M,
0.8 —+— M2
—|— Mg
0.6
Qc
<
0.4
0.2
0.0
0.0 0.2 0.4 0.6 0.8 1.0
qd
Fig. 17 Performance on Example 2 Experiment 1 using functional MAMs. We compare with the standard
symmetrization M;. We perform 100 repeats, and error bars are one sample standard deviation

 

 

with motifs each highlighting a different but equally relevant structure. Finally the sym-
metrized adjacency matrix (M.;), for which each of the blocks are indistinguishable, does
not robustly identify the higher-order structures for k = 2, but can uncover the blocks
when clustering with k = 8 and/ = 3.

Appendix E: Additional real world results

In this section we present additional results for some of our real world experiments.

US-MIGRATION network Fig. 19 plots clusterings obtained from the US-MIGRATION
network using all 15 weighted functional motifs. Note how the different motifs uncover
a variety of different clusterings, and also that they all display good spatial coherence.
For completeness, Fig. 20 shows the equivalent plots for structural motifs. Note that

motifs Mg and Mg, are bi-directional cliques on two and three vertices respectively,

 

Vg
Vy
Ve
V5
V4
V3
V2
Vi

 

Ms Mg Mio Ms Mg (8,3)

Fig. 18 The detected groups uncovered by each method using structural motifs, with k = 2 and / = 2, with
the exception of the last column which has k = 8, / = 3. We test 100 replicates and present the results as
columns in the plot. We order and color the columns as in Fig. 7. While the clustering assignments may
contain some errors, the results are relatively robust across replicates

 

 
Underwood et al. Applied Network Science (2020) 5:62 Page 37 of 41

 

 

 

Fig. 19 Weighted functional motif-based clusterings of the US-MIGRATION network, for all motifs on at most
three nodes. Each county (node) is colored by its cluster allocation

 

 

 

so their functional and structural MAMs are identical. The spatial coherence deterio-
rates for certain structural motifs, and cluster sizes are occasionally less balanced. We
believe this is to do with the high local density of the migration network, preventing
some motifs from appearing as structural instances in certain places (see Section 4.4 for
another example of structural motifs exhibiting this filtering property, which may or may
not be desirable, depending on the application). Note that this effect is most pronounced
for the motifs containing single edges (i.e. excluding Mg, M4 and M3), because
structural instances of single edges require an edge in precisely one direction, filtering
out pairs of nodes which exhibit either no mutual migration or bi-directional mutual

migration.
Underwood et al. Applied Network Science (2020) 5:62 Page 38 of 41

 

 

 

 

Fig. 20 Weighted structural motif-based clusterings of the US-MIGRATION network, for all motifs on at most
three nodes. Each county (node) is colored by its cluster allocation

Ne S

 

 

Abbreviations
ARI: Adjusted Rand index; BSBM: Bipartite stochastic block model; DSBM: Directed stochastic block model; ER:
Erdds-Rényi; MAM: Motif adjacency matrix

Acknowledgments
We would like to thank Lyuba Bozhilova for her feedback on this work. We would also like to thank Microsoft for their
generous donation of Azure credits to The Alan Turing Institute which made this work possible.

Authors’ contributions

WGU developed the methodology, wrote the R code, performed the bipartite synthetic experiments and analyzed the
real world data. AE wrote the Python code, contributed to the sparse methodology, and performed the directed
synthetic experiments. MC designed and supervised the study. All authors wrote, edited and approved the manuscript.

Funding
Andrew Elliott and Mihai Cucuringu acknowledge support from the EPSRC grant EP/N510129/1 at The Alan Turing
Institute and Accenture PLC.
Underwood et al. Applied Network Science (2020) 5:62 Page 39 of 41

Availability of data and materials
All data sets are cited and are publicly available online. Source code in R and Python is available at https://github.com/
wgunderwood/motifcluster.

Competing interests
The authors declare that they have no competing interests.

Author details

"Department of Statistics, University of Oxford, 24-29 St. Giles, Oxford, OX1 3LB, UK. 7Department of Operations Research
and Financial Engineering, Princeton University, Sherrerd Hall, Charlton Street, Princeton 08544, NJ, USA. The Alan Turing
Institute, British Library, 96 Euston Road, London NW1 2DB, UK. School of Mathematics and Statistics, University of
Glasgow, Glasgow, GL12 8QQ UK.

Received: 23 March 2020 Accepted: 26 July 2020
Published online: 10 September 2020

References

Adamic LA, Glance N (2005) The political blogosphere and the 2004 US election: Divided they blog. In: Proc. of the 3rd
Intl. Workshop on Link Discovery. ACM, New York. pp 36-43

Ahmed NK, Neville J, Rossi RA, Duffield N (2015) Efficient graphlet counting for large networks. In: 2015 IEEE International
Conference on Data Mining. IEEE, New York. pp 1-10

Aicher C, Jacobs AZ, Clauset A (2013) Adapting the Stochastic Block Model to Edge-Weighted Networks. ArXiv preprint.
https://arxiv.org/abs/1305.5782. Accessed 11 Feb 2020

Aicher C, Jacobs AZ, Clauset A (2014) Learning latent block structure in weighted networks. J Compl! Netw 3(2):221-248,.
https://doi.org/10.1093/comnet/cnu026

Albert R (2005) Scale-free networks in cell biology. J Cell Sci 118(21):4947-4957

Arthur D, Vassilvitskii S (2007) k-means++: The advantages of careful seeding. In: Proceedings of the Eighteenth Annual
ACM-SIAM Symposium on Discrete Algorithms. Society for Industrial and Applied Mathematics, Philadelphia.
pp 1027-1035

Benson AR, Abebe R, Schaub MT, Jadbabaie A, Kleinberg J (2018) Simplicial closure and higher-order link prediction. Proc
Natl Acad Sci 115(48):11221-11230. https://doi.org/10.1073/pnas.1800683115

Barabasi A.-L, Albert R (1999) Emergence of scaling in random networks. Science 286(5439):509-512

Benson AR, Gleich DF, Leskovec J (2016) Higher-order organization of complex networks. Science 353(6295):163-166

Cheeger J (1969) A lower bound for the smallest eigenvalue of the Laplacian. In: Proceedings of the Princeton
Conference in Honor of Professor S. Bochner. Princeton University Press, Princeton

Chessa A, Crimaldi |, Riccaboni M, Trapin L (2014) Cluster analysis of weighted bipartite networks: a new copula-based
approach. PLoS ONE 9(10):1-12

Chung F (2005) Laplacians and the Cheeger inequality for directed graphs. Ann Comb 9(1):1-19

Clauset A, Tucker E, Sainz M (2007) Filmtipset user movie ratings. Colo Index Compl Netw. https://icon.colorado.edu/.
Accessed 15 Apr 2019

Cucuringu M (2016) Sync-rank: Robust ranking, constrained ranking and rank aggregation via eigenvector and SDP
synchronization. IEEE Trans Netw Sci Eng 3(1):58-79

Cucuringu M, Davies P, Glielmo A, Tyagi H (2019a) SPONGE: A generalized eigenproblem for clustering signed networks.
In: AISTATS 2019. PMLR

Cucuringu M, Li H, Sun H, Zanetti L (2019b) Hermitian matrices for clustering directed graphs: insights and applications.
ArXiv preprint. https://arxiv.org/abs/1908.02096. Accessed 19 Feb 2020

Demeyer S, Michoel T, Fostier J, Audenaert P, Pickavet M, Demeester P (2013) The index-based subgraph matching
algorithm (ISMA): Fast subgraph enumeration in large networks using optimized search trees. PLoS ONE 8(4):1-15.
https://doi.org/10.1371/journal.pone.0061 183

Donath WE, Hoffman AJ (1972) Algorithms for partitioning of graphs and computer logic based on eigenvectors of
connection matrices. IBM Techn Discl Bull 15(3):938-944

Elliott A, Chiu A, Bazzi M, Reinert G, Cucuringu M (201 9a) Core-Periphery Structure in Directed Networks. ArXiv preprint.
https://arxiv.org/abs/1912.00984. Accessed 22 Mar 2020

Elliott A, Cucuringu M, Luaces MM, Reidy P, Reinert G (2019b) Anomaly Detection in Networks with Application to
Financial Transaction Networks. ArXiv preprint. https://arxiv.org/abs/1901.00402. Accessed 22 Mar 2020

Erdés P, Rényi A, et al. (1959) On random graphs. Publ Math 6(26):290-297

Florescu L, Perkins W (2016) Spectral thresholds in the bipartite stochastic block model. In: Conference on Learning
Theory. PMLR. pp 943-959

Fortunato S (2010) Community detection in graphs. Phys Rep 486(3-5):75-174

Fortunato S, Hric D (2016) Community detection in networks: A user guide. Phys Rep 659:1-44

Frey BJ, Dueck D (2007) Clustering by passing messages between data points. Science 315(5814):972-976

GeoNames (2019) GeoNames. https://www.geonames.org/. Creative Commons, Accessed 24 Mar 2019

Guattery S, Miller GL (1995) On the performance of spectral graph partitioning methods Vol. 95. pp 233-242

Guattery S, Miller GL (1998) On the quality of spectral separators. SIAM J Matrix Anal Appl 19(3):701-719

Huang J, Shen H, Hou L, Cheng X (2019) Signed graph attention networks. In: International Conference on Artificial
Neural Networks. Springer, Cham. pp 566-577

Hubert L, Arabie P (1985) Comparing partitions. J Classif 2(1):193-218

Jacob P-M, Lapkin A (2018) Statistics of the network of organic chemistry. React Chem Eng 3(1):102-118

Joseph A, Yu B, et al (2016) Impact of regularization on spectral clustering. Ann Stat 44(4):1765-1791

Karrer B, Newman ME (2011) Stochastic blockmodels and community structure in networks. Phys Rev E 83(1):016107

Kolaczyk ED, Csardi G (2014) Statistical Analysis of Network Data with R, vol. 65. Springer, New York
Underwood et al. Applied Network Science (2020) 5:62 Page 40 of 41

KONECT: The Koblenz Network Collection (2019) Unicode Languages network dataset. http://konect.cc/networks/
unicodelang. Accessed 24 Mar 2019

Leskovec J, Krevl A (2007) Astrophysics collaboration network, SNAP Datasets: Stanford Large Network Dataset Collection.
http://snap.stanford.edu/data/ca-AstroPh.html. Accessed 15 Apr 2019

Leskovec, J, Krevl A (2014) SNAP Datasets: Stanford Large Network Dataset Collection. http://snap.stanford.edu/data.
Accessed 21 Mar 2020

Li GX (2017) Divided We Tweet: Community Detection in Political Networks. Final Report, Bachelor of Science in
Engineering, Department of Engineering, Princeton University

Li P, Milenkovic O (2017) Inhomogeneous hypergraph clustering with applications. In: Advances in Neural Information
Processing Systems. Curran Associates, Inc., New York. pp 2308-2318

Li P, Milenkovic O (2018) Submodular hypergraphs: p-laplacians, Cheeger inequalities and spectral clustering. ArXiv
preprint. https://arxiv.org/abs/1803.03833. Accessed 24 June 2020

Li P, Dau H, Puleo G, Milenkovic O (2016) Motif Clustering and Overlapping Clustering for Social Network Analysis. ArXiv
preprint. https://arxiv.org/abs/1612.00895. Accessed 22 Mar 2020

LUtkepohl H (1996) Handbook of Matrices, vol. 1. Wiley, Chichester

Mangan S, Alon U (2003) Structure and function of the feed-forward loop network motif. Proc Natl Acad Sci
100(21):1 1980-11985. https://doi.org/10.1073/pnas.2133841100

Mariadassou M, Robin S, Vacher C, et al (2010) Uncovering latent structure in valued graphs: a variational approach. Ann
Appl Stat 4(2):715-742

Meila M, Pentney W (2007) Clustering by weighted cuts in directed graphs. In: Proceedings of the 2007 SIAM
International Conference on Data Mining. SIAM, Philadelphia. pp 135-144

Monti F, Otness K, Bronstein MM (2018) MotifNet: a motif-based Graph Convolutional Network for directed graphs. ArXiv
preprint. https://arxiv.org/abs/1802.01572. Accessed 22 Mar 2020

Mora BB, Cirtwill AR, Stouffer DB (2018) pymfinder: a tool for the motif analysis of binary and quantitative complex
networks. bioRxiv. https://doi.org/10.1101/364703

Nadler B, Lafon S, Kevrekidis |, Coifman RR (2006) Diffusion maps, spectral clustering and eigenfunctions of Fokker—Planck
operators. In: Advances in Neural Information Processing Systems. MIT Press, Cambridge. pp 955-962

Newman ME (2004) Analysis of weighted networks. Phys Rev E 70(5):056131

Newman M (2008) The physics of networks. Phys Today 61(11):33-38

Nguyen V, Epps J, Bailey J (2009) Information theoretic measures for clusterings comparison: is a correction for chance
necessary? In: International Conference on Machine Learning 2009. Association for Computing Machinery (ACM),
New York. pp 1073-1080

Nowicki K, Snijders TAB (2001) Estimation and prediction for stochastic blockstructures. J Am Stat Assoc
96(455):1077-1087

Onnela J-P, Saramaki J, Kertész J, Kaski K (2005) Intensity and coherence of motifs in weighted complex networks. Phys
Rev E 71(6):065103

Pashanasangi N, Seshadhri C (2020) Efficiently counting vertex orbits of all 5-vertex subgraphs, by EVOKE. In: Proceedings
of the 13th International Conference on Web Search and Data Mining. ACM, New York. pp 447-455

Qin T, Rohe K (2013) Regularized spectral clustering under the degree-corrected stochastic blockmodel. In: Advances in
Neural Information Processing Systems. Curran Associates Inc., New York. pp 3120-3128

Rand WM (1971) Objective criteria for the evaluation of clustering methods. J Am Stat Assoc 66(336):846-850

Rohe K, Qin T, Yu B (2016) Co-clustering directed graphs to discover asymmetries and directional communities. Proc Natl
Acad Sci 113(45):12679-1 2684

Rosvall M, Esquivel AV, Lancichinetti A, West JD, Lambiotte R (2014) Memory in network flows and its effects on spreading
dynamics and community detection. Nat Commun 5(1):1-13

Satuluri V, Parthasarathy S (2011) Symmetrizations for clustering directed graphs. In: Proceedings of the 14th
International Conference on Extending Database Technology. ACM, New York. pp 343-354

Schaeffer SE (2007) Graph clustering. Comput Sci Rev 1(1):27-64

Simmons BI, Sweering MJM, Schillinger M, Dicks LV, Sutherland WJ, Clemente RD (2019) bmotif: A package for motif
analyses of bipartite networks. Methods Ecol Evol. https://doi.org/10.1111/2041-210X.13149

Shi J, Malik J (2000) Normalized cuts and image segmentation. Departmental Papers (CIS) 107:888-905

Stewart GW, Sun J-G (1990) Matrix Perturbation Theory. Academic Press, Boston

Stram R, Reuss P, Althoff K-D (2017) Weighted one mode projection of a bipartite graph as a local similarity measure. In:
International Conference on Case-Based Reasoning. Springer, Cham. pp 375-389

Strassen V (1969) Gaussian elimination is not optimal. Numer Math 13(4):354-356

Tsourakakis CE, Pachocki J, Mitzenmacher M (2017) Scalable motif-aware graph clustering. In: Proc. of the 26th Intl.
Conference on World Wide Web. International World Wide Web Conferences Steering Committee, Geneva.
pp 1451-1460

U.S. Census Bureau (2002) County-to-county migration flow files. https://www.census.gov/population/www/cen2000/
ctytoctyflow/index.html. Accessed 02 Mar 2019

U.S. Census Bureau (2003) Domestic Migration Across Regions, Divisions, and States: 1995 to 2000. https://www.census.
gov/population/www/cen2000/migration. Accessed 27 June 2020, Cenus 2000 Special Reports

Veldt N, Benson AR, Kleinberg J (2020) Minimizing Localized Ratio Cut Objectives in Hypergraphs. ArXiv preprint. https://
arxiv.org/abs/2002.09441. Accessed 06 July 2020

Von Luxburg U (2007) A tutorial on spectral clustering. Stat Comput 17(4):395-416

Von Luxburg U, Bousquet O, Belkin M (2004) On the convergence of spectral clustering on random samples: The
normalized case. In: Learning Theory. Springer, Berlin. pp 457-471

Wagner D, Wagner F (1993) Between min cut and graph bisection. In: International Symposium on Mathematical
Foundations of Computer Science. Springer, Berlin, Heidelburg. pp 744-750

Wang Y, Wang H, Zhang S (2018) A weighted higher-order network analysis of fine particulate matter (PM2.5) transport in
Yangtze River Delta. Physica A: Statistical Mechanics and its Applications 496:654—662
Underwood et al. Applied Network Science (2020) 5:62 Page 41 of 41

Wasserman S, Faust K, et al. (1994) Social Network Analysis: Methods and Applications, vol. 8. Cambridge university press,
Cambridge

Wegner AE, Ospina-Forero L, Gaunt RE, Deane CM, Reinert G (2018) Identifying networks with common organizational
principles. J Compl Netw 6(6):887-913. https://doi.org/10.1093/comnet/cny003

Wernicke S (2006) IEEE/ACM Trans Comput Biol Bioinforma (TCBB) 3(4):347-359. https://doi.org/10.1109/TCBB.2006.5 1

Wernicke S, Rasche F (2006) FANMOD: A tool for fast network motif detection. Bioinformatics 22(9):1152-1153

Yin H, Benson AR, Leskovec J, Gleich DF (2017) Local higher-order graph clustering. In: Proceedings of the 23rd ACM
SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM, New York. pp 555-564

Zha H, He X, Ding C, Simon H, Gu M (2001) Bipartite graph partitioning and data clustering. In: Proceedings of the Tenth
International Conference on Information and Knowledge Management. ACM, New York. pp 25-32

Zhang Y, Rohe K (2018) Understanding regularized spectral clustering via graph conductance. In: Advances in Neural
Information Processing Systems. Curran Associates, Inc., New York. pp 10631-10640

Publisher’s Note

Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.

 

Submit your manuscript to a SpringerOpen®
journal and benefit from:

> Convenient online submission

> Rigorous peer review

> Open access: articles freely available online
> High visibility within the field

> Retaining the copyright to your article

Submit your next manuscript at > springeropen.com

 

 

 
