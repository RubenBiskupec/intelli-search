(a) Taylors Francis
Human-Computer . .
Interaction International Journal of Human-Computer Interaction

 

ISSN: (Print) (Online) Journal homepage: https://www.tandfonline.com/loi/hihc20

 

My Teacher Is a Machine: Understanding Students’
Perceptions of Al Teaching Assistants in Online
Education

Jihyun Kim, Kelly Merrill , Kun Xu & Deanna D. Sellnow

To cite this article: Jinyun Kim , Kelly Merrill , Kun Xu & Deanna D. Sellnow (2020) My
Teacher Is a Machine: Understanding Students’ Perceptions of Al Teaching Assistants in Online
Education, International Journal of Human-Computer Interaction, 36:20, 1902-1911, DOI:
10.1080/10447318.2020.1801227

To link to this article: https://doi.org/10.1080/10447318.2020.1801227

 

 

fn Published online: 12 Aug 2020.
Fone | 7
Submit your article to this journal @
lil Article views: 948
N
Q View related articles

® View Crossmark data

CrossMark

Full Terms & Conditions of access and use can be found at
https://www.tandfonline.com/action/journallnformation?journalCode=hihc20
INTERNATIONAL JOURNAL OF HUMAN-COMPUTER INTERACTION
2020, VOL. 36, NO. 20, 1902-1911
https://doi.org/10.1080/10447318.2020.1801227

Taylor & Francis
Taylor & Francis Group

® Check for updates

My Teacher Is a Machine: Understanding Students’ Perceptions of Al Teaching

Assistants in Online Education

Jihyun Kim, Kelly Merrill Jr., Kun Xu, and Deanna D. Sellnow

Nicholson School of Communication and Media, University of Central Florida, Orlando, Florida, USA

ABSTRACT

An increase in demand for online education has led to the creation of a new technology, machine
teachers, or artificial intelligence (Al) teaching assistants. In fact, Al teaching assistants have already been
implemented in a small number of courses in the United States. However, little is known about how
students will perceive Al teaching assistants. Thus, the present study investigated students’ perceptions
about Al teaching assistants in higher education by use of an online survey. Primary findings indicate
that perceived usefulness of an Al teaching assistant and perceived ease of communication with an Al
teaching assistant are key to understanding an eventual adoption of Al teaching assistant-based
education. These findings provide support for Al teaching assistant adoption. Based on the present
study's findings, more research is needed to better understand the nuances associated with the learning

experience one may have from an Al teaching assistant.

In 2016, one professor at the Georgia Institute of Technology in
the United States introduced Jill Watson, the first AI (artificial
intelligence) teaching assistant, to his class. This AI teaching
assistant was first developed for the professor’s online
Knowledge-Based Artificial Intelligence (KBAI) class. The AI
teaching assistant was built based on IBM’s Watson platform,
and it was primarily designed to answer students’ questions from
the online forums in the KBAI course. While some students
questioned the teaching assistant because of her fast responses,
the identity of the teaching assistant was not known until the
professor revealed it at the end of the semester.

While the past decade witnessed the fast development of
online education from a traditional face-to-face education, the
current technological era takes one step further. The intro-
duction of AI teaching assistants signal that the realm of
education has begun its new era by incorporating nonhuman
agents as tutors, assistants, advisors, and/or teachers, so-called
“machine teachers.” Although human teachers may not be
completely replaced by machines, machines have a great
potential to serve diverse roles in education. As Edwards
and Edwards (2017) note, “machines increasingly are being
designed to teach and to learn through interaction and to be
responsive to natural teaching and learning methods
employed by their human partners” (p. 487). Thus, the new
era of education where machines become part of the educator
pool is fast approaching.

This reality gives rise to several important questions. For
instance, what relationships exist between machine teachers
and student learning outcomes, and how do these relation-
ships compare to human teachers? What is a machine tea-
cher’s role in classroom management? Before addressing these
questions and many others, it seems prudent to understand

the degree to which people are prepared to accept the notion
of machine teachers. While technology is well advanced to
create an AI teaching assistant, little is known about how
students would perceive the AI teaching assistant.

Considering that the notion of AI in education is fairly
new, it is important to understand this phenomenon from the
perspective of technology users, particularly students. To
build this area of research, the present study examines how
perceptions about AI teaching assistants are related to stu-
dents’ attitudes toward Al-based education. Specifically, the
study focuses on the perceived usefulness and ease of com-
munication with AI teaching assistants through the theoretical
framework of the Technology Acceptance Model (TAM).

The following paper features a review of literature relevant to
the uses of technology in educational settings, the theoretical
framework of the TAM, and the TAM’s relevance to machine
teachers. Then, a description of the current study’s method and
results that are derived from the study’s design is provided.
A discussion of the findings is then presented, with implications
for research and practice, along with directions for future
research.

1. Use of technology in education
1.1. Background: Technology in education

The use of technology in the classroom is not a novel idea.
However, the particular technologies used continue to evolve
as new affordances become available (Sellnow & Kaufmann,
2018). For example, the practice has moved from teaching
math computations using an abacus, to a calculator, and now
to the computer. Lectures were reinforced with notes on

CONTACT Jihyun Kim Q jihyunkim218@gmail.com © Nicholson School of Communication and Media, University of Central Florida, Orlando, Florida, USA

© 2020 Taylor & Francis Group, LLC
chalkboards, then whiteboards, and now computers and
smartboards. Whereas formal presentations were once accom-
panied by graphics displayed on poster boards, they are now
enhanced with computerized slideshows and delivered in
face-to-face and online environments.

A major trend toward delivering entire courses online
emerged with the introduction of the World Wide Web in
1989 (McPherson, 2009). Since then, much debate has ensued
about the value of online education. This debate continues
today with reports that only 29% of faculty accept online
learning as a valid delivery method (Online Learning
Consortium, 2015). Nevertheless, the trend toward online
learning has grown to include entire programs and even entire
universities (Kelly & Westerman, 2016). In fact, a 2017 survey
conducted by the U.S. Department of Education reports that
33.7 percent of college students took at least one distance
education course (Department of Education, 2018). These
percentages will no doubt rise as a result of delivering instruc-
tion remotely during the COVID-19 global pandemic.

A good deal of research has examined whether and how to
teach most effectively online. These studies focus on pedago-
gies such as immediacy (Al Ghamdi et al., 2016), classroom
climate (Kaufmann et al, 2016), student engagement
(Walther, 2011), and learning outcome comparisons to other
delivery modes (Sellnow-Richmond et al., 2019).

In facilitating effective online learning, one particularly fruitful
area of research focuses on the importance of social presence and
self-disclosure as they are found to maintain positive teacher-
student relationships, improve student learning performance,
and build a sense of community among students (e.g., Shea
et al., 2006; Song et al., 2019; Sung & Mayer, 2012). In particular,
strong social presence of their teacher is found to facilitate more
positive learning experiences in online classes (Kim et al., 2016).
Further, Song et al. (2016) found that the effect of self-disclosure
about teachers’ basic information in the context of online educa-
tion had more weight than that in a traditional face-to-face
educational context. Focusing on the importance of teacher self-
disclosure and social presence, Song et al. (2019) found that
teacher self-disclosure fosters social presence of teachers, which
eventually facilitates positive learning experiences in online edu-
cation. In essence, fostering positive social presence is critical to
student satisfaction in online courses.

To further enhance meaningful experiences in student
learning, more advanced technologies, such as virtual reality
(VR) and augmented reality (AR) technologies, have been
employed in educational contexts. For instance, researchers
have incorporated game-based learning, location-based learn-
ing, and role playing in AR platforms to facilitate more vivid
learning experiences (Wu et al., 2012).

1.2. Social robots in education

Moreover, there has been an increased use of social robots in
education. Social robots are autonomous machines that gen-
erally follow social behavior norms and interact with humans
in various settings (Gockley et al., 2007). Although robots
were first introduced in classrooms in the 1980s, they are

INTERNATIONAL JOURNAL OF HUMAN-COMPUTER INTERACTION 1903

becoming increasingly popular today (Johal et al., 2018). In
educational settings, social robots may take on the role of
a teacher, tutor, peer, or even a care-seeking companion
(Belpaeme et al., 2018; Mubin et al., 2013; Sharkey, 2016).
As has been the case with debates surrounding the value of
delivering courses fully online so, too, has the idea of using
robots in instruction produced divergent opinions among
educational researchers (Javaheri et al., 2019). Some argue,
for example, that students prefer a human instructor even
though knowledge recall is significantly better when delivered
by a robot (Li et al., 2015). Other arguments range from issues
of cost, teacher training, and applicability (Johal et al., 2018).

In response to such concerns, a good deal of the literature
documents positive effects of social robots in educational set-
tings. A group of researchers (A. Edwards et al., 2016) found
social robots to be credible sources of information related to
student learning. In particular, students perceived social robots
to be capable of appropriately relaying information in educa-
tional settings. In another study (E. Park et al., 2011), when
educating participants on a certain topic, a robot tutor that
provided positive feedback was perceived as attractive and
acceptable. In a similar vein, social robots have been used to
help homebound students engage in a real classroom environ-
ment and interact with classmates and professors synchronously
(Double Robotics, 2017). In all, these studies support the review
of research showing that social robots in educational settings
have positive effects on student learning (Belpaeme et al., 2018).

While social robots have the potential to facilitate student
learning outcomes, there are a few aspects that may require
particular attention in order to utilize robots in education
more effectively. Castellano et al. (2013) identified two factors
in human-robot interaction that are crucial to student learn-
ing: empathy and engagement. Castellano et al. argue that
robotic tutors need to develop the ability to use empathic
messages as well as other social cues to create social bonding
between humans and machines. Li (2015) found that among
different forms of robotic technologies, a robot that is physi-
cally present can deliver more persuasive messages and
receive more attention than a virtual agent (e.g., virtually
present robot on a screen). Further, Li et al. (2015) found
interesting patterns regarding robot use in online education
contexts. They found that a video of a human instructor and
that of an animated robot have similar effects on students’
knowledge recall, but a video of a real robot has weaker effects
on participants’ recall performances.

In sum, although not always the case, most research on
robots in education has shown promising ways that can facil-
itate effective learning experiences. It is, of course, noted that
the positive effects of utilizing robots, or machines in a border
term, may vary depending on a few factors such as types/
forms of machines and content. However, considering that
machines could be helpful in facilitating effective teaching,
such as standardized teaching format and consistent content
delivery, particularly in times when health and safety may put
teachers and students at risk in face-to-face settings, there
seems to be reason why the notion of machine teachers
needs to be considered in education.
1904 (we) J. KIM ET AL.

2. Machine teachers and the technology acceptance
model

2.1. Machine teachers

As technology continues to develop, it is likely that the future of
education would eventually adopt machine teachers in diverse
roles (e.g., teaching assistant, instructor, academic advisor).
Although the present study does not intend to firmly define
the notion of machine teachers yet, it appears to be important
to initiate conceptualizing it as the new era of education unfolds.
Machines are referred to as technologies that feature a certain
level of agency in that they can play a distinct role during an
interaction (Fischer, 1990; Guzman, 2018). Teachers can be
understood as someone that encourages and empowers others
to improve affective, cognitive, and behavioral learning through
acquisition of knowledge, development, and molding of virtues
(Bloom, 1956). Based on these two concepts, a machine teacher
can be broadly understood as a technology that plays
a meaningful role during an interaction with humans in helping
them engage in affective, cognitive, and behavioral learning
through various ways.

Machine teacher is an umbrella term that can appear in
a variety of forms. In particular, they can appear either as
embodied or disembodied agents. Embodiment refers to the
idea that the system requires a physical instantiation or
a physical body (Pfeifer & Scheier, 1999). An embodied machine
teacher can be physical, virtual, or even mixed. Physically embo-
died machines can be constructed from metal, plastic, or other
materials (Li et al., 2015). Robots like NAO or Sony AIBO are
examples of physically embodied machines that have been
applied in the face-to-face pedagogical context. Virtually embo-
died machine teachers refer to those computer-generated agents
that have a visually identifiable body, which appears on a screen
only (Li, 2015). For instance, many online agents are rendered in
the form of animated characters, such as the early Microsoft’s
Clippy, an intelligent user interface for Microsoft office that
assisted users by way of an interactive animated character.
Machine teachers can also appear in a mixed form that incorpo-
rates both physical and virtual agents. That is, some physically
embodied robots are equipped with an electronic tablet that
presents embodied virtual agents on a screen (e.g., telepresent
robots). Unlike embodied machines, disembodied machine tea-
chers do not have any visible or physical instantiation but inter-
act with others in unique ways. Specifically, chatbots, software
agents, or interface agents can afford to interact with humans
through text-based or voice-based messages without requiring
a visible or physical form. For instance, in the current market,
Microsoft’s Little Ice (conversational agent; chatbot) and Google
Duplex can all be considered as disembodied agents.

Considering the increased demand and popularity of online
classes in higher education (Allen & Seaman, 2017), it is expected
that there will be a great need for machine teachers in the near
future. In particular, given the nature of an online environment,
either disembodied or virtually embodied machine teachers
would most likely be needed. However, little is known about
how students might respond to the idea of machine teachers. In
this regard, the present study examines students’ perceptions
about machine teachers through the theoretical framework of
the Technology Acceptance Model (TAM).

2.2. Technology Acceptance Model

The Technology Acceptance Model (TAM) is generally used to
explain how individuals accept and use various technologies
(Davis, 1989; Davis et al., 1989). Specifically, the TAM posits
that adoption of technologies is influenced by an individual's
behavioral intentions to use a particular technology.

Key to the TAM are both an individual’s perceived useful-
ness and perceived ease of use of the technology. Perceived
usefulness refers to the degree to which an individual views
a technology as having particularly enhancing capabilities,
whereas perceived ease of use refers to how simple and care-
free it would be for an individual to interact/engage with
a specific technology (Davis, 1989). The extant body of
research has found perceived usefulness to have a stronger
link to intention to adopt a new technology as compared to
perceived ease of use (Abdullah & Ward, 2016; Davis, 1989),
but both play a vital role in an individual’s intention to adopt
a new technology. Additionally, researchers have continuously
found perceived ease of use as a direct factor influencing
perceived usefulness (Abdullah & Ward, 2016; Park & Chen,
2007), which is aligned with the model presented by Davis
et al. (1989). These two concepts have been shown to be
directly related to attitudes toward a particular technology.
That is, the more useful the technology is perceived to be as
well as the easier it is to use the technology, the more likely
that individuals would develop positive attitudes toward the
particular technology (Davis et al., 1989). Then, positive atti-
tudes toward using a particular technology and perceived
usefulness are directly related to an individual’s behavioral
intention to use the technology, which would affect an indi-
vidual’s actual behavior of adopting the new technology.

The TAM has been applied to a variety of different tech-
nologies, including popular social technologies such as wire-
less Internet (Lu et al., 2003), smartphones (Park & Chen,
2007), social networking sites (Choi & Chung, 2013), and
virtual reality (Lin & Yeh, 2019; Sagnier et al., 2020). These
previous applications of the TAM illustrate the role that
perceived usefulness and perceived ease of use play in adopt-
ing particular technologies in different contexts.

In educational contexts, the TAM has been utilized to
understand educational technologies such as e-Portfolios for
learning (Abdullah et al., 2016), educational wikis (Liu, 2010),
electronic courseware (N. Park et al., 2007), and social media
for educational purposes (Mazman & Usluel, 2010). Much like
previous research that has applied the TAM, all of these
studies highlight the role that perceived usefulness and per-
ceived ease of use play in adopting educational technologies in
a variety of ways. For example, a study (Abdullah et al., 2016)
found the effects of both students’ perceived usefulness and
perceived ease of use of e-portfolios on an individual’s beha-
vioral intention. Additionally, Abdullah and Ward (2016)
completed a meta-analysis using the TAM to better under-
stand the adoption of e-learning, or tools that utilize online
technologies for instructional purposes.

More germane to the particular context of the present inves-
tigation, although very limited, are a couple of studies that have
adopted the TAM to understand AI-driven assessment tools in
eLearning settings (e.g., Cruz-Benito et al., 2019; Sanchez-Prieto
et al., 2019). In particular, Sanchez-Prieto et al. (2019) proposed
several arguments that highlight key factors of the TAM in the
understanding of Al-driven assessment among teachers. Based
on the core of the TAM, Sanchez-Prieto et al. argues that per-
ceived usefulness and perceived ease of use are positively related
to the teachers’ intention to use Al-driven assessment in
eLearning, which will eventually lead to the actual adoption.
Although these studies are limited to the conceptual proposi-
tions without empirical evidence, they highlight the theoretical
underpinning of the TAM in the understanding of AlI-related
educational experiences.

Taken together, the present study takes an initial approach
to understand how college students would perceive the idea of
machine teachers. Considering that it might be too unrealistic
for some students to imagine having a machine as the primary
instructor of their own class, the current study focuses on
a machine teacher functioning as a teaching assistant. For the
same reason, the study focuses on a machine teacher as
a disembodied AI agent because students may have some
familiarity with disembodied AI, considering the popularity
of voice-based AI (Statista, 2019), such as Apple’s Siri. In this
regard, the study examines students’ perceptions of an Al
teaching assistant. Taken together, the study proposes the
following hypotheses based on the original theoretical frame-
work of the TAM. See Figure 1.

H1: Perceived ease of communication with an AI teaching
assistant will positively lead to perceived usefulness of an AI
teaching assistant.

H2a-b: (a) Perceived usefulness of an AI teaching assistant
and (b) perceived ease of communication with an AI teaching
assistant will lead to positive attitudes toward using an Al
teaching assistant.

H3: Positive attitudes toward using an AI teaching assistant will
lead to intention to adopt AI teaching assistant-based education.

H4: Perceived usefulness of an AI teaching assistant will lead
to intention to adopt AI teaching assistant-based education.

   

  
   
   
   
  
  
   
 
   
 

Perceived
usefulness of
AITA

   
 

Attitude
toward new
technologies

Ease of
communication
with AITA

  
 

Figure 1. Proposed research model.
Note: AITA refers to Artificial Intelligence Teaching Assistant.

INTERNATIONAL JOURNAL OF HUMAN-COMPUTER INTERACTION 1905

3. Methods
3.1. Participants

Initially, a total of 349 undergraduate students from communi-
cation courses at a large public university in the U.S. responded
to this study. To ensure the study received data of good quality,
a few steps were taken to filter out unusable data. First, given that
the survey was distributed to multiple classes (see the procedure
section), a question was asked to indicate whether the partici-
pants have taken this survey before. Twenty-three individuals
were identified to have taken it before; thus, these second-time
responses were eliminated. Second, an attention check was per-
formed in the middle of the survey to ensure that participants
read the survey questions accurately. Five individuals failed;
therefore, they were eliminated from the sample.

After the screening process, the final sample consisted of
321 eligible participants. The average age was 21.52 years
(SD = 4.16). There were more females (n = 209: 65.1%) than
males (n = 112: 34.9%) in the sample. Majority of the parti-
cipants identified themselves as Caucasian (n = 167: 52%),
followed by Hispanic or Latino (m = 71: 22.1%), African
American (n = 54: 16.8%), and other racial/ethnic identities
(n = 29: 9%). Regarding class standing, the sample included 17
freshmen (5.3%), 80 sophomores (24.9%), 152 juniors
(47.4%), and 72 seniors (22.4%).

3.2. Procedure

A questionnaire was distributed with a university-licensed
online survey tool (www.qualtrics.;com). The primary
researcher contacted instructors of undergraduate courses
and asked whether they would be willing to share the research
participation opportunity with students. Upon approval,
a link was sent to potential participants, and they were
asked to complete the survey online.

Once participants accessed the survey, they were asked to
read and acknowledge the informed consent prior to pro-
ceeding to complete the survey. At the beginning of the
survey, participants’ attitudes toward new technologies
(e.g., Apple’s Siri, Amazon’s Alexa) were assessed. Then,

  
  
 

Attitudes
toward
AITA

   
  
  

Intention to
adopt AITA

  
 

 
1906 @&) J. KIM ET AL.

they were led to read an article about an AI teaching
assistant in higher education. This article was the actual
article that was previously published in The Washington
Post. The article was about an AI teaching assistant, which
was built by a professor at a university in the U.S. Mostly,
the article described the AI teaching assistant that was used
for the class and its role for the class. In order to avoid
a situation where participants may skip the page without
reading the article, a timer was set on that article page. This
function did not allow participants to go to the next page
for a certain duration of time, which ensured that partici-
pants read the article as part of this research participation.

After reading the article, participants were asked to com-
plete a set of questions, which asked about their perceptions
about the AI teaching assistant they learned about from the
article. At the end of the survey, participants were redirected
to a separate website, independent from the original survey,
where they could provide their name and course information
for extra credit purposes. Confidentiality was guaranteed.

3.3. Measures

Before the stimulus, attitudes toward new technologies (a =.89)
were measured with three items (adopted from Nass et al.,
1994). Example items included: “How comfortable would you
be with new technologies (e.g., robots, AI) taking routinized
roles (e.g., accountants, auto mechanics, bank tellers),” and
“ ... taking interpretive roles (e.g., editorial writers, newspaper
reporters, novelists).” Responses were obtained on a 6-point
scale (1 = Very Uncomfortable, 6 = Very Comfortable).

After the stimulus, a set of questions were asked to assess
participants’ perceptions about the AI teaching assistant.
Perceived usefulness of an AI teaching assistant (a = .94) was
measured with four items (e.g., “Using an AI teaching assis-
tant would increase my learning productivity,” and “... would
enhance my learning effectiveness”). Perceived ease of commu-
nication with an AI teaching assistant (a = .89) was measured
with four items (e.g., “It would be easy to learn how to
communicate with an AI _ teaching assistant,” and
“Interacting with an AI teaching assistant would not require
a lot of my mental effort”). Items for both perceived useful-
ness and ease of communication were modified from Davis
(1989). Responses were obtained on a 7-point Likert-type
scale (e.g., 1 = Strongly Disagree, 7 = Strongly Agree).

Attitudes toward using an AI teaching assistant (a = .95) were
measured with five items (e.g., “bad - good,” and “unfavorable -
favorable”) on a 7-point semantic differential scale. Items were
adopted from Davis (1993). Intention to adopt AI teaching
assistant-based education (a = .95) was measured with three
items (e.g., “If an AI teaching assistant-based online class is
available, I would consider taking the class,” and “ ... I would
be interested in taking the class.”). Items were adopted from
(Choi & Ji, 2015), and responses were obtained on a 7-point
Likert-type scale (e.g., 1 = Strongly Disagree, 7 = Strongly Agree).

4. Results

Before conducting the hypothesis testing, a control variable
was considered. Given that the notion of an AI teaching

assistant is an advanced concept of technology, individuals
who are generally open to new technology might be in favor
of an AI teaching assistant than others who are somewhat
resistant to adopting new technology in general. In this
regard, overall attitudes toward new technologies were
entered as a controlling variable in the data analyses.

In order to test the proposed hypotheses, including an
overall model fit for the theoretical framework of the TAM,
structural equation modeling was employed using Mplus 7
(Muthén & Muthén, 2015). Maximum likelihood estimation
was used to estimate the proposed research model. Results
suggest that the hypothesized model did not show a goodness
of fit for the data, X* (3, N = 321) = 29.02, p < .001, CFI = .97,
TLI = .89, RMSEA = .16, SRMR = .03. The process of indices
modification was used to improve the model. In Mplus, stan-
dardized residuals for correlations were reviewed to see
whether the model under-predicted any relationships. After
iterative modification, perceived ease of communication with
an AI teaching assistant was correlated with users’ intention
to adopt AI teaching assistant-based education. Although this
link was not originally identified in the TAM, which is why
the present research did not include it in the original testing
model, this link was noted in previous research (Abdullah et
al., 2016). The modified model showed that it had a goodness
of fit for the data, X* (2, N = 321) = 29.02, p > .05, CFI = .996,
TLI = .98 RMSEA = .07, SRMR = .03.

Specifically, controlling for attitudes toward new technolo-
gies, perceived ease of communication with an AI teaching
assistant positively predicted perceived usefulness of an AI
teaching assistant (B = .63, p < .001), supporting H1.
Regarding H2a-b, both perceived usefulness of an AI teaching
assistant (B = .55, p < .001) and perceived ease of communica-
tion with an AI teaching assistant (B = .35, p < .001) showed
positive relationships with users’ attitudes toward using an AI
teaching assistant. With regard to H3, attitudes toward using an
AI teaching assistant (B = .50, p < .001) positively led to inten-
tion to adopt AI teaching assistant-based education. For H4,
perceived usefulness (B = .25, p < .001) positively and directly
predicted intention to adopt AI teaching assistant-based educa-
tion. Thus, all hypotheses were supported. See Figure 2.

5. Discussion

The present study examined students’ perceptions about an
AI teaching assistant in higher education. Primary findings
indicate that perceived usefulness of an AI teaching assistant
and perceived ease of communication with an AI teaching
assistant positively predict favorable attitudes toward using an
AI teaching assistant, which consequently leads to stronger
intention to adopt AI teaching assistant-based education.
Moreover, the study reveals that perceived usefulness and
ease of communication directly predict intention to adopt
AI teaching assistant-based education.

5.1. Contributions and implications

The current study provides important contributions to and
implications for research and practice. First, the study
makes theoretical contributions to research on the TAM.
   

  
 

Perceived
usefulness of

   
 

Attitude
toward new
technologies

  
 

Ease of
Communication
with AITA

X =5.104, df=2, p>.05:
CFI = .996;

TLI = .98;

RMSEA = .07

SRMR = .029

Figure 2. Final model.

INTERNATIONAL JOURNAL OF HUMAN-COMPUTER INTERACTION 1907

  
  
 
  
   
 
   
 

 
 
 

Attitudes
toward
AITA

  
   

Intention to
adopt AITA

 
 

 

r= 42H

Note 1: AITA refers to Artificial Intelligence Teaching Assistant. Note 2: * p <.05; ** p <.01; *** p <.001.

The TAM is a useful framework that is used to understand
adoption of new technologies in diverse contexts, such as
the smartphones (Park & Chen, 2007), social media (Choi &
Chung, 2013), and virtual reality (Lin & Yeh, 2019; Sagnier
et al., 2020). Although very limited, the TAM has been also
employed to understand the adoption of AlI-based assess-
ment in education (Cruz-Benito et al., 2019; Sanchez-Prieto
et al., 2019). However, the use of TAM in these studies was
limited to proposing theoretical arguments without empiri-
cal support. To our knowledge, the present study is one of
the first instances that empirically tested the TAM being
utilized to understand the adoption of machine teachers. As
reported in the result section, the findings fully support the
underpinning of the TAM regarding the machine teacher,
more specifically in the AI-based education context. Overall,
the study’s findings provide more supporting evidence for
the TAM’s explanatory power. That is, the TAM can be, and
has been, applied to better understand how individuals
adopt new technologies in diverse contexts, and it ultimately
expands the scope of the TAM.

Second, the results of this study point to significant implica-
tions for instructional communication. As mentioned earlier,
while technological skills are well advanced to create machine
teachers, there is little understanding about how students would
perceive the idea of machine teachers. Acknowledging that many
educators remain skeptical about the value of AI in the classroom
(Johal et al., 2018), as well as the trend that robots are here to stay
(Edwards & Edwards, 2017; McDowell & Gunkel, 2016), the
present study provides baseline information that helps educators
better understand how students may perceive and react to them.
Given that much research exists pointing to the value of AI in
educational contexts as it addresses cognitive and behavioral
learning outcomes (e.g., Brown et al., 2013; Chollet et al., 2015;
A. Edwards et al., 2016; Edwards et al., 2019; Li et al., 2015; Wu

et al., 2012), perhaps addressing student affect toward the use of
Al in education is the missing link to convince skeptics and those
that may currently feel apprehensive.

Next, in an era of declining financial resources for higher
education in the United States, machine teachers may afford
an opportunity to address instructional needs in cost effective
ways in the long run. To clarify, higher education adminis-
trators attempt to address student demand for courses by
increasing enrollment caps, as well as by employing adjunct
instructors and graduate teaching assistants (GTA). In fact,
“between 2000 and 2017, total undergraduate enrollment in
degree-granting postsecondary institutions increased by 27%”
and is projected to increase another 3% by 2028 (Department
of Education, 2019). Typical class sizes for introductory level
courses at universities may range from 150 to 300 students
(Willingham, 2019). For many departments, financial and
human resources are stretched to a breaking point. There
are limits to how many adjuncts and GTAs can be staffed as
instructors without jeopardizing accreditation (Stenerson
et al., 2010). Some programs have attempted to address the
problems by employing undergraduate teaching assistants
(UTAs) (Reynolds et al., 2014); however, based on the results
of this study, it seems reasonable to consider ways in which AI
teaching assistants could play an important role in addressing
these needs as well.

The present research findings also point to the impor-
tance of training for effective use of machine teachers,
particularly AI teaching assistants. Although students’ atti-
tudes toward using AI teaching assistants might be gener-
ally positive, this might only be true if students and
teachers feel at ease with communicating with AI teaching
assistants. To be successful, then, teachers must be trained
in how to use an AI teaching assistant in ways that foster
immediacy and social presence (Kaufmann et al., 2016; Kim
1908 J. KIM ET AL.

et al., 2016; Song et al., 2019). Research confirms that when
instructors appear uncomfortable employing a particular
pedagogical strategy, student attitudes are also negative
(e.g., Liu et al., 2016; Tichavsky et al., 2015). Thus, teacher
certification programs ought to add curriculum not only to
teach preservice instructors how to use AI effectively, but
also to realize the value that AI teaching assistants can
bring to the teaching and learning experience (Edwards &
Edwards, 2017; Edwards et al., 2018, 2019). Moreover,
practicing teachers must be offered ongoing training in
the form of workshops, webinars, and online modules (AI-
Balushi & Al-Abdali, 2015; Ramirez-Montoya et al., 2017;
Tarhan, 2015). Failing to do so is essentially setting teachers
up for failure, not because AI teaching assistants are inef-
fective, but because teachers are uninformed about pedago-
gical best practices in employing them as such.

Finally, the study suggests practical implications for
developing machine teachers. The study acknowledges that
developing a program that utilizes machine teachers can be
costly at first. In order to effectively maximize their use, it
is important to create machine teachers that are favorably
accepted by both students and teachers. So, universities can
adopt the program repeatedly as long as the course exists in
their schedule. In this regard, the study’s finding highlights
that machine teachers should be perceived to be useful and
easy to communicate with, as these aspects would even-
tually lead to the actual adoption. It is important to note
that the present study does not argue that machine teachers
will replace the entire role of human teachers. However, it
might be true that human teachers can receive some help
from these machine teachers in certain areas (e.g., repeated
tasks on course management website), as they can appear in
a variety of forms with diverse functionalities.

5.2. Limitations and future research directions

While this study revealed important findings and implications
for using AI in education, the study recognizes some limita-
tions that should be considered when interpreting the patterns
of the results. First, because the study used a short article to
inform participants of an AI teaching assistant, participants
had a one-time, limited exposure to the idea of an AI teaching
assistant based on the way the article was written. Although
the selected article was written in an objective manner, which
simply describes the AI teaching assistant without biased
perspectives, it might be possible that some students may
have perceived the framing of the story as being positive or
negative. Also, learning about the AI teaching assistant by
reading the story, rather than directly interacting with it,
might have limited participants’ perceptions about the AI
teaching assistant. If participants have continued and direct
interactions with the AI teaching assistant in the real world,
their perceptions may change.

As such, future researchers should examine students’ responses
to direct exposures of an AI teaching assistant. This can be
accomplished in a variety of ways. For example, one could con-
duct a lab experiment to see how students respond to AI teaching
assistants. This method allows the researchers to manipulate key
variables (e.g., AI teaching assistant’s communication styles) to

better understand which aspects of an AI teaching assistant would
facilitate more effective learning experiences. It would also be
meaningful to conduct a longitudinal study to understand
whether and/or how student perceptions would change over
time. Qualitative methods such as interviews, focus groups, and
ethnographies can also prove to be beneficial. Interviews and
focus groups can prove direct verbal or written responses from
students about their experiences with AI teaching assistants.
Themes that emerge from these methods may help researchers
better understand underlying mechanisms that may play a role in
understanding how individuals respond to AI teaching assistants.
Moreover, ethnographies may be of interest, as researchers could
examine how students respond to AI teaching assistants in the
classroom. By immersing oneself in a classroom that utilizes AI
teaching assistants, the research can record first-hand experiences
of this phenomenon. Thus, there is a strong call for more research
in order to fully capture the idea of how students may respond to
this technology over time.

Next, students recruited for this study were from a large
pubic university that offers both online and offline courses.
Thus, it is unclear whether their responses and perceptions
about AI teaching assistants would be the same as those who
only have online education experiences. It might be possible
that students enrolled at a fully online university are comfor-
table enough with the use of technology in their education;
thus, they might be more accepting of the idea of AI teaching
assistants. In order to fully investigate this, future research
should consider collecting data from both a fully online uni-
versity as well as a traditional university to examine the
potential differences.

Another limitation is that the study only focused on one
particular type of machine teachers, an AI teaching assistant
that appeared as a disembodied agent. As mentioned earlier,
machine teachers can exist in a variety of forms including
disembodied and embodied, and they can vary in degrees of
anthropomorphism, which is the attribution of humanlike
behaviors and characteristics to nonhuman agents (Guthrie,
1993). In order to fully understand the best and optimal
adoption of machine teachers in education, more research is
needed. For example, it would be interesting to see if there is
a specific type of machine teacher that is preferred among
students. Future researchers should also observe whether dif-
ferences exist in the learning experiences based on these
different types of machine teachers. It may be possible that
students learn more with a specific type, and this would be
important information to know for future implementations of
machine teachers in classrooms.

Lastly, future research should consider potential individual
differences such as perceptions about AI, learning styles, person-
ality, sex, etc. Although the idea of AI teaching assistants brings
about much efficiency in education, it does not guarantee that
everyone will enjoy this. For example, understanding how stu-
dents view AI could be worth investigating as the perceptions of
Al in general might affect how they would view AI in educational
settings. Additionally, prior experiences with AI may also influ-
ence students to be either apprehensive or welcoming of AI
teaching assistants. In this regard, future research should further
investigate potential individual differences in adopting this new
technology in education.
6. Conclusion

The present study investigated students’ perceptions about
AI teaching assistants in higher education. Primary findings
indicate that perceived usefulness of an AI teaching assis-
tant and perceived ease of communication with an AI
teaching assistant play an important role in the understand-
ing of AI teaching assistant-based education. Based on the
current study’s initial findings, future researchers are
encouraged to expand this area of research by replicating
it with different student populations and _ teachers.
Depending on the level of education (e.g., college vs. high
school), students’ perceptions about an AI teaching assis-
tant might differ. Additionally, it is equally important to
understand how teachers would perceive the idea of AI
teaching assistants, or more broadly machine teachers, in
order to implement this new technology in education.
Moreover, AI instruction may provide an effective means
for delivering instruction when current events prohibit
face-to-face human interaction. Therefore, the present
study calls for a strong need to further advance this area
of research.

References

Abdullah, F., & Ward, R. (2016). Developing a General Extended
Technology Acceptance Model for E-Learning (GETAMEL) by
analysing commonly used external factors. Computers in Human
Behavior, 56, 238-256. https://doi.org/10.1016/j.chb.2015.11.036

Abdullah, F., Ward, R., & Ahmed, E. (2016). Investigating the influence
of the most commonly used external variables of TAM on students’
Perceived Ease of Use (PEOU) and Perceived Usefulness (PU) of e-
portfolios. Computers in Human Behavior, 63, 75-90. doi:doi.10.1016/
j.chb.2016.05.014

Al Ghamdi, A., Samarji, A., & Watt, A. (2016). Essential considera-
tions in distance education in KSA: Teacher immediacy in
a virtual teaching and learning environment. International
Journal of Information and Education Technology, 6(1), 17-22.
https://doi.org/10.7763/IJIET.2016.V6.651

Al-Balushi, S. M., & Al-Abdali, N. S. (2015). Using a Moodle-based
professional development program to train science teachers to teach
for creativity and its effectiveness on their teaching practices. Journal
of Science Education and Technology, 24(4), 461-475. https://doi.org/
10.1007/s10956-014-9530-8

Allen, E., & Seaman, J. (2017, May). Digital learning compass: Distance
education enrollment report 2017. https://onlinelearningsurvey.com/
reports/digtiallearningcompassenrollment2017.pdf

Belpaeme, T., Kennedy, J., Ramachandran, A., Scassellati, B. &
Tanaka, F. (2018). Social robots for education: A review. Science
Robotics, 3(21), eaat5954. https://doi.org/10.1126/scirobotics.aat5954

Bloom, B. S. (1956). Taxonomy of educational objectives: The classifica-
tion of educational goals. New York: David McKay Company.

Brown, L., Kerwin, R., & Howard, A. M. (2013). Applying behavioral
strategies for student engagement using a robotic education agent. In
Systems, Man and Cybernetics (SMC), 2013 IEEE international confer-
ence on IEEE (pp. 4360-4365). https://doi.org/10.1109/SMC.2013.744.

Castellano, G., Paiva, A., Kappas, A., Aylett, R., Hastie, H., & Bull, S. (2013,
July). Towards empathic virtual and robotic tutors. In International con-
ference on artificial intelligence in education (pp. 733-736). Springer.

Choi, G., & Chung, H. (2013). Applying the technology acceptance
model to social networking sites (SNS): Impact of subjective norm
and social capital on the acceptance of SNS. International Journal of

INTERNATIONAL JOURNAL OF HUMAN-COMPUTER INTERACTION ) 1909

Human-computer Interaction, 29(10), 619-628. https://doi.org/10.
1080/10447318.2012.756333

Choi, J. K., & Ji, Y. G. (2015). Investigating the importance of trust on
adopting an autonomous vehicle. International Journal of Human-
computer Interaction, 31(10), 692-702. https://doi.org/10.1080/
10447318.2015.1070549

Chollet, M., Wortwein, T., Morency, L. P., Shapiro, A., & Sherer, S.
(2015, September). Exploring feedback strategies to improving public
speaking: An interactive virtual audience framework. In Proceedings of
the 2015 ACM international joint conference on pervasive and ubiqui-
tous computing ACM (pp. 1143-1154). https://doi.org/10.1145/
2750858.2806060

Cruz-Benito, J., Sanchez-Prieto, J. C., Theron, R., & Garcia-Pefalvo, F. J.
(2019). Measuring students’ acceptance to Al-driven assessment in
eLearning: Proposing a first TAM-based research model. In
P. Zaphiris & A. Ioannou (Eds.), Learning and collaboration technol-
ogies. Design, experiences. 6th international conference, LCT 2019, held
as part of the 21st HCI international conference, HCII 2019, Orlando,
FL, USA, July 26-31, 2019. Proceedings, part I (pp. 15-25). Springer
Nature.

Davis, F. D. (1989). Perceived usefulness, perceived ease of use, and user
acceptance of information technology. MIS Quarterly, 13(3), 319-340.
https://doi.org/10.2307/249008

Davis, F. D. (1993). User acceptance of information technology:
system characteristics, user perceptions and behavioral impacts.
International journal of man-machine studies, 38(3), 475-487.
doi:10.1006/imms.1993.1022

Davis, F. D., Bagozzi, R. P., & Warshaw, P. R. (1989). User acceptance of
computer technology: A comparison of two theoretical models.
Management Science, 35(8), 982-1003. https://doi.org/10.1287/mnsc.
35.8.982

Department of Education. (2018, May). The condition of education:
A letter from the commissioner. Institute of Education Sciences
National Center for Education Statistics. https://nces.ed.gov/pro
grams/coe/indicator_cha.asp

Department of Education. (2019, May). Integrated Postsecondary
Education Data System (IPEDS), Spring 2017 and Spring 2018, Fall
Enrollment component. Institute of Education Sciences National Center
for Education Statistics. https://nces.ed.gov/programs/digest/d18/
tables/dt18_311.15.asp

Double Robotics. (2017). Blended learning/hybrid classroom. Double.
https://www.doublerobotics.com/education/

Edwards, A., & Edwards, C. (2017). The machines are coming:
Future directions in instructional communication research.
Communication Education, 66(4), 487-488. https://doi.org/10.
1080/03634523.2017.1349915

Edwards, A., Edwards, C., Spence, P. R., Harris, C., & Gambino, A.
(2016). Robots in the classroom: Differences in students’ perceptions
of credibility and learning between “teacher as robot” and “robot as
teacher”. Computers in Human Behavior, 65, 627-634. https://doi.org/
10.1016/j.chb.2016.06.005

Edwards, C., Edwards, A., Spence, P. R., & Lin, X. (2018). I, teacher:
Using artificial intelligence and social robots in communication and
instruction. Communication Education, 67(4), 473-480. https://doi.
org/10.1080/03634523.2018.1502459

Edwards, C., Edwards, A., Stoll, B., Lin, X., & Massey, N. (2019).
Evaluations of an artificial intelligence instructor’s voice: Social theory
in human-robot interactions. Computers in Human Behavior, 90,
357-362. https://doi.org/10.1016/j.chb.2018.08.027

Fischer, G. (1990). Communication requirements for cooperative pro-
blem solving systems. Information Systems, 15(1), 21-36. https://doi.
org/10.1016/0306-4379(90)90014-G

Gockley, R., Forlizzi, J., & Simmons, R. (2007, March). Natural
person-following behavior for social robots. In Proceedings of the ACM/
IEEE international conference on Human-robot interaction (pp. 17-24).
ACM. https://doi-org/10.1145/1228716.1228720

Guthrie, S. E. (1993). Faces in the clouds: A new theory of religion. Oxford
Univ Press.
1910 @) J. KIM ET AL.

Guzman, A. (2018). Human-machine communication: Rethinking com-
munication, technology, and ourselves. Peter Lang Publishing.

Javaheri, A., Moghadamnejad, N., Keshavarz, H., Javaheri, E., Dobbins, C.,
Momeni, E., & Rawassizadeh, R. (2019). Public vs Media Opinion on
Robots. arXiv Preprint. Retrieved from arXiv:1905.01615

Johal, W., Castellano, G., Tanaka, F., & Okita, S. (2018). Robots for
learning. International Journal of Social Robotics, 10(3), 293-294.
https://doi.org/10.1007/s12369-018-0481-8

Kaufmann, R., Sellnow, D. D., & Frisby, B. N. (2016). The development and
validation of the online learning climate scale. Communication Education,
65(3), 307-321. https://doi.org/10.1080/03634523.2015.1101778

Kelly, S. E., & Westerman, D. K. (2016). New technologies and distrib-
uted learning systems. In P. L. Witt (Ed.), Communication and learn-
ing (pp. 455-477). Walter de Gruyter Inc.

Kim, J., Song, H., & Luo, W. (2016). Broadening the understanding of
social presence: Implications and contributions to the mediated com-
munication and online education. Computers in Human Behavior, 65,
672-679. https://doi.org/10.1016/j.chb.2016.07.009

Li, J. (2015). The benefit of being physically present: A survey of experi-
mental works comparing copresent robots, telepresence robots, and
virtual agents. International Journal of Human-computer Studies, 77,
23-37. https://doi.org/10.1016/j.ijhcs.2015.01.001

Li, J., Kizilcec, R., Bailenson, J., & Ju, W. (2015). Social robots and virtual
agents as lecturers for video instruction. Computers in Human
Behavior, 55, 1222-1230. https://doi.org/10.1016/j.chb.2015.04.005

Lin, P. H., & Yeh, S. C. (2019). How motion-control influences a
VR-supported technology for mental rotation learning: From the
perspectives of playfulness, gender difference and technology accep-
tance model. International Journal of Human-Computer Interaction,
35(18), 1736-1746. https://doi.org/10.1080/10447318.2019.1571784

Liu, M., Navarrete, C. C., Scordino, R., Kang, J., Ko, Y., & Lim, M.
(2016). Examining teachers’ use of iPads: Comfort level, perception,
and use. Journal of Research on Technology in Education, 48(3),
159-180. https://doi.org/10.1080/15391523.2016.1175853

Liu, X. (2010). Empirical testing of a theoretical extension of the tech-
nology acceptance model: An exploratory study of educational wikis.
Communication Education, 59(1), 52-69. https://doi.org/10.1080/
03634520903431745

Lu, J., Yu, C. S., Liu, C., & Yao, J. E. (2003). Technology acceptance
model for wireless Internet. Internet Research, 13(3), 206-222. https://
doi.org/10.1108/10662240310478222

Mazman, S. G., & Usluel, Y. K. (2010). Modeling educational usage of
Facebook. Computers & Education, 55(2), 444-453. https://doi.org/10.
1016/j.compedu.2010.02.008

McDowell, Z. J., & Gunkel, D. J. (2016). Introduction to “machine
communication”. Communication +1, 5(1), 1-5. http://scholarworks.
umass.edu/cpo/vol5/iss1/1

McPherson, S. S. (2009). Tim Berners-Lee: Inventor of the world wide web.
Twenty-First Century Books.

Mubin, O., Stevens, C. J., Shahid, S., Al Mahmud, A., & Dong, J. J.
(2013). A review of the applicability of robots in education. Journal
of Technology in Education and Learning, 1(209-0015), 13. https://doi.
org/10.2316/Journal.209.2013.1.209-0015

Muthén, L. K., & Muthén, B. O. (2015). Mplus user’s guide (7th ed.).
Muthén & Muthén.

Nass, C., Steuer, J., & Tauber, E. R. (1994). Computers are social actors.
In Proceedings of the SIGCHI conference on Human factors in comput-
ing systems (pp. 72-78). doi:10.1145/191666.191703

Online Learning Consortium. (2015). 2015 online report card: Tracking online
education in the United States. Online Learning Consortium. http://online
learningconsortuim.org/read/online-report-card-tracking-online-educai
ton-united-states-2015/

Park, E., Kim, K. J., & Del Pobil, A. P. (2011, November). The effects of
a robot instructor’s positive vs. negative feedbacks on attraction and
acceptance towards the robot in classroom. In International conference
on social robotics (pp. 135-141). Springer.

Park, N., Lee, K. M., & Cheong, P. H. (2007). University instructors’
acceptance of electronic courseware: An application of the technology

acceptance model. Journal of Computer-Mediated Communication, 13
(1), 163-186. https://doi.org/10.1111/j.1083-6101.2007.00391.x

Park, Y., & Chen, J. V. (2007). Acceptance and adoption of the innova-
tive use of smartphone. Industrial Management & Data Systems, 107
(9), 1349-1365. https://doi.org/10.1108/02635570710834009

Pfeifer, R., & Scheier, C. (1999). Understanding intelligence. The MIT Press.

Ramirez-Montoya, M. S., Mena, J., & Rodriguez-Arroyo, J. A.
(2017). In-service teachers’ self-perceptions of digital competence
and OER use as determined by a xMOOC training course.
Computers in Human Behavior, 77, 356-364. https://doi.org/10.
1016/j.chb.2017.09.010

Reynolds, M., Deanna, S., Head, K., & Anthony, K. E. (2014). Exploring the
educational value of the undergraduate teaching apprentice (UTA)
experience. Journal of the Association of Communication
Administration, 33(1), 17-34. https://staticl.squarespace.com/static/
58dbel8c03596e2e942115e9/t/5906336720099e963751fbde/
1493578640472/JACA_33.1.pdf

Sagnier, C., Loup-Escande, E., Lourdeaux, D., Thouvenin, I, &
Valléry, G. (2020). User acceptance of virtual reality: An
extended technology acceptance model. International Journal of
Human-Computer Interaction, 36(11), 993-1007. https://doi.org/
10.1080/10447318.2019.1708612

Sanchez-Prieto, J. C., Cruz-Benito, J., Theron, R., & Garcia-Pefalvo, F. J.
(2019). How to measure teachers’ acceptance of Al-driven assessment
in eLearning: A TAM-based proposal. In M. A. Conde-Gonzalez,
F. J. Rodriguez-Sedano, C. Fernandez-Llamas, & F. J. Garcia-Pefialvo
(Eds.), TEEM’19 proceedings of the seventh international conference on
technological ecosystems for enhancing multiculturality (Leon, Spain,
October 16th-18th, 2019) (pp. 181-186). ACM.

Sellnow, D. D., & Kaufmann, R. (2018). Instructional communica-
tion and the online learning environment: Then, now, and next.
In M. L. Houser & A. M. Hosek (Eds.), Handbook of instructional
communication: Relational and rhetorical perspectives (2nd ed.,
pp. 195-206). Routledge.

Sellnow-Richmond, D., Strawser, M. G., & Sellnow, D. D. (2019). Student
perceptions of teaching effectiveness and learning achievement:
A comparative examination of online and hybrid delivery format.
Communication Teacher, 34(3), 248-263. https://doi.org/10.1080/
17404622.2019.173456

Sharkey, A. J. C. (2016). Should we welcome robot teachers? Ethics and
Information Technology, 18(4), 283-297. https://doi.org/10.1007/
$10676-016-9387-z

Shea, P., Li, C. S., & Pickett, A. (2006). A study of teaching presence and
student sense of learning community in fully online and web-enhanced
college courses. The Internet and Higher Education, 9(3), 175-190. https://
doi.org/10.1016/j.iheduc.2006.06.005

Song, H., Kim, J., & Luo, W. (2016). Teacher - Student relationship in
online classes: A role of teacher self-disclosure. Computers in Human
Behavior, 54, 436-443. https://doi.org/10.1016/j.chb.2015.07.037

Song, H., Kim, J., & Park, N. (2019). I know my professor: Teacher
self-disclosure in online education and a mediating role of social
presence. International Journal of Human-computer Interaction, 35
(6), 448-455. https://doi.org/10.1080/10447318.2018.1455126

Statista. (2019, February). Number of voice assistants in use worldwide
2019-2023. https://www.statista.com/statistics/973815/worldwide-
digital-voice-assistant-in-use/

Stenerson, J., Blanchard, L., Fassiotto, M., Hernandez, M., & Muth, A.
(2010). The role of adjuncts in the professoriate. Peer Review, 12(3),
23-26. https://login.Ip.hscl.ufl.edu/login?url=https://search.proquest.
com/docview/758939374?accountid=10920

Sung, E., & Mayer, R. E. (2012). Five facets of social presence in online
distance education. Computers in Human Behavior, 28(5), 1738-1747.
https://doi.org/10.1016/j.chb.2012.04.014

Tarhan, O. (2015). The state of in-service training of teachers and teacher
training in National Education Councils. Procedia-Social and Behavioral
Sciences, 197, 378-381. https://doi.org/10.1016/j.sbspro.2015.07.152

Tichavsky, L. P., Hunt, A. N., Driscoll, A., & Jicha, K. (2015). “It’s just nice
having a real teacher”: Student perceptions of online versus face-to-face
instruction. International Journal for the Scholarship of Teaching and
Learning, 9(2), 2. https://doi.org/10.20429/ijsotl.2015.090202

Walther, J. B. (2011). Visual cues in computer-mediated communication:
Cometimes less is more. In A. Kappa & N. Kramer (Eds.), Face-to-face
communication over the Internet: Emotions in a web of culture, lan-
guage, and technology (pp. 17-38). Cambridge University Press.
https://doi.org/10.1017/CBO9780511977589.003

Willingham, J. (2019, September 14). U.S. News 2020: Dept rank vs
academic rep vs overall rank plus social mobility. Public University
Honors.com. Retrieved October 20, 2019, from https://publicuniversi
tyhonors.com/category/stats-and-surveys/

Wu, H. K., Lee, S. W., Chang, H. Y., & Liang, J. C. (2012). Current status,
opportunities, and challenges of augmented reality in education.
Computers & Education, 62, 41-49. https://doi.org/10.1016/j.com
pedu.2012.10.02

About the Authors

Jihyun Kim is an associate professor in the Nicholson School of
Communication and Media at the University of Central Florida.
Her primarily research focuses on the effects and implications of

INTERNATIONAL JOURNAL OF HUMAN-COMPUTER INTERACTION ) 1911

new media/communication technologies for meaningful outcomes
(e.g., education, health). Her research also examines human-
machine communication in diverse contexts.

Kelly Merrill Jr. is a doctoral student in the School of
Communication at The Ohio State University. His primary research
interests are at the intersection of communication technology and
health communication. Specifically, he is interested in disparities
and marginalization in these areas.

Kun Xu is an_ assistant professor at the Department of
Telecommunication, University of Florida. His research focuses on
the intersection of human-computer interaction and media psychol-
ogy. He investigates how people perceive, evaluate, and respond to
robotic technologies such as social robots, computer agents and virtual
assistants.

Deanna D. Sellnow is a professor of strategic communication at the
University of Central Florida. Her research focuses on strategic instruc-
tional communication in a variety of contexts including risk, crisis, and
health. She has conducted numerous funded research projects and has
published in national and international journals.
