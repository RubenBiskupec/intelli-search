International Journal of Electrical and Computer Engineering (IJECE)
Vol. 10, No. 6, December 2020, pp. 5974~5984
ISSN: 2088-8708, DOI: 10.1159 1/ijece.v1016.pp5974-5984 O 5974

Medical vision: Web and mobile medical image retrieval
system based on google cloud vision

I Ketut Gede Darma Putra, Dewa Made Sri Arsa, I Gusti Ngurah Dwiva Hardijaya, I Gede Galang
Surya Prabawa, I Made Aris Satia Widiatmika
Information Technology, Faculty of Engineering, Universitas Udayana, Indonesia

 

Article Info ABSTRACT
Article history: The application of information technology is rapidly utilized in the medical system.
Received Jul 28, 2019 There is also a massive development in the automatic method for recognizing and

detecting objects in the real world. In this study, we present a system called Medical
Vision which is designed for people who has no expertise in medical. Medical Vi-
sion 1s a web and mobile-based application to give an initial knowledge in a medical
image. This system has 5 features; object detection, web detection, object labeling,

Revised Apr 1, 2020
Accepted May 2, 2020

 

Keywords: ;
safe search, and image properties. These features are run by embedding Google Vi-
Image retrieval sion API in the system. We evaluate this system by observing the result of some
Medical imaging medical images which inputted into the system. The results showed that our system
Mobile application presents a promising performance and able to give relevant information related to the
Web application given image.
Copyright © 2020 Insitute of Advanced Engineeering and Science.
All rights reserved.
Corresponding Author:
I Ketut Gede Darma Putra,

Information Technology, Faculty of Engineering, Universitas Udayana, Mengwitani, Bali, Indonesia.
Email: ikgdarmaputra @ unud.ac.id

1, INTRODUCTION

In this globalization era, technology has been in touch in numerous living aspects. In education,
massive technological development brings a new learning method which is called online learning or distance
learning. Barbara et al. [1] show that students who take online learning performed better than those who take
face-to-face instruction. In the medical field, moreover, intelligent technology is adapted to present and analyze
the medical image to help the reader (doctor, nurse, etc.) in making the right decision.

A computerized analysis system was firstly initiatedby Lusted in 1960s. He showed that an automatic
system could be used to determine the abnormality in chest photofluorograms [2]. Others work later studied
a computer analysis and diagnosis on bone cancer image [3]. Since then, various computer-assisted diagnosis
(CAD) systems were developed in medical image.

When designing CAD, the characteristic of image has to address firstly to ensure the kind of method
needed to improve the performance of the system. Medical image is taken from a high-end medical device
which cannot gain by human vision capabilities. This image has two characteristics; high resolution and
high pixel depth [4]. However, in a certain condition, the produced image is not clear enough because of
noises. Therefore, improving the quality of the image is necessary to deliver valuable information to the doctor.
In advance, an intelligent system can be used to provide an early diagnosis for them.

To deal with medical image challenges, various research tried to addopt an intelligent method to pro-
cess and provide analysis automatically. In breast cancer, the research area is detecting cancer in hyperspectral
imaging [5], breast cancer classification [6, 7], optical imaging and augmented reality visualization [8, 9].
Then, automatic methods were build to Lung diseases on CT images [10, 11]. Moreover, similar methods were
also created to analyze skin diseases from skin image [12-21]. If we take a look in more detail on the method,

Journal homepage: http://ijece.iaescore.com
Int J Elec & Comp Eng ISSN: 2088-8708 O 5975

deep learning has been chosen recently and massively as one of the methods for automatically analyzing the
medical image [22-39]. Deep learning has been widely used to analyze medical images in skin lesion classifica-
tion [19-21], breast cancer classification [23-26], and melanoma detection [27-29]. From those research, their
methods are built for the medical environment for specific task. Since advancing method in machine learning,
like deep learning, and availability tons of image processing libraries which can be used freely, a system which
can assist human to improve their understanding on the medical image is highly needed.

In this paper, different with previous research, we proposed a system with deep analysis on medical
image. Our system is design to produce extensive analysis on a given medical image. Our system can detect
medical object and analyze it for better understanding on it. We design our system to run on web-based system.
To improve mobility of our system, we also develope a mobile-based application. These systems are embedded
five features. The first feature is medical object detection. Its purpose is detecting all objects occurred in the
scene. The second feature is medical website detection which is designed to search related articles or images
associate with the given image. The third feature is object labeling. This feature performs entity categorization
and rank the results based on confidence score. The fourth feature is safe search which aims to classify the type
of content related to the given image. The last feature is image properties. It provides the detail of the image
based on pixel information.

This study is written as follows. In section 2. we provide brief information about Google Vision.
Then, we present our proposed system in section 3. After that, in section 4. we present the detail of system
implementation, the result of the experiments, and some discussions of the result. Then, we give the conclusion
of this study and insight for future research in section 5.

2. GOOGLE CLOUD VISION API

Google cloud vision API is a service from Google cloud platform (GCP) that can provide an analysis
of an image. This API was released on May 18, 2017, with Machine Learning and Big Data technology which
became the engine behind it. Cloud Vision API is used to identify objects in an image such as text, symbols,
and types of product objects digitally.

Google has many scenarios in the Cloud Vision API. For example developers can use Cloud Vision
API to detect whether there is a mobile in the image, detect inappropriate content, analyze someone’s emotions
recorded in the image, and extract the writing. Cloud Vision API supports the detection of objects in images
using the same technology on Google Photos so that developers can find out the names of objects in a photo.
Besides, this API can be used to avoid inappropriate image content detected with Google SafeSearch. Cloud
Vision API can also be used to analyze people’s emotions and detect various logos from famous products.
Google’s API is also able to detect the letters contained in images with automatic language identification.

3. PROPOSED SYSTEM

Generally, the process of our proposed system can be seen in Figure la. The image will be uploaded
to our system. Our engine will analyze it and provide several informations. We realized these information
as features. We designed five features on our system. Those features are object detection, label detection,
web detection, image properties, and safe search. Each feature delivers different information to the user.
Those features will be explained as follows:

(a) Object Detection: This feature is used to detect objects which can be found in the uploaded image.
The detected objects will be rounded with a square.

(b) Label Detection: For each image uploaded by the user, Medical Vision will analyze the type of content
occurred in it. For example, an actinic keratosis image is uploaded to the system. This system will
produce several labels correlated to the image which have been sorted by their confidence score. For the
actinic keratosis case, the detected labels will be finger, skin, hand, and thumb, joint, nail, gesture, flesh,
and wrist.

(c) Web Detection: This feature is used to recommend related websites which explain the image in more
detail. Two types category of website are produced; partially matched images and pages. Beside of
this links, two more information are given in this feature. The first information is the best guess la-
bel which mostly matched for the given image. Secondly, this feature presents entities information.
These entities present related diseases related to the image. For example, given an image labeled as
actinic keratoses, our system will produce several entities; actinic keratosis, keratosis, actinic cheilitis,

Medical vision: Web and mobile medical image retrieval system... (I Ketut Gede Darma Putra)
5976 0 ISSN: 2088-8708

skin cancer, a precancerous condition, keratoses, seborrheic keratosis, therapy, skin, and lesion. The first
label has the highest confidence score.

(d) Image Properties: Image properties feature is used to analyze the image based on its pixel value.
This feature gives the detail information of entities produced in web detection feature. For each entity,
three values are computed; RGB, score, and pixel fraction.

(e) Safe Search: Safe search feature is used to categorize the image into content classes. In this feature,
the image will categorize into adult content, spoof content, medical content, violence content, and racy
content. For each category, a score will be given as very likely, likely, possible, unlikely, and very
unlikely. For example, the image in Figure 1b will be annotated likely as Medical content, possible as
Violence and Racy content, and very unlikely as Adult and Spoof content.

Object detection
Medical
oe , Web detection
VISION ENQINE
Image properties

Safe search

 
 
  

 

Input image

 
      

     

(a) (b)
Figure 1. a) Medical image will be inputted to our system for analysis process on five features and
b) Example of medical image: actinic keratosis disease

send results for object detection, label
detection, web detection, safesearch
detection, and image properties in HTML format

 

a upload image

Web Browser Web Server

  

JSON Response for android
request or HTML response

for web browser request send results for object detection,

label detection, web detection,
upload image safesearch detection, and
image properties in JSON format

 

API request and API key

Mobile
searching request for application
web or android

ed

      

giving image reference

Google Vision Google Cloud
API Storage

Figure 2. The architecture of medical vision system

Int J Elec & Comp Eng, Vol. 10, No. 6, December 2020 : 5974 — 5984
Int J Elec & Comp Eng ISSN: 2088-8708 O 5977

To improve ease of access, we designed our system in the form of a web-based system and android
application. As seen in Figure 2, the user can upload an image through both applications. This image will
be sent to a web server. This server makes a request to Google Vision Server using Google Vision API.
After that, this Google Vision Server produces the image references and send it back to the web server in JSON
file. Lastly, the web server will send this result to the user.

4. RESULT AND DISCUSSION

As stated previously, Medical Vision was developed in a web-based and mobile-based system.
The web-based system was developed under HTML while the mobile application was designed for Android
only. As shown in Figure 2, the uploaded image in both browser and mobile-apps will be processed in the web
server where process this image using Google Vision API. We evaluate this system by inputting several medical
images into the system; actinic keratosis, bullous pemphigoid, chickenpox, eczema, herpes zoster, impetigo,
keloid, keratoacanthoma, lichen planus, melanoma, pustular psoriasis, seborrheic keratosis, and tinea barbae.

4.1. Web-based implementation

The example of our implementation can be seen in Figure 3-8. In this example, we test our system
by inputting the Actinic Keratosis image. Actinic keratosis (AK) is a disease that can occur in our skin caused
by ultraviolet radiation. As shown in Figure 3, we upload a picture which is classified as AK. The object
analysis tells that the image is labeled as Person with confidence score by 86.17%. Then, in Figure 4, the labels
predicted by our system shows that the image is related to finger, skin, hand, thumb, joint, nail, gesture, flesh,
and whist where the highest score is obtained as finger. Interestingly, in web detection feature, our system
accurately predicts the image as AK with confidence score by 87.34% followed by keratos, artinic chelitis,
skin cancer, a precancerous condition, keratoses, seborrheic keratosis, therapy, skin, and lesion as shown in
Figure 5. When the web detection result is clicked, the page will be directed to the new page which will show
some information related to the image. In the safe search feature, furthermore, the system will give a general
type of content for the given image as shown in Figure 8. For AK image, the result is classified likely as medical
content, possible for violence and racy content, and very unlikely as adult and spoof content.

4.2. Mbobile-based implementation

The implementation of Medical Vision in mobile apps can be seen in Figure 9. This image is actually
hands which were affected by Leprosy disease in https://www.who.int/lep/disease/en/. This disease is showed
that it infects the skin but it also may affect peripheral nerves. As shown in Figure 9a, the system detects two
objects in the given image. Those objects are glove and animal where glove has the highest confidence score.
In label detection, the labels results show that it highly related to the image qualitatively. Interestingly, the
web detection presents that the image labeled as Leprosy with 81.49% evidence score. The apps also provide
a similar image from the website.

i) Not Secure — medicalvision.profdp.com

Medical Vision

Image Analyze Result

 

| iH ® © @ ®
Object Labels Web Properties Safe Search

 

1. Person

Score: 82.87%

 

Last Updated: 2020-02-21 15:22:21

Figure 3. Object detection result for actinic keratosis image

Medical vision: Web and mobile medical image retrieval system... (I Ketut Gede Darma Putra)
5978

0

 

 

im)

Not Secure — medicalvision.profdp.com

Medical Vision

Image Analyze Result

 

o ® © @

Object Labels Web

 

1. Hand
Score: 95.91%

2. Skin
Score: 95.47%

3. Finger
Score: 95.40%

Properties

ISSN: 2088-8708

 

Safe Search

 

 

Last Updated: 2020-02-21 15:22:21
4. Joint

Score: 84.18%

5. Arm
Seore: 77 59%

Figure 4. Label detection result for actinic keratosis image

Not Secure — medicalvision.profdp.com

Medical Vision
Image Analyze Result

 

WIKIPEDIA

The Free Encyclopedia

Main page
Contents

Featured content
Current events
Random article
Donate to Wikipedia
Wikipedia store

Interaction

Help

About Wikipedia
Community portal
Recent changes
Contact page

Tools

What links here
Related changes
Upload file
Special pages
Permanent link
Page information
Wikidata item
Cite this page

In other projects

Wikimedia Commons

Print/export

Figure 6.

@

Object Labels

 

Best Guess Labels

1. Actinic keratosis hands

Language Code: en

Entities

 

1. Actinic keratosis

Score: 99.59
2. Dermatology

Score: 70.62
3. Keratosis

Last Updated: 2020-02-21 15:22:21

Score: 70.26
4. Medicine

Score: 69.93

Properties

 

Safe Search

Matched Images

http://primariabeuca.ro/images/3:
https://www.medical-
tribune.de/fileadmin/_processed_,
https://upload.wikimedia.org/wiki
SolarAcanthosis.jpg
httos://pbs.twimg.com/media/Do«

Partially Matched Images

https://lookaside.fbsbx.com/looka:
media_id=1161542184041243
https://tmu.org.ua/wp-
content/uploads/2019/08/1566337
na-kozhe-u-vzroslyh_14.jpg

Figure 5. Web detection result for actinic keratosis image

f@ en.wikipedia.

Article Talk

eS i toves
Actinic keratosis

From Wikipedia, the free encyclopedia

 

Actinic keratosis (AK), sometimes called solar keratosis or senile keratosis, '"l[2] is a pre-cancerous!) area of
thick, scaly, or crusty skin.'4II5! The term actinic keratosis can be literally understood as a disorder (-osis) of epidermal
keratinocytes that is induced by ultraviolet (UV) light exposure (actin-).!5] These growths are more common in fair-
skinned people and those who are frequently in the sun.!7! They are believed to form when skin gets damaged by UV
radiation from the sun or indoor tanning beds, usually over the course of decades. Given their pre-cancerous nature,
if left untreated, they may turn into a type of skin cancer called squamous cell carcinoma. Untreated lesions have
up to a 20% risk of progression to squamous cell carcinoma,®! so treatment by a dermatologist is recommended.

Actinic keratoses characteristically appear as thick, scaly, or crusty areas that often feel dry or rough. Size commonly

ranges between 2 and 6 millimeters in size, but they can grow to be several centimeters in diameter. Notably, AKs are
often felt before they are seen, and the texture is sometimes compared to sandpaper." They may be dark, light, tan,

pink, red, a combination of all these, or have the same color as the surrounding skin.

Given the causal relationship between sun exposure and AK growth, they often appear on a background of sun-
damaged skin and in areas that are commonly sun-exposed, such as the face, ears, neck, scalp, chest, backs of
hands, forearms, or lips. Because sun exposure is rarely limited to a small area, most people who have an AK have
more than one.!19]

If clinical examination findings are not typical of AK and the possibility of in situ or invasive squamous cell carcinoma
(SCC) cannot be excluded based on clinical examination alone, a biopsy or excision can be considered for definitive
diagnosis by histologic examination of the lesional tissue."") Multiple treatment options for AK are available.

Photodynamic therapy (PDT) is one option the treatment of numerous AK lesions in a region of the skin, termed field
cancerization.!'21 It involves the application of a photosensitizer to the skin followed by illumination with a strong light
source. Topical creams. such as 5-fluorouracil or imiauimod. mav reauire dailv application to affected skin areas over

 

& Not logged in Talk Contributions Create account Log in

Read Edit View history | Search Wikipedia Q

leds ey im lm eter me ema] es

Wikipedia and win!

 

 

Actinic keratosis
Other names Solar keratosis, senile keratosis (SK)

’ 2,

  

Actinic keratosis seen on the back of the hands

Specialty Dermatology

 

Example preview when the link in web detection result was clicked

Int J Elec & Comp Eng, Vol. 10, No. 6, December 2020 : 5974 — 5984
Int J Elec & Comp Eng ISSN: 2088-8708 0 5979

(0 Not Secure — medicalvision.profdp.com

Medical Vision

Image Analyze Result

 

 

iF ® © Cd ®
Object Labels Web Properties Safe Search

=

. RGB: 152, 108, 88
Score: 47.92%
Pixel Fraction: 0.15896825
2. RGB: 119, 78, 60
Score: 30.20%
Pixel Fraction: 0.090555556
3. RGB: 182, 139, 117
Score: 14.30%
Pixel Fraction: 0.09793651
4. RGB: 87, 44, 28
Score: 3.54%
Last Updated: 2020-02-21 15:22:21 Pixel Fraction: 0.006825397
5. RGB: 178, 152, 132
Score: 0.82%
Pixel Fraction: 0.022222223
6. RGB: 59, 12,3
Score: 0.62%
Pixel Fraction: 0.0011111111

2 mem. ine of 79

 

 

Figure 7. Image properties result for actinic keratosis image

i] Not Secure — medicalvision.profdp.com

Medical Vision
Image Analyze Result

 

 

i & © @ e
Object Labels Web Properties Safe Search
1. Adult UNLIKELY
Spoof VERY_UNLIKELY
Medical POSSIBLE
Violence POSSIBLE
Racy POSSIBLE

 

Last Updated: 2020-02-21 15:22:21

Figure 8. Safe search result for actinic keratosis image

VLAN aL 1
LEPROSY PATIENTS

a ‘

aye
res

Se

3) tg IMAGES

OBJECT

  

58.24 Glove 94.25 = Skin
56.28 = Animal 87.01 Hand
74.55 ‘Finger

71.52 Organism

(a) (b)

Medical vision: Web and mobile medical image retrieval system... (I Ketut Gede Darma Putra)
5980 0 ISSN: 2088-8708

bez 1 | ie Cle
eS te a)

 

OBJECT

Ses
Uy te sy

81.49 Leprosy

70.18 ~World Leprosy Day

58.99 Patient

55.35 Hospital

 

(c) (d)

Figure 9. Implementation result of Medical vision in mobile application, a) Object detection,
b) Label detection, c) Web detection, and d) Similar image (continue)

4.3. Performance analysis

The previous subsection shows the example of the implementation of Medical Vision in web-based and
mobile-based system. Beside of that, we evaluate our system performance for 13 medical images.
We gather the results in Table | The first column presents the actual label of the image. In the second col-
umn, the detected object for each image is presented aside with the highest confidence score. From those
result, most of the objects are highly correlated in qualitatively. However, in pustular psoriasis and seborrheic
keratosis, the object detection results are not fit the actual image. In pustular psoriasis, a watermelon object is
detected while a baked good is identified in seborrheic keratosis. If we observe, however, the pustular psoriasis
image, this disease will make a pattern in the skin and has a similar pattern like watermelon.

The label detection results show promising result where all of them presents high relation to the
disease. In the majority, the skin label has the highest confidence score. For actinic keratosis, the sample image
which is shown in Figure 3, is classified as a finger.

An interesting result is shown in the web search feature. In Table | (see appendix) most guess labels
was closely matched the actual image labels. The web search entities are also mostly related to the actual image
label. For impetigo, keratoacanthoma, pustular psoriasis, and seborrheic keratosis, web search feature produces
uncorrelated labels. However, their entities show that the results for impetigo and pustular psoriasis images are
not fit but others match up the labels. This labeling error may occur because of model limitation.

The safe search feature also shows promising. The results present that all test images categorize as
medical content, but not all images predict VL. In actinic keratosis, the image classifies likely as medical
image. From those results, there is a relation between medical and violence content. When the image labeled
as medical content, it also will be said as violence content. For example, impetigo image is predicted VL as
medical content and L as medical content.

5. CONCLUSION

In this study, we have been presented our system which is called Medical Vision. Our system is
utilized Google Cloud Vision API for processing the image. This system was built for common people with
less knowledge in the medical image. Based on our evaluation, our system may work properly in the given test
case. This system still needs some enhancements in the image processing method. In Google Cloud Vision,
the model was trained using various objects, so it will not cover all of the medical objects. Therefore, a new
model is recommended to be built in the future.

Int J Elec & Comp Eng, Vol. 10, No. 6, December 2020 : 5974 — 5984
 

Int J Elec & Comp Eng ISSN: 2088-8708 O 5981
APPENDIX
Table 1. The result of our system analysis, VU: very unlikely,
U: unlikely, P: possible, L: likely, VL: very likely
Actual Image label Object Detection Label Detection Web Search (Best guess labels) Web Search (Entities) Safe Search
Actinic Keratosis Person : 86.17 Finger : 96.17 Keratose Acinique Actinic Keratosis : 83.34 Adult : VU
Keratosis Spoof : VU
Actinic chellitis Medical : L
Skin cancer Violence : P
Precancerous condition Racy: P
Bullous Pemhigoid Egg : 53,34 Skin : 97.21 Bullous Pemphigoid Bullous pemphigoid : 73.01 Adult : VU
Nose Linear IgA bullous dermatosis Spoof : VU
Jaw Bullous dermatoses Medical : VL
Mouth Skin condition —- Violence : VL
Flesh Cicatricial pemphigoid Racy : P
Chickenpox Skin : 96,61 Chickenpox Chickenpox : 88.36 Adult : VU
Pink Smallpox Spoof : VU
Close-up Varicella zoster virus Medical : VL
Peach Attenuated vaccine Violence : L
Flesh MMR vaccine Racy : VU
Eczhema Person : 95.12 Skin : 97.37 Eczema on hands Dermatitis : 72.24 Adult : VU
Hand Dyshidrosis Spoof : VU
Fing Hand eczema Medical : VL
Close-up Eczema Violence : P
Flesh Dermatitis Racy : P
Herpes zoster Skin : 97.47 Herpes Zoster Shingles : 73.59 Adult : U
Close-up Varicella zoster virus Spoof : VU
Muscle Chickenpox Medical : VL
Lip Herpex simplex virus _—_- Violence : VL
Flesh Therapy Racy : P
Impetigo Skin : 97 Close-up Stock photography Adult : U
Finger Impetigo Spoof : VU
Hand Science photo library Medical : VL
Flesh - Violence : L
Joint Thumb Racy : VL
Keloid Lipstick Skin Hypertropic and keloid scar Scar Adult : VU
Scar Keloid Spoof : VU
Lip Hypertropic scar Medical : VL
Cheek Surgery Violence : L
Close-up therapy Racy : P
Keratoacanthoma Skin Close up Keratoacanthoma Adult : VU
Nose Spoof : VU
Close-up Medical : VL
Flesh Violence : VL
Novel Racy: U
Linchen Planus Skin Lichen planus skin Lichen planus Adult : VU
Joint Spoof : VU
Hand Medical : VL
Close-up Violence : VL
Scar Racy : P
Melanoma Lipstick Skin Melanoma skin cancer Skin cancer Adult : VU
Brown Melanoma Spoof : VU
EyeBrow Cancer Medical : VL
Cheek Melanocyte = Violence : VL
Lip Dermatology Racy : P
Pustular psoriasis Watermelon Skin Red meat Apple iphone 8 Adult : VU
Flesh Apple Spoof : VU
Red meat Pustule Medical : VL
Water Psoriasis Violence : L
Close-up Fine art america Racy: U
Seborrheic keratosis Baked Good Skin Rock Seborrheic keratosis Adult : VU
Coockie Keratosis Spoof : VU
Dessert - Medical : P
Food Actinic Keratosis Violence : U
Snack Melanoma Racy : VU
Tinea Barbae Lipstick Skin Tinea barbae Tinea barbae Adult : VU
Lip - Spoof : VU
Face Mycosis Medical : VL
Chin Tinea caphis Violence : L
Nose Tinea corporis Racy: L

 

Medical vision: Web and mobile medical image retrieval system... (I Ketut Gede Darma Putra)
5982 0 ISSN: 2088-8708

ACKNOWLEDGEMENT

This research was funded by Ministry of Research, Technology, and Higher Education of the Republic
of Indonesia with grant number 492.67/UN14.4.A/LT/2019 entitled by Smart Medical Record (Sistem Rekam
Medis Elektronik Online Terintegrasi dengan Dukungan Fingerprint, Tele Image Medicine, Smart Card, dan
GIS Google Map)”.

REFERENCES

[1] B. Means, et al., Evaluation of evidence-based practices in online learning: A meta-analysis and review
of online learning studies,” Centre for Learning Technology, 2009.

[2] L.B. Lusted, “Logical analysis in roentgen diagnosis: memorial fund lecture,” Radiology, vol. 74, no. 2,
pp. 178-193, 1960.

[3] G.S. Lodwick, Radiographic diagnosis and grading of bone tumors, with comments on computer eval-
uation,’ Proceedings National Cancer Conference, vol. 5, pp. 369-380, 1964.

[4] A. Ortiz, J. Gorriz, J. Ramirez, D. Salas-Gonzalez, and J. M. Llamas-Elvira, “Two fully-unsupervised
methods for mr brain image segmentation using som-based strategies,” Applied Soft Computing, vol. 13,
no. 5, pp. 2668-2682, 2013.

[5S] R. Pike, G. Lu, D. Wang, Z. G. Chen, and B. Fei, “A minimum spanning forest-based method for nonin-
vasive cancer detection with hyperspectral imaging,’ [EEE Transactions on Biomedical Engineering, vol.
63, no. 3, pp. 653-663, 2015.

[6] S. Reis, et al., ”Automated classification of breast cancer stroma maturity from histological images,”
IEEE Transactions on Biomedical Engineering, vol. 64, no. 10, pp. 2344-2352, 2017.

[7] J. Xu, L. Xiang, Q. Liu, H. Gilmore, J. Wu, J. Tang, and A. Madabhushi, “Stacked sparse autoencoder
(ssae) for nuclei detection on breast cancer histopathology images,’ IEEE transactions on medical imag-
ing, vol. 35, no. 1, pp. 119-130, 2015.

[8] X.Chen, D. Yang, F. Sun, X. Cao, and J. Liang, “Adaptively alternative light-transport-model-based three-
dimensional optical imaging for longitudinal and quantitative monitoring of gastric cancer in live animal,”
IEEE Transactions on Biomedical Engineering, vol. 63, no. 10, pp. 2095-2107, 2015.

[9] Y. Sato, et al., “Image guidance of breast cancer surgery using 3-d ultrasound images and augmented
reality visualization,’ IEEE Transac- tions on Medical Imaging, vol. 17, no. 5, pp. 681-693, 1998.

[10] Y. Chunran, W. Yuanvuan, and G. Yi, “Automatic detection and segmentation of lung nodule on ct im-
ages,’ 11th International Congress on Image and Signal Processing, BioMedical Engineering and Infor-
matics, pp. 1-6, 2018.

[11] X. Liu, L. Ma, L. Song, Y. Zhao, X. Zhao, and C. Zhou, “Recognizing common ct imaging signs of
lung diseases through a new feature selection method based on fisher criterion and genetic optimization,”
IEEE journal of biomedical and health informatics, vol. 19, no. 2, pp. 635-647, 2014.

[12] M. Sadeghi, T. K. Lee, D. McLean, H. Lui, and M. S. Atkins, “Detection and analysis of irregu-
lar streaks in dermoscopic images of skin lesions,’ IEEE Transactions on Medical Imaging, vol. 32,
no. 5, pp. 849-861, 2013.

[13] D. H. Chung and G. Sapiro, “Segmenting skin lesions with partial-differential-equations-based image
processing algorithms,’ IEEE transactions on Medical Imaging, vol. 19, no. 7, pp. 763—767, 2000.

[14] R. Suganya, “An automated computer aided diagnosis of skin lesions detection and classification
for dermoscopy images,” International Conference on Recent Trends in Information Technology,
pp. 1-5, 2016.

[15] A. H. Shahin, A. Kamal, and M. A. Elattar, “Deep ensemble learning for skin lesion classification from
dermo- scopic images,” 9th Cairo International Biomedical Engineering Conference, pp. 150-153, 2018.

[16] T. Polevaya, R. Ravodin, and A. Filchenkov, “Skin lesion primary morphology classification with end-
to-end deep learning network,” International Conference on Artificial Intelligence in Information and
Communication, pp. 247-250, 2019.

[17] M. A. Albahar, “Skin lesion classification using convolutional neural network with novel regularizer,”
IEEE Access, vol. 7, pp. 306-313, 2019.

[18] K. Shimizu, H. Iyatomi, M. E. Celebi, K.-A. Norton, and M. Tanaka, “Four-class classification of skin
lesions with task decomposition strategy,’ [EEF transactions on biomedical engineering, vol. 62, no. 1,
pp. 274-283, 2014.

Int J Elec & Comp Eng, Vol. 10, No. 6, December 2020 : 5974 — 5984
Int J Elec & Comp Eng ISSN: 2088-8708 i) 5983

[19] O. Abuzaghleh, B. D. Barkana, and M. Faezipour, “Noninvasive real-time automated skin lesion analysis
system for melanoma early detection and prevention,” [EFE journal of translational engineering in health
and medicine, vol. 3, pp. 1-12, 2015.

[20] J. Kawahara, S. Daneshvar, G. Argenziano, and G. Hamarneh, “Seven-point checklist and skin lesion
classifica- tion using multitask multimodal neural nets,” IEEE journal of biomedical and health informat-
ics, vol. 23, no. 2, pp. 538-546, 2018.

[21] F. Rundo, S. Conoci, G. L. Banna, A. Ortis, F. Stanco, and S. Battiato, “Evaluation of leven-
berg—marquardt neural networks and stacked autoencoders clustering for skin lesion analysis, screening
and follow-up,” IET Computer Vision, vol. 12, no. 7, pp. 957-962, 2018.

[22] D. Mulfari, A. Celesti, M. Fazio, M. Villari, and A. Puliafito, “Using google cloud vision in assistive
technology scenarios,’ IEEE Symposium on Computers and Communication (ISCC), pp. 214-219, 2016.

[23] P. Meyer, V. Noblet, C. Mazzara, and A. Lallement, “Survey on deep learning for radiotherapy,’ Com-
puters in Biology and Medicine, vol. 98, pp. 126—146, 2018.

[24] J. de la Torre, A.Valls, and D. Puig, “A deep learning interpretable classifier for diabetic retinopathy
disease grading,” Neurocomputing, 2019.

[25] A.B. Levine, C. Schlosser, J. Grewal, R. Coope, S. J. Jones, and S. Yip, “Rise of the machines: Advances
in deep learning for cancer diagnosis,” Trends in Cancer, vol. 5, no. 3, pp. 157-169, 2019.

[26] M. P. McBee, et al., “Deep learning in radiology,’ Academic Radiology, vol. 25, no. 11, pp. 1472-1480,
2018.

[27] J. Zhang, Y. Xie, Q. Wu, and Y. Xia, “Medical image classification using synergic deep learning,’ Medical
Image Analysis, vol. 54, pp. 10 — 19, 2019.

[28] R. Wason, “Deep learning: Evolution and expansion,’ Cognitive Systems Research, vol. 52, pp. 701—708,
2018.

[29] A. Mahbod, G. Schaefer, I. Ellinger, R. Ecker, A. Pitiot, and C. Wang, “Fusing fine-tuned deep features
for skin lesion classification,’ Computerized Medical Imaging and Graphics, vol. 71, pp. 19-29, 2019.

[30] P.M. Burlina, N. J. Joshi, E. Ng, S. D. Billings, A. W. Rebman, and J. N. Aucott, “Automated detection
of erythema migrans and other confounding skin lesions via deep learning,’ Computers in Biology and
Medicine, vol. 105, pp. 151-156, 2019.

[31] A. Dascalu and E. David, “Skin cancer detection by deep learning and sound analysis algorithms: A
prospective clinical study of an elementary dermoscope,” EBioMedicine, vol. 43, pp. 107-113, 2019.

[32] M. Chen, P. Zhou, D. Wu, L. Hu, M. M. Hassan, and A. Alamri, “Ai-skin : Skin disease recognition based
on self-learning and wide data collection through a closed loop framework,” Information Fusion, 2019.

[33] S. Khan, N. Islam, Z. Jan, I. U. Din, and J. J. P. C. Rodrigues, “A novel deep learning based framework
for the detection and classification of breast cancer using transfer learning,’ Pattern Recognition Letters,
vol. 125, pp. 1-6, 2019.

[34] X. Li, M. Radulovic, K. Kanjer, and K. N. Plataniotis, “Discriminative pattern mining for breast can-
cer histopathology image classification via fully convolutional autoencoder,’ IEEE Access, vol. 7, pp.
433-445,2019.

[35] M. K. Elbashir, M. Ezz, M. Mohammed, and S. S. Saloum, “Lightweight convolutional neural
network for breast cancer classification using rna-seq gene expression data,’ IEEE Access, vol. 7,
pp. 338-185, 2019.

[36] D. Bardou, K. Zhang, and S. M. Ahmad, “Classification of breast cancer based on histology images using
convolutional neural networks,” IEEE Access, vol. 6, pp. 680-693, 2018.

[37] S. H. Kassani and P. H. Kassani, “A comparative study of deep learning architectures on melanoma
detection,” Tissue and Cell, vol. 58, pp. 76—83, 2019.

[38] A. A. Adegun and S. Viriri, “Deep learning-based system for automatic melanoma detection,”
IEEE Access, 2019.

[39] L. Yu, et al., “Automated melanoma recognition in dermoscopy images via very deep residual networks,”
IFEFE transactions on medical imaging, vol. 36, no. 4, pp. 994-1004, 2016.

Medical vision: Web and mobile medical image retrieval system... (I Ketut Gede Darma Putra)
5984 0 ISSN: 2088-8708

BIOGRAPHIES OF AUTHORS

I Ketut Gede Darma Putra was born in Mengwitani, 24 April 1974. A lecturer in Department
of Information Technology, Udayana University Bali, Indonesia. He received his S.Kom degree in
Informatics Engineering from Institute of Sepuluh November Technology Surabaya, Indonesia on
1997. He received his Master Degree on Informatics and Computer Engineering from Electrical
Engineering Department, Gadjah Mada University, Indonesia on 2000 and achieved his Doctorate
Degree on Informatics and Computer Engineering from Electrical Engineering Department, Gadjah
Mada University, Indonesia on 2006. His research interests are Biometrics, Image Processing, Data
Mining, and Soft Computing.

  

Dewa Made Sri Arsa is a lecturer in Department of Information Technology, Universitas Udayana,
Bali, Indonesia. In 2014, he obtained Bachelor degree in Computer Science, Universitas Udayana.
Then, he collected the Master degree in Faculty of Computer Science, Unversitas Indonesia. Cur-
rently, he actively studies in the applicaiton of machine learning in various areas. He is also interested
in image processing, nature inspired based optimization method, and computer vision.

 

I Gusti Ngurah Dwiva Hardijaya is undergraduate student in Department of Information Technol-
ogy, Universitas Udayana, Bali, Indonesia. He deeply studied data and information management.
Beside of it, he actively develops mobile application.

I Gede Galang Surya Prabawa is undergraduate student in Department of Information Technology,
Universitas Udayana, Bali, Indonesia. His research interest is UI and UX. He studied more in data
and information management.

I Made Aris Satia Widiatmika is undergraduate student in Department of Information Technology,
Universitas Udayana, Bali, Indonesia. He was born in Bali, Indonesia. He took data and information
management field on study. Moreover, he attracts to learn about big data technology and internet of
things.

 

Int J Elec & Comp Eng, Vol. 10, No. 6, December 2020 : 5974 — 5984
