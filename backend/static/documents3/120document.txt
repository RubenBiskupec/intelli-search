Np} | Digital Medicine

REVIEW ARTICLE OPEN

www.nature.com/npjdigitalmed

® Check for updates

Automatic, wearable-based, in-field eating detection
approaches for public health research: a scoping review

Brooke M. Bell@'™, Ridwan Alam @”, Nabil Alshurafa@**, Edison Thomaz’, Abu S. Mondol®, Kayla de la Haye@®', John A. Stankovic®,

John Lach@/ and Donna Spruijt-Metz'*?

Dietary intake, eating behaviors, and context are important in chronic disease development, yet our ability to accurately assess
these in research settings can be limited by biased traditional self-reporting tools. Objective measurement tools, specifically,
wearable sensors, present the opportunity to minimize the major limitations of self-reported eating measures by generating
supplementary sensor data that can improve the validity of self-report data in naturalistic settings. This scoping review summarizes
the current use of wearable devices/sensors that automatically detect eating-related activity in naturalistic research settings. Five
databases were searched in December 2019, and 618 records were retrieved from the literature search. This scoping review
included N = 40 studies (from 33 articles) that reported on one or more wearable sensors used to automatically detect eating
activity in the field. The majority of studies (N = 26, 65%) used multi-sensor systems (incorporating > 1 wearable sensors), and
accelerometers were the most commonly utilized sensor (N = 25, 62.5%). All studies (N = 40, 100.0%) used either self-report or
objective ground-truth methods to validate the inferred eating activity detected by the sensor(s). The most frequently reported
evaluation metrics were Accuracy (N= 12) and F1-score (N = 10). This scoping review highlights the current state of wearable
sensors’ ability to improve upon traditional eating assessment methods by passively detecting eating activity in naturalistic settings,
over long periods of time, and with minimal user interaction. A key challenge in this field, wide variation in eating outcome
measures and evaluation metrics, demonstrates the need for the development of a standardized form of comparability among

sensors/multi-sensor systems and multidisciplinary collaboration.

npj Digital Medicine (2020)3:38; https://doi.org/10.1038/s41746-020-0246-2

INTRODUCTION

Dietary intake (i.e, what and how much is consumed), eating
behaviors (i.e., food choices and motives, feeding practices), and
context (i.e., who is eating, when, where, with whom, etc.) play a
significant role in the development of chronic diseases, including
type 2 diabetes, heart disease, and obesity'°. Recent data from
the National Health and Nutrition Examination Survey (NHANES)
indicate that national obesity prevalence for U.S. adults (39.6%) and
for U.S. youth (18.5%) is the highest ever documented (compared
with 14.5% and 5.0%, respectively, in the early 1970s)’~*. Poor diet is
estimated to have contributed to 11 million deaths globally in
2017'°. Despite this strong association between food intake and
health, our ability to accurately assess dietary intake, eating
behaviors, and context are three existing challenges in dietary
research. Dietary intake/eating behavior assessment in both youth
and adult populations historically relies on self-reporting tools! '"'7.
The most commonly used tools to assess dietary intake/eating
behaviors are 24-h recalls, food records (food diaries), and food
frequency questionnaires (FFQ)'*'*. Major limitations of these
methods include participant burden and recall or memory
bias'*’'®, which can lead to under- and over-reporting of dietary
intake, skewing research findings in both directions'’. Measure-
ment tools that can minimize these limitations are crucial for

accurately detecting temporal patterns of food and nutrient intake
and having measurement sensitivity to detect intake changes, and
to ultimately discern the influences of dietary intake and eating
behaviors on health outcomes.

Traditional methods of eating assessment typically summarize
dietary measures at the hour-, day-, week-, or even year-level''"*.
Although these can be helpful in understanding relationships
between eating behavior and its predictors, important micro-level
temporal patterns and processes are not measured nor can they
be explored with these measures. The ability to explore micro-
level eating activities, such as meal microstructure (the dynamic
process of eating, including meal duration, changes in eating rate,
chewing frequency, etc.)'®, food choices'’, and processes (e.g.,
eating rate*°; eating mimicry*'*; etc.), is important because
recent literature suggests that they may play an important role on
food selection, dietary intake, and ultimately, obesity and
disease risk.

Emerging technologies present the opportunity to improve
these assessment methods by using methods that improve the
quality and validity of data that is collected, and by passively
measuring eating activity in naturalistic settings over long periods
of time with minimal user interaction. Technological advances in
dietary assessment tools include: (i) web-based self-administered

‘Department of Preventive Medicine, Keck School of Medicine, University of Southern California, Los Angeles, CA 90089, USA. “Department of Electrical and Computer
Engineering, School of Engineering and Applied Science, University of Virginia, Charlottesville, VA 22904, USA. *Department of Preventive Medicine, Feinberg School of Medicine,
Northwestern University, Chicago, IL 60611, USA. “Department of Computer Science, McCormick School of Engineering, Northwestern University, Chicago, IL 60611, USA.
°Department of Electrical and Computer Engineering, Cockrell School of Engineering, The University of Texas at Austin, Austin, TX 78712, USA. (Department of Computer Science,
School of Engineering and Applied Science, University of Virginia, Charlottesville, VA 22904, USA. ‘Department of Electrical and Computer Engineering, School of Engineering and
Applied Science, The George Washington University, Washington, DC 20052, USA. 8center for Economic and Social Research, Dornsife College of Letters, Arts, and Sciences,
University of Southern California, Los Angeles, CA 90089, USA. *Department of Psychology, Dornsife College of Letters, Arts, and Sciences, University of Southern California, Los
Angeles, CA 90089, USA. “email: brooke.bell@usc.edu

np} nature partner

Scripps Research Translational Institute journals
np}

B.M. Bell et al.

 

24-h recall tool, which aims to reduce respondent burden”; (ii)
mobile device-assisted ecological momentary assessment
(mMEMA), which focuses on reducing recall bias by collecting
real-time data in naturalistic settings’; (iii) photo-assisted and
image-based dietary assessments, which attempt to reduce
respondent burden and recall bias*’; and (iv) wearable sensors,
which offer a suite of measurement tools that seek to tackle all of
these limitations*°?’. Wearable devices with embedded sensors in
particular allow for the passive collection of various data streams
that can be used to develop algorithms to infer eating behaviors
in naturalistic settings and, with some types of sensors, over long
periods of time. Collecting near-continuous data in the context of
daily life, where behavior actually occurs, has proven to be
extremely difficult for researchers and burdensome for partici-
pants*°?”. However, wearable sensors can lessen the burden by
passively collecting data while users go about their daily lives with
minimal user input, compared with existing methods.

In the past decade, a range of wearable sensors for the purpose
of automating eating detection have been proposed and studied.
However, these studies have been primarily conducted in a
combination of controlled lab and semi-controlled field set-
tings*®*’, and for good reason: these systems are challenging to
develop, deploy, and evaluate. More recently, however, the
research field has rapidly expanded the testing of these devices
in the field. Previous research has shown significant differences in
eating metrics (e.g., duration of meals, number of bites, etc.)
between similar in-lab and in-field studies*°, illustrating the
importance of in-field testing and in-field validation of wearable
sensors. Field deployment is crucial because it is where humans
are more likely to behave naturally as compared with a research
lab setting, and many of the influences on eating behavior cannot
be replicated in a laboratory. Moreover, non-eating behavior that
confounds these sensors (e.g., smoking, biting nails, etc.) are too
many, and not all known, to replicate in a natural way in
controlled settings. The data from wearable sensors deployed in
the field will offer researchers a wealth of temporally-rich, highly
contextualized eating activity data that can address exciting and
novel research questions that were previously inexplorable.

The next step toward integrating these wearable technologies
into public health research is to continue testing the wearable
technology in the field, while beginning to address and solve the
unique technical, analytical, and multidisciplinary challenges that
arise from this effort. Wearable sensors provide the opportunity to
examine and understand real-time eating behavior in context, but
their introduction into field testing has been slow and challenging.
It is unclear what kind of information is available in the literature
about the unique features and challenges of field testing.
Moreover, the measures with which these sensors are reported
and evaluated is also highly varied and non-uniform. Therefore, a
scoping review was conducted in order to:

1. catalog the current use of wearable devices and sensors that
automatically detect eating activity (dietary intake and/or
eating behavior) specifically in free-living research settings;

2. and identify the sample size, sensor types, ground-truth
measures, eating outcomes, and evaluation metrics used to
evaluate these sensors.

It was outside the scope of this paper to systematically review
contextual factors, if any, detected with these automatic,
wearable-based methods; however, a brief discussion on the
potential for these methods in future research is included. In
addition, a discussion of key challenges of in-field testing and
recommendations for future research directions are included.

A scoping review was chosen due to the heterogenous
methods used in this field of research.

npj Digital Medicine (2020) 38

METHODS

The reporting of this scoping review adheres to the Preferred
Reporting Items for Systematic reviews and Meta-Analyses
Extension for Scoping Reviews (PRISMA-ScR) checklist®'.

Information sources

We conducted a literature search of the PubMed, SCOPUS, IEEE
Xplore, ACM Digital Library, and Google Scholar (first 50 results)
databases for all literature published through December 2019. A
research librarian assisted with the literature search strategy,
which was further refined by the authorship team. The records
retrieved from the databases were imported into a web-based
systematic review management tool, Covidence**. We also hand
searched the reference lists of the originally included publications
for additional eligible studies.

Literature search

The literature search strategy included a combination of keywords
and variations to identify articles that addressed (i) eating
assessment/detection, (ii) wearable technology, and (iii) free-
living research settings. Keywords included “eat”, “food intake”,
“diet”; “monitor”, “assess”, “detect”; and “wearable”, “device”,
“sensor”, “technology”, “smart watch”, “smartwatch”, “ambulatory”,
“free living”, “in field”, “in the wild”. The full search term strategy
that was used for each database is outlined in Supplementary
Table 1.

Eligibility criteria

Peer-reviewed journal or conference papers were considered for
inclusion in the review if they were published prior to December
22, 2019 and were written in English. Furthermore, eligible papers
needed to have described/reported on all of the following
components within the contents of the paper:

1. Any wearable device or sensor (i.e., worn on the body) that was used
to automatically (i.e, no required actions by the user) detect any
form of eating (e.g., content of food consumed, quantity of food
consumed, eating event, etc.). Proxies for “eating” measures, such as
glucose levels or energy expenditure, were not included. A “device”
is defined as a wearable with embedded sensors that senses the
body or environment and records data either on-device or externally
through Bluetooth.

2. “In-field” (non-lab) testing of the sensor(s), in which eating and
activities were performed at-will with no restrictions (i.e., what,
where, with whom, when, and how the user ate could not be
restricted). There was no limitation on the length of in-field testing.
Furthermore, studies in which participants completed lab proce-
dures (e.g., sensor calibration) followed by an in-field observation
period that included eating were included. Studies that were
described as semi-free living (e.g., participants wore device in the
wild without restriction, but ate their meals in the lab), or studies
that did not fit our aforementioned definition of “in-field”, were
excluded.

3. At least one evaluation metric (e.g., Accuracy, Sensitivity, Precision,
F1-score) that indicated the performance of the sensor on detecting
its respective form of eating.

Review articles, commentary articles, study protocol articles,
and any other articles without reported results from empirical
research were excluded.

Screening and selection of articles

The records retrieved from the databases were imported into a
web-based systematic review management tool, Covidence**. Any
duplicate articles were removed.

First, the titles and abstracts of all articles were reviewed.
Articles were excluded at this initial screening phase if they did
not describe at least one wearable device or sensor that was used
to automatically detect any form of eating. If this information

Scripps Research Translational Institute
Records identified through searching
multiple databases (n = 606)

Records identified though
handsearching (n=12)

 

Duplicates removed (n = 40)

 

Title and abstract screened (n = 578)

Records excluded - not relevant
(n = 492)

Full-text articles assessed for
eligibility (n = 86)

Full-text articles excluded (n = 53)

-No wearable sensor or sensor did
not meet criteria: n = 20

-Not in-field/free-living: n= 19

-No evaluation metric: n = 6
-Review paper/chapter: n = 5

Commentary: n= |
Could not retrieve full text: n = 1
Not peer-reviewed: n = 1

 

Articles included (n = 33)

 

Fig. 1 Flow diagram of article selection process.

could not be ascertained from the title and/or abstract, the
article’s full text was reviewed in the next screening phase to
determine whether it fit the eligibility criteria. Furthermore, if the
abstract indicated that the study was not conducted in the field
under free-living conditions, it was excluded. Otherwise, this
criterion was assessed in the full-text screening phase (Fig. 1).

After the initial title/abstract screening process, the full texts of
any remaining articles were assessed. Articles were further
excluded if they did not meet the remaining eligibility criteria,
including studies being conducted in free-living conditions;
reporting at least one evaluation metric of the sensor's
performance; being peer-reviewed; and reporting results from
empirical research (Fig. 1).

Scripps Research Translational Institute

B.M. Bell et al.

np)

 

Data extraction and synthesis

If any research article reported on more than one in-field study
that fit our eligibility criteria (and contained different subject
samples), then all eligible studies from that article were included
in our review as separate studies.

Two research assistants independently extracted the following
study characteristics from the final set of eligible studies using a
custom-made data extraction worksheet. The extracted study
characteristics were reviewed by first author BMB, and discrepan-
cies were discussed and resolved by authors BMB and RA.

1. Study sample size: the total number of participants for each study.

2. Length of data collection period in free-living environment: how
long the participants wore the sensor(s) (i.e., participated in the
study) in the field.

3. Number of wearable sensors used to detect eating: the total number
of wearable sensors in which the sensor’s signal data were used, at
least in part, to detect eating. Any other equipment that was part of
the overall sensor system, but did not ultimately contribute signal
data to detect eating, was not included in this count.

4. Types of wearable sensor(s) used to automatically detect eating: the
type of sensors embedded within the selected wearable devices in
which the sensor's signal data were used, at least in part, to detect
eating.

5. Ground-truth method(s): the method, if any, that was used in the
study to evaluate the performance of the sensor(s) in the free-living
environment.

6. Form of eating activity (eating outcome) measured by the sensor(s):
eating outcomes that were at least partially derived from sensor
signal data and had a corresponding evaluation metric. In some
cases, multiple eating outcomes for a single study were included.
Terminology used to describe the eating outcome in the original
article was maintained in our reporting.

7. Evaluation metric(s) of the sensor(s): any evaluation metric,
reported either in text, a table, or a figure, that described the
performance of the wearable sensor(s) on detecting eating in
free-living settings. If the exact numerical value was not reported
or could not be ascertained from a figure, and it was not reported
numerically anywhere else in the text, then this evaluation metric
was not included in Table 1. Only evaluation metrics that were
exclusively for eating activity detection were included. Evaluation
metrics that included the detection of other activities (e.g.,
sleeping, exercising, etc.) were not included. Often, multiple
metrics were reported for different methods/algorithms
deployed. If the article’s authors indicated or highlighted the
best performing method or algorithm result, then this was
selected and included in the table for each unique method.
Otherwise, the best performing (typically the highest value) of
each unique method was identified in the article by the first
author (BMB) and included in Table 1. Last, we exclusively
included the metrics reported in the studies, and did not calculate
any metrics, even if calculations were possible. For example, if
Sensitivity and Specificity were reported, but Accuracy was not
reported, we did not calculate Accuracy even though possible
with the reported data.

Methods of summarizing data

Mean and standard deviation were calculated for each extracted
continuous variable (sample size, length of time for data
collection, number of sensor types, evaluation metric). Frequency
tables were constructed for each extracted categorical variable
(sensor types, ground-truth methods, eating outcomes).

Furthermore, the reported eating outcomes were grouped into
three categories:

i. inferred eating occasions: the incident or event of eating activity;
ii. inferred chews (mastication): the grinding of food into smaller
pieces by teeth;
iii. inferred hand-to-mouth gestures: the placement of food into the
mouth via movement of the hand to the mouth (also referred to as
“bite”).

npj Digital Medicine (2020) 38
%E 1°98 = AUAINSUaS

%6S°Z28 = UOISID01d

%93°98 = AdeInd.V

sanbIuyra} YIOMJaN |DANAN [DIY

‘(L000 > @) uoWNg Ysnd pue (L00°0
> d) soWJUOW UOHsSabul 31}eWO Ne
WO} ‘YIP ‘Bis a1aM Ho; Hues
WwoJj suoleinp aposida Bulyey
isIsKJDUD SUOSUDAWIOD ajdi1jn/W
*Spoujow

Jayjo pue Bo; buljes usamjaq
juaweelbe 100d 3nq ‘uoWNgG Usnd
2 JOWUOW UO!sSabu! dI}eWO Ne
UdaMjeq JUBWIaIBe POOH
:sis{[DUD UDW}/\y-pub|g

%78 = AyDYyIDNeds
%L8 = AUAIISUaS
%L8 = Adeund.y

%Z8 = AUAIUSUAS
%OZL = ANJA BAIDIPIId BAIUISOd
Q :SdAIISOd asje4
€ :saaiebau asje4

%GTL = |IPI9Y
%CBL = UOISID9Id

%6'98 = Ayoyioeds

%EL8 = AUAIISUS

ZL :SUOIaSUI asje4

(97 40) Z :suonejeq

(97 $0) bz :saposida

paepayjep Aj}a1OD ‘sdUJAW S PIDM
(9Z JO) 9 :saposida passiyy

Z| :saposida payejap Ajasje4
(92 40)

0Z :seposida payej}ap A}}D91105
‘JUaIDYJaod AYUDIIWIS psodI0f£

(QL JO) SL ‘SOAISOd ONAL
Z ‘SOAIUSOd asje4

%6Z = ||29°Y
%7°'L8 = UOISID91d
%L°O08 = 809S-|4
%€6 = Adeund.y

% L°06 = |1P9°Y

%L LY = UOISID9Id

LL :y/saanisod asyjey ‘Bay
%€'°78 = Adeinddy

B.M. Bell et al.

o(S)IUJOW UOIJENILAS 4D9]as

 

Np)

aye}U!l poor

uoleinp aposids buljey

sypeus/sjeal|

Ayanoe Burney

saposida buljey

saposida buljey

saposida buljey

saposida buljey

Buimau)

s}uanea Buljey

(s)aw0d}no Huey

uoj1ng ysnd ‘bo; AWAY

uojng ysnd ‘bo; bunez

(sjuedidiyied

€z Bululewe) uoiNG

Jaye auoyd yews elA Ho; Hues
‘(sqyuedinivied oz 3suy) bo; Huryey

Boy AWADY

dde suoydyeus eiA Go; Gulez

adIAep Hulpso da,
uo UOjNG JayIeW
‘dde suoudyews ela Go; buljez

(UOIIN|OSAI
S-|) EABWULD ODPIA a/qQelea/\

(UOIIN|OSAI
S-|) EABWULD ODPIA a/qQelea/\

Boy AWADY

(S)poy}ewW YINIJ}-PUuNOID

Josuas AywIxojd Y]

,Josuas abneb

UI2I}JS DU}DI9]BOZald (Z)

JaJBWOII9]aD>9V (L)

JaAlaDeJ

pue Joyiuwsuel,
(44) Aduanbay-o1pey (€)

,Josuas abneb

UI2I}JS DU}DI9]BOZald (Z)

JaJBWOII9]aD>9V (L)

(auOYydyews
ul) adodsosAy (Z)
(auOYydyews

Ul) J9JBWOIIJ9DIV (L)

Jajawojeubeyy
ado dsosA5
Ja} BWIOIIa|aDIV

€)
C)
L)
C)

Nn nN

(auOYydyews

Ul) J9JBWOIIJ9DIV (L)

Sapospele (DWI)
weiBoAw04}99]9 (L)

auoydodi (L)

auoYydodiy (€)

Josuas Aywuixosd yy (Z)

g(MWi) yun

jUdWaINSeaW jelwau (L)

Josuas Ayiwixoid

(YI) Peseszuy (Z)
adodsosAy (L)

(s)adA} JOSUaS

C

sod} JOSUaS
JO ‘ON

UVC

UVC

Aep |

Kep |

Aep |

yybu | pue Aep |

UC

(skep ZX) UE

ZL gp, E LOZ ‘boouey

8 4,ZL07Z ‘yeInog

€v gv LOZ ‘buog

bv ge LLOZ ‘buog

SL <8 LOZ ‘uNYD

oeZ LOZ
vl ‘wayra|g
vl o<B LOT ‘19

OL ,-ZL0Z ‘upag

y9 9  --SLOZ ‘Upeg
uoneinp Jeay oyuyne
UOISsas HUIAl|-2a14 aZIs aj}dwes 3sdl4

 

‘(Ov =N) Salpnys ydieasas uolDa}ap Buea paseq-ajqeseam Ul payodas adUeWOJJad pue spoyujea-) “| alqey

Scripps Research Translational Institute

npj Digital Medicine (2020) 38
Np}

B.M. Bell et al.

 

ELL = SeAIuSOd ani
ZZ = SPAIUSOd asyje4
v7 = saniebau asje4

%73'9/ = ADeindde Hulusea| daeq
%Ev'S9 = Adeinddy

:poyjaw

(OdO7) 1NO UOSIag AUC aAbaT
%7L' 76 = ADeindde Bulusea| daaq
%L9°SZ = ADeindd.V/

:poyjaw

(OSOT) 1NO ajdwips aucC aavaT

%0L~ = |!P99Y

%8L~ = UOISIDAId

%78~ = AdDeundV/

‘€ Palgns %OL~ = |!222Y
%0L~ = UOISID9/d

%6'96 = Adeind.V7

‘Z@ pub | syalqns

%6'68 = |299Y

%8'°68 = UOISID91d

%9°68 = Adeind.V

‘AJUO DIOP 13}aWIO1a/aIID

pub Josuas d1Dajaozaid buisp

MTEL = ADeINDIDV

%b'S8 = ||229Y

%9'88 = UOISIDAd

%9'°S8 = 910DS-|4

%VT79 = (ONjeA anjosqe

ueaW) JO UOIJEWIISS JUNOD MayUD

%LS'68 = []P9°u

%CL'96 = UOISIDA1d

%LL'E6 = AeunddV

:(anbiuyda} bulbbog)

SISAJOUY AJDUIWIDSIG ADAUIT SJaYs!4
€ :SaAIUISOd asje4

(LL 40)

Z :saposida payiquap! Ajj9a1105
sanbiuyra} aUIYID 10}DaA oddns
L :‘SOAIIsOd asyje4

(LL 40)

8 :saposida paylquap! Aj}991105
sanbiuyra} YIOMJaN /DANAN JODY
%0 L'08 = AMAIISUaS

%9IL'ES = UOISIDIId

%€6'L8 = AdeInd.V

sanbiuyra} aUIYID 10}DaA oddns

e(S)U}JBWW UO!ENIEAS 4D9]9S

Juana Bulyuup e
BHulpadeid sjusWaAOW
yiNOW-0}-puep}

saposida buljey

(,S81q,,) SUOOW
Yy NOW-O}-pueH

aye}U!l poor

aye}U!l poor

aye}U!l poor

SM2YD

aye}U!l poor

saposida |eal|

(s)aw0d}no Huey

ydwoid auoyd
ajIqowW eIA UOCI}eJOUUe JUWI}-/eayY

eJQWeD OAPIA Huldej-JUOI
auoyudyeus e& UUM Ssaposida
Hulzea say} papsodas sjuediiwed

(UOIIN|OSAI
S-O|) CABLED ODDPIA a/qQelea/\

uojng ysnd ‘bo; bunez

uojng ysnd

uojng ysnd ‘bo; burez

uoyng yusnd
‘49YUNOD Ale} B]Qeyod

uoj1ng ysnd ‘bo; AWAY

Boy AWADY

(S)poy}ewW YINIJ}-PUuNOID

(NWI Ul) PdodsouAy (Z)
(NWI Ul)
JaJBWOII9]aD>9V (L)

(Jaspeay YyOOJaN|g
ul) FUOYdOJIIW (L)

ado dsosAy (Z)
JaJBWOII9]aD>9V (L)

JOAI9IOI

pue Jayilusuel} 4y (¢)
Josuas Wil

D1}D9|B0Zald (Z)

J9JBWUOID|BDIV (L)

JOAI9IOI

pue Jayilusuel} 4y (7)
,Josuas abneb

UIeI}S DUDIIJBOZald (L)

JaJBWOII9]aD>9V (L)

Josuas Wil
D}D9|B0Zald (L)

JOAI9IOI

pue Jayilusuel} 4y (¢)
,Josuas

WUJY 211399|80Zald (Z)

J9JBWUOID|BDIV (L)

JaAlaDeJ

pue Jayilusuel} 4y (¢)
,Josuas abneb

UI2I}JS DU}DI9]BOZald (Z)
J9JBWUOID|BDIV (L)

JOAI9D94
pue Jajjuusuel) 4Y (€)

(s)adA} JOSUaS

sod} JOSUaS
JO ‘ON

us-¢ G  g,6L0Z ‘SeWOD

sAep OL uey} DIOW v 79 LOT ‘ORD

SINOY [PJaAVS € 5,9L07 ‘eunyo4

cpV LOZ
UVC ZL “‘eue}Uu04
pre LOZ
Uz ZL ‘euejuo4
yes 8 .,8L0Z ‘boole4
yEs 8 -,ZL0Z ‘boole4
Ue ZL 4, 9L0Z ‘booue4
UY 8b~ L
uoneinp Jeay oyuyne
uolssas BuIAl|-8e/4 9aZIs ajdues 3sJl4

panuluo> | aqeL

npj Digital Medicine (2020) 38

Scripps Research Translational Institute
B.M. Bell et al.

Np)

 

90ZL :AWAIWDe
Huljyea payipeid A}ja1105
‘4jUO DIOP adorsosAb BulsN

%EB = |JPI9Y
%ST = UOISID91d
%62 = Adeund.y

%Z8 = |[P9°Y
%YLE = UOISID91q
%S3 = AdDeind.y

766'0 = Apioyineds

Z88°0 = |!2294

L060 = uOIsIDad

7680 = 9109S-|4

v08'0 = Xepu| psedder abesaAY
(s) ZL6’‘7Ev = SAAISOd andl

(S) Zp@'‘p7y’9 = sanieBau ani
(S) Z8L‘Zv = Seaiusod asje4

(Ss) €80’SS = sennebau asyey

%0°28 = Ayoyioeds

%0'VL

= AVAINSUaS

(Z =») %81 = Xepul Uaping uayM
%6'SL— = JOD |JPJBAC

%6'9 = JOM BHe}UsIIad Ueay
MIVE

= JOJJa a6e}UadJ9d ajnjosqe uesay|

YL LZ = |IP99Y
%bv'99 = UOISIDAd
LQ :SeAINISOd ani
Ly :SaAlyisod asyje4

€€ :saatebau asyje4

WE'y = JOM |JEIZAO
%0'VL =4019 BHeJUSs.INd URED!

%B'LE
= Joa abejUadJad aynjosqe ueayy

%G LL = |JPI°Y
%LL8 = UOISIDAd
SEL :SOAINSOd aniL
LE :SaAIsod asyje4
Or :seniebou asje4
S80 = ||P994

780 = UOISIDa1d
S8°0 = a109S-4

e(S)IU}JBWW UO!JENIEAS 4D9/9S

Ayianoe Burjez

sjeaw

sjeaw

sjeaw

(saposida)

sebew! YUP pue pooy

ayequ! Pini

AWAIDe Hurnjug

ayequ! Pini

AWAIDe Hurnjug

(s)aw0d}no Huey

(Yd}eM eS

ul) adodsOsAy (Pp)

(auoYydyews Ul) SdD (€)
(Yd}eM eS

Ul) J9JBWOJI/9DIV (Z)
(auOYydyews

dde asuoydyews eid Bo AWAY Ul) JOJBWOJIJaD9V (L)

auoYydodiW (Z)
S9}OU SDIOA (YD}eEMEWS Ul)
‘sjeall JO so}OUd ‘Ho; HulyeyZ JOSUaS UOIJOW JelJaU| (1)

(SSe|D ajbooy
ul) JOSUSS UO!IOW (€)
auoYydodiW (Z)
S9}OU SDIOA (YD}eEMEWS Ul)
‘sjeall JO so}OUd ‘Ho; HulyeyZ JOSUaS UOIJOW JelJaU| (1)

(Yd}eM eS

ul) adodsosAy (Z)
(Yd}eM eS

Ho; Huey Ul) JOJBWOJIJaD9V (L)
(uO! Nose PJD ODPIA

S-OL) CABLED ODPIA aIQelea/\\ ajqeiesn (L)

(Yd}eM eS

ul) adodsosAy (Z)
(Yd}eM eS

Ul) J9JBWOIIJ9DIV (L)

(UOIIN|OSAI
S-G) PEIDWULD OSPIA a/qQelea/\

(Yd}eM eS

ul) adodsosAy (Z)
(Yd}eM eS

Ul) J9JBWOIIJ9DIV (L)

(UOIIN|OSAI
S-G) PEIDWUUED OSPIA a/qQelea/\

(S)poy}ewW YINIJ}-PUuNOID (s)adA} JOSUaS

sod} JOSUaS
JO ‘ON

eo8 LOC
yyUoW | L ‘euyyeseaen
skep ¢ 10 Z 9
zoL LOC
(sAep ZX) UZL S ‘YNOUDUIW
(uosiad

Jad s 96¢'/| ‘abe1ane

UO) peyiodal JON 9 6102 ‘SIsyUAy
4IoM | L ps8 LOZ ‘elf
skep 7 8
6po LOC
Aep | OL ‘j3ue}eWUeH
uoneinp Jeay oyuyne
uolssas BuIAl|-8e/4 9aZIs ajdues 3sJl4

panuluo> | aqeL

Scripps Research Translational Institute

npj Digital Medicine (2020) 38
 

=
(UOIIN|OSAI (Yd}eM eS
s}uawOoW buljez S-09) PIBWUULD ODPIA aIQeElea/\\ Ul) J9JBWOIIJ9DIV (L) L sKep LE L ©
(uosiad 0
%3'88 = ||e20yY Jad saynulw 7p a
%/°99 = UOISIDAId (UOIIN|OSAI (Yd}eM eS yg ‘abesane 6s&S LOZ a
%L'9/ = 3109S-4 s}uawOoW buljez S-09) PIBWUULD ODPIA aIQeElea/\\ Ul) J9JBWOIIJ9DIV (L) L UO) peyiodal JON Z ‘ZEWOUL v
%08 = Ayoyioads 2
%69 = AUAIUSUAS ado dsosAy (Z) =
%SZ = Adeund.y Ayanoe Burney Ho; Huey J9}BWOII}2D>°V (L) Z Kep | POL gc9LOZ ‘ewueYsS =
%S6 = |]229Y D
(Guay (yd}eMyeWS a
abeull Jaye) %S6 = UOISIDAId ul) adodsouky (¢€) 2
(Z@ + 1 Apnjys) pauiquwoy (Aep ay} jo (yd}eMyeWS
(LS JO) pua je jeunof poo} auoydyeuws ul) BBW (Z)
Bp :SdaAIUISOd ANIL Z :SaAIyISOd asyje4 eIA sabew! ay} payepljea (yYd}eMYeWS
(Lg JO) € :sennebeu asjey sjeayy s}uedidied) exawed yd}eMyWeWS Ul) J9JBWOIIJ9DIV (L) € skep 9-7 G
(Yd}eM eS
ul) adodsosAy (¢€)
(Aep ay} jo (yd}eMyeWS
(O€ JO) 67 :SEANISOd any pua je jeusnof poo} auoydyeuws ul) e1BWW (Z)
Z ‘SOAIUSOd asje4 eIA sabew! ay} payepljea (yYd}eMYeWS
s (O€ JO) | :seAneBeu asjey saposids buljey sjzuedidiyed) evawed ydJeMYeWS Ul) J9JBWOIIJ9DIV (L) € skep S v 7c8L0Z ‘UaS
@ (yd}eMyeuws
2g ul) adodsosAy (¢€)
s (Aep ay} jo (yd}eMyeWS
oo 6Z ‘S@AIISOd ani pua je jeusnof poo} auoydyeuws ul) e1BWW (Z)
%/’°ET = SAAIUSOd asje4 eIA sabew! ay} payepljea (yYd}eMYeWS
%E'E = SOANeHaU ase spouiad BuljeyZ = sjuedidivied) esauied YdJeEMeCWS Ul) J9JBWOIIJ9DIV (L) € skep S v
(Yd}eM eS
ul) adodsosAy (¢€)
(Aep ay} jo (yd}eMyeWS
LL ‘SOAINISOd andy pua je jeusnof poo} auoydyeuws ul) e1BWW (Z)
WE LE = SOAISOd asje4 eIA sabew! ay} payepljea (yYd}eMYeWS
%E'SE = SAaAIeHau asje4 spouiad BuljeyZ = sjuedidivied) esauied YdJeEMeCWS Ul) J9JBWOIIJ9DIV (L) € skep Z 9
(Yd}eM eS
ul) adodsosAy (¢€)
(Aep ay} jo (yd}eMyeWS
LE :SOAINISOd and pua je jeusnof poo} auoydyeuws ul) e1BWW (Z)
%€'09 = SAAISOd asje4 eIA sabew! ay} payepljea (yYd}eMYeWS
%0 = sanizeHbau asje4 spouiad BuljeyZ = sjuedidivied) esauied YdJeEMeCWS Ul) J9JBWOIIJ9DIV (L) € skep S Z gL LOZ ‘URS
%001 = |l€22Y £
%8/ = UOISIDAId =
%LS ec
= (dyw) uolsidaid BHesane ues (UOIIN|OSAI PJBWUCD ODPIA ¢¢8 LOZ =
%06 = 2109S-|4 sjuana Ale\iq S-[) PABWED ODDPIA aIqQeleay\ ajqeiesn (L) L skep rv L “J\UOQIUDS 5
sPueg YOSOIIIW (P) 8
ZL0 = [1X24 auoYydoJsIW (€) S
290 = UOISIDAId s}USWOW (QuUOYdyewWs Ul) Sd5d (Z) »c9 LOZ E
69'0 = 309s-4 ,¥e4-0}-]NOQY,, dde suoydyeus eiA Go; Gulez plosuas © eAIDEWY (L) v skep S 8 ‘uewyey o
oO
sad} s0suas uoljeinp Jea, “ouyne a
e(S)U}JBWW UO!ENIEAS 4D9]9S (s)aw0d}no Huey (S)poy}ewW YINIJ}-PUuNOID (s)adA} JOSUaS jO ‘ON uolssas BuIAl|-8e/4 9aZIs ajdues S414 4
penuljuOd | xjqeL =
YN
B.M. Bell et al.

Np)

 

yosuas ainjesadwua} UDsS pue VWOYUWUOW 9a}e1 Weay ‘ado dsoiA6 ‘JaJBWOJIjaI9e Ue Bulpnyjul ‘slosuas Aueu SUIEJUOD JEU} JOD} SSOUIY/YDIEMPeWS e S| PUG YOSOIDIW) FUL,

‘leg

“AYAIDE [eW@POsDaIa SaiNseaW JOSUaS O BADAYY OL,
eue}UO4 Pue AOUOZES) [1e}aP BAOW U! Paqlidsap SI JOSUaS BY} YIIYM UI! YOUN awes ayy Aq paysijqnd Ajsnolnasd Jaded e Wo} pajde1}x9 SEM JOSUAS S14} aqIsSap Ajayenbape Oo} papaau UO!eWJOJU! |EUONIPPY,,

‘SJajaWO}aUBeW soWljJOWOs pue ‘sadorsojAb ‘SI9JBUUOI9/9IIC JO UO!}EUIQWUOD e JO pesiiduos AyjeridAy SI JEU} DDIADP e SI (NIAI|) WUN JUSWWSINSesdwW JelsuUl UVa

‘payodas s} poyjauw ydea JO} JUJaW UOHeNjeAra

anbiun ydea JOj anjea payoda ysaybiy ay) ‘Apnys aj6uls e ulyUM pazenjera ajam suYyWobye JO/pue spoujyaw ajdijjnw 4] “ajqe} siy} Ul payoday s! Daw UO!eNjers anbiun yde~a Joj anjea paysodas ysaybiy aul,

 

S60 < |]X&9°u

G60 < UOISIDAId

(vr JO) Ep :SeAISOd aniy
0 :saAlqsod asje4

(vy JO) | :seanebeu asyey

%8'8L = |IP9°Y
%ELL = UOISIDAd

%L'86 = [12294
%7'86 = UOISIDAId
%7'S6 = A109S-| 4

%YLE~ = UOISIDed
Z~ :Kep jad
paflqns jad suondajap asje4

%0°L9 = |IP9°Y

%9°8T = UOISID91d

O€ ‘SAIPAIIDe

BHuruup peyipeid A}a1105
[UOIJDIYISSDID SAXkDG AAIDN

%0°9S = ||P9°Y

%L' LO = UOISID91d

€€ ‘SaIMAIDe

BHuruup peyipeid A}a1105
[UONDIYISSDID AUIYID 40}2aA Yoddns

%8'°69 = ||P9°Y

%TTI = UOISID91d

SCL ‘SORIAIIe

Huljyea payipeid A}ja1105
[UOIJDIYISSDID SAXDG AAIDN

%8°L8 = |IP9°Y

%E LB = UOISID9Id

LGL ‘sonlaAloe

Huljyea payipeid A}ja1105
[UONDIYISSDID AUIYID| 40}2aA Yoddns

%E'9L = [1e29Y
1%9'68 = UOISIDAId
1%9°6/ = aJ10DS-4
%9'8L = [12294
%T'S9 = UOISIDALd
%O°LZ = VIODS-4

e(S)IU}JBWW UO!JENIEAS 4D9/9S

s}uanea Buljey

Buimau) Boy AWADY sapolpaje OWI (L)
s}uanea Buljey Ho; Huey sapolpaje OWI (L)
AWAIWDe

bunes Auap/wuyuod 0} paysnd
uoyNg jedIskyd ydJemyeWs
‘dde ajousanq ul bo; Hunez

(Yd}eM eS

Buljez Ul) JOJBWOJIJaD9V (L)

AWAIDe Hurnjug

(peyodai
yOu UO!NjOSa1) (@UOYud yes

Ayanoe Burney Ul) EIDWIED ODPIA ajqeiea\ auoydodiw (1)

AYAIDe Huljes jeayy Boy AWADY auoydodiw (1)

(s)aw0d}no Huey (S)poy}ewW YINIJ}-PUuNOID (s)adA} JOSUaS

sod} JOSUaS
JO ‘ON

Aep | OL ,.A8L0z ‘bueyz

Aep | OL ¢o@8L07 ‘bueyz

SHIM Z Z zo9 LOZ ‘PA

Aep | G jo LOZ ‘}UeIEA

9S LOZ

YL- 0z ‘ZEWOUL

uoneinp Jeay oyuyne

uolssas BuIAl|-8e/4 9aZIs ajdues 3sJl4

panuluo> | aqeL

Scripps Research Translational Institute

npj Digital Medicine (2020) 38
These three categories are not exhaustive of all possible types
of eating outcome categories, but rather only represent those that
were derived from this review’s included studies.

RESULTS
Literature search

The literature search produced 618 research articles, with 40
duplicates, resulting in 578 articles to be screened. After reviewing
all article titles and abstracts, the full texts of 86 of these articles
were further reviewed for eligibility. After removing articles that
did not meet the inclusion criteria (see Fig. 1 for full list of
exclusion reasons), 33 articles were deemed eligible for the
review!®?-% (Fig. 1). Six of these articles*°*7°7°”? reported on
more than one in-field study that fit our eligibility criteria, so N=
40 studies (from 33 articles) is considered to be the final sample
size for the review.

Study characteristics

The earliest publication year of the reviewed papers was 2011, and
the most recent year was 2019. The sample size of the studies
ranged from 1 to 104 participants, with a mean of 10.83
participants (SD = 16.73) per study (Table 1). The length of time
for data collection in the “wild” environment varied and was not
always reported with an exact numerical value or unit. Therefore,
we will just report the range: 2h to 1 month. The reported length
of time for each study is available in Table 1.

Wearable sensors

The majority of studies (N= 26 of 40) used multi-sensor systems
(incorporating > 1 wearable sensor) to automatically detect eating
activity '839343 7-41.44 4648499 1-54.50-58° On average, 2.10 wearable
sensors (SD = 0.96) were used in the studies, with a range of
1-4 sensors (Table 1). Approximately 63% (N = 25) of the 40 studies
utilized an accelerometer (device that determines acceleration)
either by itself (N= 4) or incorporated into a sensor system (N =
21) to detect eating activity 937417997078: 499 193.9059. (Table 2),
The second most frequently utilized wearable sensor was a
gyroscope (device that determines’ orientation) (N=
15)22:3839,40,48,49,91,93,90-58 followed by a microphone (N=

Table 2. Frequency and percentage of sensor types in included
studies, ordered by frequency.

Sensor type Frequency Percentage

(of 40 studies)

62.50%
37.50%
20.00%
17.50%
15.00%
12.50%
7.50%
7.50%
7.50%
5.00%
5.00%
2.50%
2.50%
2.50%
2.50%

Accelerometer

Gyroscope

Microphone

Piezoelectric sensor

Radio-frequency transmitter and receiver
Smartwatch camera

Electromyogram electrodes

Motion sensor

Infrared proximity sensor
GPS
Wearable video camera

Affectiva Q Sensor
Inertial measurement unit
Magnetometer

Microsoft Band

—=- - S- =a NN WWW MN HW N CO WN

Scripps Research Translational Institute

 

B.M. Bell et al.

np)

 

34,35,47,52,54,60,61 18,40-42,44,45
8) ' , a RF

a piezoelectric sensor (N= 7)
transmitter and receiver (N= 6)'®4°4'44*° and a smartwatch
camera (N=5)°°?’ (Table 2). EMG electrodes*°***, a motion
sensor’, and an infrared proximity sensor*****” were used in three
studies each. Wearable video cameras’? and GPS°*>* were used
in two studies. Last, the Affectiva Q sensor (used to measure
electrodermal activity)>*, an inertial measurement unit (IMU)**, a
magnetometer’, and a Microsoft Band®* were used in one study
each (Table 2).

Ground-truth methods

To evaluate the performance of the wearable sensors in
automatically detecting eating in the field, 100% of studies (N =
40) used one or more validation methods in which the “ground-
truth” eating data reported by the participants (self-report
methods) or produced by other wearable devices (objective
methods) were compared with the inferred eating activity
detected by the sensor(s).

Self-report methods.
all daily activities, including eating, via a log or diary
while six studies had participants self-report just eating activ-
ity?79° 1949863 In one study, participants were asked to record
their eating episodes with a smartphone front-facing video
camera to obtain ground-truth eating*’. In another study,
participants used a push button, located on a wireless device, as
the primary method for self-reporting food intake; participants
pressed and held a button during chewing to indicate the start
and end of a chewing bout*. In Farooq and Sazonov*’,
participants used a push button, and they also counted their
number of chews during each chewing bout by using a portable
tally counter (a device used to incrementally count something).

Other studies used multiple self-report methods to collect
ground-truth eating activity. Six studies used both an eating or
activity log in addition to a marker/push button'®°°4°*"49°, Two
studies, both reported in Mirtchouk et al.°*, had participants use a
combination of eating logs, voice notes (“spoken annotations”),
and self-taken photos at the start and end of meals.

Six of the studies had participants self-report
33,38,40,53,60,64

Objective methods.
AO) 34,35,46,49,50,55,59,61

One-quarter of studies (N=10_ of
outfitted participants with a wearable video
camera for the length of their respective data collection period, in
which the video clips were later annotated by a person or persons
from the research team to indicate periods of eating activity. The
video cameras captured images at varying levels of resolution:
three studies captured images in 1-s intervals; two studies
captured images every 5s; two studies captured images every
10s; and two studies captured images every 60s.

Mixed methods. Two studies sent participants real-time messages
to confirm whether or not they were eating. In Ye et al.°’,
participants were sent a short message on their smartwatch if an
eating gesture was detected; participants were able to confirm or
reject if they were eating in real-time. Similarly, in Gomes and
Sousa*®, when drinking activity was detected, participants were
sent an alert on their smartphone and could then confirm or reject
if they were drinking in real-time.

Last, five studies (reported in two papers) used an “automated
food journaling system”, which consisted of a combination of self-
report (food journal), wearable sensor (smartwatch inertial
sensors), and objective data (smartwatch camera) to discern
ground-truth of eating activity in real-time°°°?’. When the wrist-
worn smartwatch detected an eating episode, the smartwatch
then captured images and sent them to a server. After image
processing techniques were applied to eliminate irrelevant
images, a subset of relevant images were stored in the server

npj Digital Medicine (2020) 38
np}

B.M. Bell et al.

 

10

Table 3.
category.

Reported eating outcomes (n = 45) from included studies, by

Category 1: Eating
occasions (n = 40)

Category 2:
Chews (n= 3)

Category 3: Hand-to-
mouth gestures (n = 2)

Hand-to-mouth
motions: 1

“About-to-Eat”
moments: 1

Chewing: 2
Chews: 1 Hand-to-mouth
movements preceding a
drinking event: 1

Dietary events: 1

Drinking activity: 3
Eating: 1
Eating activity: 4

Eating episode
duration: 1

Eating episodes: 6
Eating events: 3
Eating moments: 2
Eating periods: 3
Fluid intake: 2

Food & drink images
(episodes): 1

Food intake: 5

Meal eating activity: 1
Meal episodes: 1
Meals: 4
Meals/snacks: 1

 

and could be viewed by the user to assist with their self-report
online food journaling?®”’.

Eating outcomes

Authors collectively reported on 22 different types of eating
outcomes (Table 1). For each study, only the eating outcome that
was (a) directly measured by the wearable sensors, and (b)
evaluated with comparison to a ground-truth method is included
in Tables 1 and 3 and is reported in this section. Five
studies***?°''* reported two eating outcomes each that fit these
criteria, therefore the five additional outcomes were included,
totaling 45 eating outcomes.

The reported measures were grouped into three categories: (1)
inferred eating occasions, (2) inferred chews, and (3) inferred
hand-to-mouth gestures (Table 3). The majority of studies (N = 37
of 40) used wearable sensors to infer eating occasions (Category
1), however, these measures were often referred to in different
terms (e.g., “eating event” vs. “eating episode” vs. “dietary event”).
Three studies inferred chews (Category 2)****°* and two studies
inferred hand-to-mouth gestures (Category 3)*°”*°.

Sensor evaluation metrics

Studies often reported multiple and varied evaluation metrics. All
reported evaluation metrics for their corresponding eating
outcome(s) are included in Table 1. The most frequently reported
metrics were Accuracy and F1-score. Twelve studies reported
Accuracy? 37 4144-47928 and =10 studies reported F1-
scorer 1348919499,99,09,83 Due to the lack of a standardized
evaluation metric across studies, we do not summarize (calculate
mean, standard deviation, etc.) the reported metrics. However,
select evaluation metric values for each study are available in
Table 1.

npj Digital Medicine (2020) 38

DISCUSSION

Detecting and monitoring human eating behavior in the real-
world is a growing field and offers exciting and novel
opportunities for future public health research. Previous literature
reviews on automatic eating detection methods have often placed
a focus on sensor modalities and technologies in any research
setting’®, on specific sensor modalities, such as wearable video
cameras”, or on specific sensor locations, such as the upper
limb*?. No review to date has focused specifically on studies that
use wearable devices to automatically detect eating activity in
naturalistic settings. Furthermore, this review has been written by
a multidisciplinary team, with a multidisciplinary audience in
mind. Below we provide a discussion on trends in wearable
sensors for eating detection, a summary of technical, analytical,
and multidisciplinary challenges that occur when conducting in-
the-wild research, and recommendations for future public health
research directions.

Summary of key findings

This scoping review included 40 studies that reported on the use
of wearable sensors to automatically detect eating in the field
published through December 2019. The majority of studies
utilized accelerometers (N = 25 of 40) and/or gyroscopes (N= 15
of 40) to automatically detect eating activity via wearable sensors.
Self-reported eating was the most frequently used method for
collecting ground-truth eating activity data, whereas objective
methods such as wearable video cameras were used in only one-
quarter of studies (N= 10 of 40).

Variations of ‘inferred eating occasions’ (e.g., eating episode,
eating event, eating period) were the most commonly reported
eating measure (N = 37), followed by inferred chews (N = 3), and
then inferred hand-to-mouth gestures (N= 2). The most com-
monly reported evaluation metrics were Accuracy (N = 12) and F1-
score (N= 10).

In reviewing the methods and performance of wearable devices
and sensors that automatically detect eating in naturalistic
research settings, several trends and major challenges can be
identified.

Trends, challenges, and recommendations

Sensors. In this review, we observe that early research efforts
attempted to find novelty and improvement by experimenting
with new sensor types and/or sensor locations. The first paper to
report the use of a single sensor to detect eating was in 2012°',
but it did not become more prevalent until 2015°”°°: it became
much more popular by 2018, in which more than half of the 10
papers published that year only used a single sensor??? 0",
With time, these efforts have converged into a shorter list of
sensor types and locations with emphasis on two major criteria:
the sensors’ ability to capture the patterns of eating outcomes,
and the real-world practicality, which includes user comfort,
acceptability, and accessibility of continuously wearing these
sensors in a real-world setting for a long duration of time. As seen
in Tables 1 and 2, the majority of studies utilized accelerometers
(N = 25) and/or gyroscopes (N = 15), typically embedded within a
wrist-worn smartwatch or device. This observation highlights the
emergence of smartwatches as a potentially practical and user-
friendly modality for real-world eating behavior monitoring. In
addition to the user advantages, smartwatch-based methods also
have engineering advantages, such as facilitating compact and
concise form factor, containing reasonable computational and
power resources (e.g., low battery footprint), and offering wide
possibilities for adoption with the rising Internet of Things (IOT)-
cloud-edge-based ubiquitous computing era.

Another noted trend is the combination of multiple sensors’
information from different modalities placed on various on-body

Scripps Research Translational Institute
locations (for example, the piezoelectric strain gauge-infrared
proximity sensor-accelerometer combination used in a few
studies'®*°*'**), However, using a ‘multi-sensor system’ (ie.,
multiple sensors) as opposed to a single sensor introduces a
multitude of challenges, ranging from having to integrate
different sampling rates and signal amplitudes to issues arising
from data synchronization (i.e., aligning sensor signals in time
across multiple devices due to differences in clock times) and
reliability (i.e., ensuring a consistent sampling rate to maintain
high quality data throughout the study). Despite these challenges,
this multi-sensor approach offers high potential for real-time
monitoring and tracking of human eating behavior. Multi-sensor
fusion can provide further context-awareness, which can aid in
modeling of behavior; and in optimization of power (e.g., a low
power sensor can trigger a higher power sensor only when
necessary) and computational complexities, which is vital for
sensor-driven monitoring in real-world settings. Furthermore, it
can provide new opportunities for simultaneously detecting
eating behavior (e.g., when people are eating), dietary intake
(e.g., what people are eating), and context (e.g., where people are
eating, with whom), culminating in a much fuller understanding of
individual eating patterns and dynamics.

Two papers that were retrieved in the original literature search,
but were not ultimately included in the review because they did
not report an evaluation metric of the automatic eating detection
performance, have started to do this. Vaizman et al. and Gemming
et al. report on using wearable sensors and mobile devices to
automatically capture both eating and contexts in natural
environments (free living)°°°’. In Gemming et al.°°, social and
contexts such as eating location, external environment (indoor/
outdoor), physical position, social interaction, and viewing media
screens are collected. Similarly, Vaizman et al.°” collect contexts
such as location (e.g., in class, in a meeting, at a restaurant),
activities (e.g., running, drinking (alcohol), eating), and company
(e.g., with friends). These recent works suggest that automatic
eating and context detection methods offer opportunities to
provide valuable, rich, real-time information with important
obesity-prevention research implications.

Ground-truth methods. Our review indicates that there is still a
strong reliance on self-report as the method of determining
ground-truth eating activity in the field. Although using objective
methods such as wearable video cameras®® to determine when
eating activity has occurred can be very costly and time-intensive,
maintaining eating and/or activity logs is a process that is very
burdensome on the participant and ultimately relies on their
memory on when food was eaten. In studies comparing food
diaries to the doubly labeled water method, which uses doubly
labeled water as a biomarker for energy intake and is considered
the “gold-standard” method®’ of dietary assessment, there is
evidence that misreporting of dietary intake is common’’.
Moreover, these “gold-standard” methods have recently been
shown to exhibit methodological biases’°, particularly when
individuals consume low-carbohydrate diets; and have only been
used to evaluate self-reported dietary intake, not self-reported
timing of eating activity. The accuracy of self-reported timing of
eating activity via food diaries is unknown. The aforementioned
limitations in current eating assessment methodology were often
cited in the reviewed articles as the motivating factor for
developing wearable technologies that can overcome these
constraints. Therefore, the use of these self-report methods to
validate the wearable sensors may need to be reconsidered in the
future when evaluating the reported performance of these
sensors.

The trend in ground-truth validation is increasingly in favor of
using a wearable video camera because of the increased
confidence established from visually confirming the activity
or behavior being performed; 10 of the included studies

Scripps Research Translational Institute

B.M. Bell et al.

np)

 

used wearable video
0d)s 2473 2146:4990:95,59,6 |

cameras as ground-truth meth-
, With six of those studies taking place in
the last three years (2017-2019). However, privacy and stigma
challenges associated with wearable video cameras remain when
studying participants in free-living populations, particularly if the
objective is to capture authentic eating behavior’ '. Several device-
(i.e., video camera lens orientation, location, look and feel) and
data-specific factors (i.e, what is being collected by the video
camera) introduces discomfort, thereby influencing an individual's
willingness to act naturally and results in wearers modifying their
behavior or abandoning the device’'. However, these devices may
only need to be worn for a limited time, to aid in the process of
validating and building machine learning-based models that
detect eating in the real world.

Mobile device-assisted ecological momentary assessment
(mMEMA), repeated sampling of one’s behavior in real-time and
in-context**, has been suggested as a promising tool for eating
assessment’~, and may also serve as a novel tool to evaluate the
performance of wearable sensors in the field. In a recent review,
Schembre and colleagues’* summarize the existing literature on
mEMA methods for the measurement of dietary intake in research
studies. They conclude that mobile ecological momentary dietary
assessment methods may be interchangeable with existing
methods, in addition to reducing participant burden, recall biases,
and technological barriers while maximizing ecological validity”®.

Two studies (Ye et al.°*, Gomes and Sousa*®) included in this
review used a novel method for obtaining ground-truth eating
activity in the wild similar to mEMA. When an eating/drinking
gesture was detected via the wearable sensors, the watch or
phone displayed a short message asking the user to confirm or
reject that the user was eating/drinking. Similarly, in a study not
included in this review, Spruijt-Metz et al.’* report on an
integrated system of wearable sensors and smartphones that
collects family eating behavior data in the wild, and propose using
mEMA to collect ground-truth eating data’. mEMA and similar
methods do have their own limitations, such as relying on self-
reported eating activity and the potential for low compliance, yet
may offer the ability to capture and validate ground-truth eating
activity in naturalistic settings for longer periods of time as
compared with other subjective and objective measures, thus
potentially improving research scalability and participant accept-
ability.

Exploration and implementation of new methods for acquiring
ground-truth eating activity in naturalistic settings, as well as
continued testing of the emerging methods such as wearable
video cameras and mEMA, is warranted in future research in order
to improve the validity and reliability of eating detection via
wearable sensors.

Limitations of the scoping review

To our knowledge, this is one of the first review papers to date
that catalogs and summarizes the current use of wearable sensors
that automatically detect eating activity specifically in free-living
or uncontrolled research settings. However, due to this strict
inclusion criteria, we did not include papers that reported on
sensors deployed in semi-controlled settings, which may have
contributed to a more comprehensive review of the current
sensors being used in this field of research. In addition, the lack of
both a standardized eating outcome (see Table 3) and a
standardized evaluation measure of said eating activity prevented
us from comparing successes across studies. Moreover, we
selected and reported the ‘best’ evaluation metric from studies
in Table 1 (typically the highest value), thus potentially biasing the
overall takeaway message of how accurate these sensors are at
detecting eating in the wild. Last, some evaluation metric results
for the included papers were exclusively reported in figures (not

npj Digital Medicine (2020) 38

11
Np)

B.M. Bell et al.

 

12

textually or numerically), and were omitted from this review due
to the data extraction protocol.

From research to practice

Recent technological advances have provided engineers with the
capability to develop sensors and devices that can collect the data
needed to objectively infer eating activity in a variety of novel
ways, such as inferring bites via data from wrist-worn sensors”,
sensing jaw movement to infer chewing activity**, and utilizing
the signal obtained from EMG electrodes to infer when eating
events occur®’. This variety of sensors and abundance of inferable
eating outcomes, however, contributes to the difficulty of
comparing performance across sensors and evaluation methods.
Some form of comparability among similar modalities will be
necessary in order to integrate wearable sensors into public health
research. This includes developing some standardized form of
comparability, such as standardized terminology and standardized
evaluation metrics, or at least the sharing of algorithms that are
used to infer various eating behaviors. Importantly, identification
of meaningful eating outcomes and the development of the
algorithms to detect these outcomes would benefit from being
generated with input from relevant collaborators such as
computer scientists and engineers, health behaviorists, and
nutritionists.

Researchers within the public health field are increasingly
interested in utilizing wearable sensors to assess eating activity.
However, diet, which is one of the most important factors that
contributes to overweight and obesity status and other diseases, is
notoriously hard to assess with our current methods'®. Although
flawed, more traditional methods offer assurance in what type of
eating outcome is being measured. For instance, 24-h dietary
recalls typically obtain detailed information on all foods and
beverages consumed on a given day, which can later be
processed into meaningful behaviors (at least, meaningful as
determined by the nutrition field) such as average total intake of
kilocalories per day or an overall healthy eating index. As indicated
by the numerous eating outcomes extracted from the papers (see
Table 3), the same assurance cannot necessarily be granted for
wearable sensors, especially considering the evidence that how an
eating occasion is defined can significantly influence how eating
patterns are characterized’°. The wide variation in sensor
modalities makes this difficult, but also offers us novel research
questions that researchers could never consider before (e.g., How
is an individual’s number of bites taken throughout the day
associated with their risk for developing obesity? Does an
individual’s chewing rate predict cardiovascular disease risk? Etc.).

Future directions

Eating is a highly dynamic behavior that occurs over time and in
context. Research has repeatedly shown that contexts have
important impacts on eating patterns and health outcomes,
including social contexts like eating with family’’~-”’, physical
contexts like living in a rural food environment®”, and psycholo-
gical contexts like chronic stress levels®'®*. Eating data from
wearable sensors, in conjunction with other technologies that can
detect these additional contextual features, can be used to
eventually develop models of human eating behavior in real time
and in context, which can be leveraged to develop adaptive,
personalized interventions to predict and change obesity-related
behavior, and ultimately, improve population health.

CONCLUSIONS

How do the results from all of these papers inform field work,
and how do all of the various sensor modalities reviewed here,
really work in the wild? The field is still nascent, and the accuracy
of our sensors are still dependent on careful constraints and

npj Digital Medicine (2020) 38

assumptions. Collecting data in the wild is considerably more
challenging than conducting research in controlled settings. In
the wild, we lose continuous control of our sensors, participants
tamper with the hardware or software, new operating systems
bring down our software temporarily. Therefore, successful
deployment requires really robust sensing and algorithms that
have been tried repeatedly, rather than re-invented again and
again. If the goal is to be able to detect eating behaviors in a
fully unconstrained manner over a long period of time, novelty
can no longer be valued over accuracy. We hope that this review
will convince our communities to undertake the hard work and
collaboration necessary to develop the kinds of reliable
technologies that are required to conduct long-term real-world
studies. Developing accurate, robust, automatic and wearable-
based eating detection methods will radically reform scientific
understanding of eating behavior in time and context and
public health.

Received: 1 July 2019; Accepted: 13 February 2020;
Published online: 13 March 2020

REFERENCES

1. Neuhouser, M. L. The importance of healthy dietary patterns in chronic disease
prevention. Nutr. Res. 70, 3-6 (2019).

2. Jannasch, F., Kroger, J. & Schulze, M. B. Dietary patterns and type 2 diabetes: a
systematic literature review and meta-analysis of prospective studies. J. Nutr. 147,
1174-1182 (2017).

3. Higgs, S. & Thomas, J. Social influences on eating. Curr. Opin. Behav. Sci. 9, 1-6
(2016).

4. Tourlouki, E., Matalas, A-L. & Panagiotakos, D. B. Dietary habits and cardiovascular
disease risk in middle-aged and elderly populations: a review of evidence. Clin.
Inter. Aging 4, 319-330 (2009).

5. Robinson, E., Thomas, J., Aveyard, P. & Higgs, S. What everyone else is eating: a
systematic review and meta-analysis of the effect of informational eating norms
on eating behavior. J. Acad. Nutr. Dietetics 114, 414-429 (2014).

6. Reicks, M. et al. Influence of parenting practices on eating behaviors of early
adolescents during independent eating occasions: implications for obesity pre-
vention. Nutrients 7, 8783-8801 (2015).

7. Hales, C. M., Fryar, C. D., Carroll, M. D., Freedman, D. S. & Ogden, C. L. Trends in
obesity and severe obesity prevalence in us youth and adults by sex and age,
2007-2008 to 2015-2016. JAMA 319, 1723-1725 (2018).

8. Fryar, C. D., Carroll, M. D. & Ogden, C. L. Prevalence of Obesity among Children and
Adolescents: United States, Trends 1963-1965 through 2009-2010 (National Center
for Health Statistics, 2012).

9. Fryar, C. D., Carroll, M. D. & Ogden, C. L. Prevalence of Overweight, Obesity, and
Extreme Obesity among Adults: United States, Trends 1960-1962 through
2009-2010 (National Center for Health Statistics, 2012).

10. Afshin, A. et al. Health effects of dietary risks in 195 countries, 1990-2017: a
systematic analysis for the Global Burden of Disease Study 2017. Lancet 393,
1958-1972 (2019).

11. Shim, J.-S., Oh, K. & Kim, H. C. Dietary assessment methods in epidemiologic
studies. Epidemiol. Health 36, e2014009 (2014).

12. Thompson, F. E., Subar, A. F., Loria, C. M., Reedy, J. L. & Baranowski, T. Need for
technological innovation in dietary assessment. J. Am. Dietetic Assoc. 110, 48-51
(2010).

13. Magarey, A. et al. Assessing dietary intake in children and adolescents: con-
siderations and recommendations for obesity research. Int J. Pediatr. Obes. 6,
2-11 (2011).

14. Willett, W. in Nutritional Epidemiology (Oxford University Press, 1998).

15. Livingstone, M. B., Robson, P. J. & Wallace, J. M. Issues in dietary intake assess-
ment of children and adolescents. Br. J. Nutr. 92(Suppl 2), $213-S222 (2004).

16. Westerterp, K. R. & Goris, A. H. C. Validity of the assessment of dietary intake:
problems of misreporting. Curr. Opin. Clin. Nutr. Metab. Care 5, 489-493 (2002).

17. Schoeller, D. A. Limitations in the assessment of dietary energy intake by self-
report. Metabolism 44, 18-22 (1995).

18. Doulah, A. et al. Meal microstructure characterization from sensor-based food
intake detection. Front. Nutr. 4, 31 (2017).

19. Marcum, C. S., Goldring, M. R., McBride, C. M. & Persky, S. Modeling dynamic food
choice processes to understand dietary intervention effects. Ann. Behav. Med. 52,
252-261 (2018).

Scripps Research Translational Institute
20.

21.

22.

23.

24.

25.

26.

27.

28.

29.

30.

31.

32.

33.

34.

35.

36.

37.

38.

39.

40.

41.

42.

43.

AA,

45.

46.

Ohkuma, T. et al. Association between eating rate and obesity: a systematic
review and meta-analysis. Int J. Obes. 39, 1589-1596 (2015).

Bell, B. M. et al. Sensing eating mimicry among family members. Transl. Behav.
Med. 9, 422-430 (2019).

Sharps, M. et al. Examining evidence for behavioural mimicry of parental eating
by adolescent females. An observational study. Appetite 89, 56-61 (2015).
Subar, A. F. et al. The Automated Self-Administered 24-hour dietary recall
(ASA24): a resource for researchers, clinicians, and educators from the National
Cancer Institute. J. Acad. Nutr. Diet. 112, 1134-1137 (2012).

Shiffman, S., Stone, A. A. & Hufford, M. R. Ecological momentary assessment. Annu
Rev. Clin. Psychol. 4, 1-32 (2008).

Boushey, C. J., Sooden, M., Zhu, F. M., Delp, E. J. & Kerr, D. A. New mobile methods
for dietary assessment: review of image-assisted and image-based dietary
assessment methods. Proc. Nutr. Soc. 76, 283-294 (2017).

Spruijt-Metz, D. et al. Advances and controversies in diet and physical activity
measurement in youth. Am. J. Preventive Med. 55, e81-e91 (2018).

McClung, H. L. et al. Dietary intake and physical activity assessment: current tools,
techniques, and technologies for use in adult populations. Am. J. Preventive Med.
55, e93-e104 (2018).

Vu, T., Lin, F., Alshurafa, N. & Xu, W. Wearable food intake monitoring technolo-
gies: a comprehensive review. Computers 6, 4 (2017).

Heydarian, H., Adam, M., Burrows, T., Collins, C. & Rollo, E. M. Assessing eating
behaviour using upper limb mounted motion sensors: a systematic review.
Nutrients 11, 1168 (2019).

Doulah, A. et al. The importance of field experiments in testing of sensors for
dietary assessment and eating behavior monitoring. in 40th Annual International
Conference of the IEEE Engineering in Medicine and Biology Society (EMBC),
5759-5762 (2018).

Tricco, A. C. et al. PRISMA extension for scoping reviews (PRISMA-ScR): checklist
and explanation. Ann. Intern. Med. 169, 467-473 (2018).

Veritas Health Innovation. Covidence Systematic Review Software, www.covidence.
org.

Bedri, A., Verlekar, A., Thomaz, E., Avva, V. & Starner, T. Detecting mastication: a
wearable approach. in Proceedings of the 2015 ACM on International Conference
on Multimodal Interaction, 247-250 (2015).

Bedri, A. et al. EarBit: using wearable sensors to detect eating episodes in
unconstrained environments. Proc. ACM Interact., Mob., Wearable Ubiquitous
Technol. 1, 37 (2017).

Bi, S. et al. Auracle: detecting eating episodes with an ear-mounted sensor. Proc.
ACM Interact. Mob. Wearable Ubiquitous Technol. 2, 1-27 (2018).

Blechert, J., Liedlgruber, M., Lender, A. Reichenberger, J. & Wilhelm, F. H.
Unobtrusive electromyography-based eating detection in daily life: a new tool to
address underreporting? Appetite 118, 168-173 (2017).

Chun, K. S., Bhattacharya, S. & Thomaz, E. Detecting eating episodes by tracking
jawbone movements with a non-contact wearable sensor. Proc. ACM Interact.
Mob. Wearable Ubiquitous Technol. 2, 1-21 (2018).

Dong, Y., Hoover, A., Scisco, J. & Muth, E. Detecting eating using a wrist mounted
device during normal daily activities. in Proceedings of the International Con-
ference on Embedded Systems, Cyber-physical Systems, and Applications (ESCS), 1
(2011).

Dong, Y., Scisco, J., Wilson, M., Muth, E. & Hoover, A. Detecting periods of eating
during free-living by tracking wrist motion. /EEE J. Biomed. Health Inform. 18,
1253-1260 (2014).

Farooq, M., Fontana, J. M., Boateng, A. F., Mccrory, M. A. & Sazonov, E. A com-
parative study of food intake detection using artificial neural network and sup-
port vector machine. Proc. 2013 12th Int. Conf. Mach. Learn. Appl. 1, 153 (2013).
Farooq, M. & Sazonov, E. Detection of chewing from piezoelectric film sensor
signals using ensemble classifiers. in Proceedings of the Annual International
Conference of the IEEE Engineering in Medicine and Biology Society (EMBS),
4929-4932 (2016).

Farooq, M. & Sazonov, E. Segmentation and characterization of chewing bouts by
monitoring temporalis muscle using smart glasses with piezoelectric sensor. [EEE
J. Biomed. Health Inform. 21, 1495-1503 (2017).

Farooq, M. & Sazonov, E. Accelerometer-based detection of food intake in free-
living individuals. IEEE Sens. J. 18, 3752-3758 (2018).

Fontana, J. M., Farooq, M. & Sazonov, E. Estimation of feature importance for food
intake detection based on Random Forests classification. in 35th Annual Inter-
national Conference of the IEEE Engineering in Medicine and Biology Society (EMBC),
6756-6759 (2013).

Fontana, J. M., Farooq, M. & Sazonov, E. Automatic ingestion monitor: a novel
wearable device for monitoring of ingestive behavior. /EEE Trans. Biomed. Eng. 61,
1772-1779 (2014).

Fortuna, C., Giraud-Carrier, C. & West, J. Hand-to-mouth motion tracking in free-
living conditions for improved weight control. in [EEE International Conference on
Healthcare Informatics (ICHI), 341-348 (2016).

Scripps Research Translational Institute

B.M. Bell et al.

Np}

 

47.

48.

49.

50.

51.

52.

53.

54.

55.

56.

57.

58.

59.

60.

61.

62.

63.

64.

65.

66.

67.

68.

69.

70.

71.

72.

Gao, Y. et al. iHear food: eating detection using commodity bluetooth headsets.
in 2016 IEEE First International Conference on Connected Health: Applications,
Systems and Engineering Technologies (CHASE), 163-172 (2016).

Gomes, D. & Sousa, |. Real-time drink trigger detection in free-living conditions
using inertial sensors. Sensors 19, 2145 (2019).

Hamatani, T., Elhamshary, M., Uchiyama, A. & Higashino, T. FluidMeter: gauging
the human daily fluid intake using smartwatches. Proc. ACM Interact. Mob.
Wearable Ubiquitous Technol. 2, 1-25 (2018).

Jia, W. et al. Automatic food detection in egocentric images using artificial
intelligence technology. Public Health Nutr. 22, 1168-1179 (2019).

Kyritsis, K., Diou, C. & Delopoulos, A. Detecting meals in the wild using the inertial
data of a typical smartwatch. 47st Annual International Conference of the IEEE
Engineering in Medicine and Biology Society (EMBC), 4229-4232 (2019).
Mirtchouk, M. et al. Recognizing eating from body-worn sensors: combining free-
living and laboratory data. Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.
1, 1-20 (2017).

Navarathna, P., Bequette, B. W. & Cameron, F. Wearable device based activity
recognition and prediction for improved feedforward control. in 2078 Annual
American Control Conference (ACC), 3571-3576 (2018).

Rahman, T., Czerwinski, M., Gilad-Bachrach, R. & Johns, P. Predicting “about-to-
eat” moments for just-in-time eating intervention. in Proceedings of the 6th
International Conference on Digital Health Conference, 141-150 (2016).

Schiboni, G., Wasner, F. & Amft, O. A privacy-preserving wearable camera setup
for dietary event spotting in free-living. in /EEE International Conference on Per-
vasive Computing and Communications Workshops, 872-877 (2018).

Sen, S., Subbaraju, V., Misra, A., Balan, R. K. & Lee, Y. Experiences in building a real-
world eating recogniser. in Proceedings of the 4th International on Workshop on
Physical Analytics, 7-12 (2017).

Sen, S., Subbaraju, V., Misra, A., Balan, R. & Lee, Y. Annapurna: building a real-
world smartwatch-based automated food journal. in /JEEE 19th International
Symposium on A World of Wireless, Mobile and Multimedia Networks (WoWMoM),
1-6 (2018).

Sharma, S., Jasper, P., Muth, E. & Hoover, A. Automatic detection of periods of
eating using wrist motion tracking. in /EEE First International Conference on
Connected Health: Applications, Systems and Engineering Technologies (CHASE),
362-363 (2016).

Thomaz, E., Essa, |. & Abowd, G. D. A practical approach for recognizing eating
moments with wrist-mounted inertial sensing. in Proceedings of the 2015 ACM
International Joint Conference on Pervasive and Ubiquitous Computing, 1029-1040
(2015).

Thomaz, E., Zhang, C., Essa, |. & Abowd, G. D. Inferring meal eating activities in
real world settings from ambient sounds: a feasibility study. in Proceedings of the
20th International Conference on Intelligent User Interfaces, 427-431 (2015).
Yatani, K. & Truong, K. N. BodyScope: a wearable acoustic sensor for activity
recognition. in Proceedings of the 2012 ACM Conference on Ubiquitous Computing,
341-350 (2012).

Ye, X., Chen, G., Gao, Y., Wang, H. & Cao, Y. Assisting food journaling with
automatic eating detection. in Proceedings of the 2016 CHI Conference Extended
Abstracts on Human Factors in Computing Systems, 3255-3262 (2016).

Zhang, R. & Amft, O. Free-living eating event spotting using EMG-monitoring
eyeglasses. in [EEE EMBS International Conference on Biomedical & Health Infor-
matics (BHI), 128-132 (2018).

Zhang, R. & Amft, O. Monitoring chewing and eating in free-living using smart
eyeglasses. /EEE J. Biomed. Health Inform. 22, 23-32 (2018).

Gemming, L., Utter, J. & Ni Mhurchu, C. Image-assisted dietary assessment: a
systematic review of the evidence. J. Acad. Nutr. Diet. 115, 64-77 (2015).
Gemming, L., Doherty, A., Utter, J., Shields, E. & Ni Mhurchu, C. The use of a
wearable camera to capture and categorise the environmental and social context
of self-identified eating episodes. Appetite 92, 118-125 (2015).

Vaizman, Y., Ellis, K. & Lanckriet, G. Recognizing detailed human context in the
wild from smartphones and smartwatches. /EEE Pervasive Comput. 16, 62-74
(2017).

Alshurafa, N. et al. Counting bites with bits: expert workshop addressing calorie
and macronutrient intake monitoring. J. Med. Internet Res. 21, e14904 (2019).
Buchowski, M. S. Doubly labeled water is a validated and verified reference
standard in nutrition research. J. Nutr. 144, 573-574 (2014).

Hall, K. D. et al. Methodologic issues in doubly labeled water measurements of
energy expenditure during very low-carbohydrate diets. bioRxiv, https://doi.org/
10.1101/403931 (2018).

Alharbi, R. et al. | can’t be myself: effects of wearable cameras on the capture of
authentic behavior in the wild. Proc. ACM Interact. Mob. Wearable Ubiquitous
Technol. 2, 1-40 (2018).

Engel, S. G. et al. Ecological momentary assessment in eating disorder and
obesity research: a review of the recent literature. Curr. Psychiatry Rep. 18, 37
(2016).

npj Digital Medicine (2020) 38

13
Np)

B.M. Bell et al.

 

14

73. Schembre, S. M. et al. Mobile ecological momentary diet assessment methods for
behavioral research: systematic review. JMIR mHealth uHealth 6, e11170 (2018).

74. Spruijt-Metz, D., de la Haye, K., Lach, J. & Stankovic, J. A. M2FED: monitoring and
modeling family eating dynamics. in Proceedings of the 14th ACM Conference on
Embedded Network Sensor Systems, 352-353 (2016).

75. Ma, M. et al. MA2G: a monitor of monitoring systems with ground truth validation
features for research-oriented residential applications. in /EEE 14th International
Conference on Mobile Ad Hoc and Sensor Systems (MASS), 10-18 (2017).

76. Leech, R. M., Worsley, A., Timperio, A. & McNaughton, S. A. Characterizing eating
patterns: a comparison of eating occasion definitions. Am. J. Clin. Nutr. 102,
1229-1237 (2015).

77. Videon, T. M. & Manning, C. K. Influences on adolescent eating patterns: the
importance of family meals. J. Adolesc. Health 32, 365-373 (2003).

78. Neumark-Sztainer, D., Wall, M., Story, M. & Fulkerson, J. A. Are family meal pat-
terns associated with disordered eating behaviors among adolescents? J. Adolesc.
Health 35, 350-359 (2004).

79. Suggs, L. S., Della Bella, S., Rangelov, N. & Marques-Vidal, P. Is it better at home
with my family? The effects of people and place on children’s eating behavior.
Appetite 121, 111-118 (2018).

80. Lenardson, J. D., Hansen, A. Y. & Hartley, D. Rural and remote food environments
and obesity. Curr. Obes. Rep. 4, 46-53 (2015).

81. Torres, S. J. & Nowson, C. A. Relationship between stress, eating behavior, and
obesity. Nutrition 23, 887-894 (2007).

82. Isasi, C. R. et al. Psychosocial stress is associated with obesity and diet quality in
Hispanic/Latino adults. Ann. Epidemiol. 25, 84-89 (2015).

83. Sazonov, E. S. & Fontana, J. M. A sensor system for automatic detection of food
intake through non-invasive monitoring of chewing. /EEE Sens. J. 12, 1340-1348
(2012).

ACKNOWLEDGEMENTS

The authors wish to thank Jean Hyon, Anna Satterfield, Rebecca Braganca, and
Cynthia Li for their assistance with article review and data extraction. This work was
supported in part by National Science Foundation grants SCH-1521740, SCH-
1521722, and IIS-1418622; and National Institutes of Health grant 1K25DK113242-
01A1. The funders had no role in study design, data collection and analysis, decision
to publish, or preparation of the paper.

npj Digital Medicine (2020) 38

AUTHOR CONTRIBUTIONS

B.M.B. and D.S.-M. contributed to the conception of the review paper. B.M.B. and R.A.
contributed to the acquisition of the data. All authors substantially contributed to the
analysis and interpretation of data, and to the writing and revision of the paper.

COMPETING INTERESTS

The authors declare no competing interests.

ADDITIONAL INFORMATION

Supplementary information is available for this paper at https://doi.org/10.1038/
s41746-020-0246-2.

Correspondence and requests for materials should be addressed to B.M.B.

Reprints and permission information is available at http://www.nature.com/
reprints

Publisher’s note Springer Nature remains neutral with regard to jurisdictional claims
in published maps and institutional affiliations.

Open Access This article is licensed under a Creative Commons

ig Attribution 4.0 International License, which permits use, sharing,
adaptation, distribution and reproduction in any medium or format, as long as you give
appropriate credit to the original author(s) and the source, provide a link to the Creative
Commons license, and indicate if changes were made. The images or other third party
material in this article are included in the article’s Creative Commons license, unless
indicated otherwise in a credit line to the material. If material is not included in the
article’s Creative Commons license and your intended use is not permitted by statutory
regulation or exceeds the permitted use, you will need to obtain permission directly
from the copyright holder. To view a copy of this license, visit http://creativecommons.
org/licenses/by/4.0/.

© The Author(s) 2020

Scripps Research Translational Institute
