Neural Processing Letters (2020) 52:2583-2605
https://doi.org/10.1007/s11063-020-10362-0

®

Check for
updates

Detecting Ordinal Subcascades

Ludwig Lausser’. Lisa M. Schafer'. Silke D. Kihlwein'. Angelika M. R. Kestler?.
Hans A. Kestler'!?@

Accepted: 1 October 2020 / Published online: 19 October 2020
© The Author(s) 2020

Abstract

Ordinal classifier cascades are constrained by a hypothesised order of the semantic class labels
of a dataset. This order determines the overall structure of the decision regions in feature space.
Assuming the correct order on these class labels will allow a high generalisation performance,
while an incorrect one will lead to diminished results. In this way ordinal classifier systems
can facilitate explorative data analysis allowing to screen for potential candidate orders of
the class labels. Previously, we have shown that screening is possible for total orders of all
class labels. However, as datasets might comprise samples of ordinal as well as non-ordinal
classes, the assumption of a total ordering might be not appropriate. An analysis of subsets
of classes is required to detect such hidden ordinal substructures. In this work, we devise a
novel screening procedure for exhaustive evaluations of all order permutations of all subsets
of classes by bounding the number of enumerations we have to examine. Experiments with
multi-class data from diverse applications revealed ordinal substructures that generate new
and support known relations.

Keywords Ordinal classification - Classifier cascades - Error bounds - Subsets - Supersets

1 Introduction

Extensive data collections are considered valuable resources for hypothesis generation as
well as theory building and confirmation. Providing samples of major concepts or categories,
they can be seen as the foundation of data-driven learning and reasoning. Classical machine
learning techniques focus on the discrimination of individual concepts. Depending on the

Ludwig Lausser and Lisa M. Schafer have contributed equally to this work.

Electronic supplementary material The online version of this article (https://doi.org/10.1007/s11063-020-
10362-0) contains supplementary material, which is available to authorized users.

EI Hans A. Kestler
hans.kestler@uni-ulm.de; hans.kestler @ leibniz-fli.de

! Institute of Medical Systems Biology, Albert-Einstein-Allee 11, 89081 Ulm, Germany
Leibniz Institute on Aging — Fritz Lipmann Institute, 07745 Jena, Germany
Internal Medicine I, University Hospital Ulm, 89069 Ulm, Germany

Q) Springer
2584 L. Lausser et al.

chosen model type, they allow an interpretation of the underlying discrimination rule and
the generation of hypotheses on its intrinsic characteristics [10,27,45]. For example, features
with a high impact on a decision boundary can be reported when screening for potential
causes of class differences [21,34,36]. Dense regions can be extracted when the definition of
prototypic cases is of interest [16]. Combined with external domain knowledge classification
models can also give hints to higher-level processes involved [35,47].

Hypotheses on the relations of the categories are only rarely provided [9,22,52]. Never-
theless, they have tremendous explanatory potential as they link different concepts collected
for a specific subject. This information is complementary to the intrinsic characteristics men-
tioned above. Together they allow a holistic overview of the matter. One type of classifier
that utilises interclass relations are ordinal classifiers [11]. An ordinal classifier relies on an
ordinal relationship of the kind a ~ b ~ c, which is assumed for the semantic concepts
(class labels) of a dataset but not guaranteed for its feature representation. The assumed
semantic ordering guides the training process of an ordinal classifier. If it is reflected in the
feature space, the ordinal classifier can achieve high sensitivities. Otherwise, it will show a
diminished performance [33].

A dependency on a predefined class order can be established in different ways. The overall
structure, as well as the training algorithm of a classification model, can be modified. The first
one is most prominently used for ordinal adaptations of hierarchical multi-class architectures
based on sequences of binary classifiers [40]. The order of these sequences can be designed
to reflect assumed class orders. Examples can be ordinal classifier cascades [18], which are
modifications of general decision lists [45], ordinal versions [23] of nested dichotomies [19]
or systems based on directed acyclic graphs [44]. More specific modifications can be applied
to different types of base classifiers [11,12]. A training algorithm can be adapted for ordinal
classification by utilising specific performance measures [50] or cost-sensitive base classi-
fiers [31,39].

Here, we now do not assume any order on the class labels but instead, screen for potential
candidate orders on the semantic level. Nevertheless, the assumption of a total order of
classes might not be appropriate in the presence of non-ordinal categories. We propose a
novel screening procedure for generating hypotheses on ordinal relations among subsets
of these categories. It extensively replaces de novo modelling by memoisation techniques
bringing exhaustive evaluation into range. We utilise ordinal classifier cascades to screen
through all class combinations and highlight those sub-cascades that achieve a predefined
minimal class-wise sensitivity which is more difficult for longer sub-cascades. We, therefore,
focus on those that cover as many classes as possible. We found that accurate sub-cascades
can also result in a compact assignment of the remaining categories and conclude that they
hence allow for hypothesis generation on these remaining non-ordinal classes.

The remaining article is organised as follows. Section 2 provides the underlying notation
and concepts of ordinal classification. In Sect. 3, we describe our screening method. We
outline the design of our experiments and results in Sects. 4 and 5 and discuss them in
Sect. 6.

2 Methods

The basic building block of our screening experiments is the training and evaluation of
classification models, the classifiers. In its basic version, a classifier is a function designed

Q) Springer
Detecting Ordinal Subcascades 2585

for categorising an object into one out of || predefined and fixed classes y € Y

c:R"’ — yp. (1)
The corresponding classification task is typically named binary (|| = 2) or multi-class
(|Y| > 2). The object is presented as a vector x = (X],..., Xn)E of measurements which we

assume to be embedded in the n-dimensional real-valued space IR”. A classifier is adapted
to a classification task via a set of labeled training examples JT = {(x;, y; Nin i i € Y. The
training algorithm and the concept class of the classifier is chosen a priori.

The performance of a classifier is typically evaluated on an independent set of validation
samples V = {(x;, yer: Although a classifier is trained to predict a predefined set of
classes Y, it is applied in altered scenarios in which a subset y; € Y’ C Y or a superset
y; € Y’ D J of classes might be used. We will therefore define our performance measures
in dependency on the label set of interest.

All performance measures will be based on conditional prediction rates of type

pel |Xy) = ra > Yew=y'): (2)

xEXy

The symbol I.; denotes the indicator function and 7, denotes a set of samples of class y. Other
(re-)sampling schemes might be applied but will not change the theoretical characteristics
discussed in this work. Three types of conditional prediction rates can be distinguished:

sensitivities if y=y’ and y,yey (3)
confusions if yy’ and y,y ey (4)
external rates if y¢Y and y’ey. (5)

While (class-wise) sensitivities and confusions occur for the learned set of classes JY, the
external rates describe the classifiers behaviour on samples of foreign classes y € Y’ \ y.

A standard performance measure for classification tasks is the empirical accuracy. In
dependency on a label set Y it can be formulated as

dyey Pe(y | %y)|¥y|
deyey |X| .
In its standard version, the empirical accuracy is applied to the full set of classes but it might

also be applied to a sub- or superset of classes. In the following, we focus on the minimal
class-wise sensitivity as a quality measure for a multi-class classifier system

Acc, (Y) = (6)

Sming(Y) = min Pc(y | Ay). (7)

It can be seen as a lower bound on the overall accuracy

dyey Dey | ty) |¥y|

Acce(y) = (8)
yey | ry |
> dyey minyey Pe(y" | Xy) |X, | (9)
deyey |X5|
= minyrey pe(y’ | XY) (10)
= Smin,(V). (11)

Q) Springer
2586 L. Lausser et al.

In the context of analysing subsets of classes, Smin, shows a monotonicity on the number
of classes. For a non empty subset of classes

YVcy, VAG: Smin.(Y’) > Smin,(Y). (12)

For external classes y’ ¢ , we define the percentage of the most frequently predicted class
label y € ) as the purity of y’

pur,(y’) = max pe(y | Vy). (13)
yey

2.1 Ordinal Classification

Ordinal classification is a multi-class classification task (|| > 2), in which we hypothesise
that the classes are related via an ordinal relationship

Yd) < +++ < YY), (14)

where the subscript y;;) indicates the position of the class within the ordering (ith class). The
symbol ~< indicates that this ordering is only known (or assumed) for the verbal concepts.
Its reflection in feature space cannot be guaranteed. Nevertheless, ordinal classifiers are
constrained to this ordering and try to identify an embedding that reflects this ordinality.
If such an embedding can be found, the chosen feature representation might be seen as
evidence for the hypothesised ordinal relationship; otherwise the ordinal classifier will suffer
from a decreased generalisation performance (Fig. 1). The classifier will typically not be
able to predict all classes of V. Its performance might be measured by the minimal class-
wise sensitivity Smin-())). The susceptibility of ordinal classifiers to incorrect class orders
is therefore an important characteristic for the screening processes, in which we try to select
reflected/relevant class orders among all possible class orders.

2.1.1 Ordinal Classifier Cascades

Our screening procedure is based on ordinal classifier cascades, which can be seen as ensem-
ble multi-class classifiers
h:R"’ —y (15)

based on an ensemble € = few}! of |V| — 1 binary base classifiers

cj) : R" — {ya), v4} (16)

designed for predicting a pair of two consecutive classes within the assumed class ordering.
We utilise pairwise training in the following meaning that each base classifier ci) is trained
on the samples of two consecutive classes

Ti) = {(x y) | & y) ET, y € {yi vasn}}- (17)

The cascade itself can be seen as an untrainable fusion architecture, which evaluates the base
classifiers sequentially according to the assumed class order

ya) if cqay(%) = ya)
h(x) = yi) if /\ (cc) (x) = sven) A Ci) (X) = Ya) (18)
j<i

Yay) else.

Q) Springer
Detecting Ordinal Subcascades 2587

(a) original order: (c) wrong order:

Y1 ~< Y2 < Y3 < Ya ~ 'Y5 < YE X< Y7 X< YB Y1 ~< Y2 < Y3 < Y5 ~ Y4 < ‘YE X< ‘YT X< YB

 

 

(b) inverse order: (d) wrong order:

Ys < Y7 < Yo < Y5 < Y4 < YB < 'Y2 < YI Y1 ~< Y2 < Y3 < Ya < ‘YB X U7 X< ‘YO X U5

 

Y1:@ y2:@ y3:O ys:O Ys: O Ys: O Y7:O Ys:O

 

Fig.1 Influence of class order on ordinal classifier cascades. The figure shows four ordinal classifier cascades
trained under different assumptions of the class order. Panel a: A class order that is reflected by the data. The
inverse order is shown in Panel b. Note, that the decision regions differ in both cases. Panels c, d: Examples
for class orders that are not reflected by the data. Here, decision regions of individual classes can be empty or
even do not exist

2.1.2 Pairwise Training of Base Classifiers
The pairwise training of the base classifiers improves the training and the evaluation time of

ordinal classifier cascades when multiple class orders are tested. As the pairwise training of a
base classifier c(;) does not take into account any foreign classes ) \ {y(i), y@i+1)}, a classifier

g) Springer
2588 L. Lausser et al.

Table 1 Scheme of predicted class labels

 

Classifier Validation samples (x, y) € V
Cj, | (X) xE XY, Lee xe XY. Lee xX € Ly),

X15 +++ X|Xy, | wee X15 +++ X|AXy, | wee X15 +++ X|Xiy))|
Vis Vj a a Ci,j (XI), +--+ Cif RX |)

The table provides the predicted class labels of a set of pairwise trained base classifiers c;,; for a validation
set V = {(x;, ye. As pairwise trained base classifiers do not depend on the chosen class order, all base

classifiers and predictions have to be calculated only once. The table is of size (‘¥ ) x |V| for classes Y. The
scheme of the table can be extended for arbitrary resampling strategies

designed for predicting classes y; and y;
Ci,j :R” — {vis vy} (19)

will be identical for all class orders. The classifier c;,; is not based on the class order. The
screening process through all class orderings can therefore be based on a common set of (9 )
base classifiers and their predictions, which can be memoized beforehand. We propose to
construct a prediction table as shown in Table 1, which allows the evaluation of all cascades
without training and evaluation of the base classifiers.

2.1.3 Error Bounds

As a consequence of their invariant predictions, also the conditional prediction rates of
pairwise trained base classifiers are invariant against the order of classes. They can again
be precalculated and looked up if necessary (Table 2). Previously, it has been shown that
the class-wise sensitivities of an ordinal classifier cascade are upper bounded by a set of
conditional prediction rates of the corresponding base classifiers [37].

Theorem 1 Let h denote an ordinal classifier cascade

h:R° —- y= {ya).--+> Yay} (20)
with base classifiers E = {c),...,C(y|-1)}. Let furthermore Xi) be a non-empty set of
samples of class yi). Then the sensitivity of h for yi) is limited by

PrOG@ | By) < Pc) (Vi) | Xi) (21)
Ph (Vii) | Xyiy) < min Pew (V(k+41) | Xy iy). (22)

Note that neither the construction nor the evaluation of an ordinal classifier cascade is required
for providing these upper limits. A limit to the minimal class-wise sensitivity of an ordinal
classifier cascade can be given by a set of lookups. In this way a large proportion of those
cascades that will not pass a predefined threshold t < Smin,(V) can be rejected before
starting the more expensive calculations on the prediction table (Table 1). We utilise the
CASCADES algorithms [37], which realises this strategy as preprocessing step in order to
reduce the computational burden. Only those cascades, which pass this filter will be evaluated
for their real minimal class-wise sensitivity.

Q) Springer
Detecting Ordinal Subcascades 2589

Table 2 Scheme of prediction Classifier

Classes y €
rates

cj, j (x) yq a Yk Lee yy

Vis Vj ve = Pej, ; Vil yx)

The table provides the conditional prediction rates of a set of pairwise

trained base classifiers c;,; for a set of validation V = {(x;, nee

AS pairwise trained base classifiers do not depend on the chosen class
order, all conditional prediction rates have to be calculated only once.

The table is of size (3!) x |¥Y| for classes Y

 

(a) ordinal cascade (b) ordinal subcascade

Fig.2 Schematic drawing of ordinal cascades. a A scheme of a full ordinal cascade that comprises all available
classes y(1), ---, (6). b An ordinal subcascade. Here classes (1), ... , y(6) are embedded in a larger collection
of classes (black circles), which can not be linked via one single ordinal relationship

3 Screening for Ordinal (Sub-)structures

Here, we focus on the analysis of multi-class datasets that are not originally designed for
ordinal classification (Fig. 2). That is, we do not assume a unique ordinal relationship for all
classes in Y. The classes in Y can instead be seen as a loose collection of known categories
within a common context of interest. Nevertheless, subsets of classes ¥’ C Y can fulfil
our quality criteria for ordinal classification. The corresponding decision regions can be
interpreted as an ordinal structure, and we might hypothesise an ordinal relation between the
classes in ’. Here, memoization tables (Tables 1, 2) proposed for the full set of classes Y
can directly be repurposed for the analysis of any subset of classes Y’.

3.1 Size of the Search Space

The number of candidate cascades is dependent on the chosen screening task. In all cases, it
can be decomposed in the number of class orders ||! and the number of subsets (‘” ) of a

predefined size k!:

Full cascades: o(|Y|) = ||!
Subcascades of size k: sz (||) = (Vk!

! For simplification we allow cascades of length k = 1 in this section.

Q) Springer
2590

Table 3 Number of candidate cascades

L. Lausser et al.

 

IY| =5 |Y| = \Y| = 15 |Y| = 20 \Y| = 25
Sal IYI) 325 9.8 x 10° 3.5 x 1012 6.6 x 1018 4.2 x 1025
o(|V}) 120 3.6 x 10° 1.3 x 10!2 2.4 x 1918 1.5 x 1025
salt IY) /odVI) 2.708 2.718 2.718 2.718 2.718

The table provides the number of possible full cascades o(||) and subcascades sgjj(|V|) for |V| =
{5, 10, 15, 20, 25} classes

IYI (121)

It might be noteworthy that sz (|V|) < sjyj-« (|) for k < |Y|/2.
The ratio of the number of all subcascades and the number of full cascades is approximately
given by the Euler number as

All subcascades: sqjj(|Y|) =

san IV) = eh (as (23)
=r 4 (24)
and the ratio itself ¥y
Sall (|Y|) 1 IVl-00.
— e ~ 2.718. 25
ol) yp >)

Examples for numbers of candidate cascades can be found in Table 3. Note that for other
(traditional) types of ordinal classifiers the evaluation of each candidate cascade requires the
de novo training of the corresponding model. As these training phases by far exceed the time
complexity of evaluating the memoization tables (Tables 1, 2), the proposed screenings are
infeasible for traditional algorithms and implementations.

3.1.1 Properties of Subcascades

The combinatorics show that the overall number of subcascades exceeds the overall number
of full cascades by only a constant factor. Nevertheless, we expect a much higher number
of candidate subcascades to pass a threshold on the minimal class-wise sensitivity than a
number of candidate full cascades.

Theorem 2 Let yi) ~ ... ~ ya) ~ ... < yay) denote an arbitrary but fixed class order
of the classes in Y and h : R" — Y an ordinal classifier cascade designed for this class
order and based on an ensemble of pairwise trained base classifiers E = few}! . Let
furthermore Y’ = Y\ {yy} and h' : R” > Y’ denote an ordinal classifier cascade designed
for class order yy) < ... < ya—1) < Yi+l) <~... < yay based on E' = E\ {cy}, ifi = 1,

ET =E\ {cqy-v}, fi = |Y| and
E' = (E \ {ew-1). ew}) U eG_1)} (26)
otherwise, where
cl, 00) = [re if CG—1)(X) = Ya-1) . (27)
yitn fF cg-y®) = ya

Q) Springer
Detecting Ordinal Subcascades 2591

In this case
Sminy, (VY) < Sminy (Y’). (28)

Proof From the monotonicity of the minimal class-wise sensitivity (Equation 12) we get
Sminy(Y) < Smin; (Y’). (29)

Cascade h’ is constructed from the same base classifiers as h. Only one classifier is
removed, which closes the option of predicting class label yi). In case i = 1, all samples
that would have been classified as y1) by A are directly sent to c(2) by h’. This is of course
also true for all remaining samples with c(1)(x) = y2) in h. Therefore for each class label
y € ¥’, the set of samples that receive this class label y by h’ comprises at least all samples
that receive class label y by h. The corresponding class-wise sensitivities and their minimum
can only be increased.

In case 1 <i < ||, additionally classifier c(;_1) and ci) are replaced by Cat)? which
redirects those samples that would be sent from c(;—1) to cj). The common preamble of base
classifiers of h and h’ leads to identical class-wise sensitivities for classes y(1),..., Y(@i—1)-
Those classes that received class label y(;) by A are again reclassified into one of the subsequent
classes leading to equivalent or increased class-wise sensitivities.

In case i = |], the cascades h and h’ share the longest possible preamble of base
classifiers. Only the samples receiving class label yj3),) by 4 will be reclassified as y(jy\—1)
by h’ leading to at least the class-wise sensitivity for class yqy)).

We therefore get for all cases

Sminn (VY) < Sminy(Y’). (30)

O

Theorem 2 states that a subcascade h’ constructed from a full cascade h by removing
a single class yi) and by reconnecting the corresponding base classifiers is guaranteed to
achieve at least the same minimal class-wise sensitivity on Y’ than h on J. It can recursively
be applied to h’ and its own subcascades leading to a transitive relationship between a full
cascade and all its subcascades. The more classes a cascade comprises the more difficult
it will be to reach a predefined minimal class-wise sensitivity. We will therefore focus on
longer cascades.

4 Experiments

We evaluated our screening procedure empirically in 10 x 10 cross-validation experi-
ments [24]. All ordinal classifier cascades were based on linear SVMs (cost=1) [49]. The
TunePareto Software was used for the evaluation of base classifiers [41]. All time measure
experiments were performed on an AMD Opteron(tm) Processor 6276 with 2.6 GHz (32
cores with HT) and 512 GB RAM.

As mentioned above, alternative systems are unlikely to cope with the computational
burden of exhaustive screenings (Sect. 3). Reference classifiers were therefore directly applied
to those orders identified by our screening procedure.

We compared our results to those of other multi-class architectures based on indepen-
dently trained linear SVMs (cost=1). As ordinal reference architectures we used a splitted
ordinal classifier cascade (Scc, pairwise training) denoted as “voter 3” by Jiang et al. [26],
the ensembles of nested dichotomies (END, |€| = 20) [19] and directed acyclic graphs

Q) Springer
2592 L. Lausser et al.

Table 4 Overview of the analysed datasets

 

n |Y| |S| ISy|

d,: Handwritten digits

64 10 5620 y, = 554 y2 = 571 y3 = 557 y4 = 572 y5 = 568
y6 = 558 y7 = 558 yg = 566 y7 = 558 yg = 566
yo = 554 yjo = 562

d: Isolet

617 26 77197 Y{,--+> 26 = 300

d3: Cancer cell lines

54613 9 174 y, = 18 y = 15 y3=21 y4 = 26 ys = 18
yo = 21 y7 = 23 yg = 26 yo = 6

d4: Leukemia

54613 18 2096 yy = 40 y2 = 36 y3 = 58 y4 = 48 y5 = 28
yo = 351 y7 = 38 yg = 37 yo = 40 yjo = 237
yyy = 122 y12 = 448 y13 = 76 yi4 = 13 y15 = 206
y16 = 74 y17 = 70 yig = 174

ds: TCGA

52762 8 2370 y, =45 yy = 424 y3 = 182 y4 = 521 ys = 177
yo = 321 y7 = 611 yg = 89

do: C.elegans

22548 10 123 yp = 12 y = 12 y3 = 13 y= 11 ys = 13
yo = 13 y7 = 10 yg = 14 yo = 11 yio = 14

d7: Wound healing

54613 8 857 yy = 338 y2 = 68 y3 = 107 y4 = 116 y5 = 104
yo = 54 y7 = 33 yg = 37

dg: HPA-axis

54 7 336 Y{,--- 7 = 48

The domain, the dimensionality n, the number of classes ||, samples |S| and the number of samples per class
|Sy| are given

(DAG) [44]. As non-ordinal references the one-against-one (OaQO) and the one-against-all
(OaA) architectures were applied [40].

Additionally, our results were compared to a 1D self-organising map (SOM) [30]. This
mapping was performed using the standard settings of the R-package kohonen [53,54]
(learning rate: [0.05,0.01], but no layer normalisation). The nodes and consequently the
clusters were labelled based on the cascade under investigation.

4.1 Datasets

The screening procedure is evaluated on eight multi-class datasets from different domains.
The main characteristics of the analysed datasets can be found in Table 4. We used data,
which comprises different representations of alphanumeric characters (written and spoken)
from the machine learning database UCI [13], and gene expression and methylation profiles
which were measured either by microarrays or by deep sequencing.

Q) Springer
Detecting Ordinal Subcascades 2593

d,: Handwritten digits dataset. The handwritten digits dataset was made publicly available
by Alpaydin and Kaynak [3] as part of the UCI repository [13]. This dataset is a collection
of bitmaps of digits written by 43 different people. The classes y;, ..., yjq correspond to the
labels 0,..., 9.

dz: Isoletdataset. The Isolet (Isolated Letter Speech Recognition) dataset by Fanty and
Cole [17] and downloaded from the UCI repository [13] consists of spoken letters of the
alphabet. The classes y,,..., y26 correspond to the labels a, ..., z.

d3: Cancer celllines. The NCI-60 dataset (GSE32474) was collected by Pfister et al. [43].
It consists of gene expression profiles from cell lines that derived from different cancer tissue
types. The different cancer types are: y,;: Leukemia, y2: Breast cancer, y3: Ovarian cancer,
y4: Melanoma, y5: Central nervous system (CNS), v6: Colon cancer, y7: Renal cancer, yg:
Non-small cell lung cancer, yo: Prostate cancer.

d4: Leukemia. As a prephase to the MILE Study (Microarray Innovations In LEukemia)
program expression data from blood and bone marrow samples from acute and chronic
leukemia patients was collected (GSE13159). Kohlmann et al. [29] could hereby show that
standardised experimental protocols can lead to comparable results across different labora-
tories. The samples have been categorised in different leukemia subgroups and assigned to
class labels as follows: yj: ALL (acute lymphocytic leukaemia) with hyperdiploid karyotype,
y2: ALL with t(1;19), y3: ALL with t(12;21), y4: AML (acute myeloid leukaemia) complex
aberrant karyotype, y5: AML with inv(16)/t(16;16), ye: AML with normal karyotype and
other abnormalities, yz: AML with t(11q23)/MLL, yg: AML with t(15;17), yo: AML with
t(8;21), yj9: c-ALL/Pre-B-ALL without t(9;22), y},: c-ALL/Pre-B-ALL with t(9;22), yj:
CLL (chronic lymphocytic leukaemia), yj}3: CML (chronic myeloid leukaemia), yj4: mature
B-ALL with t(8;14), yjs5: MDS (myelodysplastic syndromes), y}6: Non-leukemia and healthy
bone marrow, y,7: Pro-B-ALL with t(11q23)/MLL, y;8: T-ALL.

ds: TCGA. This dataset is acollection of datasets that was generated by the TCGA Research
Network (http://cancergenome.nih.gov/). The feature space consists of the intersection of
all features of the single datasets. The different cancer types are assigned to class labels
as follows: y;: Cholangiocarcinoma (CHOL), y2: Liver hepatocellular carcinoma (LIHC),
y3: Pancreatic adenocarcinoma (PAAD), y4: Colon adenocarcinoma (COAD), y5: Rectum
adenocarcinoma (READ), ye: Kidney renal papillary cell carcinoma (KIRP), y7: Kidney
renal clear cell carcinoma (KIRC), yg: Kidney chromophobe carcinoma (KICH).

do: C. elegans. Baugh et al. [6] analysed the influence of the homeodomain protein PAL-1
of the C-lineage-specific gene regulatory network in the model organism C. elegans. They
gathered gene expression data of samples of wild-type embryos and mutant embryos at 10
points in time after the 4-cell-stage of the embryo (GSE2180). We normalised (mas5) and
labelled these samples based on the points in time: y;: 0 minutes, y2: 23 minutes, y3: 41
minutes, y4: 53 minutes, y5: 66 minutes, ye: 83 minutes, y7: 101 minutes, yg: 122 minutes,
yg: 143 minutes, yjg: 186 minutes.

d7: Wound healing. Xiao et al. [56] analysed the total cellular RNA of blood samples
taken from severe blunt trauma patients (GSE36809). They performed a time scale analysis
and took samples at different points in time after the injury. We normalised (mas5) and
summarised the different points in time, measured in hours and labelled them as follows: y,:
(0,50), y2: [50,100), v3: [100,150), y4: [150,200), ys: [200,400), ye: [400,600), v7: [600,800),
yg: control.

dg: HPA-axis. This dataset by Agba et al. [1] comprises measurements of DNA methy-
lation patterns of different promoters of the glucocorticoid receptor gene (NR3C1) and the
imprinting control region of IGF2/H19 of 7 tissues of rats. These profiles especially enclose
measurements of the hypothalamic-pituitary-adrenal-axis (HPA-axis), a neuroendocrine sys-

Q) Springer
2594 L. Lausser et al.

tem which is known to be involved in the regulation of stress reactions. In our experiments,
the classes denote the different tissue types y;: Cortex, y2: Hippocampus, y3: Hypothalamus,
y4: Pituitary, ys: Adrenal, ye: Skin, y7: Liver.

5 Experimental Results and Interpretation

In this section we will present the results on the utilised benchmark data sets and give some
interpretation on these results. Table 5 provides an overview on the extracted longest cascades.
Between one and five cascades were detected per dataset passing the dataset specific highest
threshold. They achieved minimal class-wise sensitivity thresholds ranging from 0.75 to 0.9.
The theoretical maximum number of cascades is for all datasets more than 800 times larger
than the number of returned cascades. A general overview about the numbers of cascades that
pass the first threshold in comparison to the number that pass the second threshold (dataset
specific) is given in the Supplementary Information.

Longest cascades. Graph representations of the longest cascades can be found in Figs. 3
and 4. It can be seen that all found cascades overlap in at least one class except for the TCGA
data ds. The extrema in the amount of overlap are ds which shows no overlap and cascades
of dz and dg which overlap in all except one class. Further structures that can be observed
are that cascades differ in one class at the beginning (d2) in the middle (dg) or at the end (d1),
but especially if more than two cascades pass the minimal sensitivity criterion the cascades
also align to more complex graphs (d3, dg).

Classes that are not included into the subcascade. Extended confusion tables for the
longest cascades are shown in the Supplementary Information. Figure 5 shows exemplarily
the confusion table for the TCGA dataset ds. As focusing on the detection of subcascades,
classes exist that are not part of the longest cascades, termed Others in Figs. 3 and 4. These
classes can be split in classes that are not part of any of the longest subcascades (uncovered
classes) and classes that are not part of the specific subcascade but part of another of the
longest subcascades returned (alternative class). Presenting a sample of one of these classes
to a specific subcascade, these samples are necessarily classified as one of the cascade classes
as there is no rejection possibility. A general overview of how distinct the allocation of these
additional classes to cascade classes is, provides the mean of the purity values (Eq: 13)
(Table 5).

De novo calculation vs memoization scheme. In order to demonstrate the impact of the
proposed memoization techniques we performed additional experiments with a traditional
implementation of an ordinal classifier cascade. That is each training phase is realised as
a de novo adaptation of the classification model. Both versions were based on the same
implementation of base classifiers (SVM) [41] and did not use any parallelisation. The runtime
of both approaches was compared on dataset dq (|V| = 18), which corresponds to Sqjj (||) >
10!8 subcascades. Again a 10 x 10 CV was conducted for each subcascade. The memoization
techniques allowed to accomplish this screening in about 1868 minutes, while the de novo
calculation of a single 10 x 10 CV on all || = 18 classes (fixed class order) required 798
minutes. The de novo calculation is therefore not able to perform this screening in a feasible
amount of time.

Performance comparison. As the complexity of an ordinal classifier cascade is rather low in
comparison to the complexity of the chosen reference classifiers we have chosen to run these
algorithms only for the longest subcascades identified by the initial screening. The minimal
class-wise sensitivities achieved by the reference classifiers on the longest subcascades are

Q) Springer
Detecting Ordinal Subcascades 2595

d,: Handwritten digits (t=0.75, 1=5)
Cascades:

dz: Isolet (t=0.9, 1=10)

Cascades:

    

lef] [em] [en] [ea] [bix] [dis] [dgix] [zi] [cit]

dg: Cancer cell lines (t=0.85, 1=5)

Cascades: » Others:

Breast
cancer

 

d4: Leukemia (t=0.75, 1=7)

Cascades: <y

 

Others:

@)
@)

ALL Cy) mat. B-ALL AML
t(12;21) t(8;14)

norm. k.

c-ALL/Pre-B-ALL Cy:) AML & other abnor-
t(9;22) comp. ab. k. malities

Fig.3 Longest cascades detected for datasets dj — d4. Descriptions of the datasets are given in the text. For
each dataset the threshold (t) and the length of the longest cascades (1) is stated. The individual cascades are
color encoded differently. For datasets d, and d> the left out classes (others) are not shown

Q) Springer
2596 L. Lausser et al.

ds: TCGA (t=0.9, 1=4)

Cascade:
CHOL

LIHC KIRC  PAAD_ READ :
: COAD
g ; / : KIRP

KICH

dg: C. elegans (t=0.75, 1=9)

Cascades:

 

186 min

O min 23 min 41 min 53 min 101 min 122min~= 143 min

d7: Wound healing (t=0.8, 1=4)

Cascades:

Others:

[400, 600) : C:) [50, 100)

: [150, 200)

control [100, 150) (0,50): Cy) [200, 400)
[600, 800) :

dg: HPA-axis (t=0.9, 1=5)

  
  

  

Cascades: Hi Others:
ippocampus

  

Cortex

 

Pituitary Adrenal

Hypothalamus
Fig.4 Longest cascades detected for datasets d5 — dg. Descriptions of the datasets are given in the text. For

each dataset the threshold (t) and the length of the longest cascades (1) is stated. The individual cascades are
color encoded differently. Additionally, the left out classes, which are classes that are not included in neither

of the cascades are depicted as others

Q) Springer
Detecting Ordinal Subcascades 2597

Table 5 The characteristics of the longest cascades

 

Cascade Smin Pury) + PUF nc
d,: Handwritten digits (t= 0.75, l= 5): 2(30240) alt=2 unc=3
Y7<Y2<Y6<Y10<Y4 79.8 53.6 72.9
Y7<Y3<)Y6<Y1IOX<yYB 76.2 56.4 74.6
dy: Isolet (t= 0.9, = 10): 2 (> 1-10!4) alt=1 unc=15
Y19<¥6<Y13<V14<y1 <Y2<y4<y7<y26<yY3 90.8 41.8 66.0
y25<Y6<Y13<V14<Y1<y2~<y4~<y7<y26~<yY3 90.4 100 68.6
d3: Cancer cell lines (t= 0.85, I= 5): 4(15120) alt=3 unc=1
Y1~<¥6<Y3~<Y8 <4 88.5 62.4 55.3
Y1<Y6~<Y3~<yY8x<ys5 88.5 62.3 39.3
Y1 <y9~< 3 <Y7~<y5 86.7 51.8 38.7
Y1<Y6~<Y3<Y7~<Y5 86.1 67.8 42.0
d4: Leukemia (t= 0.75, I= 7): 2(> 1 - 10/8) alt=6 unc=5
Y12<Y2<Y10<Y18<y5~<yo~<yg 75.8 69.3 61.1
Y1<Y17<Y5<Y7<Y13 <V15<Y16 75 77.0 69.8
ds: TCGA (t= 0.9, l= 4): 1(1680) alt=0 unc=4
Y2<Y7 <3 <5 91.2 NA 94.8
dg: C. elegans (t= 0.75, l= 9): 2(> 3 - 10!) alt=1 unc=0
y1<y2~<y3<y4<y6<y7<yYg~<yo~<yio 79.3 52.3 NA
y1<yY2<y3 <y4~<y5~<y7<yYg~<yo~<yio 79.3 52.3 NA
d7: Wound healing (t= 0.8, 1=4): 2(1680) alt=1 unc=3
Y8<Y6<Y3~<Y1 82.3 89.1 67.0
Y8<Y7<Y3~<Y1 80.3 82.2 65.3
dg: HPA-axis (t= 0.9, 1=5): 5(2520) alt=1 unc=1
Y7<Y6<)2~<)Y4~<y5 93.1 85.6 68.3
Y7<Y6<Y2<Y5 <4 93.1 95.2 68.3
Y5 <Y4~<Y2~<)Y6~<Y7 92.7 87.7 89.8
Y5 <Y4~<)3~<)6<y7 92.3 90.8 43.3
Y7<Y6<Y3~<V4~<Y5 91.4 90.4 36.5

 

For each dataset the threshold (t), the length of the longest cascade (1) and the number of the returned cascades,
as well as the maximal number of theoretical possible cascades (in brackets) is given. Classes that are not
part of the cascade are splitted in alternative classes (classes that are part of another returned cascade) and
uncovered cascades (classes that are not within any of the longest cascades) and the size of each of these
subsets is given as alt and unc. For each cascade the minimal class-wise sensitivity Smin is give, as well as
the averaged misclassification purity values for the alternative subset pur,;, and the uncovered subset pur,,,,.

shown in Table 6. An overview on all sensitivities is given in the Supplementary Information.
The comparison to the non-ordinal architectures (OaO, OaA) demonstrate the impact of
(correct) ordinal information by a higher performance of the ordinal classifier cascade (Occ).
In five out of eight datasets (d4 — dg) cascades exist for which the OaO achieved lower
minimal sensitivities and did not even pass the minimal threshold (t). For the OaA this was
observed only twice (d6, d7). The ordinal architectures, the ensembles of nested dichotomies
(END) and directed acyclic graphs (DAG), perform well on these datasets and constrained to
the selected orders. Both approaches did not pass the minimal threshold t on d7. The END did

Q) Springer
2598 L. Lausser et al.

Table 6 The table shows the minimal class-wise sensitivity performance as % of various methods on the
selected subcascades

 

Occ Scc END DAG SOM OaO OaA

d,: Handwritten digits (t= 0.75, l= 5)

Y7<V2~<V6~<yY10~<y4 79.8 30.6 97.8 a) 0.0 96.6 96.7
Y7<Y3~<V6~<yV1I0<yg 76.2 22.1 98.6 98.7 2.6 96.6 98.0
d2: Isolet (t= 0.9, l= 10)

V19<Y6<V13<Y14~<Y] <y2~y4~<y7~<y26~<y3-90.8 24.2 93.0 92.7 11.3 92.6 91.1
Y25 <V6<V13<V14~y] <Y2~y4~y7~<y26<y3 904 = «611.0 92.5 92.7 0.1 92.6 91.2
d3: Cancer cell lines (t= 0.85, l= 5)

V1 <6 <Y3~<yg~x<y4 88.5 37.7 96.2 96.5 5.7 96.2 98.5
V1 <V6<Y3~<yg~<y5 88.5 63.9 100.0 100.0 11.7 100.0 100.0
Y1 <9 <y3~<y7~<y5 86.7 6.7 100.0 100.0 11.4 100.0 100.0
Y1<Y6<¥3~<y7~<y5 86.1 66.1 100.0 1000 12.4 100.0 100.0
d4: Leukemia (t= 0.75, l= 7)

Y12<Y2~<V10<V18<y5<yo~<yg 75.8 0.0 85.0 84.4 0.1 81.6 87.5
Y1~V17<Y5 ~V7<V13 ~V15<V16 75.0 17.1 749 77.7 1.3 66.5 77.8
ds: TCGA (t= 0.9, l= 4)

Y2<Y7<y3~<ys5 91.2 93.8 95.2 95.8 10.1 50.5 96.5
do: C. elegans (t= 0.75, l= 9)

V1 <y2<¥3~<V4~<yV6~<y7<yYg~<yo~yI0 79.3 0.0 81.4 79.3 6 79.3 79.0
Y1 <2 <Y3~<y4~<y5~<y7~<yg~<yo~<y1o 79.3 50.8 81.4 79.3 5 66.2 68.2
d7: Wound healing (t= 0.8, 1=4)

V8 ~<V6<y3~<y] 82.3 76.1 80.6 82.8 9.7 33.0 83.5
yg <y7~<y3~<y] 80.3 56.4 65.1 72.4 10.3 22.7 69.4
dg: HPA-axis (t= 0.9, 1=5)

Y7<Y6~<y2~<y4~<y5 93.1 92.7 95.8 93.1 91.7 76.2 97.5
Y1<V6<Y2~<y5~<y4 93.1 92.7 95.8 93.1 1.5 76.2 97.5
Y5<y4~<y2~<y6<yY7 92.7. 92.7 95.8 93.1 0.0 76.2 97.5
Y5<V4~<y3~<V6<yY7 92.3 92.3 95.2 92.3 0.0 62.3 95.4
Y7<Y6<y3~<y4~<y5 91.5 92.3 95.4 92.3 58.5 62.3 95.4

Various ordinal classifier methods, as the investigated ordinal classifier cascade (Occ), Nested Dichotomies
(END), directed acyclic graph SVMs (DAG) or splitted (ordinal) classifier cascade (Scc) are applied to the order
returned by the cascades algorithm within the screening. Additionally, a linear self-organising map (SOM)
was used to cluster the data and the cluster performance was evaluated based on the order. Furthermore, two
non-ordinal multi-class approaches, one-against-one (OaO) and one-against-all (OaA) are used

also slightly pass the threshold on d4. The splitter ordinal classifier cascade (Scc) achieved
high minimal class-wise sensitivities only on dg dataset and ds. It would have deselected
individual classes in our experiments. With the exception of the first cascade of dg SOM was
also not able to separate all classes of the cascades.

Handwritten digits dataset. The two longest cascades of length five which are found in
d, the digit dataset overlap at three classes. A meaningful interpretation of the direction is
not obvious, but the returned cascades show possible structural properties. There are three
digits (O, 4, 8) that are uncovered classes and in both cascades the 8 is mainly allocated to the
second cascade position, corresponding once to the digit 2 and once to 1. If 1 is placed at the

Q) Springer
Detecting Ordinal Subcascades 2599

second position, 0 is mainly classified as 6, whereas in the other cascade (2 at position two),
0 is classified as 5 (the third position of the cascade), which means that in the first case the
first decision region is placed in a way that the samples of class 6 and 0 are on the same side,
whereas in the second case they lay on opposite sides and hence the directions of the first
relation in the feature space for both cascades differ. The two cascades split at the second and
at the last position of the cascade and the purity values for the alternative classes show that
on average half of the samples of the alternative classes are assigned to one intra-cascade
class.

Isolet dataset. Dataset dz corresponds to a spoken representation of letters. Two cascades
of length 10 pass a minimal class-wise sensitivity threshold of 0.9. The uncovered classes
are classified to around 70% on average to the same class and the heatmaps (Supplemen-
tary Information) show that they are not well-distributed as many entries are zero. The two
cascades differ only in their first position (s vs. y). If not part of the cascade the class s is
completely assigned to the second cascade class f, whereas in the case in which y is not part
of the cascade its assignment fades out till the fifth intra-cascade class. The different classes
might be grouped based on the phonetic alphabet. In this case s, f, m and n share the sound
[e], but y does not, which might be one possible interpretation of what is observed. The last
five classes (b, d, g, z, c) of both cascades share the sound [i:]. The further letters (e, p, t, v)
that are pronounced using this sound are also mainly classified as one of these classes. Why
they are not included in the main cascade is not clear from the semantic level. The cascade,
however, reveals that the samples and hence the classes are located in a way that including
one of those classes seem to change the direction of the decision region sequence in a way
that would lead to shorter sequences.

Cancer cell lines. The cancer cell line dataset d3 shows four cascades of length five.
There is only one class, y2: breast cancer, that is not part of any cascade and reveals a low
purity. All four cascades share their first class, y,: leukemia and their center class, y3: ovarian
cancer. If not part of the returned cascade no sample of y6: colon cancer or yg: lung cancer
is Classified as yo: prostate cancer, however the other way round yo: prostate cancer splits
half-half between those classes, which reveals that the decision regions differ depending on
the assumed order and outlines the importance of the fact that the assumed order has to
be appropriately reflected in the feature representation. The correlation within this dataset
can be explained by messenger molecules. Both prostate as well as ovarian are affected by
sex hormones [28]. The fact that leukemia is twice as prevalent in men as in women [2]
does not rule out the influence of sex hormones and may explain why leukemia is closer to
prostate cancer. A similar relationship can also be found between ovarian and kidney cancer.
Here, it is assumed that estrogen has a protective effect on the kidney, while testosterone
damages the kidney [7,48]. Likewise, an effect of sex hormones on the CNS is clearly
confirmed [57]. Here, a decrease in hormone concentration during aging can be attributed to
loss of neuronal functions. Various studies support a neuroprotective role of estrogens on this
neuronal decline [58]. The other cascade connects neurotransmitter-controlled tissues. The
central nerve system is controlled by a diversity of neurotransmitters [42]. Non-adrenergic,
non-cholinergic nerves are known to control the gut as well as the urogenital tract [5]. Since
the lung develops embryonically seen from the foregut, it is not surprising that non-adrenergic,
non-cholinergic nerves are also present [5]. In addition, secreted neurotransmitter such as
glutamate are known to be involved in T-cell leukemia [20].

Leukemia. Both cascades found in dg share exactly one class y5: AML with inv(16)
/t(16,16). In both cascades classes that correspond to lymphoid leukemia (LL) are placed
before this class and afterwards classes that correspond to myeloid leukemia (ML) or syn-
dromes that might develop into a myeloid leukemia, with the exception of the healthy bone

Q) Springer
2600 L. Lausser et al.

Fig.5 Longest cascade of the ds: TCGA (t= 0.9)
5. = .

TCGA dataset ds (extended
confusion matrix). The sensitivity pp

values and the conditional LIHC
prediction rates for the classes

belonging to the selected KIRC
cascades as well as the external

rates of classes that do not belong

to the cascade are shown. The PAAD

    
  

0.05

 

  

    

     
  

dataset specific threshold (t) an

the minimal class-wise sensitivity READ | 0.01

is given in the heading. The

columns give the order of classes CHOL 01 | 0.06] 002
predicted by the cascade (from

left to right). The rows give all

classes of a dataset. They are split COAD

 

  

 

 

 

in two blocks (separated by a red
line): classes covered by the own KICH
cascade (top), other classes
(bottom) KIRP 0.02
© © ey) Q

class-wise sensitivity

0.0 ii 1.0

 

marrow. It can be observed that the AML classes that are not included into one of the cascades
are not classified as an own entity according to the WHO classification system [4]. The sam-
ples of those classes might be considered as not distinct enough to be included. Furthermore, it
was shown that certain subtypes of LL show a higher incidence for the expression of myeloid
antigens and these are pro B-All and early T-ALL [55] which are the LL classes at the found
ML-LL transition. This might lead to the hypothesis that the found subcascades represent a
sequence of similar but still distinct subtypes. The cascade showing a higher average purity
for both, the alternative and the uncovered classes (others), reflects the grouping of ML and
LL also in these classes. The observed characteristic that classes of similar concepts form
subcascades within the context of a larger research topic, reveals that the proposed screening
procedure is able to find orders within such a group but is also at the same time able to relate
these groups using the same consecutive and hence overarching pattern.

TCGA data. For the TCGA dataset ds consisting of eight classes, a cascade of length four
achieved a minimal class-wise sensitivity higher than 90%. For ds all uncovered classes are
assigned with a purity of at least 80%. An order for most tissue derived tumors of endodermal
or mesodermal origin can be found here. Only the data for kidney renal clear cell carcinoma
(KIRC) cannot be assigned to the mesodermal germ layer. Similar findings were made by
Berman [8] in his classification analysis. Here, he found that epithelial tumors with meso-
dermal origin in particular exhibit class independent behavior [8]. In line with this, there are
various differentiation protocols to derive functional pancreatic or liver cells from human
pluripotent stem cells (hPSCs) while few protocols are able to induce effective kidney dif-
ferentiation [32]. Thus, differentiation of renal cells and associated tumors is somehow more
complex in comparison to other tissues. One reason for this might be the complex architecture
of the kidney with all its functional units [32] that require a variety of differentiation factors
not only specific for kidney.

Q) Springer
Detecting Ordinal Subcascades 2601

C.elegans and wound healing data. In contrast to the other datasets, the class labels of
do and d7 are given by consecutive time points and therefore might be seen as hypothesised
ordinal class labels. These timelines were not completely reconstructed in our experiments.
Nevertheless the identified subcascades followed the assumed order.

For C.elegans dg two cascades passed a minimal class-wise sensitivity threshold of 75%
that included all classes despite one. Both orderings correspond to a progression in time and
either the class corresponding to samples taken at minute 66 (ys) or the ones taken at minute
83 (ye) are skipped. In both cases the uncovered classes were assigned to their assumed
ordinal neighbours with a purity over 90%. The high similarity of classes y5 and y6 are also
indicated by a decreased classification performance of the corresponding base classifier (74%
minimal class-wise sensitivity, data not shown) suggesting that in this period the expression
does not change a lot. The detected cascades therefore rather constructs an ordinal sequence
of discriminable events than a reconstruction of the timeline.

Similar observations can be gained for the wound healing dataset d7. Here two cascades
of length four achieved a minimal class-wise sensitivity higher than 80%. They differ in
their second class. In the first cascade y6 is chosen, which corresponds to the samples taken
between 400 and 600 minutes after injury. In the second one, y7 is covered, which comprises
to the samples taken between 600 and 800 minutes after injury. If uncovered, yg receives the
class label of y7 (and vice versa) with a purity of over 80%. Both cascades were not able
to cover three classes that reflect earlier time points (y2, y4, y5). These external classes are
assigned to their assumed ordinal neighbours (within the cascade) with a purity of at least
90%. As the class definitions are again based on prior assumptions they most likely do not
correspond to large changes in the process. This can be also seen in the minimal class-wise
sensitivity of the binary classifiers, which are below 0.8 for time-based neighbouring classes,
except for the first class y; and the control class yg. Based on the classification tendency of
the uncovered classes one might conclude that the expression profile of the first 50 minutes
after injury and the control one is quite distinct from the process in between. Furthermore
the assignment of the uncovered and alternative classes are consistent with the findings that
wound healing consists of overlapping phases [51].

HPA-axis methylation data. Not considering both directions and the classes at the two last
cascade positions the subcascades of dg reduce to two orderings:

(liver <skin~<hippocampus /hypothalamus < pituitary ~adrenal). One part of one
cascade hypothalamus < pituitary ~<adrenal is reported as HPA-axis and known to con-
trol stress reaction. The role of the hippocampus in the control of stress reaction and its
interconnection towards the hypothalamus might lead to the effect that hippocampus and
hypothalamus are not discriminable anymore if a relation reflecting the interplay of stress
response is considered. The neighbourhood between skin and the HPA-axis within the cas-
cade reflects the findings by Agba et al. [1] that methylation patterns in skin are closely
related to the patterns within the HPA-axis.

6 Discussion and Conclusion

Although the task of classification is mainly based on the assumption of pairwise distinct
concepts, itis highly unlikely that no other relationship among the classes exists. Nevertheless,
these relations might be implicit or even unknown. They might be revealed by analysing
suitable data representations.

Q) Springer
2602 L. Lausser et al.

In this work, we utilise ordinal classifier cascades for detecting ordinal relations in each
subset of classes. This multi-class architecture is highly sensitive to the order of classes
as decision regions of early classes overlay decision regions of later ones. Interestingly, this
property causes more rejections than the performance of the corresponding base classifiers. In
our study, almost all classes would have been separable in pairwise classification experiments.

From a combinatorial point of view the number of candidate cascades increases exponen-
tially in the number of classes. The proposed exhaustive screening is therefore out of range
for approaches that require a de novo generation of all classification models. It would require
the training of an ordinal classifier for each subset of classes and each permutation thereof. In
our approach we circumvent this complexity by the extensive use of memoization techniques
and theoretical error bounds. This allowed us to perform exhaustive screens for datasets
with 26 classes, which corresponds to the evaluation of more than 107’ candidate orders.
The runtime of our approach is mainly determined be the training of the required number
of base classifiers which is quadratic in the overall number classes. It therefore brings into
range ordinal classifier cascades based on more sophisticated but also more complex base
classifiers [14,15,25,38,46,59]. To our knowledge, our screening is the first one that applies
memoization techniques to ordinal classification. It might be a blue print for other ordinal
classifiers or fusion architectures.

Due to the transitive relationship between the minimal class-wise sensitivities of a cascade
and its subcascades, the probability of larger ordinal structures decreases. Long ordinal
subcascades must be seen as rare events. As such, we consider the longest cascades that pass
the highest threshold on the minimal class-wise sensitivity as being the most informative
ones. Of course, both length and threshold are clearly dependent on the classification task
and the chosen data representation. There is no guarantee that cascades of suitable length
will be found.

The identified subcascades can be seen as ordered subsets of well separable classes. They
might be considered as a roadmap of axes organising the complete collection of classes.
However, not all classes are connected in this network. The labels of these external classes
cannot be predicted by the ordinal classifier cascades. As most base classifiers do not possess
a rejection option, the samples of the external classes will in general be assigned to cascade
classes. Although the classification of these samples is incorrect, the association to one of the
ordinal classes can reveal properties of the external classes. In our experiments, we observed
a large set of external classes that are assigned to a small set of consecutive classes of an
ordinal classifier cascade. They might be a hint to a too fine granular classification (e.g.
caused by inappropriate sampling), which cannot be separated in feature space. The whole
process of identifying subcascades can also be seen as a selection of a maximal number of
classes that can collectively be discriminated. This in turn can give rise to new hypothesis
about the processes involved like “Is this entity really a distinct new group?”’, or “There could
be some stagnation in the development after a certain time’.

Overall, our experiments show that ordinal substructures of classes can be detected in
feature space and that they corroborate existing findings. These structures might be seen as
hypotheses for ordinal relations and also for discriminative entities among the corresponding
class concepts, which can be investigated in a more detailed analysis. From a theoretical
point of view, the aggregation of ordinal subcascades remains an open research question. It
might be addressed in form of multi-class architectures that directly address partial orders of
classes.

Acknowledgements We thank Konstanze Déhner and Thomas Barth for helpful comments on some of the
found orderings. The research leading to these results has received funding from the German Research Founda-

Q) Springer
Detecting Ordinal Subcascades 2603

tion (DFG, GRK 2254 HEIST and SFB 1074 project Z1), and the Federal Ministry of Education and Research
(BMBF, e:Med, conFirm, id 01ZX1708C) all to HAK.

Funding Open Access funding enabled and organized by Projekt DEAL.

Compliance with Ethical Standards

Conflict of interest The authors declare that they have no conflict of interest.

Open Access This article is licensed under a Creative Commons Attribution 4.0 International License, which
permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give
appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence,
and indicate if changes were made. The images or other third party material in this article are included in the
article’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is
not included in the article’s Creative Commons licence and your intended use is not permitted by statutory
regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder.
To view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0/.

References

Go

11.

12.

13.

14.

15.

16.

17.

. Agba O, Lausser L, Huse K, Bergmeier C, Jahn N, Groth M, Bens M, Sahm A, Gall M, Witte O, Kestler

HA, Schwab M, Platzer M (2017) Tissue-, sex-, and age-specific DNA methylation of rat glucocorticoid
receptor gene promoter and insulin-like growth factor 2 imprinting control region. Physiol Genomics
49(11):690—702

. Allain E, Venzl K, Caron P, Turcotte V, Simonyan D, Gruber M, Le T, Lévesque E, Guillemette C, Vanura

K (2018) Sex-dependent association of circulating sex steroids and pituitary hormones with treatment-free
survival in chronic lymphocytic leukemia patients. Ann Hematol 97(9):1649-1661

. Alpaydin E, Kaynak C (1998) Cascaded classifiers. Kybernetika 34:369-374
. Arber D, Orazi A, Hasserjian R, Thiele J, Borowitz M, Le Beau M, Bloomfield C, Cazzola M, Vardiman

JW (2016) The 2016 revision to the World Health Organization classification of myeloid neoplasms and
acute leukemia. Blood 127(20):2391—2405

. Barnes P (1984) The third nervous system in the lung: physiology and clinical perspectives. Thorax

39(8):561-567

. Baugh LR, Hill AA, Claggett JM, Hill-Harfe K, Wen JC, Slonim DK, Brown EL, Hunter CP (2005) The

homeodomain protein PAL-1 specifies a lineage-specific regulatory network in the C. elegans embryo.
Development 132(8):1843—1854

. Baylis C (2009) Sexual dimorphism in the aging kidney: differences in the nitric oxide system. Nat Rev

Nephrol 5(7):384—396

. Berman J (2004) Tumor classification: molecular analysis meets Aristotle. BMC Cancer 4(1):10
. Bishop C (2006) Pattern recognition and machine learning. Springer, New York
. Breiman L, Friedman JH, Olshen RA, Stone CJ (1984) Classification and regression trees. The Wadsworth

statistics/probability series. Chapman and Hall/CRC, Boca Raton

Cardoso J, Pinto da Costa J (2007) Learning to classify ordinal data: the data replication method. J Mach
Learn Res 8:1393-1429

Crammer K, Singer Y (2001) Pranking with ranking. In: Dietterich T, Becker S, Ghahramani Z (eds)
Proceedings of the 14th international conference on neural information processing systems: natural and
synthetic. Advances in neural information processing systems, vol 14. MIT Press, Cambridge, pp 641-647
Dheeru D, Karra TE (2017) UCI machine learning repository

Ding S, Zhang N, Zhang X, Wu F (2017) Twin support vector machine: theory, algorithm and applications.
Neural Comput Appl 28(11):3119-3130

Ding S, Zhao X, Zhang J, Zhang X, Xue Y (2019) A review on multi-class TWSVM. Artif Intell Rev
52(2):775-801

Edla D, Jana P (2012) A prototype-based modified DBSCAN for gene clustering. Procedia Technol
6:485—492

Fanty M, Cole R (1991) Spoken letter recognition. In: Lippmann RP, Moody JE, Touretzky DS (eds)
Advances in neural information processing systems 3. Morgan-Kaufmann, New York, pp 220-226

Q) Springer
2604 L. Lausser et al.

18.

19.

20.

21.

22.
23.

24.

25.

26.

27.

28.
29.

30.
31.

32.

33.

34.

35.

36.

37.

38.

39.

40.

4].

42.

43.

Frank E, Hall M (2001) A simple approach to ordinal classification. In: Raedt LD, Flach P (eds) Proceed-
ings of the machine learning: ECML 2001—12th European conference on machine learning, Freiburg,
Germany, September 5-7, 2001, lecture notes in artificial intelligence, vol 2167. Springer, Berlin, pp
145-156

Frank E, Kramer S (2004) Ensembles of nested dichotomies for multi-class problems. In: Proceedings of
the 21st international conference of machine learning (ICML-2004). ACM Press, London, pp 305-312
Ganor Y, Levite M (2014) The neurotransmitter glutamate and human T cells: glutamate receptors and
glutamate-induced direct and potent effects on normal human T cells, cancerous human leukemia and
lymphoma T cells, and autoimmune human T cells. J Neural Transm 121(8):983—1006

Guyon I, Elisseeff A (2003) An introduction to variable and feature selection. J Mach Learn Res 3:1157-
1182

Hastie T, Tibshirani R, Friedman JH (2001) The elements of statistical learning. Springer, New York
Hiihn J, Hiillermeier E (2009) Is an ordinal class structure useful in classifier learning? J Data Min Model
Manag 1(1):45-67

Japkowicz N, Shah M (2011) Evaluating learning algorithms: a classification perspective. Cambridge
University Press, New York

Jayadeva A, Khemchandani R, Chandra S (2007) Twin support vector machines for pattern classification.
IEEE Trans Pattern Anal Mach Intell 29(5):905-910

Jiang Z, Sun G, Gu Q, Chen D (2014) An ordinal multi-class classification method for readability assess-
ment of Chinese documents. In: Buchmann R, Kifor CV, Yu J (eds) Knowledge science, engineering and
management. Springer, Cham, pp 61—72

Kestler HA, Lausser L, Lindner W, Palm G (2011) On the fusion of threshold classifiers for categorization
and dimensionality reduction. Comput Stat 26(2):321-—340

Key T (1995) Hormones and cancer in humans. Mutat Res Fundam Mol Mech Mutagen 333(1):59-67
Kohlmann A, Kipps T, Rassenti L, Downing J, Shurtleff S, Mills K, Gilkes A, Hofmann WK, Basso G,
Dell’ Orto M, Foa R, Chiaretti S$, De Vos J, Rauhut S, Papenhausen P, Hernandez J, Lumbreras E, Yeoh
A, Koay E, Li R, Wm Liu, Williams P, Wieczorek L, Haferlach T (2008) An international standardization
programme towards the application of gene expression profiling in routine leukaemia diagnostics: the
microatray innovations in LEukemia study prephase. Br J Haematol 142(5):802—807

Kohonen T (1995) Self-organizing maps, vol I. Springer, Berlin

Kotsiantis S, Pintelas P (2004) A cost sensitive technique for ordinal classification problems. In: Vouros
G, Panayiotopoulos T (eds) Proceedings of the methods and applications of artificial intelligence: third
hellenic conference on AI (SETN 2004), Samos, Greece, May 5-8, 2004. Springer, Berlin, pp 220-229
Lam A, Freedman B, Morizane R, Lerou P, Valerius M, Bonventre J (2014) Rapid and efficient differen-
tiation of human pluripotent stem cells into intermediate mesoderm that forms tubules expressing kidney
proximal tubular markers. J Am Soc Nephrol 25(6):1211—1225

Lattke R, Lausser L, Miissel C, Kestler HA (2015) Detecting ordinal class structures. In: Schwenker
F, Roli F, Kittler J (eds) Proceedings of the multiple classifier systems—12th international workshop
(MCS 2015), Giinzburg, Germany, June 29-July 1, 2015. Image processing, computer vision, pattern
recognition, and graphics, vol 9132. Springer, Cham, pp 100-111

Lausser L, Miissel C, Kestler HA (2013) Measuring and visualizing the stability of biomarker selection
techniques. Comput Stat 28(1):51-65

Lausser L, Schmid F, Platzer M, Sillanpéa MJ, Kestler HA (2016) Semantic multi-classifier systems for
the analysis of gene expression profiles. Arch Data Sci Ser A 1(1):157—176

Lausser L, Szekely R, Schirra LR, Kestler HA (2017) The influence of multi-class feature selection on
the prediction of diagnostic phenotypes. Neural Process Lett 48(2):863-880

Lausser L, Schafer LM, Schirra LR, Szekely R, Schmid F, Kestler HA (2019) Assessing phenotype order
in molecular data. Sci Rep 9(1):11746

Lausser L, Szekely R, Klimmek A, Schmid F, Kestler HA (2020) Constraining classifiers in molecular
analysis: invariance and robustness. J R Soc Interface 17(163):20190612

Lin HT, Li L (2012) Reduction from cost-sensitive ordinal ranking to weighted binary classification.
Neural Comput 24(5):1329-1367

Lorena AC, de Carvalho ACPLF, Gama JMP (2009) A review on the combination of binary classifiers in
multiclass problems. Artif Intell Rev 30:19-—37

Miissel C, Lausser L, Maucher M, Kestler HA (2012) Multi-objective parameter selection for classifiers.
J Stat Soft 46(5):1-27

Nicoll R, Malenka R, Kauer J (1990) Functional comparison of neurotransmitter receptor subtypes in
mammalian central nervous system. Physiol Rev 70(2):513-565

Pfister T, Reinhold W, Agama K, Gupta S, Khin S, Kinders R, Parchment R, Tomaszewski J, Doroshow
J, Pommier Y (2009) Topoisomerase I levels in the NCI-60 cancer cell line panel determined by validated

Q) Springer
Detecting Ordinal Subcascades 2605

44,

45.
46.

47.

57.
58.

59.

ELISA and microarray analysis and correlation with indenoisoquinoline sensitivity. Mol Cancer Therap
8(7):1878-1884

Platt JC, Shawe-Taylor J, Cristianini N (1999) Large margin DAG’s for multiclass classification. In: Solla
SA, Leen TK, Miiller K (eds) Proceedings of the 12th international conference on neural information pro-
cessing systems: mini-symposium on causality in time series, advances in neural information processing
systems, vol 12. MIT Press, Cambridge, pp 547-553

Rivest RL (1987) Learning decision lists. Mach Learn 2(3):229-246

Schwenker F, Kestler HA, Palm G (2001) Three learning phases for radial-basis-function networks. Neural
Netw 14(4—5):439-458

Taudien S, Lausser L, Giamarellos-Bourboulis EJ, Sponholz C,FS, Felder M, Schirra LR, Schmid F,
Gogos C,SG, Petersen BS, Franke A, Lieb W, Huse K, Zipfel PF, Kurzai O, Moepps B, Gierschik P,
Bauer M, Scherag A, Kestler HA, Platzer M (2016) Genetic factors of the disease course after sepsis: rare
deleterious variants are predictive. EBioMedicine 12:227—238

. Valdivielso J, Jacobs-Cacha C, Soler MJ (2019) Sex hormones and their influence on chronic kidney

disease. Curr Opin Nephrol Hypertens 28(1):1—9

. Vapnik VN (1998) Statistical learning theory. Wiley, New York

Waegeman W, Baets BD, Boullart L (2008) Roc analysis in ordinal regression learning. Pattern Recognit
Lett 29(1):1-9

. Wang PH, Huang BS, Horng HC, Yeh CC, Chen YJ (2018) Wound healing. Chin Med Assoc 81(2):94—-101

Webb AR (2002) Statistical pattern recognition, 2nd edn. Wiley, Chichester

. Wehrens R, Buydens L (2007) Self- and super-organizing maps in R: the Kohonen package. J Stat Softw

21(5):1-19
Wehrens R, Kruisselbrink J (2018) Flexible self-organizing maps in Kohonen 3.0. J Stat Softw 87(7):1-18

. Wiernik P, Dutcher J, Gertz M (2018) Neoplastic diseases of the blood. Springer, Berlin

Xiao W, Mindrinos M, Seok J, Cuschieri J, Cuenca A, Gao H, Hayden D, Hennessy L, Moore E, Minei
JP, Bankey P, Johnson J, Sperry J, Nathens A, Billiar T, West M, Brownstein B, Mason P, Baker H,
Finnerty C, Jeschke M, Lopez MC, Klein M, Gamelli R, Gibran N, Arnoldo B, Xu W, Zhang Y, Calvano
S, McDonald-Smith G, Schoenfeld D, Storey J, Cobb J, Warren H, Moldawer L, Herndon D, Lowry
S, Maier R, Davis R, Tompkins R (2011) A genomic storm in critically injured humans. J Exp Med
208(13):2581—2590

Young W, Goy R, Phoenix C (1964) Hormones and sexual behavior. Science 143(3603):212—218
Zarate S, Stevnsner T, Gredilla R (2017) Role of estrogen and other sex hormones in brain aging: neuro-
protection and DNA repair. Front Aging Neurosci 9:430

Zhang N, Ding S, Zhang J, Xue Y (2018) An overview on restricted Boltzmann machines. Neurocomputing
275:1186—-1199

Publisher’s Note Springer Nature remains neutral with regard to jurisdictional claims in published maps and
institutional affiliations.

Q) Springer
