Wei et al. EURASIP Journal on Advances in Signal Processing
https://doi.org/10.1186/s13634-020-00676-5

(2020) 2020:20

EURASIP Journal on Advances
in Signal Processing

RESEARCH Oy else =e

Adaptive dictionary learning based on local
configuration pattern for face recognition

Check for
updates

 

Dongmei Wei', Tao Chen', Shuwei Li', Dongmei Jiang’, Yuefeng Zhao! and Tianping Li!

Abstract

Sparse representation based on classification and collaborative representation based classification with regularized
least square has been successfully used in face recognition. The over-completed dictionary is crucial for the
approaches based on sparse representation or collaborative representation because it directly determines
recognition accuracy and recognition time. In this paper, we proposed an algorithm of adaptive dictionary learning
according to the inputting testing image. First, nearest neighbors of the testing image are labeled in local
configuration pattern (LCP) subspace employing statistical similarity and configuration similarity defined in this paper.
Then the face images labeled as nearest neighbors are used as atoms to build the adaptive representation dictionary,
which means all atoms of this dictionary are nearest neighbors and they are more similar to the testing image in
structure. Finally, the testing image is collaboratively represented and classified class by class with this proposed
adaptive over-completed compact dictionary. Nearest neighbors are labeled by local binary pattern and microscopic
feature in the very low dimension LCP subspace, so the labeling is very fast. The number of nearest neighbors is
changeable for the different testing samples and is much less than that of all training samples generally, which
significantly reduces the computational cost. In addition, atoms of this proposed dictionary are these high dimension
face image vectors but not lower dimension LCP feature vectors, which ensures not only that the information
included in face image is not lost but also that the atoms are more similar to the testing image in structure, which
greatly increases the recognition accuracy. We also use the Fisher ratio to assess the robustness of this proposed
dictionary. The extensive experiments on representative face databases with variations of lighting, expression, pose,
and occlusion demonstrate that the proposed approach is superior both in recognition time and in accuracy.

Keywords: Collaborative representation classification, Nearest neighbors, Local configuration pattern (LCP), Statistical
similarity, Configuration similarity

1 Introduction

As a biological feature, the human face has been paid
more attention because it can be easily captured with a
common camera even without cooperation of the sub-
ject. Yet the performance of face recognition is affected
by the expression, illumination, occlusion, pose, age
change, and so on. There are still some challenges in the
field of unrestricted face recognition.

 

* Correspondence: yuefengzhao@126.com; Sdsdltp@163.com

"Shandong Provincial Engineering and Technical Center of Light
Manipulations & Shandong Provincial Key Laboratory of Optics and Photonic
Device, School of Physics and Electronics, Shandong Normal University, Jinan
250014, China

Full list of author information is available at the end of the article

o) Springer Open

 

Facial images are very high dimensional, which is bad
for classification. So dimension reduction is carried out
before classification. Principle component analysis (PCA)
[1-4] has become the classic reducing dimension ap-
proach and has been used widely in image processing
and pattern recognition fields. All training images make
up covariance matrix, and these eigenvectors corre-
sponding to the bigger eigenvalues of covariance matrix
span the linear feature subspace. Through projecting
high-dimensional original face images onto the low di-
mensional linear feature subspace, PCA performs the di-
mension reduction and preserves the global structure of
an image.

© The Author(s). 2020 Open Access This article is licensed under a Creative Commons Attribution 4.0 International License,
which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give
appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if

changes were made. The images or other third party material in this article are included in the article's Creative Commons
licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons
licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain
permission directly from the copyright holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0/.
Wei et al. EURASIP Journal on Advances in Signal Processing

Designed as a texture descriptor originally, local binary
patterns (LBP) [5] is a simple and efficient algorithm, it
can capture the local structural features that are very im-
portant for human texture perception. Researches show
that LBP is discriminative and robust to illumination, ex-
pression, pose, misalignment, and so on. LBP has been a
popular feature extraction approach and has been used
successfully in face recognition [6—8]. Up to now, some
improved approaches based on LBP have been pre-
sented, such as complete LBP (CLBP) [9], local Gabor
LBP [10], multi-scale LBP [11], and so on. Because the
intensity of the central pixel is independent to its LBP
value, the information embodying the relationship be-
tween pixels in the same neighborhood is lost. Guo et al.
[12] proposed the local configuration pattern (LCP) in-
cluding both local structural and microscopic features.
The local structural features are represented by the pat-
tern occurrence histograms, just as LBP, and the micro-
scopic features are described by optimal model
parameters. The microscopic configuration features re-
veal the pixel-wise interaction relationships. It has been
proved LCP is an excellent feature descriptor. In this
paper, we use LCP to measure the similarities between
face images and finally to find neighbors of testing
image.

Many researches confirmed that sparse representation
and collaborative representation are good at image pro-
cessing, such as image reconstruction, image representa-
tion, and image classification. Li et al proposed an
effective approach called patch matching-based multi-
temporal group sparse representation to restore the
missing information that should be contained in remote
sensing images [13] (Patch Matching-Based Multitem-
poral Group Sparse Representation for the Missing In-
formation Reconstruction of Remote-Sensing Images).
Yang et al. [14] regarded face recognition as a globally
sparse representation problem and proposed the face
recognition (FR) approach known sparse representation
based on classification (SRC), in which the over-
complete dictionary is formed by training face images.
Subsequently, To improve the recognition accuracy with
occlusion, Wright et al. [15] subsequently introduced an
identity matrix to code the outlier pixels that were oc-
cluded. Yang et al. [16] viewed the sparse coding as a
sparsity constrained robust regression problem and pro-
posed the robust sparse coding method. It is more ro-
bust to detect outliers than SRC. In 2010, Yang et al.
[17] introduced Gabor features into SRC; they projected
firstly the high-dimension facial images into the lower
dimension Gabor-feature space and then used SRC to
classify. This approach greatly decreased the size of the
occlusion dictionary compare with that of SRC. As a re-
sult, recognition-time is reduced. Ou et al. proposed an
approach of face recognition with occlusion named

(2020) 2020:20

Page 2 of 12

structured sparse representation based classification
[18]. In which, occlusion dictionary is not an identity
matrix, but is learned from data and is smaller than that
of SRC. In addition, the occlusion dictionary is inde-
pendent of the training sample as possible, so the occlu-
sion is sparsely represented by the learned occlusion
dictionary and can be separated from the occluded
image. The testing image is classified by the recovered
non-occluded image. Ou also provided another occlu-
sion dictionary learning algorithm named discriminative
nonnegative dictionary learning, where the occlusions
were estimated adaptively by the reconstruction errors
and weights for different pixels were learned during it-
erative processing [19]

The resolution method of sparse representation vector
(or sparse solution) is another crucial issue for sparse rep-
resentation based on classification (SRC), which influences
the recognition accuracy and recognition time. The first
researchers, such as the above mentioned, hold the view
that “sparsity” of the sparse representation vector is the
most crucial for SRC and paid more attention to the
“sparsity” of sparse solution. Because /)_norm
minimization is NP-hard, they used /;_norm minimization
to replace /)_norm minimization as the optimal solution
(the sparsest solution). But /;_norm minimization is time-
consuming, which is bad for recognition especially in the
case of real-time identification. Ma et al [20] proposed a
discriminative low-rank dictionary learning, in which the
over-completed discriminative dictionary is composed of
series of sub-dictionaries. Atoms of each sub-dictionary
are training images from the same category, so they are
linearly correlated and all sub-dictionaries are low-rank
with a compact form. Zhang et al. [21] also regarded the
feature coding problem as the low-rank matrix learning
problem and researched local structure information
among features on the image-level. Using the similarities
among local features embraced in the same spatial neigh-
borhood, an exacting joint representation of these local
features w.r.t. the codebook was founded. Zhang et al [22]
analyzed the mechanism of SRC and found that “collabor-
ation representation” among categories is the crucial fac-
tor for SRC. He relaxed the demand on “sparsity” and
used /,-norm to replace /,;-norm as the sparse constraint
condition and proposed the algorithm known collabora-
tive representation based on classification with regularized
least square (CRC_RLS). Gou et al investigated deeply
approaches based on _ collaborative representation-
classification and proposed several novel approaches of
classification based on collaborative representation
[23-26]. He proposed a two-phase probabilistic collab-
orative representation-based classification [25], in
which the nearest representative samples are chosen
first and then each testing sample is represented and
classified by those chosen nearest samples. In Ref.
Wei et al. EURASIP Journal on Advances in Signal Processing

[26], the locality of data is employed to constrain the
collaborative representation in order to _ represent
faithfully testing images with the nearest samples. In
this paper, we proposed a new and simple approach
based on sparse representation and LCP features. We
pay our attention to the over-completed compact dic-
tionary. Atoms of this proposed dictionary are all
nearest neighbors in LCP feature subspace, so struc-
tures of atoms are more similar to that of testing im-
ages and the atoms’ number is greatly decreased
compared with the training images, which will im-
prove the recognition accuracy and reduce the recog-
nition time.

This paper is organized as follows: related theories
about SRC and LCP were described in Section 2. The
proposed face recognition approach using a sparse
representation-based adaptive nearest dictionary was
described in Section 3. Experimental results were pro-
vided in Section 4 and conclusions were illustrated in
Section 5.

2 Related

2.1 Sparse representation based on classification

Assume there are M training face images from Q sub-

jects, each subject has m, images, M = S Mq. Let Vz,
q=1

;€ #**' denote the d-dimension vector stretched by the

ith image from theqgth class (subject) and yrepresent the

testing image vector. Let matrix Xq = [vg1,°°°,Vqm,|

whose column vectors are the training images from the

gth class, X = [Xq, °+:,X,, °°, XQ] € KR7*™ is the set of all

training images.

Yang et al. [14] proved that face recognition can be
regarded as sparse representation based on classification
(SRC) if there were enough training face images (the
number of training face images M should be greater
than the dimension of image, i., d<M). In this case,
the testing imagey can be as the sparse linear combin-
ation of all training images, i.e.,

Histogram LCP
equalization feature

Testing
images

(2020) 2020:20

Page 3 of 12

y=Xp (1)

T Mxil :
where Bp a B11+B1,2, Pa nBorBomel ° 1s the

representation coefficient vector.

Sparse representation classification firstly encodes the
testing image by all training images according to Eq. (1)
and then classifies class-by-class. Specifically, if the
testing image y comes from the qth subject (class),
entries of its $6 should be zero except for those

associated with  thegth p=
T ;

[0, 50,8, 45Bg2; Ba ings, ---,O]° (T is transpose op-

eration). In fact, any entry of Bcan be very small non-

zero, so the identity of y is determined by the residual

class ideally, ive.

between yt and its reconstruction by each class. Let B,

T . -
= |B, 1+Bq2+°*'»Bqm,] be the representation coefficient

associated with the gth class. The reconstruction of the
test image by the qth class training samples denotes
byVo Vq=XqBo the residual rz = lly — ygllo = lly — XBelle.
The testing image is classified to the qth class if r, is the
minimum residual, ice.,

identity(y) = arg minr, (2)
q

How to get the representation coefficient vector from
Eq. (1) is crucial for sparse representation. Sparse repre-
sentation requires the dictionary to satisfyd <M, so Eq.
(1) has more than one solution. The sparest solution is
generally considered as the optimal solution for classifi-

cation. The optimal solution expressed B is the solution
of Eq. (3), while it is a NP-hard problem.

B= arg min |llo st. XB=y (3)

Theories of sparse representation and compressed
sensing reveal that /)>-norm minimization solution and
/;-norm minimization solution were nearly equivalent
when the solution is sparse enough. So Yang [14]

LCP
feature

Histogram
equalization

Training
images

Label adaptively the nearer neighboring

training sample according to testing sample

Building adaptive dictionary
Collaborative representation and classification
Identity of testing image

 

Fig. 1 Flowchart of this proposed algorithm (CRC_NLCP)
Wei et al. EURASIP Journal on Advances in Signal Processing

(2020) 2020:20

Page 4 of 12

 

=
—
&
£
”
Q
4
0
“
O
o
Oo
Cc
&
a
°
a
ar
a
=
O

100

* Chi-BRD-Distance
* Chi-BRD-Similarity

150

Image Index

Fig. 2 Chi-BRD-distances and chi-BRD-similarities

employed /,-norm to replace /p-norm and estimated the
optimal representation vector by Eq. (4)

B= arg min |iBlh st. ||XB-y|l.<e (4)

where edenotes the error term including noisy and
model error, and this is the well-known sparse represen-
tation based on classification (SRC).

Zhang employed /)-norm as the sparse constraint
condition to solve representation vector using regular-
ized least square and proposed CRC_RLS algorithm
[22], in which the representation vector can be ob-
tained by Eq. (5)

B= arg min { |ly-XBll + Al|Bll> } (5)

With regularized least squares method, the unique so-
lution of Eq. (5) can be easily educed as B=

(X?X + MI) 'XTy, where J is a regularization parameter
given experientially.

AssumeP = (X'X + AlI| )~'X’, it is clear that P is inde-
pendent of y, so P can be seen as a projection matrix de-
cided only by training images. Just projecting y onto P,
B can be solved easily, B=Py.

According to sparse representation theory, the over-
completed dictionary should be satisfied that the num-
ber of features is greater than that of an atom. However,
face recognition is a typical small-size-sample task and
matrix X made directly by face images could not be an
over-completed dictionary. Generally, dimension reduc-
tion was performed before a sparse representation.

2.2 Local configuration pattern

In essence, LBP feature is the histogram build by LBP
value of all pixels in an image. LBP of the given pixel is
defined as follows [5]:

 

P-1
S- 1, a=0

LBPp = u(g)-&) 2h ula) = {0 a<0O
p=0

(6)

where R is the radius of the circle neighborhood cen-
tered at the given pixel, P is the number of neighboring
samples spaced at regular intervals on this circle, g-is
gray of the center pixel, and g, (p= 0,1, ---P- 1) denotes
gray of its neighboring.

Regard the LBP as a circular binary string with P bits,
the number of two bitwise transitions 0 and 1 is defined
as U. If U<2, then the LBP are defined as a uniform
pattern, notated LBP ie . Ojala et al. [5] defined the

rotation-invariant uniform patterns LBP3’?:

P-1
ppt? = D u(g,-g.), U(LBPp.,) <2 (7

P+1, otherwise

LetN;, denotes the occurrence of the k-pattern in-

wih ;
cluded in LBP,Nx = >> 5) O(LBP He (i, j),k), (kK =0,1,
i=1 j=1
--,2?), where 6(x,y) is the Dirac function. Histogram H
expresses the LBP feature vector of the image.

H = INi, Nx, +, Ns] (8)

where S is the maximum value of LBP pattern.

Although the LBP feature vector can capture the stat-
istical feature of the image and is robust for illumination,
it neglects the relationship between neighboring pixels,
which leads to wrong classification results when images
have the same LBP feature but the different gray varia-
tions between the center pixel and its neighboring pixels.
Guo et.al [12]. introduced the microscopic feature (MiC)
information into LBP and proposed a local configuration
pattern (LCP).
Wei et al. EURASIP Journal on Advances in Signal Processing

Table 1 The description on both face databases

 

 

Database name AR ORL
Number of class 100 40
Number of image per subject 14 10

Total number of image 1400 400
Number of training image per class 7 6

Total number of training-image 700 240
Number of testing image per class 7 4

Total number of testing image 700 160

Size of image 60 x 43 112 x 92

 

Let A = (do, °::,;4p_1) presents a parameter vector and

g = (go, °*', Zp_1)presents a neighboring vector of center
P-1

pixel. The central pixel can be reconstructed by 2. 8p
p=

P-1
the reconstruction error | g,- )/ apg, |will be minimum
=0

when parameter vector A reaches optimum.

Assume there are N; pixels whose patterns are all
equal to L, let cy(i = 1,-:-, Nz) denote the gray value of
the ith center pixel belonging to L pattern, these N; gray
values made up the matrix C,=(cy,cj, --*,cy,,). Vector

SF = (Si Si1 sZip-1) consists of the gray values of
L
$1
. . . L . __ see __
neighboring pixels of cy , matrix G,= =
L
SN,
L bee L
810: ’ §1 p-1 L L
; ,Ar = (a, °*', 45_,) represents the
§N,,0° "5 SN P-1

optimal parameters corresponding to the L pattern. C;,
A,, and G, satisfy Eq. (9)

C, = ALG, (9)
With overwhelming probability N;> >P, hence the

matrix G; is over-determined and the optimal parameter
vector A; can be computed by the least squares.

(2020) 2020:20

Page 5 of 12

A, =C,G}(G7G,)~ (10)
A small probability event (N;,<P)is regarded as
unreliable and its model parameters are set to zero. The

P-1
Fourier transform of A, is@,(k), 6,(k) = >> ale Pnko|P
p=0

(k = 0,:::,P-1). MiC features consist of the amplitude
of the Fourier transform (|@,(k)|), denoted by ®;.

@, = (16,(0)|,--, 162(P-1)) (11)

Appending N; to ®,, LCP feature corresponding to L
pattern can be obtained by the Eq. (12). The LCP feature
vector of an image can be obtained by concatenating all
S LCP features, it is denoted by Fycp.

F,cp=[1, Ni, -, Bs, Ns] (12)

3 Methods

According to sparse representation theories, the more
similar the atom is to the testing sample, the sparser the
representation vector is, and the greater recognition ac-
curacy of the dictionary is.

Let 4 =m,/Mdescribe the sparsity of the representa-
tion vector. If all classes have the same number of
training samples, theny=1/Q, else min,(m,)/M<n<
max,(m,)/M, where min,(m,) and max,(m,) are the
minimum and the maximum number of training sam-
ples for each class. The representation vector is
sparser with the smallery. Clearly, we want to make
ysmall enough. There are two ways to make y
smaller. One is to augment categories and the other
is to reduce the sample size of each class. For the
former, it is difficult to ask more enough volunteers
to take face picture. So we use the second way to in-
crease the sparsity. A testing image may be not repre-
sented sufficiently if we discard randomly some
training images, which are bad for the recognition ac-
curacy. In this paper, we recommend to utilize the
nearest neighboring images of the testing image as
atoms to build a dictionary so that the testing image
can be represented sparsely and faithfully. SRC then

 

 

(a) Equalized image (b) LBPy\” spectrum

20 30 40 50 60
index of feature vector
(c) LCP feature vector

 

Fig. 3 One face image and its LCP feature vector. a Equalized image. b LBP SY spectrum. ¢ LCP feature vector
 

 

Wei et al. EURASIP Journal on Advances in Signal Processing (2020) 2020:20 Page 6 of 12
250 T T T T
? * a * * * a *
# ‘ a aes ee eR emg atin a
200P Te a yk BAe OT LO titan, |

150-

woop.

Number of Nearer Neighbor

ao
Oo
T

 

o ° * ”° e © gee

ooe .
Forman * afte, oe
° =. %e .

e

~ .

 

* Criterion-A
* Criterion-B

 

 

 

 

 

100

150 200 250

Index of Image

Fig. 4 Scatter diagram of nearest neighbors of training images from ORL

 

are performed on this proposed dictionary. We call
this proposed approach for FR as “Collaborative rep-
resentation classification based adaptive nearer-
neighbor-dictionary” (CRC_NLCP). Figure 1 shows
the flowchart of this proposed algorithm.

The proposed algorithm includes two stages, the
first is to learn adaptively the over-completed diction-
ary, and the second stage is the SRC process. Diction-
ary learning includes rough similarity measurement,
nearest neighbor criterion, and dictionary atom
selection.

3.1 Similarity measurement

As the aforementioned, the LCP feature includes the
statistical feature (LBP feature) described by the histo-
gram and the microscopic configuration feature de-
scribed by the parameter vector (MiC feature). So we
measure the similarity among images in these two fea-
ture subspaces respectively.

3.1.1 Statistical similarity
In essence, the LBP feature vector is a frequency histo-
gram, so the chi-square distance is a good measurement

to estimate the similarity between histograms. Hu et.al
[27] proved that the distance-based chi-square is not
robust for partial occlusion and they may lose the co-
occurrence relations that benefit to improve the recogni-
tion accuracy. Hence, he proposed a bin ratio-based
distance (BRD).
ino H’ A A A ry? ss B B
Assuming = [ut uy, uojand H = [uy, ug,

us| are respectively two unit histogram vectors corre-

oe
)

sponding the image A and image B, BRD of these two
images are defined as Eq. (13):

Q Q B_A__B_A\ 2
dyep (HA ) = Ula (13)
i=l j=l i
where the numerator term (up uuu; ) embodies the

ratio-relations and the differences of bins included in the
same histogram, and the denominator is the standard
term. He also proved the combination of BRD and chi-
square distance, notated as dy*ppp and defined by Eq.
(14), is superior to both them for classification.

 

—
°
Q
<=
2
oO
Zz
ro
oO
pa
O
oO
Zz
we
°
ro
oO
a
iS
a
Zz

* Criterion-B
+ Criterion-C
* Criterion-A

*
1K x
* ORR x
aK’ * *
* xg * Poe
* * y *

Index of Image

Fig. 5 Scatter diagram of nearest neighbors of training images from AR

 
Wei et al. EURASIP Journal on Advances in Signal Processing

(2020) 2020:20

Page 7 of 12

 

 

-*CDF by Criterion-A
—-CDF by Criterion-B
— PDF by Criterion-A
— PDF by Criterion-B

°
©
T

 

 

a
T

 

BR
T

2
a
&
o

w

3
a

a
£
5

Zz

 

°
1)
T

EA=112.44
VA=12.78

 

=210.76 |
VB=10.55

Lou L y aM
80 100 120 140 160 180 200 220 240
Number of Neighbor

(a) ORL database

 

 

 

 

 

 

 

 

 

Number of Sample

Number of Neighbor

(b) AR database

Fig. 6 Cumulative distribution function (CDF) and probability density function (PDF)of the nearer-neighbor-number. a ORL database. b

AR database

 

~A ~B\X. ~A ~B\X
dmsubsup (Ht A’) ™ = dyy (A °
2
lit +a’ uu
3
at (ul +u?)
(14)
~A ~BX Q (uA—u8)?
where d(H ,H ) =2)/~5-+ is a chi-square dis-
i=.

tance of (HO ; Hf). For the unit length histograms, values

of dmsubsup’-sxare all very small, for example, the max-
imum value is shown in Fig. 2 (red rhomb) is 0.025, and

: 2 :
differences dmsubsup*-2x> are even smaller, which means

dmsubsup*-sxv has less discrimination feature and is not
fit to measure the statistical similarity. We defined a new
statistical similarity measurement named “chi-square-
BRD-similarity” and notated as € to estimate the similar-
ity of images in the LBP feature subspace.

€(A, B) = - log dmsubsup (A, a’) (15)

Clearly, Chi-square-BRD-similarity (€) is the minus
logarithm of dmsubsup*-»x , it expands nonlinearly the
value range of dmsubsup*-» . Figure 2 shows the chi-
BRD-distance (dmsubsup*-»» ) indicated by red rhombs

 

and Chi-square-BRD-similarity (€) denoted by blue stars
between one image and the others from the ORL face

database. Clearly, € is more discriminative than d

msubsup\-», The larger €, the more similar two images
are. Chi-BRD-distance between the image and itself is
zeros while the chi-square-BRD-similarity is infinity.

3.1.2 Configuration similarity

In the MiC feature subspace, we use Euclidean distance
to measure the configuration similarity between two
imagesx ,andx, notatingp(%1, x2).

p(*1;%2) = ||P(x1)-O(x2) |, (16)

Clearly, two images are more similar if their Euclidean
distance is smaller.

3.2 Neighboring images selection criteria
According to Eq.(7)~(11), we can obtain unit histogram

H,; and Mic feature®,; from training imagev,, ; and

q@ i
H, (unit histogram of testing image) and ®,(MiC feature
of testing image). Let €, ; andp, describe respectively
the statistical similarity and configuration similarity be-
tween testing image y andv, ,€,; = €(Hy,H,;) can be
obtained by Eq. (13) ~(15); pg, ;=I1®,- ®,, jllz can be
computed according to Eq. (16).

 

a om

>

5
2
<=
ho)
2
eo
S
§
=
3
za

150

Index of image

Fig. 7 The number of nearest neighbors in each category

 
Wei et al. EURASIP Journal on Advances in Signal Processing

(2020) 2020:20

Page 8 of 12

 

=
a
Oo

=
oO
Oo

2
=
©
oe
L
©
x=
a
it
.
3
©
2
©
>

30 4
Index of Principal Component
(a) Fisher-ratio along the different component

Sum-value of Fisher Ratio

No
Oo
Oo
oO

=
oa
Oo
oO

=
Oo
Oo
oO

oa
So
Oo

10 20 30 40 50 6 70
Index of Principal Component

(b) Cumulative sum of fisher-ratio

Fig. 8 Fish-ratios of dictionaries for one testing image. a Fisher's ratio along the different components. b Cumulative sum of fisher-ratio

_ "q
Define €, = wn, >» §4i as “class-average-statistical simi-
i=1

larity.” If ¢,; > Ey, then the training imagev,, jis labeled as
statistical neighboring. Similarly, define ‘class-average-

Ng
configuration similarity’ as p, = a Pg ;: Vq, iS labeled
Vj=1

as configuration neighboring if p, ;</,,.

There are two criteria to label the nearest neighbor-
ing samples. One, named criterion-A, is that the nearest
neighboring image should be labeled as both statistical
neighboring and configuration neighboring. The other,
named criterion-B, is that the nearest neighboring
image was labeled as either statistical neighboring or
configuration neighboring. Whatever criterion is used,
there must be enough training samples in each class to
be labeled as the nearest neighbor. If not, the comple-
mentary criterion, named criterion-C, must be per-
formed. In this paper, the complementary criterion
(criterion-C) is to sort respectively the training images
in LBP and MiC subspace, and then keep labeling the
closer ones in both two subspaces until the quantity of
the nearest neighbor in each class reaches the require-
ment. Generally, the number of the nearest neighbor in
each class should be between 2 and half of the number
of training images in each class. The algorithm of
labeling the nearest neighbor is summarized as the
algorithm 1.

Algorithm 1: Nearest Neighbor Labeling

Step1 Project all face image into LCP subspace and extract the LBP and Mic features, H. ai? H y? ® 4, and ® yo

Step2 Compute the statistical similarity ¢,, and the configuration similarity p,, between y and all training
image v,,v,,, Then compute the class-average-statistical similarity & and class-average-configuration
similarity /, ;

Step3 Label nearest neighboring images using different criterion class by class:

A) The nearest neighboring image satisfies both ¢, ; 2 E and p,, SP, ;
B) The nearest neighboring image satisfies either ¢ , > é or Py; <P, ;

C) Keep labeling the nearest neighbor image in LBP and MiC until the number of nearest neighbors is
between 2 and m,/2.

3.3 Building an adaptive dictionary

For this proposed approach, it is crucial to fast find and
label these training samples that are more similar to the
inputting testing image. So we compute the similarity in
the lower-dimension LCP feature subspace. However,

 

compared to the face image, LCP feature vector loses
much information, which are bad for SRC. We employ
the original face image as an atom to make up the dic-
tionary, which means all atoms of the dictionary are
these face-image-vectors labeled in the LCP subspace,
but not LCP-feature-vectors. That is to say, sparse repre-
sentation and classification are performed in face image
space but not in feature subspace. The experimental re-
sults shown in the later section also verify that SRC
based on image vector is better than based on the LCP
feature vector.

Use these training images labeled the nearest neighbor
as the atoms to build the over-completed dictionary. In
order not to be confused with the ordinary dictionary
notated by X (defined in Section 2.1), we use R to notate
this proposed adaptive nearest neighbor dictionary.R = [
Rj, «+, R,, +:+, Ro], where R, = Wai Va jevvy; Jem" (l<

Ji» Ja**s js < Mg}, whose column vectors are the nearest
neighbors selected from the gth subject’s training im-
ages. Integer x, indicates that there are x,nearest neigh-
bor images are chosen in the qth class. Usually,
Ki #Ky#, ‘11, # Kg.

3.4 Assessment of the adaptive dictionary

The over-completed dictionary greatly affects the per-
formance of SRC. We employ Fisher’s ratio as the criter-
ion to quantitatively evaluate the validity of the
dictionary. Using the within-class scatter and the
between-class scatter, Fisher’s ratio directly assesses the
class separation performance. For the q-class and p-class,
their Fisher’s ratio along the /-principal component vec-
tor direction F,, ,, ; is defined

T

w Sp,w,

Fyql = 17

where Sy = (Uy — Ug) (Up - Hq) is the between-class

scatter matrix of the class p and class q, f4,is the p-class
mj

mean, flgis the q-class mean; Sy = 3) jp, (r Dei Bj
i=l

)(%;i-H;)") is the within-class scatter matrix for the
Wei et al. EURASIP Journal on Advances in Signal Processing

(2020) 2020:20

Page 9 of 12

 

©
co

o
@

o
‘

>
oO
©
po
=
oO
oO
<
&
2
=
ce
oD)
3
oO
®
~

o
Nh

100
Feature Dimension

Fig. 9 The curve of recognition accuracy with feature-dimension

class p and class q, x;, ; is the ith image from the jth
class, m; is the number of the images in the class j; w,
is the eigenvector corresponding to the eigenvalue 1,
w, express the transposition of w;,. The coefficients 1/2
and m,; remove the interference brought by the different
sample size of each class.

From Eq. (17), we can see that F, 4, =Fy, p, For the
whole dictionary, the fisher ratio along /-principal com-
ponent is defined as the mean of F notated F;:

pq@ tl?
5 Q Q
Fi Q(Q-1) ps » Fra

i=1 j=i+1

(18)

Integer Q, defined in Section2.1, represents the num-
ber of class included in the dictionary.

4 Results and discussion
In this section, the performance of the proposed algo-
rithm is verified based on two standard face databases,
AR [28] and ORL [29]. Both face databases involve some
changes in gender, illumination, pose, expression, glass,
and time. The detailed data used in this paper are list in
Table 1.

This proposed adaptive dictionary is different for dif-
ferent testing images, so different sets of training

140

150

 

samples have a little influence on experimental results.
We randomly selected training samples to repeat the
proposed algorithm for multiple times and presented the
average result in the later of this section. All algorithms
are coded by MATLAB 2015 and performed on the
same computer with 2.6GHz CPU and 8G RAM. In this
paper, we never use any parallel computing or GPU.

4.1 Nearest neighbor image selection based on LCP
features
In order to reduce computation while retaining neigh-
bor attribution, we employ the rotation-invariant uni-
form pattern to compute the similarities between
images. Set P = 8, R = 1, and the length of the LCP
feature vector is 90. Figure 3 presents an example
about one face image and its LCP feature vector,
where (a) is the equalized image, (b) is the rotation-
invariant uniform LBP pattern spectrum for P 8
and R = 1, and (c) is the LCP feature vector corre-
sponding to (c). The ten groups of red vertical line ‘f’
denote the ten normalized MiC feature vectors re-
spectively, the ten black solid vertical lines describe
the frequencies of all patterns in LBP.

In this paper, all images were equalized in advance
to reduce the effects of illumination. The number of

160 180 200 220

Number of atoms

 

Fig. 10 Solving times for a different number of atoms
Wei et al. EURASIP Journal on Advances in Signal Processing

Table 2 Recognition accuracy on ORL

(2020) 2020:20

Page 10 of 12

Table 4 Recognition accuracy with occlusion on AR

 

 

 

 

 

Best recognition rate Optimal number of features = Algorithm Wears glasses Wears scarf
PCA 0.900 100 PCA 0.400 0.147
SRC 0.920 100 SRC 0.480 0.543
CRC_RLS 0.931 95 CRC_RLS 0.530 0.777
CRC_ LBP 0.706 10 CRC_NLCP 0.735 0.826
CRC_NLCP 0.975 95

 

nearest neighbors is different for different testing im-
ages. Figure 4 represents the scatter diagrams of the
nearer-neighbor-number for the face database ORL.
The numbers of nearest neighbor both on criterion-A
and on criterion-B (given in algorithm 1) are reason-
able. It is unnecessary to perform criterion-C.

Figure 5 represents the scatter diagrams of the
nearer-neighbor-number for the face database AR. For
some images, its numbers of nearest neighbor labeled
by criterion-A are relatively small to the number of
classes. So the number labeled criterion-C is shown
in Fig. 5.

For clarity, we presented the Cumulative Distribution
Function (CDF) and Probability Density Function (PDF)
of the nearer-neighbor-number for AR and ORL in
Fig.6, where EA and VA are mean and variance respect-
ively of the numbers. Obviously, the number of nearest
neighbor labeled by criterion-A is mainly between 130
and150 in AR database, it is much less than the total
number of training images.

For each image in the database ORL, the number of its
nearest neighbors in each class is shown in Fig. 7. It is
clear that the number of nearest neighbors labeled by our
method is almost half of that of training samples and the
nearest neighbor images are distributed in all categories.
So the number of categories is not reduced, but the num-
ber of atoms in each category is reduced, which reduces
the dictionary thickness and improves the sparsity.

4.2 Adaptive dictionary

Face image is a high dimension with lots of discrim-
inative information. But the LCP feature dimension is
90 and LBP feature dimension is only 10 in this
paper. So much information is missed in the LCP or
LBP feature subspace, which leads to classify wrong.

Table 3 Recognition accuracy without occlusion on AR

 

 

Feature dimension 10 54 120 300
PCA - 0.680 0.70.1 0.713
SRC - 0.833 0.895 0.933
CRC_RLS - 0.805 0.900 0.938
CRC_ LBP 0.57.0 - - -
CRC_NLCP - 0.838 0.943 0.950

We use fish-ratio defined by Eq. (17) to measure the
discrimination of the dictionary. In order to compare,
three dictionaries are created. As baseline, the first
dictionary, denoted by D_o, is composed by all train-
ing original facial images and is stationary for all test-
ing images; the second dictionary proposed in this
paper and denoted by D_, is composed by the nearest
neighbor facial images, and the third dictionary de-
noted by D> is composed by the nearest neighbor
LCP feature vectors. Atom feature dimensions of both
t Do and D., are equal to the size of the facial
image and are much larger than the atoms’ number,
but for the dictionary D_, the atom feature dimension
is dependent on the type of LBP.

According to Eq. (18), fish-ratio is defined independ-
ently along each principal component vector direction.
We compute the fish-ratios of the three dictionaries
along the bigger principal component vector directions.
As an example, Fig. 8 presents the fish-ratios of different
dictionaries for the same testing images from ORL. The
length of the LCP feature vector is 90, so we compute
the fish-ratio of the first 90 principal component direc-
tions for the D_, and for the other dictionaries, the prin-
cipal component is less than the number of the atom.
Figure 7b shows the cumulative sum of fish-ratio from
the first-principal component to the given-principal
component. We can conclude that the classification
performance of the proposed dictionary in the paper is
superior to the other two dictionaries.

Since the sparse dictionary requires the number of
atoms to be greater than the feature number of atoms,
the feature number of atoms is the image resolution,
and the image resolution is far greater than the number
of images; PCA dimensionality reduction is required to
calculate the sparse coefficient.

4.3 Recognition accuracy

The testing image is first collaboratively represented
with its neighbors labeled in the LCP feature subspace,

Table 5 Time to solve one SRV on database ORL(s)

 

 

 

Method Number of atoms

240 150 120
2,~2, 0.2674 0.1775 0.1463
RLS 0.0077 0.0027 0.0015

 

 
Wei et al. EURASIP Journal on Advances in Signal Processing

Table 6 Time to solve one SRV on database AR (s)

 

 

 

Method Feature Number of atoms
dimension 799 500 300 200
2, ~8, 100 0.4974 0.3345 0.2362 0.1982
200 0.5482 0.3844 0.2542 --
300 0.6890 0.4834 -- --
400 0.8241 0.5921 -- --
RLS 290 0.0804 0.0408 0.0173 --
450 0.0870 0.0420 -- --

 

and then it is classified using its over-completed com-
pact dictionary. In this paper, we use the recognition ac-
curacy to measure the recognition performance.

Number of the testing samples classified correctly

 

Recognition acuracy =
6 y Total number of testing samples

(19)

Figure 9 shows the curve between the right recogni-
tion rate and feature-dimension for different dictionaries
on ORL. In which, PCA, SRC, and CRC_RLS have the
same fixed dictionary D.9o; CRC_NLCP and SRC_NLCP
have the same proposed adaptive dictionary D_p, and the
difference between them is the former used collaborative
representation while the later used sparse representation.
CRC_LBP-riu2 and CRC_LBP-u2 employ the dictionary
D_, and they employed different kinds of LBP.

To be clearer, we listed the best recognition rate and
the corresponding optimal feature number in Table 2.
The proposed algorithm has the greatest recognition ac-
curacy reached 97.5% and a relatively small number of
features 95. CRC_LBP has the least recognition accuracy
rate because the number of features is too small.

Table 3 shows the recognition accuracy of the OR
database for different numbers of feature. Obviously, the
proposed algorithm is the best one for any dimension,
and the recognition rate was improved by 0.5—4.3%
compared with the second best. The robustness of this
proposed method to occlusion (wears glasses or scarf) is
authenticated on AR database and the results are pre-
sented in Table 4. Our algorithm recognition accuracy is
increased by 20.5% for glass and by 4.9% for scarf. Each
algorithm has different requirements for feature dimen-
sion, and the classification will not be performed if fea-
ture dimension is not satisfactory.

4.4 Recognition time

For those approaches based on the sparse representa-
tion, recognition time consists of a solution to represen-
tation vector (SRV) and pattern matching. In this paper,
we employ the nearest neighbor classifier, which is the
simplest and fast, to classify. The recognition time was

(2020) 2020:20

Page 11 of 12

mainly decided by SRV. Neither ¢,~£, used in SRC nor
regularized least squares (RLS) used in CRC_RLS, the
time to solve SRV is mainly determined both by the
number of dictionary atoms and by feature dimension.
Any increase in either of the two numbers will make the
solution time longer. Figure 10 provided the curve of the
time spent on one SRV with the number of atoms and
feature dimensions on the database ORL.

For ORL, when feature dimension equals to 95, the
time to solve one SRV with different numbers of atoms
and different methods is listed in Table 5. For database
AR, the time is given in Table 6. Experiment results
show that the recognition time is greatly reduced as the
number of atoms decreases and that the RLS method is
much faster thane, ~2,.

In addition, the number of atoms must be greater than
the feature dimension, if not, there will be no solution.

5 Conclusion

Over-complete dictionaries are very important for sparse
representation based on classification. In this paper, we
presented an adaptive dictionary learning approach. We
choose separately the training images that are closer to
the testing image from each class as the atoms to adap-
tively make up the over-complete dictionary. The pro-
posed dictionary changes with the different testing
images. The closer training images are called nearest
neighbors labeled class by class in the LCP feature sub-
space, so atoms are more similar to the testing in struc-
ture, which increases the recognition accuracy. In
addition, the number of nearest neighboring images is
much smaller than that of total training images, which
greatly reduced the recognition time. Fisher’s ratio also
shows the proposed adaptive dictionary is more discrim-
inatory. Experiment results also show that collaborative
representation classification based on this proposed
adaptive nearest neighbor dictionary is excellent in rec-
ognition accuracy and in recognition time.

To accurately and quickly identify the input testing
images, we pay more attention to build an adaptive dic-
tionary. The main idea is to find the nearest neighbors
of testing images in each class. If the number of training
samples is small for certain classes, then the advantages
of this proposed algorithm will disappear. In addition,
only Euclidean distance is selected to measure MiC simi-
larity, and we did not investigate other distance formulas
such as “cosine coefficient distance.” We also did not
consider the image noise. In the next work, we will em-
ploy different distances such as “Jeffreys and Matusita
distance,” “cosine coefficient distance,” “Canberra dis-
tance,” and “generalized Dice coefficients” to find simi-
larity between images and investigate influence brought
by noise.
Wei et al. EURASIP Journal on Advances in Signal Processing

Abbreviations

PCA: Principle component analysis; FR: Face recognition; LBP: Local binary
patterns; LCP: Local configuration pattern; SRC: Sparse representation based
on classification; CRC_RLS: Collaborative representation based classification
with regularized least square; RLS: Regularized least square; MiC: Microscopic
feature; BRD: Bin ratio-based distance; SRV: Representation vector;

CDF: Cumulative distribution function; PDF: Probability density function

Acknowledgements

The authors acknowledge the support of Shandong Province Science Key
Research and Development Project (2016GGX101016) and the Innovation
Group of Jinan (2018GXRCO10).

Author's contributions

Dongmei Wei conceived the algorithm and designed experiments. Dongmei
Wei, Taochen, and Shuwei Li perform the experiments. Dongmei Wei,
Yuefeng Zhao, and Dongmei Jiang analyzed the results. Dongmei Wei and
Tianping Li drafted the manuscript. The authors read and approved the final
manuscript.

Funding

The work was supported by Shandong Province Science Key Research and
Development Project (2016GGX101016) and the Innovation Group of Jinan
(2018GXRCO10).

Availability of data and materials
Please contact the corresponding author for data requests.

Consent for publication
Not applicable.

Competing interests
The authors declare that they have no competing interests.

Author details

"Shandong Provincial Engineering and Technical Center of Light
Manipulations & Shandong Provincial Key Laboratory of Optics and Photonic
Device, School of Physics and Electronics, Shandong Normal University, Jinan
250014, China. *School of Electronic Information, Qingdao University,
Qingdao, China.

Received: 8 November 2019 Accepted: 16 March 2020
Published online: 07 May 2020

References

1. M. Turk, A. Pentland, Eigenfaces for recognition. J. Cogn. Neurosci. 3(1), 71-
86 (1991). https://doi.org/10.1162/jocn.1991.3.1.71

2. M. Slavkovié, J. Dubravka, Face recognition using eigenface approach.
Serbian Journal of Electrical Engineering 9(1), 121-130 (2012)

3. MA-A. Bhuiyan, Towards Face Recognition Using Eigenface. Int. J. Adv.
Comput. Sci. Appl. 7(5), 25-31 (2016)

4. Alorf A A. Performance evaluation of the PCA versus improved PCA (IPCA) in
image compression, and in face detection and recognition{C\// Future
Technologies Conference. 2017.

5. T. Ojala, M. Pietikdinen, T. Maenpdaa, Multiresolution Gray-Scale and Rotation
Invariant Texture Classification with Local Binary Patterns. IEEE Transactions
on Pattern Analysis & Machine Intelligence 24(7), 971-987 (2002). https://
doi.org/10.1109/tpami.2002.1017623

6. MA. Rahim et al., Face Recognition Using Local Binary Patterns (LBP). Global
Journal of Computer Science & Technology (2013)

7. Xie S, Shan S, Chen X, et al. V-LGBP: Volume based local Gabor binary
patterns for face representation and recognition[C]. International
Conference On Pattern Recognition, 2008: 1-4 2013. doi: https://doi.org/10.
1109/ICPR.2008.4761374

8B. Yang, S. Chen, A comparative study on local binary pattern (LBP) based
face recognition: LBP histogram versus LBP image. Neurocomputing
120(10), 365-379 (2013). https://doi.org/10.1016/j.neucom.201 2.10.032

9. Zhenhua, G,, Z. Lei, and Z. David, A Completed Modeling of Local Binary
Pattern Operator for Texture Classification. Image Processing IEEE
Transactions, 2010. 19(6): p. 1657-1663.doi: https://doi.org/10.1109/TIP.2010.
2044957

 

(2020) 2020:20

Page 12 of 12

10. W. Zhang et al., Local Gabor Binary Patterns Based on Kullback—Leibler
Divergence for Partially Occluded Face Recognition. IEEE Signal Processing
Letters 14(11), 875-878 (2007). https://doi.org/10.1109/lsp.2007.903260

11. W. Wang, F.F. Huang, J.W. Li, Face description and recognition using multi-
scale LBP feature. Opt. Precis. Eng. 16(4), 696-705 (2008). https://doi.org/10.
1080/02533839.2008.967 1389

12. Y. Guo, G. Zhao, M. Pietikdinen, Local Configuration Features and
Discriminative Learnt Features for Texture Description (2014). https://doi.org/
10.1007/978-3-642-39289-4_5

13. X. Li, H. Shen, H. Li, et al., Patch Matching-Based Multitemporal Group
Sparse Representation for the Missing Information Reconstruction of
Remote-Sensing Images. IEEE Journal of Selected Topics in Applied Earth
Observations and Remote Sensing 9(8), 3629-3641 (2017). https://doi.org/
10.11 09/JSTARS.2016.2533547

14. AY. Yang et al., Feature selection in face recognition: A sparse
representation perspective. IEEE Trans. Pattern Anal. Mach. Intell. (2007)

15. J. Wright et al, in /EEE International Conference on Automatic Face & Gesture
Recognition. Demo: Robust face recognition via sparse representation (2009).
https://doi.org/10.1109/TPAMI.2008.79

16. M. Yang et al., in Computer Vision and Pattern Recognition. Robust sparse
coding for face recognition (2011). https://doi.org/10.1109/CVPR.2011.
5995393

17. M. Yang, L. Zhang, in European Conference on Computer Vision. Gabor
Feature Based Sparse Representation for Face Recognition with Gabor
Occlusion Dictionary (2010). https://doi.org/10.1007/978-3-642-15567-3_33

18. W. Ou, X. You, D. Tao, P. Zhang, et al., Robust face recognition via occlusion
dictionary learning. Pattern Recogn. 47, 1559-1572 (2014). https://doi.org/
10.1016/j.patcog.2013.10.017

19. W. Ou, X. Luan, J. Gou, et al., Robust discriminative nonnegative dictionary
learning for occluded face recognition. Pattern Recogn. Lett. 107, 41-49
(2018). https://doi.org/10.1016//j.patrec.201 7.07.006

20. MaL,Wang C, Xiao B , et al. Sparse representation for face recognition
based on discriminative low-rank dictionary learning[C]// Computer Vision
and Pattern Recognition (CVPR), 2012 IEEE Conference on. IEEE, 2012. doi:
https://doi.org/10.1109/CVPR.2012.6247977

21. Zhang T, Ghanem B, Liu S , et al. Low-Rank Sparse Coding for Image
Classification[C]// 2013 IEEE International Conference on Computer Vision
(ICCV). IEEE Computer Society, 2013. doi: https://doi.org/10.1109/ICCV.2013.
42

22. L. Zhang, M. Yang, X. Feng, Sparse representation or collaborative
representation: Which helps face recognition? 2011(5), 471-478 (2011).
https://doi.org/10.1109/ICCV.2011.6126277

23. J. Gou, B. Hou, W. Ou, Q. Mao, et al., Several robust extensions of
collaborative representation for image classification. Neurocomputing 348,
120-133.27 (2019). https://doi.org/10.1016/j.neucom.2018.06.089

24. J. Gou, L. Wang, Z. Yi, Y. Yuan, W. Ou, et al., Discriminative Group
Collaborative Competitive Representation for Visual Classification. IEEE
International Conference on Multimedia and Expo (ICME) (2019). https://doi.
org/10.1109/ICME.2019.00255

25. J. Gou, L. Wang, B. Hou, Y. Yuan, et al., Two-phase probabilistic collaborative
representation-based classification. Expert Syst. Appl. 133, 9-20 (2019).
https://doi.org/10.1016/j.eswa.2019.05.009

26. J. Gou, L. Wang, Z. Yi, Y. Yuan, et al., A New Discriminative Collaborative
Neighbor Representation Method for Robust Face Recognition. IEEE Access
6(74713), 74727 (2018). https://doi.org/10.1109/ACCESS.2018.2883527

27. W. Hu et al., Bin Ratio-Based Histogram Distances and Their Application to
Image Classification. Pattern Analysis & Machine Intelligence IEEE
Transactions 36(12), 2338-2352 (2014). https://doi.org/10.1109/tpami.2014.
2327975

28. AR. Available from: http://rvll.ech.purdue.edu/~aleix/aleix_face_DB.html.

29. ORL. Available from: http://www.cam-orl.co.uk.

 

Publisher’s Note
Springer Nature remains neutral with regard to jurisdictional claims in
published maps and institutional affiliations.
