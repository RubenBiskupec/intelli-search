np} Quantum Information

ARTICLE OPEN

www.nature.com/npjqi

® Check for updates

Convex optimization of programmable quantum computers

Leonardo Banchi'*™, Jason Pereira@®’, Seth Lloyd*° and Stefano Pirandola@®*”

A fundamental model of quantum computation is the programmable quantum gate array. This is a quantum processor that is fed
by a program state that induces a corresponding quantum operation on input states. While being programmable, any finite-
dimensional design of this model is known to be nonuniversal, meaning that the processor cannot perfectly simulate an arbitrary
quantum channel over the input. Characterizing how close the simulation is and finding the optimal program state have been open
questions for the past 20 years. Here, we answer these questions by showing that the search for the optimal program state is a
convex optimization problem that can be solved via semidefinite programming and gradient-based methods commonly employed
for machine learning. We apply this general result to different types of processors, from a shallow design based on quantum
teleportation, to deeper schemes relying on port-based teleportation and parametric quantum circuits.

npj Quantum Information (2020)6:42 ; https://doi.org/10.1038/s41534-020-0268-2

INTRODUCTION

Back in 1997 a seminal work by Nielsen and Chuang' proposed a
quantum version of the programmable gate array that has
become a fundamental model for quantum computation’. This
is a quantum processor where a fixed quantum operation is
applied to an input state together with a program state. The aim
of the program state is to induce the processor to apply some
target quantum gate or channel? to the input state. Such a desired
feature of quantum programmability comes with a cost: the
model cannot be universal, unless the program state is allowed to
have an infinite dimension, i.e., infinite qubits'*. Even though this
limitation has been known for many years, there is still no exact
characterization on how well a finite-dimensional programmable
quantum processor can generate or simulate an arbitrary
quantum channel. Also there is no literature on how to find the
corresponding optimal program state or even to show that this
state can indeed be found by some optimization procedure. Here,
we show the solutions to these long-standing open problems.

Here, we show that the optimization of programmable
quantum computers is a convex problem for which the solution
can always be found by means of classical semidefinite program-
ming (SDP), and classical gradient-based methods that are
commonly employed for machine learning (ML) applications. ML
methods have found wide applicability across many disciplines”,
and we are currently witnessing the development of new hybrid
areas of investigation, where ML methods are interconnected with
quantum information theory, such as quantum-enhanced ML
(refs. °'°; e.g., quantum neural networks, quantum annealing,
etc.), protocols of quantum-inspired ML (e.g., for recommendation
systems'' or component analysis and supervised clustering’),
and classical learning methods applied to quantum computers, as
explored here in this manuscript.

In our work, we quantify the error between an arbitrary target
channel and its programmable simulation in terms of the diamond
distance*’'*, and other suitable cost functions, including the trace
distance and the quantum fidelity. For all the considered cost
functions, we are able to show that the minimization of the
simulation error is a convex optimization problem in the space of

the program states. This already solves an outstanding problem
that affects various models of quantum computers (e.g.,
variational quantum circuits), where the optimization over classical
parameters is non-convex and therefore not guaranteed to
converge to a global optimum. By contrast, because our problem
is proven to be convex, we can use SDP to minimize the diamond
distance and always find the optimal program state for the
simulation of a target channel, therefore optimizing the program-
mable quantum processor. Similarly, we may find suboptimal
solutions by minimizing the trace distance or the quantum fidelity
by means of gradient-based techniques adapted from the ML
literature, such as the projected subgradient method'* and
the conjugate gradient method'”'®. We note indeed that the
minimization of the &,-norm, mathematically related to the
quantum trace distance, is widely employed in many ML tasks'”"'°,
SO many of those techniques can be adapted for learning program
states.

With these general results in our hands, we first discuss the
optimal learning of arbitrary unitaries with a generic program-
mable quantum processor. Then, we consider specific designs of
the processor, from a shallow scheme based on the teleportation
protocol, to higher-depth designs based on port-based teleporta-
tion (PBT)'?-7' and parametric quantum circuits (PQCs)*’, introdu-
cing a suitable convex reformulation of the latter. In the various
cases, we benchmark the processors for the simulation of basic
unitary gates (qubit rotations) and various basic channels,
including the amplitude damping channel that is known to be
the most difficult to simulate****. For the deeper designs, we find
that the optimal program states do not correspond to the Choi
matrices of the target channels, which is rather counterintuitive
and unexpected.

RESULTS

We first present our main theoretical results on how to train the
program state of programmable quantum processors, either via
convex optimization or first-order gradient-based algorithms. We
then apply our general methods to study the learning of arbitrary
unitaries, and the simulation of different channels via processors

‘Department of Physics and Astronomy, University of Florence, via G. Sansone 1, -50019 Sesto Fiorentino (Fl), Italy. 2INFN Sezione di Firenze, via G.Sansone 1, I-50019 Sesto
Fiorentino (Fl), Italy. 7Department of Computer Science, University of York, York YO10 5GH, UK. “Department of Mechanical Engineering, Massachusetts Institute of Technology
(MIT), Cambridge, MA 02139, USA. ’Research Laboratory of Electronics, Massachusetts Institute of Technology (MIT), Cambridge, MA 02139, USA. “email: leonardo.banchi@unifi.it

Published in partnership with The University of New South Wales

np} nature partner

journals
L. Banchi et al.

 

 

_-"
=_

  

-_=
-_=-
=

Program Processor

Output

Fig. 1 Quantum processor Q with program state 7 that simulates
a quantum channel €, from input to output. We also show
the CPTP map A of the processor, from the program state 7 to the
output Choi matrix xy, (generated by partial transmission of the
maximally entangled state ©).

built either from quantum teleportation and its generalization, or
from PQCs.

Programmable quantum computing

Let us consider an arbitrary mapping from d-dimensional input
states into d’-dimensional output states, where d’#d in the
general case. This is described by a quantum channel € that may
represent the overall action of a quantum computation and does
not need to be a unitary transformation. Any channel € can be
simulated by means of a programmable quantum processor,
which is modeled in general by a fixed completely positive trace-
preserving (CPTP) map Q that is applied to both the input state
and a variable program state 7. In this way, the processor
transforms the input state by means of an approximate channel
Eq as

En(e) = Tr[Q(p @ m)], (1)

where Tr2 is the partial trace over the program state. A
fundamental result! is that there is no fixed quantum “processor”
Q that is able to exactly simulate any quantum channel €. In other
terms, given €, we cannot find the corresponding program 7 such
that € = €,. Yet simulation can be achieved in an approximate
sense, where the quality of the simulation may increase for larger
program dimension. In general, the open problem is to determine
the optimal program state 7 that minimizes the simulation error,
that can be quantified by the cost function

Co(m1) = |]E — Enl|., (2)

namely the diamond distance*”'* between the target channel €
and its simulation €,. In other words,

Find 7 such that C, (77) = min;C, (7). (3)

From theory’, we know that we cannot achieve Cy =0 for
arbitrary € unless 7 and Q have infinite dimensions. As a result, for
any finite-dimensional realistic design of the quantum processor,
finding the optimal program state 77 is an open problem. Recall

that the diamond distance is defined by ||&€ — €,||, :=
maxg||Z © E(g) — ZT ® En(@)||,, where Z is the identity map and
||O||, := TrVO'O is the trace norm’.

It is important to note that this problem can be reduced to a
simpler one by introducing the channel’s Choi matrix

XE, =T® E,(O)
=d"S i) (j) @ Tr[Q(i)(/ @ m)], (4)
ij

where © := |@)(Q| is a d-dimensional maximally entangled state.
From this expression, it is clear that the Choi matrix y¢_ is linear in
the program state 7. More precisely, the Choi matrix y- at the
output of the processor Q can be directly written as a CPTP linear
map A acting on the space of the program states 7, i.e.,

Xn °= Xe, = A(71). (5)
This map is also depicted in Fig. 1, and fully describes the action of

npj Quantum Information (2020) 42

the processor Q. Then, using results from refs. **°*°, we may write
C.(m) <dC\(m) < 2d\/Cr(m), (6)
where

Ci(m™) = [Xe — Xnlli (7)

is the trace distance” between target and simulated Choi matrices,
and

Cr(m) = 1—F(m)’, (8)

where F(z) is Bures’ fidelity between the two Choi matrices y- and
Xm Le.,

F(t) := || VXeVXnl|, = Tey) VXeXnVKXe- (9)

Another possible upper bound can be written using the quantum
Pinsker’s inequality*”*®. In fact, we may write C,() <

(2In /2),/Cr(m), where
Ca(7) = min{S(Xe||Xn); S(Xal Xe) 5;

and S(p||o) := Trl[p(log,o —log,o0)| is the quantum relative
entropy between pe and o. In Supplementary Note 1.3, we also
introduce a cost function C,(7) based on the Schatten p-norm.

(10)

Convex optimization

One of the main problems in the optimization of reconfigurable
quantum chips is that the relevant cost functions are not convex in
the set of classical parameters. This problem is completely solved
here thanks to the fact that the optimization of a programmable
quantum processor is done with respect to a quantum state. In
fact, in the methods section, we prove the following

Theorem 1 Consider the simulation of a target quantum channel
E by means of a programmable quantum processor Q. The
optimization of the cost functions Cy, Ci, Cr, Cr, or C, is a convex
problem in the space of program states 7. In particular, the global
minimum 7 for Cg can always be found as a local minimum.

This convexity result is generally valid for any cost function that
is convex in 7. This is the case for any desired norm, not only the
trace norm, but also the Frobenius norm, or any Schatten p-norm.
It also applies to the relative entropy. Furthermore, the result can
also be extended to any convex parametrization of the program
states.

When dealing with convex optimization with respect to positive
operators, the standard approach is to map the problem to a form
that is solvable via SDP (refs. 77°°). Since the optimal program is
the one minimizing the cost function, it is important to write the
computation of the cost function itself as a minimization. For
the case of the diamond distance, this can be achieved by using
the dual formulation*’. More precisely, consider the linear map
QO, = € — Ez with Choi matrix xq = Xe — Xp = Xe — A(77), and the
spectral norm ||O||,, := max{||Oul| : ue C%, |u|] <1}, which is

the maximum eigenvalue of VO'O. Then, by the strong duality of
the diamond norm, C.(7) = ||O,||, is given by the SDP (ref. *°)

Minimize 2||Tr2Z||,.,
Subjectto Z >0 and Z > d(x- — A(n)).

The importance of the above dual formulation is that the diamond
distance is a minimization, rather than a maximization over a set
of matrices. In order to find the optimal program 77, we apply the
unique minimization of Eq. (11), where 7 is variable and satisfies
the additional constraints 7>=0 and Tr(7) = 1.

In the methods section, we show that other cost functions, such
as C, and C; can also be written as SDPs. Correspondingly, the
optimal programs 77 can be obtained by numerical SDP solvers.
Most numerical packages implement second-order algorithms,
such as the interior point method*'. However, second-order

(11)

Published in partnership with The University of New South Wales
methods tend to be computationally heavy for large problem
sizes°**’*?, namely when 77 contains many qudits. In the following
section, we introduce first-order methods, that are better suited
for larger program states. It is important to remark that there also
exist zeroth-order (derivative-free) methods, such as the simulta-
neous perturbation stochastic approximation method**, which
was utilized for a quantum problem in ref. *°. However, it is known
that zeroth-order methods normally have slower convergence
times*° compared to first-order methods.

Gradient-based optimization

In ML applications, where a large amount of data is commonly
available, there have been several works that study the minimiza-
tion of suitable matrix norms for different purposes '”'°°”°°. First-
order methods, are preferred for large dimensional problems, as
they are less computationally intensive and require less memory.
Here, we show how to apply first-order (gradient-based)
algorithms, which are widely employed in ML applications, to
find the optimal quantum program.

For this purpose, we need to introduce the subgradient of the
cost function C at any point 7 € S, which is the set

dC(m) = {Z: C(o) — C(m) > Tr|Z(o — 7)], Vo € S}, (12)

where Z is Hermitian *?*® If C is differentiable, then dC(m) contains
a single element: its gradient V C(7). We explicitly compute this
gradient for an arbitrary programmable quantum processor (1)
whose Choi matrix xe = x, = A(z), can be written as a quantum
channel A that maps a generic program state to the processor's
Choi matrix. This map can be defined by its Kraus decomposition

A(1) = So AnmTAl, for some operators A,. In fact, let us call A*(o) =

SAL pA the dual map, then in the methods section we prove the
following

Theorem 2 Consider an arbitrary quantum channel € with Choi
matrix x, that is simulated by a quantum processor Q with map ((7)
= x, (and dual map A’). Then, we may write the following gradients
for the trace distance cost C,(m) and the infidelity cost C,(7)

VCi(m) = Y— sign(Ax)A* (Px), (13)
k

VCr(m) = —2,/1 — Cr(m) VF (71), (14)

VF (nt) = SN’ [Vxe(vReN(m) Ve) VRE]. (15)

where A, (P,) are the eigenvalues (eigenprojectors) of the
Hermitian operator yx, —X¢. When C,(m) or C;-(7) are not
differentiable in 7, then the above expressions provide an element
of the subgradient 0C(7).

Once we have the (sub)gradient of the cost function C, we can
solve the optimization min;csC(m), using the projected subgra-
dient method'**?. Let Ps be the projection onto the set of
program states S, namely Ps(X) = argmin,<s || X — 7||,, that we
show to be computable from the spectral decomposition of any
Hermitian X (see Theorem 3 in the “Methods” section). Then, we
iteratively apply the steps

1) Select an operator g, from 0C(77;),

(16)
2) Ti+1 = Ps(mMi — ai9;),

where / is the iteration index, a; is what is called "learning rate”,
and Theorem 2 can be employed to find g; at each step. It is
simple to show that 77; converges to the optimal program state 77
in O(e~?) steps, for any desired precision ¢€ such that
|C(7) — C(7t)| < e. Another approach is the conjugate gradient
method'°*?, sometimes called Frank-Wolfe algorithm. Here, we

Published in partnership with The University of New South Wales

L. Banchi et al.

np)

 

apply

1) Find the smallest eigenvalue |o;) of VC(7;),
m+? Ja)(or 7

1; 0;) (Oj\.

i+2° 74200"

When the gradient of fis Lipschitz continuous with constant L, the
method converges after O(L/e) steps'°*'. To justify the applic-
ability of this method, a suitable smoothening of the cost function
must be employed. The downside of the conjugate gradient
method is that it necessarily requires a differentiable cost function
C, with gradient VC. Specifically, this may create problems for the
trace distance cost C, that is generally non-smooth. A solution to
this problem is to define the cost function in terms of the smooth
trace distance C,(m) = Tr{hy(x, —X¢)], where h, is the so-called
Huber penalty function h,(x) = x*/(2u) if |x| <p and |x| — y/2 if
|x| =>. This quantity satisfies C,,(71) < C,(7) < C,(m) + ud/2 and is a
convex function over program states, with gradient

VCu(mT) = AA (Xn — Xe).

2) Mj41. =

Learning of arbitrary unitaries

One specific application is the simulation of quantum gates or,
more generally, unitary transformations?**?”. Here, the infidelity
provides the most convenient cost function, as the optimal
program can be found analytically. In fact, suppose we use a
quantum processor with map A to simulate a target unitary U.
Because the Choi matrix of U is pure |y,,)(xy|, we first note that

F(m)? = (xy|A(7)|Xy) and then we see that Eq. (15) drastically
simplifies to VF(m) = A*(\xy)(Xy|)/4/4F (7). As a result, we find

VCr(m) = —A"[|Xu) Kull; (18)

where there is no dependence on 7. Therefore, using the
conjugate gradient method in Eq. (17), we see that the optimal
program state 77 for the infidelity cost function C; is a fixed point of
the iteration and is equal to the maximum eigenvector of

A"(Xu) Xull-

Teleportation processor

Once we have shown how to optimize a generic programmable
quantum processor, we discuss some specific designs, over which
we will test the optimization procedure. One possible (shallow)
design for the quantum processor Q is a generalized teleportation
protocol*® over an arbitrary program state 7. In dimension d, the
protocol involves a basis of d* maximally entangled states |@;) and
a basis {Uj} of teleportation unitaries such that Tr(U!U;) = dé;
(ref. *”). An input d-dimensional state p and the A part of the
program 74g are subject to the projector |@;)(@j|. The classical
outcome ij is communicated to the B part of 74g, where the
correction U7" is applied.

The above procedure defines the teleportation channel €,
over ¢

E8*(0) = DUR (OF |o° on oR\uP 09

Its Choi matrix can be written as y, = Atele(7), where the map of
the teleportation processor is equal to

Aeete(t) = d-? S (UF @ U;) (UF @ Ui)", (20)

which is clearly self-dual A’ = A. Given a target quantum channel €
which is teleportation covariant?***, = namely — when
[7, U> & U;| = 0, then we know that its simulation is perfect and
the optimal program 77 is the channel’s Choi matrix, i.e., one of the
fixed points of the map tele. For a general channel, the optimal
program 77 can be approximated by using the cost functions in our
Theorem 2 with A being given in Eq. (20), or directly found by

optimizing Co(7).

npj Quantum Information (2020) 42
np}

L. Banchi et al.

 

Alice

discard By,
k Ai

 

Fig. 2 PBT scheme. Two distant parties, Alice and Bob, share N
maximally entangled pairs {Ax, By hey: Alice also has another system
C in the state |W). To teleport C, Alice performs the POVM {NA°} on
all her local systems A = {A;};_, and C. She then communicates the
outcome i to Bob. Bob discards all his systems B = {B,};_, with the
exception of B; After these steps, the state |W) is approximately
teleported to B;. Similarly, an arbitrary channel € is simulated with
N copies of the Choi matrix yore, The figure shows an example with
N=5, where j= 4 is selected.

Port-based teleportation

A deeper design is provided by a PBT processor, whose overall
protocol is illustrated in Fig. 2. Here, we consider a more general
formulation of the original PBT protocol'”?°, where the resource
entangled pairs are replaced by an arbitrary program state 77. In a
PBT processor, each party has N systems (or ‘ports’), A= {Aj, ...,
An} for Alice and B = {B,, ..., By} for Bob. These are prepared in a
program state 7T,ag. To teleport an input state p,, Alice performs a
joint positive operator-value measurement (POVM) {Mf} (ref. '”) on
system C and the A-ports. She then communicates the outcome /
to Bob, who discards all ports except B;, which is the output Bout.
The resulting PBT channel P,, : Hct Hz,,, is then

out

N
Pr (0) — 2 Tr ap.c | VTi(7TaB ® Pc) Vii] Bi— Bout

N
= 2 Trg clli(7aB & Po))5,—Bor?
[=

where B; = B\B; = {Bx : k#i}.

In the standard PBT protocol'®”°, the program state is fixed as
Tap= &y_,0a,B,, where |Oq,2,) are Bell states, and the following
POVM is used

n= Ni +7 ( — yr) (22)

where

Ml; = One! OacOqe’’, (23)
N

Onc (= S- Daic, (24)
i=]

and o '” is an operator defined only on the support of o. The PBT

protocol is formulated for N>=2 ports. However, we also include
here the trivial case for N = 1, corresponding to the process where
Alice’s input is traced out and the output is the reduced state of
Bob’s port, i.e., a maximally mixed state. In the limit N — 9, the
standard PBT protocol approximates an_ identity channel
P,() © p, with fidelity'**'F, = 1—O(%), so perfect simulation

npj Quantum Information (2020) 42

is possible only in the limit N > °°, Since the standard PBT protocol
provides an approximation to the identity channel, we call it Zy.

From the PBT simulation of the identity channel, it is possible to
approximate any general channel € by noting that € can be
written as a composition € o Z, where Z is the identity channel.
This is done by replacing the identity channel Z with its PBT
simulation Zy, and then applying € to B;. However, since Bob does
not perform any post-processing on his systems B, aside from
discarding all ports B, with k #i, he can also apply first the channel
E®" to all his ports and then discard all the ports B, with k #i. In
doing so, he changes the program state to

Tap = 1a ® Ep [1 Oaa,] = @haXer™

In other terms, any channel € can be PBT approximated by N
copies of its Choi matrix y- as program state. Since PBT simulation
can be decomposed as €,; = € 0 Zn, the error CY =|] € — E,||, in
simulating the channel € = € oT satisfies

CY =||EoT —EoTy || <|| Z — In|, < 2d(d—1)N"',"

(25)

(26)

where we used the data processing inequality and an upper
bound from ref. *®. While the channel’s Choi matrix assures that
CY — 0 for large N, for any finite N it does not represent the
optimal program state. In general, for any finite N, finding the
optimal program state 7Tag simulating a channel € with PBT is an
open problem, and no explicit solutions or procedures are known.

We employ our convex optimization procedures to find the
optimal program state. This can be done either exactly by
minimizing the diamond distance cost function Cy via SDP, or
approximately, by determining the optimal program state via the
minimization of the trace distance cost function C, via either SDP
or the gradient-based techniques discussed above. For this second
approach, we need to derive the map A of the PBT processor,
between the program state 7 to output Choi matrix as in Eq. (5).
To compute the Choi matrix and CP-map A, we consider an input
maximally entangled state |Dpc) and a basis let) of A{B\B}C. Then,
by using Eq. (21) and the definition A(z) = Xp, = 1p ® Pr [oc],
we find the map Aagg_.pz,,, Of a PBT processor

VN © 1gp|Opc).

out

A(n) = SOK ynKi, Ky := (e
ij

 

(27)

Note that a general program state for PBT consists of 2N qudits,
and hence the parameter space has exponential size d*”.
However, because the PBT protocol is symmetric under permuta-
tion of port labels, we show in Supplementary Note 6 that one can
exploit this symmetry and reduce the number of free parameters
N+d*—1

d*—1
the number of ports N. Despite this exponential reduction, the
scaling in the number of parameters still represents a practical
limiting factor, even for qubits for which O(N'). A suboptimal
Strategy consists in reducing the space of program states to a
convex set that we call the “Choi space” C. Consider an arbitrary
probability distribution {p,} and then define

C={m: =) ppg”, Tra(Ogg) = a | 1}.
k

to the binomial coeffficient ) which is polynomial in

(28)

One can show (see Supplementary Note 6) that a global minimum
in C is a global minimum in the extremal (non-convex) subspace
for py = 6x1, Consisting of tensor products of Choi matrices Pag
Among these states, there is the N-copy Choi matrix of the target
channel ye™ = [Z @ E(\@)(@|)]°", which is not necessarily the
optimal program, as we show below.

Parametric quantum circuits

Another deep design of quantum processor is based on
PQCs (refs. 774°). A PQC is a sequence of unitary matrices

Published in partnership with The University of New South Wales
U(t) = Up(ty)...U2(t2)U;(t)), where U;(t;) = exp(it;H;) for some
Hamiltonian H; and time interval t. The problem with PQCs is
that the cost " functions in the classical parameters** are not
convex, so that numerical algorithms are not guaranteed to
converge to the global optimum. Here, we fix this issue by
introducing a convex formulation of PQCs, where classical
parameters are replaced by a quantum program. This results in a
programmable PQC processor that is optimizable by our methods.
The universality of PQCs can be employed for universal channel
simulation. Indeed, thanks to Stinespring’s dilation theorem, any
channel can be written as a unitary evolution on a bigger space,
E(P,) = Trr,[U(e, & Oo)U"], where the system is paired to an extra
register Ro and 9) belongs to Ro. In the Stinespring representation,
U acts on system A and register Ro. In ref. *°, it has been shown
that sequences of two unitaries, Up and U,, are almost universal for
simulation, i.e., any target unitary U can be approximated as U
-- Uy*U5° U7? UG" for some integers m,. Under suitable conditions,
it takes O(d*e °) steps to approximate U up to precision e. The
choice between U, and U, is done by measuring a classical bit. We
may introduce a quantum version, where the two different
unitaries Up = e”” or U; = e”” are chosen depending on the state
of qubit R;. This results in the conditional gate

Uj = exp(iHy & |0),(0| + iH ® |1)y(1)). (29)

Channel simulation is then obtained by replacing the unitary
evolution U in the Stinespring dilation via its simulation. The result
is illustrated in Fig. 3, where the program state 77 is defined over R

= (Ro, ..., Ru) and each H; acts on the input system A and two
ancillary. qubits Ro and R,. Following the universality construction
of ref. *°, we show in the Supplementary Note 3.4 that the channel
shown in Fig. 3 provides a universal processor. Moreover, the
channel A that maps any program 77 to the processor’s Choi matrix
is obtained as

A(m) =Tre| Oar (Osa ® mr) Usp | (30)

where Use = 1g @ Th _ Via p, Ri from which we can identify the
optimal program |77) via our ‘methods.

PQCs are not inherently monotonic. A deeper (higher N) design
may simulate a given channel worse than a more shallow design.
We can design a modified PQC that is monotonic by design, which
we designate a “monotonic PQC” (mPQC), by replacing the qubits
in our program state with qutrits, and modifying Eq. (29) to read

U; = exp (io ® |0), (0| + iH; @ |1),(1 [+02 |2),(21), (31)
eb

, Up, - Uo, - Uo, - Uo,
Ao)
191)
by |
Os) _
)

04

Fig. 3 PQC Scheme. Thanks to the Stinespring decomposition, a
quantum channel is written as a unitary evolution in an extended
space. The corresponding unitary is then simulated via a parametric
quantum circuit that, at each time, applies a certain unitary
depending on the state of the quantum register.

Published in partnership with The University of New South Wales

L. Banchi et al.

np)

 

where 0 is a zero operator, so that gate j enacts the identity
channel if program qutrit j is in the state |2) (2|. Then, if it were the
case that a PQC with N program qubits could simulate a given
channel better than one with N + m, a mPQC with N + m qutrits in
the program state could perform at least, as well as the PQC with
N program qubits by setting the first m qutrits to |2)(2|. This
processor design is both universal and monotonic. More precisely,
let C(PQCy) denote the value of a cost function C for simulating a
channel € with an N-gate PQC, using the optimal program state,
and let C(mPQC,y) denote the value of C for simulating € with an
N-gate mPQC, again using the optimal program state. We are then
guaranteed that

C(mPQCy) < min C(PQCw). (32)

Processor benchmarking

In order to show the performance of the various architectures, we
consider the simulation of an amplitude damping channel with
probability p. The reason is because this is the most difficult
channel to simulate, with a perfect simulation only known for
infinite dimension, e.g., using continuous-variable quantum
operations”®. In Figs. 4 and 5, we compare teleportation-based,
PBT, PQC, and “mPQC” programmable processors whose program
states have been optimized according to the cost functions Cy
and C,. For the PBT processor, the trace distance cost C, is
remarkably close to Cy and allows us to easily explore high
depths. Note that the optimal program states differ from the naive
choice of the Choi matrix of the target channel. Note too that PQC
processors display non-monotonic behavior when simulating
amplitude damping channels, meaning that shallow PQC proces-
sors (e.g., for N= 4) may perform better than deeper processors.
For the PQC processor, we use the universal Hamiltonians Ho =
V2(X ®Y —Y @X) and Hy = (V2Z 4+ V3Y + V5X) @ (Y + V2Z),
where X, Y, and Z are Pauli operators. mPQC processors guarantee
that deeper designs always perform at least, as well as any
shallower design. In Fig. 5 perfect simulation is achievable at
specific values of p because of our choice of the universal gates Up
and U,. More details are provided in the Supplementary Note 3.

Many other numerical simulations are performed in the
Supplementary Note 3 where we study the convergence rate in
learning a unitary operation, the exact simulation of Pauli

0.8

0.6

IE — Exllo

0.4

0.2

 

0.0
0.0 0.2 0.4 0.6 0.8 1.0

P

Fig. 4 Diamond distance error C, in simulating an amplitude
damping channel €, at various damping rates p. We compare the
performance of different designs for the programmable quantum
processor: standard teleportation and PBT with N ports (PBTj). The
optimal program 77 is obtained by either minimizing directly the
diamond distance C, (solid lines), or the trace distance C, (dashed
lines) via the projected subgradient iteration. In both cases, from 7
we then compute C,(77). The lowest curves are obtained by
optimizing 7 over the Choi space in Eq. (28). For comparison, we
also show the (non-optimal) performance when the program is the
channel’s Choi matrix (dotted lines).

npj Quantum Information (2020) 42
np}

L. Banchi et al.

 

IE — Exllo

   

1.0

Fig. 5 Diamond distance error Cy, in simulating an amplitude
damping channel €, at various damping rates p. We compare the
performance of two different designs for the programmable
quantum processor: POQCs with N+ 1 registers (PQC,) and mono-
tonic parametric quantum circuits with N+ 1 registers (mMPQCy). In
both cases the optimal program |7r) is obtained by minimizing the
diamond distance Cy.

channels, and approximate simulation of both dephasing and
amplitude damping channels. In particular, we study the
performance of the approximate solution when optimizing over
larger, but easier-to-compute, cost functions, such as the trace
distance or the infidelity.

DISCUSSION

In this work, we have considered a general finite-dimensional
model of a programmable quantum processor, which is a
fundamental scheme for quantum computing and also a primitive
tool for other areas of quantum information. By introducing
suitable cost functions, based on the diamond distance, trace
distance and quantum fidelity, we have shown how to character-
ize the optimal performance of this processor in the simulation of
an arbitrary quantum gate or channel. In fact, we have shown that
the minimization of these cost functions is a convex optimization
problem that can always be solved.

In particular, by minimizing the diamond distance via SDP, we
can always determine the optimal program state for the
simulation of an arbitrary channel. Alternatively, we may minimize
the simpler but larger cost functions in terms of trace distance and
quantum fidelity via gradient-based methods adapted from ML, so
as to provide a very good approximation of the optimal program
state. This other approach can also provide closed analytical
solutions, as is the case for the simulation of arbitrary unitaries, for
which the minimization of the fidelity cost function corresponds
to computing an eigenvector.

We have then applied our results to various designs of
programmable quantum processor, from a shallow teleportation-
based scheme to deeper and asymptotically universal designs that
are based on PBT and PQCs. We have explicitly benchmarked the
performances of these quantum processors by considering the
simulation of unitary gates, depolarizing and amplitude damping
channels, showing that the optimal program states may differ
from the naive choice based on the Choi matrix of the target
channel. Moreover, our results can be applied also for universal
quantum measurements”.

A potential application of our work may be the development of
“programmable” model of cloud-based quantum computation,
where a client has an input state to be processed by an online
quantum server that is equipped with a programmable quantum
processor. The client classically informs the server about what type
of computation it needs (e.g., some specified quantum algorithm)
and the server generates an optimal program state that closely

npj Quantum Information (2020) 42

approximates the overall quantum channel to be applied to the
input. The server then accepts the input from the client, processes
it, and returns the output together with the value of a cost
function quantifying how close the computation was with respect
to the client’s request.

Our results may also be useful in areas beyond quantum
computing, wherever channel simulation is a basic problem. For
instance, this is the case when we investigate the ultimate limits of
quantum communications**, design optimal Hamiltonians for
one-way quantum repeaters, and for all those areas of quantum
sensing, hypothesis testing and metrology that are based on
quantum channel simulations °'. Indeed the study of adaptive
protocols of quantum channel discrimination (or estimation) is
notoriously difficult, and their optimal performance is not
completely understood. Nonetheless, these protocols can be
analyzed by using simulation techniques**”' where the channel,
encoding the unknown parameter, is replaced by an approximate
simulating channel, and its parameter is mapped into the label of
a program state (therefore reducing the problem from channel to
State discrimination/estimation). In this regard, our theory
provides the optimal solution to this basic problem, by determin-
ing the best simulating channel and the corresponding
program state.

METHODS
Convexity proofs

In this section, we provide a proof of Theorem 1, namely we show that the
minimization of the main cost functions Cy, C, and Cr is a convex
optimization problem in the space of the program states 7. This means
that we can find the optimal program state 7 by minimizing Co or,
alternatively, suboptimal program states can be found by minimizing
either C, or Cr. For the sake of generality, we prove the result for all of the
cost functions discussed in the previous sections. We restate Theorem 1
below for completeness:

Theorem The minimization of the generic cost function C = Cy, Cy, Cr, Cr
or C, for any p > 1 is a convex optimization problem in the space of program
states.

Proof Let us start to show the result for the diamond distance Cy. In this
case, we can write the following

C. [pm + (1 — p)r']
= Il ~ Epny(1—p)n'||,
1
"ip +1 —p)E —pEx — (1 —p)En'|le
(2)
< ||pPE — pEq||, + || — p)E — 1 — p)En'||.,

(3)
<pll€ — Enlla + (1 — PIE — Ew
= pC.(m) + (1 — p)C.(m"),

—

 

llo

where we use (1) the linearity of €, (2) the triangle inequality, and (3) the
property ||xA||; = |x|||Al|,, valid for any operator A and coefficient x.

For any Schatten p-norm C, with p21, we may prove convexity
following a similar reasoning. Since for any combination 77 := Po7o + P,™M,
with po +p; =1, we have A(7r) = poA(710) + p;A(71,), then by exploiting
the triangle inequality, and the property ||xA||, = |x|||Allp, we can show that

Cp(PoMo + Pi) :=|| Xe — A(PoM0 + Pi) |p
S Po || Xe — A) ||p + Pr || Xe — AGT) II
= PoCp(Mo) + P1Cp(™) .

(34)

To show the convexity of C;, defined in Eq. (8), we note that the fidelity
function F(o, 0) satisfies the following concavity relation®?

2
(Saene) = S— pxF(0x,.0)°
k k

Due to the linearity of x,=A(m), the fidelity in Eq. (9) satisfies F2 >
> KP KF i, for 7 := 5°,p,m. Accordingly, we get the following convexity

(35)

Published in partnership with The University of New South Wales
result

Cr [dan] < S- pCe(M) : (36)
k k

For the cost function Cp, the result comes from the linearity of A(z) and the
joint convexity of the relative entropy. In fact, for 7 := po + p,m, we
may write

SIA) ||Xe] = S[PoA(710) + PAG) |IXe]
= SlpoA(70) + PiA(71)||PoXe + Pike] (37)
< poS[A(70), Xe] + P1S|AVM), Xe],

with a symmetric proof for S|y-||A(7)|. This implies the convexity of Cp(77) in
Eq. (10).

Convex classical parametrizations

The result of the Theorem 1 can certainly be extended to any convex
parametrization of program states. For instance, assume that 7=7(A),
where A = {A} is a probability distribution. This means that, for 0 < p< 1 and
any two parametrizations, A and A’, we may write

m[pA + (1 — p)a'] = pr(A) + (1 — p)m(’). (38)

Then the problem remains convex in A and we may therefore find the
global minimum in these parameters. It is clear that this global minimum A
identifies a program state 7(A) that is not generally the optimal state 77 in
the entire program space S, even though the solution may be a
convenient solution for experimental applications.

Note that a possible classical parametrization consists of using classical
program states, of the form

m(A) = > Ailg;) (@il: (39)

where {|9;)} is an orthonormal basis in the program space. Convex
combinations of probability distributions therefore define a convex set of
classical program states

Scass = {1:1 = >_Ailei) Gil: (9;|0;) = Sj}- (40)

Optimizing over this specific subspace corresponds to optimizing the
programmable quantum processor over classical programs. It is clear that
global minima in Sgas; and S are expected to be very different. For
instance, Sgas, Cannot certainly include Choi matrices that are usually very
good quantum programs.

Gradient-based optimization

As discussed in the main text, the SDP formulation allows the use of
powerful and accurate numerical methods, such as the interior point
method. However, these algorithms are not suitable for high-dimensional
problems, due to their higher computational and memory requirements.
Therefore, an alternative approach (useful for larger program states)
consists of the optimization of the larger but easier-to-compute cost
function C = C, (trace distance) or C- (infidelity), for which we can use first-
order methods. Indeed, according to Theorem 1, all of the proposed cost
functions C : S — IR are convex over the program space S and, therefore,
we can solve the optimization min;esC(7) by using gradient-based
algorithms.

Gradient-based convex optimization is at the heart of many popular ML
techniques, such as online learning in a high-dimensional feature space’ ’,
missing value estimation problems'®, text classification, image ranking,
and optical character recognition®’, to name a few. In all of the above
applications, “learning” corresponds to the following minimization
problem: min,esf(x), where f(x) is a convex function and S is a convex
set. Quantum learning falls into this category, as the space of program
states is convex due to the linearity of quantum mechanics and the fact
that cost functions are typically convex in this space (see Theorem 1).
Gradient-based approaches are among the most applied methods for
convex optimization of non-linear, possibly non-smooth functions>”.

When the cost function is not differentiable, we cannot formally define
its gradient. Nonetheless, we can always define the subgradient oC of C as
in Eq. (12), which in principle contains many points. When C is not only
convex but also differentiable, then dC(7) = {VC(7)}, i.e., the subgradient
contains a single element, the gradient VC, that can be obtained via the
Fréchet derivative of C (for more details see Supplementary Note 4). When

 

Published in partnership with The University of New South Wales

L. Banchi et al.

np)

 

C is not differentiable, the gradient still provides an element of the
subgradient that can be used in the minimization algorithm.

In order to compute the gradient VC, it is convenient to consider the
Kraus decomposition of the processor map A. Let us write

A(t) = So AxrAL, (41)
k

with Kraus operators A, We then define the dual map A’ of the processor
as the one (generally non-trace-preserving), which is given by the
following decomposition

A*(p) = S- APA. (42)
k

With these definitions in hands, we can now prove Theorem 2, which we
rewrite here for convenience.

Theorem Suppose we use a quantum processor Q with map (7) =x, in
order to approximate the Choi matrix x- of an arbitrary channel €. Then, the
gradients of the trace distance C,(m) and the infidelity C-(7) are given by the
following analytical formulas

VCi(m) = S— sign(Ay)A* (Pk), (43)
k

VCr(m) = —2,/1 — Cr(m) VF (71), (44)

VE (m) = 5° | Vie (vREN(T) Ve) *VKE] 45)

where A; (P,) are the eigenvalues (eigenprojectors) of the Hermitian operator
Xn —Xe- When C,(7) or C-(71) are not differentiable at 7m, then the above
expressions provide an element of the subgradient OC(7).

Proof We prove the above theorem assuming that the functions are
differentiable for program 7. For non-differentiable points, the only
difference is that the above analytical expressions are not unique and
provide only one of the possibly infinite elements of the subgradient.
Further details of this mathematical proof are given in Supplementary Note
4. Following matrix differentiation, for any function f(A) = Tr|g(A)] of a
matrix A, we may write

dTr[g(A)] = Tr{g'(A)dA], (46)

and the gradient is Vf(A) = g'(A). Both the trace distance and fidelity cost
functions can be written in this form. To find the explicit gradient of the
fidelity function, we first note that, by linearity, we may write

A(m + 6m) = A(t) + A(671) , (47)
and therefore the following expansion

VXeN t+ 6m) /Xe = VXeN(1)/Xe + VXeN(67) Xe - (48)

From this equation and differential calculations of the fidelity (see
Supplementary Note 4.2 for details), we find

dF — ; Tr (VEN m7) VXe) ?VKe (On) Ve | . (49)

where dF = F(7 + 67) — F(7). Then, using the cyclic property of the trace,
we get

dF = ; Tr IA" | Vke( VXEN(T) Ve) *VXe| é| (50)

Exploiting this expression in Eq. (46), we get the gradient VF(7) as in Eq.
(45). The other Eq. (44) simply follows from applying the definition in Eq.
(8).

For the trace distance, let us write the eigenvalue decomposition
Xn —Xe = > MePr (51)
k

Then using the linearity of Eq. (47), the definition of a processor map of Eq.
(5) and differential calculations of the trace distance (see Supplementary
Note 4.3 for details), we can write

dC; (m) = S¢sign(Ag) Tr [P,A(d77)]
k
= Yesign(A,) Tr [A* (Px) dz] (52)
k

= Tr{A"[sign(X, — Xe)]a7} .

npj Quantum Information (2020) 42
L. Banchi et al.

 

From the definition of the gradient in Eq. (46), we finally get
VCi (71) = A" |sign(X7 — Xe)], (53)

which leads to the result in Eq. (43). I

The above results in Eqs. (44) and (43) can be used together with the
projected subgradient method'* or conjugate gradient algorithm'”’'® to
iteratively find the optimal program state in the minimization of
minyesC(m) for C=C, or Cr. In the following sections, we present two
algorithms, the projected subgradient method and the conjugate gradient
method, and show how they can be adapted to our problem.

Projected subgradient methods have the advantage of simplicity and
the ability to optimize non-smooth functions, but can be slower, with a
convergence rate O(e*) for a desired accuracy ¢. Conjugate gradient
methods'”'® have a faster convergence rate O(e~'), provided that the
cost function is smooth. This convergence rate can be improved even
further to O(e 1/2) for strongly convex functions’* or using Nesterov’s
accelerated gradient method*'. The technical difficulty in the adaptation of
these methods for learning program states comes because the latter is a
constrained optimization problem, namely at each iteration step the
optimal program must be a proper quantum state, and the cost functions
coming from quantum information theory are, generally, non-smooth.

Projected subgradient method

Given the space S of program states, let us define the projection Ps onto
S as

Ps(X) = argmin ||X — ml, , (54)
mes

where argmin is the argument of the minimum, namely the closest state
m € S to the operator X. Then, a first-order algorithm to solve minjzesC(7)
is to apply the projected subgradient method'**”, which iteratively applies
the iteration (16), which we rewrite below for convenience

1) Select an operator g; from 0C(m7;),
(55)
2) Update 741 = Ps(mj — aig;),

where / is the iteration index and q; a learning rate.

The above algorithm differs from standard gradient methods in two
aspects: (i) the update rule is based on the subgradient, which is defined
even for non-smooth functions; (ii) the operator 77; — ajg; is generally not a
quantum state, so the algorithm fixes this issue by projecting that operator
back to the closest quantum state, via Eq. (54). The algorithm converges to
the optimal solution 7 (approximating the optimal program 77) as'*

e,+G)\4_,a
C(m) — C(m.) < CF Gd 41 =, (56)
2 K=1 A
where e; =|| Tr — 71, ||, is the initial error (in Frobenius norm) and G is

such that II gll3 <G for any g € OC. Popular choices for the learning rate
that assure convergence are a, « 1/Wk and a, = a/(b +k) for some a, b>
0.

In general, the projection step is the major drawback, which often limits
the applicability of the projected subgradient method to practical
problems. Indeed, projections like Eq. (54) require another full optimization
at each iteration that might be computationally intensive. Nonetheless, we
show in the following theorem that this issue does not occur in learning
quantum states, because the resulting optimization can be solved
analytically.

Theorem 3 Let X be a Hermitian operator in a d-dimensional Hilbert space
with spectral decomposition X = UxU", where the eigenvalues x; are ordered in
decreasing order. Then Ps(X) of Eq. (54) is given by

Ps(X) = UAU', A; = max{x; — 0,0}, (57)
where @ = 15°(x;—1) and
j=1

_~

k
s= nan € [1,... Lt 1} (58)

Proof Any quantum (program) state can be written in the diagonal form
m= VAV', where V is a unitary matrix, and A is the vector of eigenvalues in
decreasing order, with A ;=0 and YA;=1. To find the optimal state, it is
required to find both the optimal unitary V and the optimal eigenvalues A
with the above property, i.e.,

Ps(X) = argmin ||X — VAV' ||. . (59)
V,

npj Quantum Information (2020) 42

For any unitarily invariant norm, the following inequality holds (ref. *°, Eq.
IV.64):

|X — am], =||x -All., (60)

with equality when U = V, where X = UxU' is a spectral decomposition of X
such that the x;s are in decreasing order. This shows that the optimal
unitary in Eq. (59) is the diagonalization matrix of the operator X. The
eigenvalues of any density operator form a_ probability simplex.
The optimal eigenvalues A are then obtained thanks to Algorithm 1 from
ref. |”.

In the following section, we present an alternative algorithm with faster
convergence rates, but stronger requirements on the function to be
optimized.

Conjugate gradient method

The conjugate gradient metho , sometimes called the Frank-Wolfe
algorithm, has been developed to provide a better convergence speed and
to avoid the projection step at each iteration. Although the latter can be
explicitly computed for quantum states (thanks to our Theorem 3), having
a faster convergence rate is important, especially with higher dimensional
Hilbert spaces. The downside of this method is that it necessarily requires a
differentiable cost function C, with gradient VC.

In its standard form, the conjugate gradient method to approximate the
solution of argmin,.;C(7) is defined by the following iterative rule

1) Find argmin,.s Tr [oVC(7;)],

2) Tiny = Ti +35 (o —1;) = Ti +450.

15,39
d

(61)

The first step in the above iteration rule is solved by finding the smallest
eigenvector |o) of VC(z7)). Indeed, since 7 is an operator and C(7) a scalar,
the gradient VC is an operator with the same dimension as 77. Therefore,
for learning quantum programs, we find the iteration (17), that we rewrite
below for convenience

1) Find the smallest eigenvalue |o;) of VC(77),
5 (62)
Tis) =
) i+] 7) Ti +>
When the sjadient of C is Lipschitz continuous with constant L, the
conjugate gradient method converges after O(L/e) steps'®*'. The
following iteration with adaptive learning rate a; has even faster
convergence rates, provided that C is strongly convex”:

5 01) (orl.

1) Find the smallest eigenvalue |o;) of VC(77;),

2) Find aj = argmingeyo14(ti, VC(m))
+a? 6 || i|[C, fort, = |oi) (oi| — mi,

3) Tis. = (1 — Qj); + aj|0;) (oj|.

where the constant Bc and norm || - ||- depend on C (ref. >’).

In spite of the faster convergence rate, conjugate gradient methods
require smooth cost functions (so that the gradient VC is well defined at
every point). However, cost functions based on trace distance (7) are not
smooth. For instance, the trace distance in one-dimensional spaces
reduces to the absolute value function |x| that is non-analytic at x =0.
When some eigenvalues are close to zero, conjugate gradient methods
may display unexpected behaviors, though we have numerically observed
that convergence is always obtained with a careful choice of the learning
rate. In the next section, we show how to formally justify the applicability
of the conjugate gradient method, following Nesterov’s smoothing
prescription”

Smoothing: smooth trace distance

The conjugate gradient method converges to the global optimum after
O(5) steps, provided that the gradient of C is L-Lipschitz continuous*'.
However, the constant L can diverge for non-smooth functions like the
trace distance (7) so the convergence of the algorithm cannot be formally
stated, although it may still be observed in numerical simulations. To
solidify the convergence proof (see also Supplementary Note 5.2), we
introduce a smooth approximation to the trace distance. This is defined by
the following cost function that is differentiable at every point

Cy (7) = Tr [Au (Xn — Xe)| = > hal) , (64)
J

where A; are the eigenvalues of x, —X¢ and h, is the so-called Huber

Published in partnership with The University of New South Wales
penalty function

2

2
hy (x) := | 4
2

The previous definition of the trace distance, C, in Eq. (7), is recovered for
uu — 0 and, for any non-zero pu, the C, bounds C;, as follows
ud
2 )
where d is the dimension of the program state 77. In Supplementary Note
5.2, we then prove the following result

Theorem 4 The smooth cost function C,(m) is a convex function over
program states and its gradient is given by

VG, (7) = ALA (Xn — Xe)] (67

where hi, is the derivative of h,. Moreover, the gradient is L-Lipschitz
continuous with

if |x| <p,

(65)
if |x| <p.

Cult) < C(t) < Cult) + (66)

L=-—
U ’

where d is the dimension of the program state.

Being Lipschitz continuous, the conjugate gradient algorithm and its
variants*'°* converge up to an accuracy e after O(L/e) steps. In some
applications, it is desirable to analyze the convergence in trace distance in
the limit of large program states, namely for d > oo. The parameter pi can
be chosen such that the smooth trace distance converges to the trace
distance, namely C, > C, for d > o. Indeed, given the inequality (66), a
possibility is to set u = O(a") for some n > 0 so that, from Eq. (68), the
convergence to the trace norm is achieved after O(d?"") steps.

(68)

DATA AVAILABILITY

The datasets generated and analyzed during the current study are available from the
corresponding author on reasonable request.

CODE AVAILABILITY

The codes used for this study are available from the corresponding author on
reasonable request.

Received: 21 November 2019; Accepted: 25 March 2020;
Published online: 19 May 2020

REFERENCES

1. Nielsen, M. A. & Chuang, |. L. Programmable quantum gate arrays. Phys. Rev. Lett.
79, 321 (1997).

2. Nielsen, M. A. & Chuang, |. L. Quantum Computation and Quantum Information
(Cambridge University Press, Cambridge, 2000).

3. Watrous, J. The Theory of Quantum Information (Cambridge Univ. Press, 2018).

4. Knill, E., Laflamme, R. & Milburn, G. J. A scheme for efficient quantum compu-
tation with linear optics. Nature 409, 46 (2001).

5. Bishop, C. M. Pattern Recognition and Machine Learning (Springer, 2006).

6. Wittek, P. Quantum Machine Learning: What Quantum Computing Means to Data
Mining (Academic Press, Elsevier, 2014).

7. Biamonte, J. et al. Quantum machine learning. Nature 549, 195 (2017).

8. Dunjko, V. & Briegel, H. J. Machine learning & artificial intelligence in the quantum
domain: a review of recent progress. Rep. Prog. Phys. 81, 074001 (2018).

9. Schuld, M., Sinayskiy, |. & Petruccione, F. An introduction to quantum machine
learning. Contemp. Phys. 56, 172-185 (2015).

10. Ciliberto, C. et al. Quantum machine learning: a classical perspective. Proc. R. Soc.
A 474, 20170551 (2018).

11. Tang, E. A quantum-inspired classical algorithm for recommendation systems. In
Proceedings of the 51st Annual ACM SIGACT Symposium on Theory of Com-
puting (STOC 2019). Association for Computing Machinery, New York, NY, USA,
217-228. https://doi.org/10.1145/3313276.3316310 (2019).

12. Tang, E. Quantum-inspired classical algorithms for principal component analysis
and supervised clustering. Preprint at https://arxiv.org/abs/181 1.00414 (2018).

13. Kitaev, A. Y., Shen, A. & Vyalyi, M. N. Classical and Quantum Computation, 47
(American Mathematical Society, Providence, Rhode Island, 2002).

14. Boyd, S., Xiao, L. & Mutapcic, A. “Subgradient methods.” lecture notes of EE392o0,
Stanford University, Autumn Quarter 2004 (2003):2004-2005.

Published in partnership with The University of New South Wales

L. Banchi et al.

 

15.

16.

17.

18.

19.

20.

21.

22.
23.

24.

25.

26.

27.

28.

29.

30.

31.

32.

33.

34.

35.

36.

37.

38.

39.

40.

41.

42.

43.

AA,

45.

46.

47.

48.

49.

Jaggi, M. Convex optimization without projection steps. Preprint at https://arxiv.
org/abs/1108.1170 (2011).

Jaggi, M. Revisiting frank-wolfe: projection-free sparse convex optimization. In
Proceedings of the 30th International Conference on International Conference on
Machine Learning, Vol 28 |-427(2013).

Duchi, J., Shalev-Shwartz, S., Singer Y. & Chandra, T. Efficient projections onto the
| 1-ball for learning in high dimensions. In Proceedings of the 25th international
conference on Machine learning, 272-279 (ACM, 2008).

Liu, J., Musialski, P., Wonka, P. & Ye, J. Tensor completion for estimating missing
values in visual data. IEEE Trans. Pattern Anal. Mach. Intell. 35, 208-220 (2013).
Ishizaka, S. & Hiroshima, T. Asymptotic teleportation scheme as a universal pro-
grammable quantum processor. Phys. Rev. Lett. 101, 240501 (2008).

Ishizaka, S. & Hiroshima, T. Quantum teleportation scheme by selecting one of
multiple output ports. Phys. Rev. A 79, 042306 (2009).

Ishizaka, S. Some remarks on port-based teleportation. Preprint at https://arxiv.
org/abs/1506.01555 (2015).

Lloyd, S. Universal quantum simulators. Science 273, 1073-1078 (1996).
Pirandola, S., Laurenza, R., Ottaviani, C. & Banchi, L. Fundamental limits of
repeaterless quantum communications. Nat. Commun. 8, 15043 (2017).
Pirandola, S. et al. Theory of channel simulation and bounds for private com-
munication. Quant. Sci. Tech 3, 035009 (2018).

Nechita, |., Puchata, Z., Pawela, £. & Zyczkowski, K. Almost all quantum channels
are equidistant. J. Math. Phys. 59, 052201 (2018).

Fuchs, C. A. & van de Graaf, J. Cryptographic distinguishability measures for
quantum-mechanical states. /EEE Trans. Info. Theory 45, 1216-1227 (1999).
Pinsker, M. S. Information and information stability of random variables and pro-
cesses (Holden-Day, San Francisco, 1964).

Carlen, E. A. & Lieb, E. H. Bounds for entanglement via an extension of strong
subadditivity of entropy. Lett. Math. Phys. 101, 1-11 (2012).

Watrous, J. Semidefinite programs for completely bounded norms. Theory
Comput. 5, 217-238 (2009).

Watrous, J. Simpler semidefinite programs for completely bounded norms. Chi-
cago J. Theor. Comput. Sci. 8, 1-19 (2013).

Vandenberghe, L. & Boyd, S. Semidefinite programming. SIAM Rev. 38, 49-95
(1996).

Chao, H.-H. First-Order Methods for Trace Norm Minimization (University of Cali-
fornia, Los Angeles, 2013).

Monteiro, R. D. C. First-and second-order methods for semidefinite programming.
Math. Program. 97, 209-244 (2003).

Spall, J. C. Adaptive stochastic approximation by the simultaneous perturbation
method. /EEE Trans. Automat. Contr. 45, 1839-1853 (2000).

Zhuang, Q. & Zhang, Z. Physical-layer supervised learning assisted by an
entangled sensor network. Phys. Rev. X 9, 041023 (2019).

Harrow, A. & Napp, J. Low-depth gradient measurements can improve con-
vergence in variational hybrid quantum-classical algorithms. Preprint at https://
arxiv.org/abs/1901.05374 (2019).

Cai, J.-F., Candés, E. J. & Shen, Z. A singular value thresholding algorithm for
matrix completion. SIAM J. Optimiz. 20, 1956-1982 (2010).

Recht, B., Fazel, M. & Parrilo, P. A. Guaranteed minimum-rank solutions of linear
matrix equations via nuclear norm minimization. SIAM Rev. 52, 471-501 (2010).
Nesterov, Y. Introductory Lectures on Convex Optimization: A Basic Course, Vol 87
(Springer Science & Business Media, New York, 2013).

Coutts, B., Girard, M. & Watrous, J. Certifying optimality for convex quantum
channel optimization problems. Preprint at https://arxiv.org/abs/1810.13295
(2018).

Nesterov, Y. Smooth minimization of non-smooth functions. Math. Program. 103,
127-152 (2005).

Khaneja, N., Reiss, T., Kehlet, C., Schulte-Herbriiggen, T. & Glaser, S. J. Optimal
control of coupled spin dynamics: design of nmr pulse sequences by gradient
ascent algorithms. J. Magn. Reson. 172, 296-305 (2005).

Banchi, L., Pancotti, N. & Bose, S. Quantum gate learning in qubit networks: toffoli
gate without time-dependent control. npj Quantum Info. 2, 16019 (2016).
Innocenti, L. Banchi, L. Ferraro, A. Bose S. & M. Paternostro, M. Supervised learning
of time-independent hamiltonians for gate design. New J. Phys. (in press) https://
doi.org/10.1088/1367-2630/ab8aaf (2020).

Mitarai, K., Negoro, M., Kitagawa, M. & Fujii, K. Quantum circuit learning. Phys. Rev.
A 98, 032309 (2018).

Bennett, C. H. et al. Teleporting an unknown quantum state via dual classical and
einstein-podolsky-rosen channels. Phys. Rev. Lett. 70, 1895 (1993).

Pirandola, S., Eisert, J., Weedbrook, C., Furusawa, A. & Braunstein, S.L. Advances in
quantum teleportation. Nat. Photon. 9, 641-652 (2015).

Pirandola, S., Laurenza, R., Lupo, C. & Pereira, J. L. Fundamental limits to quantum
channel discrimination. npj Quantum Info 5, 50 (2019).

Lloyd, S. Almost any quantum logic gate is universal. Phys. Rev. Lett. 75, 346
(1995).

npj Quantum Information (2020) 42

Np}
Np)

L. Banchi et al.

 

10

50. D’Ariano, G. M. & Perinotti, P. Efficient universal programmable quantum mea-
surements. Phys. Rev. Lett. 94, 090401 (2005).

51. Pirandola, S., Bardhan, B. R., Gehring, T., Weedbrook, C. & Lloyd, S. Advances in
photonic quantum sensing. Nat. Photon 12, 724-733 (2018).

52. Uhlmann, A. The transition probability. Rep. Math. Phys. 9, 273-279 (1976).

53. Duchi, J., Hazan, E. & Singer, Y. Adaptive subgradient methods for online learning
and stochastic optimization. J. Mach. Learn. Res. 12, 2121-2159 (2011).

54. Garber, D. & Hazan, E. Faster rates for the frank-wolfe method over strongly-
convex sets. In Proceedings of the 32nd International Conference on International
Conference on Machine Learning, Vol 37, 541-549 (2015).

55. Bhatia, R. Matrix Analysis, Vol 169 (Springer Science & Business Media, New York, 2013).

ACKNOWLEDGEMENTS

L.B. acknowledges support by the program "Rita Levi Montalcini” for young
researchers. S.P. and J.P. acknowledge support by the EPSRC via the ‘UK Quantum
Communications Hub’ (Grants EP/M013472/1 and EP/T001011/1), and S.P. acknowl-
edges support by the European Union via the project ‘Continuous Variable Quantum
Communications’ (CiViQ, no 820466).

AUTHOR CONTRIBUTIONS

All authors contributed to prove the main theoretical results and to the writing of the
manuscript.

COMPETING INTERESTS

The authors declare no competing interests

npj Quantum Information (2020) 42

ADDITIONAL INFORMATION

Supplementary information is available for this paper at https://doi.org/10.1038/
$41534-020-0268-2.

Correspondence and requests for materials should be addressed to L.B.

Reprints and permission information is available at http://www.nature.com/
reprints

Publisher’s note Springer Nature remains neutral with regard to jurisdictional claims
in published maps and institutional affiliations.

Open Access This article is licensed under a Creative Commons

ri Attribution 4.0 International License, which permits use, sharing,
adaptation, distribution and reproduction in any medium or format, as long as you give
appropriate credit to the original author(s) and the source, provide a link to the Creative
Commons license, and indicate if changes were made. The images or other third party
material in this article are included in the article’s Creative Commons license, unless
indicated otherwise in a credit line to the material. If material is not included in the
article’s Creative Commons license and your intended use is not permitted by statutory
regulation or exceeds the permitted use, you will need to obtain permission directly
from the copyright holder. To view a copy of this license, visit http://creativecommons.
org/licenses/by/4.0/.

© The Author(s) 2020

Published in partnership with The University of New South Wales
