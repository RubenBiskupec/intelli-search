Computers and Electronics in Agriculture 179 (2020) 105817

 

    

Contents lists available at ScienceDirect

Cyn eC a
and electronics

ra Ui g=)
Computers and Electronics in Agriculture : oes
ELSEVIER journal homepage: www.elsevier.com/locate/compag a

 

 

computing with deep learning EDANet

Check for

Adaptive autonomous UAV scouting for rice lodging assessment using edge |:

Ming-Der Yang a,b Jayson G. Boubin” *, Hui Ping Tsai a,b, Hsin-Hung Tseng asd,"

Yu-Chun Hsu“*”, Christopher C. Stewart ‘

* Department of Civil Engineering, and Innovation and Development Center of Sustainable Agriculture, National Chung Hsing University, Taichung 402, Taiwan

> Pervasive AI Research (PAIR) Labs, Hsinchu 300, Taiwan
© Department of Computer Science, The Ohio State University, Columbus, OH 43210, USA

 

ARTICLE INFO ABSTRACT

 

 

Keywords:
Autonomous UAV
Deep learning
Edge computing
Rice lodging
Adaptive

Rice is a globally important crop that will continue to play an essential role in feeding our world as we grapple
with climate change and population growth. Lodging is a primary threat to rice production, decreasing rice yield,
and quality. Lodging assessment is a tedious task and requires heavy labor and a long duration due to the vast
land areas involved. Newly developed autonomous crop scouting techniques have shown promise in mapping
crop fields without any human interaction. By combining autonomous scouting and lodged rice detection with
edge computing, it is possible to estimate rice lodging faster and at a much lower cost than previous methods.
This study presents an adaptive crop scouting mechanism for Autonomous Unmanned Aerial Vehicles (UAV). We
simulate UAV crop scouting of rice fields at multiple levels using deep neural networks and real UAV energy
profiles, focusing on areas with high lodging. Using the proposed method, we can scout rice fields 36% faster
than conventional scouting methods at 99.25% accuracy.

 

1. Introduction

Rice, Oryza sativa L., is an essential staple crop worldwide and has a
significant impact on world politics and economics. Under the effects of
global climate change and a world population increase by 2 billion
persons in the next 30 years (Brown and FuC, 2008; Pison, 2019),
maintaining stable rice production is a priority task for many countries
to maintain food security. Many studies have shown that rice lodging is
the primary factor that weakens rice production. Lodging reduces
photosynthesis (Setter et al., 1997), decrease yield (Lang et al., 2012),
and significantly diminishes rice quality (Zeng et al., 2017). A large
number of studies address rice lodging problems from a cultivation
perspective analyzing the mechanisms and the causes of rice lodging
(Ookawa et al., 2010; Okuno et al., 2014). In contrast, other studies
concentrate on developing effective methods to assess rice lodging
(Ogden et al., 2002; Yang et al., 2017; Liu et al., 2018). Traditional rice
lodging assessment relies heavily on manual in situ assessment and
random sampling (Yang et al., 2017); however, the traditional manual

assessment method has significant drawbacks. Typically, a preliminary
disaster valuation, a comprehensive investigation, and a review sam-
pling assessment are needed to complete a rice lodging assessment,
which may take approximately 1 to 2 months to accomplish in total.
Consequently, the rice field cannot be replanted, and the field owner’s
livelihood is dramatically impacted. Additionally, the delineation of the
rice lodging area is performed by officers manually, which is prone to
subjectivity and frequently leads to controversies. Lastly, due to the vast
land areas involved in natural disasters, the traditional manual assess-
ment faces challenges of high labor cost and efficiency. An effective rice
lodging assessment method is urgently needed.

Remote sensing techniques like satellite imagery provide a feasible
solution to investigate rice lodging over vast areas of land (Liu et al.,
2018). Nonetheless, satellite images are usually limited by their spatial
and temporal resolution, as well as their spectral band features (Nelson
et al., 2014). Additionally, cloud contamination can limit the usability of
optical satellite images as thick clouds can completely occlude target
landscapes. In recent years, utilizing unmanned aerial vehicle (UAV)

* Corresponding authors at: Department of Civil Engineering, and Innovation and Development Center of Sustainable Agriculture, National Chung Hsing Uni-

versity, Taichung 402, Taiwan (H.P. Tsai, H.-H. Tseng) and Department of Computer Science, The Ohio State University, Columbus, OH 43210, USA (J. G. Boubin).

E-mail addresses: mndyang@nchu.edu.tw (M.-D. Yang), boubin.2@buckeyemail.osu.edu (J.G. Boubin), huiping.tsai@nchu.edu.tw (H.P. Tsai), d108062001 @mail.
nchu.edu.tw (H.-H. Tseng), d107062002@mail.nchu.edu.tw (Y.-C. Hsu), cstewart@cse.ohio-state.edu (C.C. Stewart).

https://doi.org/10.1016/j.compag.2020.105817

Received 18 July 2020; Received in revised form 30 September 2020; Accepted 1 October 2020

Available online 12 October 2020
0168-1699/© 2020 The Authors.

(http://creativecommons.org/licenses/by-nce-nd/4.0/).

Published by Elsevier

B.V. This is an _ open

access article under the CC BY-NC-ND license
M.-D. Yang et al.

technology to obtain timely information on crop lodging has created
numerous opportunities due to UAVs ability to fly in cloudy conditions
(Zheng et al., 2020). UAVs can be equipped with high-spatial-resolution
cameras to collect high spatial aerial red-green-blue (RGB) images for
crop lodging assessment. The capability of UAV to obtain high spatial
accuracy aerial images is complemented by the benefit of a global
positioning system (GPS) and inertial navigation system (INS) technol-
ogy. Yang et al. (2017) used UAV images combined with a spatial and
spectral mixed image classification method, which classified rice lod-
ging at 96.17% accuracy. Based on UAV images, Chu et al., 2017 pro-
duced a 3D canopy height model to detect corn lodging severity
depending on height percentiles against preset thresholds. Later, Chu
et al. (2017) developed a lodging index to automatically reflect the
severity of corn lodging and yield after harvesting. Liu et al. (2018)
combined thermal infrared images with UAV images to identify lodging
rice, which has a false positives rate and a false negative rate of less than
10%.

In the meantime, the development of deep learning techniques has
achieved evident results in agriculture applications (Kamilaris and
Prenafeta-Boldu, 2018). Chu and Yu (2020) developed an end-to-end
prediction model by fusing two back-propagation neural networks
(BPNNs) with an independently recurrent neural network (IndRNN) for
rice yield prediction. Wang et al. (2020) proposed a deep learning and
depth camera combined solution to improve UAV environmental
perception and autonomous obstacle avoidance. Zhao et al. (2019) used
a deep learning U-shaped Network (UNet) architecture for rice lodging,
with results showing that the dice coefficients on the RGB and multi-
spectral datasets reach 0.942 and 0.9284, respectively. Yang et al.
(2019) compared vegetation index (VI) with a convolutional neural
network (CNN) based approach for rice grain yield estimation at the
ripening stage using UAV images. The results show that this CNN based
approach performs much better than the VI-based regression model.
Yang et al. (2020) applied deep-learning to UAV images to estimate rice
lodging in paddies over a large area. The semantic segmentation net-
works, including FCN-AlexNet and SegNet, are proven to have lower
latency, approximately 10 to 15 times faster, and a lower misinterpre-
tation rate than that of the maximum likelihood method. However, the
studies, as mentioned earlier, all perform their analysis from an offline
approach. Few applications attempt real-time rice lodging assessment.
Mardanisamani et al. (2019) presented a deep convolutional neural
network (DCNN) architecture using a transfer learning technique for
lodging classification, which achieves comparable results while having a
substantially lower number of parameters. The author emphasized that
DCNN can be deployed on low-cost hardware, which can be suitable for
real-time applications.

Recently, the development of edge computing devices and tech-
niques has improved researchers’ ability to process large amounts of
data in a real-time manner without offloading to the cloud (Satyanar-
ayanan, 2017). The usage of graphical processing units (GPUs) for deep
learning and the availability of powerful processors at the edge allow
practitioners to analyze data quickly without the cloud. Edge computing
has been used to advance many emerging research areas in Computer
Science, from the internet of things (IoT) applications (Atzori et al.,
2010) to smart homes (Alam et al., 2012) and smart cities (Burange and
Misalkar, 2015).

Edge computing has also been applied to agricultural scouting ap-
plications. Vasisht et al. (2017) used edge computing techniques to
create FarmBeats, a novel precision agriculture platform that gathers
data from sensors, cameras, and drones to enable precision agriculture
techniques. Instead of transmitting all data to the cloud, a local com-
puter or laptop device is used to process drone imagery data, which
corresponds to the concept of edge computation (Yousefpour et al.,
2019). As shown in Fig. 1, the connection of edge computing nodes to
sensors like UAVs provides advantages, including high mobility,
simplicity, interactivity, and responsiveness. Additionally, a simplified
ad hoc NN (neural network) can be implemented for a specific purpose/

Computers and Electronics in Agriculture 179 (2020) 105817

ere e-em lay

   
   

> Information complexity
Oo Computation power
Comprehensive NN
penditure
—
i
f
(
\
\ Sensors
\
\
\

 

}
\ Edge computing
“a nodes

Mobility
Simplicity
Ad hoc NN

High

Interactivity
Responsivity

Low

Fig. 1. Comparison of functions of edge computation and cloud-based system.

target. In contrast, several challenges, such as high communication la-
tency and information complexity, need to be considered in the cloud-
based system. In the present study, the connection of edge computing
nodes to sensors is taken as the primary focus on developing an effective
rice lodging assessment method.

Precision agriculture techniques like satellite imagery, UAV scan-
ning, and even advanced platforms like FarmBeats are all linked in that
they are automated. These approaches perform low-level tasks without
human decision-making but require high-level human planning to
perform well. Advancements at the edge allow for more complex au-
tonomy policies to be implemented, allowing for autonomous, rather
than automated systems to perform agricultural scouting and manage-
ment tasks. Early attempts at fully autonomous precision agriculture
using fully autonomous aerial systems (FAAS) have been implemented
(Boubin et al., 2019a; Boubin et al., 2019b), and early fully autonomous
precision agriculture software is available (Boubin et al., 2019c). Boubin
et al. (2019) presented an open-source software package for FAAS,
which includes autonomous UAV routines for agricultural scouting and
demonstrates that fully autonomous routines can benefit significantly
from correct edge compute architectures and autonomy policies (Boubin
et al., 2019a; Boubin et al., 2019b). Simulated approaches to FAAS have
also been demonstrated. Boubin et al. (2019b) show that given appro-
priate pathfinding algorithms and autonomy policies, accurate yield
maps of crop fields can be generated by viewing only 40% of a field,
saving power, time, and money for the farmer. Combining FAAS tech-
niques with deep learning at the edge may greatly impact future preci-
sion agriculture techniques.

In this study, an effective rice lodging assessment method is proposed
by combining deep learning and FAAS techniques with UAV images.
Notably, the EDANet model was trained to study rice lodging informa-
tion extracted by conventional digital RGB images. Three UAV scouting
approaches, namely 200 m high altitude scouting, 50 m low altitude
scouting, and an adaptive fly height, are investigated, and the corre-
sponding energy consumption and rice lodging accuracy are assessed.
Specifically, the following contributions of this paper are highlighted as
follows.

1. An adaptive autonomous UAV scouting technique utilizing EDANet,
a deep learning model, is proposed to assess rice lodging. The
adaptive autonomous UAV scouting mechanism is designed based on
M.-D. Yang et al.

a threshold-based rice lodging assessment derived from the EDANet
model.

2. Visible spectrum information and three vegetation indices are
extracted and calculated from UAV images collected from two real
rice lodging occasions in Taiwan. Both visible spectrum information
and vegetation indices were used for EDANet model training and
testing.

3. The proposed adaptive autonomous UAV scouting approach is
compared with the other two approaches - 50 m low altitude
scouting and 200 m high altitude scouting - in terms of associated
rice lodging identification accuracy and scouting time.

4. The comparison of three approaches is performed in a simulation-
based research software SoftwarePilot, in which an autonomy cube
data structure (Boubin et al., 2019c) links UAV images with spatial
information and an energy profiling using DJI Phantom 4 Pro (P4P)
is applied.

5. Through a series of lodged percentage threshold settings for the
simulator, our proposed adaptive autonomous UAV scouting
approach demonstrates excellent performance in significantly
reducing scouting time and preserving relatively high rice lodging
identification accuracy.

The remainder of this paper is organized as follows. Section 2 de-
scribes our experimental methods, datasets, machine learning process,
and adaptive scanning algorithm. Section 3 provides results from ex-
periments. Section 4 discusses the results, their impact, and future work.
Section 5 provides conclusions.

2. Materials and methods

Two rice lodging occasions associated with massive rainfall events in
June 2017 and May 2019 in the Mozi Shield Park in Wufeng District,
Taichung City, Taiwan, were investigated. Visible spectrum information
of the field was collected in June 2017 by a fixed-wing UAV and in May
2019 by a rotary-wing UAV for training and testing, respectively.
Detailed camera, flight height, area covered, training, and testing
dataset information are shown in Table 1. All UAV collected images
were mosaicked using Agisoft Metashape software and processed with
image tile generating using Python for semantic segmentation model
input purposes.

Besides normalized visible spectrum information of Rn (normalized
red), Gn (normalized green) and Bn (normalized blue), three vegetation
indexes, Excess Green index (ExG), Excess Red index (ExR), and Excess
Green minus Excess Red index (ExGR), were calculated for the training
and testing datasets (Woebbecke et al., 1995; Meyer and Neto, 2008).
Formulas of these three vegetation indices are listed below.

ExG=2xG,—R,—B,

ExR=14xR,-—G,

Table 1
Detail of training and testing datasets.

Training dataset Testing dataset

Camera/Platform Sony QX-100/SV- DJI Phantom 4 Pro
1000A

Collection Date 2017 / 06 / 08 2019 / 05 / 2019 /05
21 [23

Resolution(width*height) 46,343 * 25,658 5472 * 3648

Flight Height (m) 200 50 200

Area covered (ha) 430 4.4 120

GSD (cm) 5.3 1.3 5.7

Tile resolution(col * row) 480 * 480 1349 * 899 5472 *

pixels 3648
# effective tiles 3485 220 65
# tiles in col * row 96 * 53 - -

Computers and Electronics in Agriculture 179 (2020) 105817

ExGR=ExG—-ExR=3xG,-—2.4xR,—B,

2.1. Semantic segmentation model training

We used an implementation of the Efficient Dense modules with
Asymmetric convolution network (EDANet) developed by Lo et al.
(2019) to detect rice lodging. The network architecture of EDANet is
shown in Fig. 2, which is comprised of three major components,
including three downsampling blocks, which are adopted from the ENet
initial block (Basu and Woodard, 2016), two EDA blocks consist of 5 and
8 EDA modules respectively, and one projection layer. With the special
two-branch design of the downsampling layers, module-level dense
connectivity inspired by DenseNet (Huang et al., 2017), and a specific
dilated asymmetric convolution technique, EDANet outperforms many
state-of-art systems with high efficiency at low computational cost and
model size (Lo et al. 2019), which makes EDANet a promising network
for real-time semantic segmentation.

In the present study, the EDANet was trained using Adam optimizer
with weight decay 1le-4, batch size 10, for 50 epochs. As suggested by Lo
et al. (2019), the initial learning rate (init_Ir) was set to 5e-4, and a
polynomial learning rate policy was employed with power 0.9 for the
learning rate of each iteration Irie, in formula (4).

Ijer = init_Ir*(1— iter/max_iter)!"™" (4)

The model training environment information is shown in Table 2
below. The EDANet model performance was evaluated using five metrics
listed in Table 3: Precision, Recall, Accuracy, Overall accuracy, and F1
score. These metrics are expressed through the calculated TP (True
Positives), TN (True Negatives), FP (False Positives), and FN (False
Negatives) for any given class c (Dong et al. 2019; Papadomanolaki et al.
2019).

2.2. UAV scouting

To gain an accurate assessment of rice lodging, fields must be scouted
in their entirety to determine the percent of total lodged crops
throughout. When scouting an area, operators must concern themselves
with a number of factors, of which UAV battery life and image ground
sample distance (GSD) are principal. UAV batteries are highly con-
strained, lasting for flight times between 20 and 40 min depending on
the UAV model. We define one UAV flight as one full discharge of the
UAV battery by assuming that the UAV takes off with a full battery and
ends the flight with an empty battery. Mapping a field of considerable
size may require many flights over hours to days, depending on the
number of UAVs and batteries available, their recharge time, and GSD.
Flight times can be decreased by increasing UAV altitude, which will, in
turn, increase GSD.

GSD, and consequently, flight altitude and camera quality, must be
considered. Image quality and clarity directly influence the ability of
subject matter experts and machine learning algorithms to detect field
abnormalities (Yang et al., 2011; Yang et al., 2018). When scouting for
lodged rice, it is important to assure that all regions of the field can be
accurately classified, and consequently, each image must have a GSD
high enough to allow this. Given that raising GSD increases scouting
time (independent of camera quality), a tradeoff emerges. Crop scouters
must simultaneously balance detection accuracy and total scouting time,
which can lead to increased costs, respectively, from unsubsidized lost
crops, labor, and equipment.

Three mapping strategies are shown in Fig. 3 to demonstrate these
differences. For a small section of a field (requiring 36 images to fully
map at low altitude and four at high altitude), we outline three mapping
strategies: high altitude, low altitude, and adaptive scouting. Low alti-
tude and high altitude scouting exhibit the two principal differences
previously described. Low altitude scouting requires significantly more
energy and time to complete its task, requiring a second UAV mission in
M.-D. Yang et al.

Input

  

Projection Layer

Downsampling Block [ EDA Module

Computers and Electronics in Agriculture 179 (2020) 105817

Output

 
   

EDA Block

Fig. 2. EDANet architecture. (Figure adapted from Lo et al. (2019)).

Table 2
Model training environment information.
CPU Intel Xeon Gold 6154 @3.00 GHz (4 cores/GPU node)
RAM 90 GB/GPU node
Accelerator NVIDIA Tesla V100 GB SMX2/GPU node
Image TensorFlow-1.0py3
Libraries Python 3.6.8, NumPy 1.14.5, scikit-image 0.16.1, Keras 2.3.2,

TensorFlow-GPU 1.14, Jupiter notebook, CUDA 10.1

 

Table 3
Model performance evaluation metrics.
Evaluation Formula
Metrics
Precision recision. <<
P ¢ TP, + FP,
Recall recall. — TP,
‘ ~ TP, + FN,
Accuracy accuracy, — TP. + TN;
Ye TP, + TN. + FP, + FN,
Overall n P
OA = yt, ——
accuracy duc=1 TP, + TN; + FP, + FN,
F, score __ 2 x Precision x Recall

FE, =
' Precision + Recall
Notes TP (True Positives), TN (True Negatives), FP (False Positives) and

FN (False Negatives)

this scenario to take each picture. In contrast, high altitude scouting is
capable of capturing the entire section of the field in only four images.

The tradeoff, however, is that high altitude scouting is less capable of
predicting lodging. It can not properly guarantee the correctness of its
predictions at its decreased GSD. We can see in Fig. 3 that high altitude
scouting mispredicts lodging in a number of regions. Given the high GSD
of low altitude scouting, we can accept its lodging predictions as cred-
ible. A strategy that combines the high accuracy of low altitude scouting
and the low energy costs of high altitude scouting could be dominant. In
this paper, we present an autonomous scouting procedure that uses high
altitude scouting to inform selective low altitude scouting.

2.3. Autonomous scouting

Autonomous scouting allows UAVs to make decisions on where to
scan for high GSD images based on potentially inaccurate, but infor-
mative predictions from low GSD scouts at high altitude. In short, UAVs
scout the field at high altitude first. An edge system analyzes these im-
ages in situ, then uses machine learning to determine positions to
investigate at low altitudes based on classification accuracy and

certainty.

Fig. 4 shows how autonomous scouting can help balance the accu-
racy of low altitude scouting with the energy efficiency of high altitude
scouting. The UAV first performs a high altitude scan and predicts lod-
ging in each region of the field at the edge. Once lodged areas are
classified at the high altitude, the UAV investigates all lodged areas at
the low altitude. In this example scenario, the UAV can gain a 100%
accurate picture of lodging in the field subsection by using half the en-
ergy of low-altitude scouting.

Autonomous scouting does, however, include a substantive hard-
ware addition to the above requirements for both high and low altitude
automated scouting procedures. Automated scouting can be done by a
pilot or lightweight edge system. Images do not need to be processed
locally, so simple systems are sufficient. Autonomous scouting, however,
requires an edge system capable of controlling the UAV and executing
simplified machine learning algorithms within a reasonable time-frame,
which would require a hardware accelerator such as a GPU.

Fig. 4 describes the autonomous scouting algorithm in detail. For this
scenario, we define the high altitude scouting height as 200 m, and the
low altitude scouting height as 50 m. There are six key steps to complete
an entire mission.

1. UAV must map at least one high altitude section of the field. This
entails the UAV flying to a GPS waypoint at the center of the 200 m
region being mapped and capturing an image.

2. Once the edge system downloads images of at least one region,
machine learning is used to predict rice lodging in regions of high
altitude images. Each image is decomposed into subsections that
correspond to a possible 50 m image (i.e., a 200 m image decomposes
into 16 50 m subsections). Each region is then given a certain lodged
percentage (i.e., the percentage of pixels in that region represents
lodged rice). Regions are then marked as uncertain if their lodged
percentage is above a user-provided threshold. Uncertain regions are
regions that must be explored further to accurately gauge lodging.

3. Once all regions are predicted, our system finds the most efficient
route in which a UAV can fly to visit all uncertain regions. To do this,
the edge system calculates the least cost Hamiltonian path between a
fully connected graph whose vertices include the UAV’s current
position and all uncertain regions. This Hamiltonian path is then
remapped to a UAV flight path, such that the UAV flies to each un-
certain region once (Gurevich and Shelah 1987).

4. The UAV descends from its 200 m height and flies to the next region
in the Hamiltonian path at 50 m altitude.

5. The UAV then captures a 50 m image of each uncertain region, flying
along the prescribed Hamiltonian flight path.
M.-D. Yang et al. Computers and Electronics in Agriculture 179 (2020) 105817

 

Step Whole Field Scouting Approaches
1 6 «12 «18 «6224 #30) «360— tl LowAltitude Scouting 2) High Altitude Scouting

 

1) Low Altitude Scouting
UAV Mission 1 Battery% 99 77 59 41 23 5 7

UAV Mission 2 Battery % 100 100 100 100 = «=©100 6100) 95
Scouting % 4 20 36 52 68 84 100

 

 

“Current Zone FO AO FI A2 £3. A4 FS

2) High Altitude Scouting

UAV Mission | Battery% 9% 77

Scouting % 25 100 3) Adaptive Scouting

Current Zone E2 Fin High Altitude Initial S couting Low Altitude Informed Scouting
3) Adaptive Scouting a) ka Ka | Ke a A 1 | |

UAV Mission 1 Battery% 995 77 59 41

Scouting % 8 38 = 69100

Current Zone D2 Cl £3 _ Fin

 

 

 

 

     

 

 

 

Managem ent Zone Status

Wxeathy BM uUnhealthy Bi Predicted GM Predicted
Healthy Unhealthy

Fig. 3. Three scouting methods over a small area of cropland: 1) Low altitude scouting, 2) high altitude scouting, and 3) adaptive scouting. For each scouting
method, scouting is tracked at 4 step intervals, logging battery of each necessary UAV mission, scouting completion percentage, and position.

1. Capture 200m image 2. Estimate Lodged Regions 3. Calculate Hamiltonian path

Pe | tt
——

jm ULL mee TL
TLL LLL er
TT LL ey

an
|
|
| |
| |
| |
|
| |
|
|
| |
pt
tt
. ||
IN

|

Pett tt
Pt tt
Pett
Pt ttt
Pt
Pt
Pt eee
Pte
SERRE

i
7]

 

6. Find accurate lodged % 5. Capture 50m Image 4. Fly to problem areas at
50m height

™) UAV Field of View [J ProblemArea

Fig. 4. A visual depiction of the autonomous scouting algorithm for 200 m and 50 m altitudes.
M.-D. Yang et al.

6. Once all images are captured, the edge system downloads each
image. It calculates its lodged percentage using the high GSD 50 m
images, thus gaining a more accurate picture of actual rice lodging.

2.4. Scouting in simulation

Crop scouting with autonomous UAV requires considerable infra-
structural support, including software construction, testing, and regu-
lation compliance. Furthermore, rice lodging on a large scale may
happen more often with the increasing severity of typhoons or storms
caused by global climate change. Therefore, an efficient crop scouting
method is urgently needed for the challenge of rice lodging assessment,
and careful testing and evaluating are also needed to ensure practicality.
For these reasons, we chose to simulate our scouting algorithms using
the lodged rice data sets mentioned earlier in this section. Crop scouting
and autonomous UAV simulation mechanisms have been tested and
validated in prior work (Boubin et al., 2019a; Boubin et al., 2019b).
Using these methods, we were able to construct valid simulations and
gather results for our scouting techniques.

2.4.1. Autonomy profiling

Autonomous systems must have the ability to fully navigate dynamic
environments. For UAV, this implies the ability to fly to any point within
some two-dimensional or three-dimensional space relevant to the
problem at hand. When scouting a crop field for lodged rice, an auton-
omous UAV must have the ability to fly to and sense data at any point
within the three-dimensional region where sensed data would be rele-
vant to the field being scouted. When planning a crop scout, however,
certain components of this bounding region can be abstracted to obtain
similar results. For instance, the UAV may only fly at one altitude,
presumably selected to balance image GSD and flight time.

Similarly, UAVs are usually only required to fly to a subset of points
within the space, such that the subset of points allows the UAV to fully
observe the crop field. Crop scouting and UAV mission plans in this

oe

    

| A -

} 50m
CG)

Wn

Background

Hl ee és MAT i: &

   

Rice paddy Rice lodging

50m Height Linked Images

Vi

Computers and Electronics in Agriculture 179 (2020) 105817

respect are usually represented by a set of GPS waypoints and altitudes
read by mission planning software that pilots the UAV automatically.
Unlike automatic flight, autonomous systems make high-level decisions,
like which waypoint to fly to next, in flight.

Given both the amount of possible sensed data by an autonomous
crop scouting UAV and its ability to choose which data is sensed at
runtime, profiling autonomous UAV for simulation can be difficult. To
simulate lodged rice crop scouting, we used the autonomy cube, a data
structure specifically created to aid in autonomous vehicle simulation
(Boubin et al., 2019a), Autonomy cubes are data structures that combine
sensed data (e.g., images, videos, other sensor readings) with spatial
information (e.g., altitude, GPS locations). Each piece of data in an
autonomous cube is linked to both an altitude and GPS location. As
shown in Fig. 5, data also have links to surrounding data points based on
possible flight actions. A flight action is defined as any movement or
process that the UAV can undertake to solve its autonomy goal (e.g.,
takeoff, land, fly up 150 m, fly west 10 m, capture an image, hover).
Flight actions are combined to create a complete UAV flight. Missions
generally consist of UAV takeoff and landing combined with some series
of UAV translation actions (e.g., fly left, fly up) and data sensing (e.g.,
capture images). For our simulation, we have created a set of standard
flight actions that can be used for aerial scouting.

For every possible flight action of the UAV being modeled that dis-
places the UAV, a link will exist to data sensed at that position. These
links allow simulated UAV to navigate virtual environments easily,
accessing sensed data from real UAV missions. To construct autonomous
cubes, a considerable amount of profile data is required. We sensed
lodged rice data from Mozi Shield Park in Wufeng District in Taichung
City, which we built into autonomy cubes using available research
software (Boubin et al., 2019c).

2.4.2. Energy profiling

To properly evaluate the performance of a simulated UAV flight, the
energy expenditure of each possible flight action for both UAV and

200m

al i) Pav ie

fd y
hs i

 

\

Road _ Bare land

200m Height Image

 

Fig. 5. Autonomy cubes capture both sensed data and spatial information. Sensed data points are spatially linked by flight action. In this figure, sensed data is liked

by both cardinal direction and altitude.
M.-D. Yang et al.

compute must be known. To construct valid simulations, we created
energy profiles for both UAV and compute. We define an energy profile
as the execution time in seconds and energy expenditure in joules for
every action available to a given system. In this context, an aircraft’s
energy profile would include energy and execution time information for
each flight action. For a base station, this would include energy and
execution time information for each flight control, classification, or data
movement task.

To obtain this information, we used methods from prior work
(Boubin et al., 2019b). We performed each compute and flight action
100 times, fitting the execution time to normal distributions and
recording energy expenditure in watts to construct energy profiles. We
gathered energy and execution time information from UAV and edge
systems using SoftwarePilot (Boubin et al., 2019c). Flight actions were
profiled at Glacier Ridge Metropark in Dublin, Ohio (Fig. 6), using a DJI
Phantom 4 Pro (P4P).

Table 4 shows the results of the profiling with the P4P. Flight actions
include translation at 2 m/s, data capture and transfer, hovering, and
takeoff/landing. The simulated UAV translates at 2 m/s in all directions
for consistency. At the height of 50 m, the UAV must move 10 m along
one of its horizontal axes to see a different image in our dataset, and
similarly, at 200 m, the UAV must move 35 m. For this reason, we
profiled each movement along the horizontal axis (left, right, forward,
and backward) at both 10 m and 35 m. Vertical translations (fly up,
down, takeoff/landing) were also profiled. We combined takeoff and
landing into one action per prior work (Boubin et al., 2019b), and
profiled translation between the 50 m and 200 m heights at 2 m/s.
Lastly, we profiled interactions with edge systems. The Sense Data ac-
tion includes capturing an image with the UAV camera and transferring
it to the edge system. The hover action is used when the UAV idles,
awaiting commands from the edge system during the adaptive approach.

2.4.3. Simulated scouting

Using autonomy cubes and energy profiles, we constructed software
to simulate the three whole field mapping strategies detailed earlier in
this section. Fig. 7 shows how to construct the simulator. Inputs include
workload settings (e.g., machine learning models, flightpath type), the
autonomy goal (i.e., to estimate the lodged percentage of the crop field),
and autonomy cubes. Based on the flightpath type, potentially sensed
data and model outputs, flight paths for the UAV are generated. Once a

Computers and Electronics in Agriculture 179 (2020) 105817

Table 4
Simulated flight actions and their energy cost as profiled with a DJI Phantom 4
Pro (P4P).

UAV Flight Action Energy (J) Battery Consumption (%) Time (sec)

P4P Takeoff/Land 249 0.95 14
Left 10 m 558 0.76 5
Left 35 m 558 2.65 17.5
Right 10 m 558 0.76 5
Right 35 m 558 2.65 17.5
Forward 10 m 661 0.89 5
Forward 35 m 661 3.14 17.5
Backward 10 m 514 0.69 5
Backward 35 m 514 2.44 17.5
Fly Up 150 m 560 2.28 15
Fly Down 150m _ =—‘519 2.11 15
Sense Data 367 0.05 5
Hover 257 0.07 1

flightpath is generated, it can be used to determine the number of each
flight and compute the actions required. We sample the normal distri-
butions of these actions latency, which are used to calculate energy
expenditure in joules.

Adaptive scouting in the simulation was principally compared to low
and high altitude scouting, which both scout the entire field using
EDANet to predict lodging at 50 m and 200 m respectively after the
flight. All three methods were simulated with UAV starting at one of 4
corners of the waypoint grid and moving first in either of the two
possible directions from the start point in a lawnmower fashion for a
total of 8 possible traversals of the grid. Simulations were run on a
Lenovo Thinkpad T470 laptop with an Intel 7500U CPU and 24 GB of
RAM running Ubuntu Linux 18.04. The simulator was written in Python
3.6 and was given pre-segmented images from our EDANet model.

3. Results

To develop the proposed adaptive crop scouting mechanism, we
carefully trained EDANet, the semantic segmentation model, to ensure
model capability for lodging assessment. Additionally, we simulated
UAV crop scouting of rice fields at multiple levels using EDANet and real
UAV energy profiles. Hence, accuracy and scouting time were compared
between the proposed adaptive crop scouting, 50 m scouting, and 200 m

 

DF Flight Test Zone

Fig. 6. Aerial view of Glacier Ridge Metropark in Dublin, Ohio, where the flight action profiling was performed.
M.-D. Yang et al.

     
     
 

 

. compute
workload architecture profiling
settings generate
goals flight path

autonomy . aircraft
cubes aircraft profiling

  
    
     

Computers and Electronics in Agriculture 179 (2020) 105817

compute

Power
Consumption

 
   

:
flight actions modeling

1. latency
2. energy

3. hover power

Fig. 7. Workload settings, goals, autonomy cubes, and energy profiles are taken as inputs to the simulation. These inputs are used to generate flight paths and

determine the overall power consumption and execution time of UAV missions.

scouting. Furthermore, overlap and cost considerations of UAV scouting
were also investigated.

3.1. Semantic segmentation model training and testing

Due to the limited space, only the F1 score and overall accuracy (OA)
among the six metrics are reported for the training results. As shown in
Table 5, the highest OA reaches 94.87% when RGB information is used.
For these five classes (rice paddy, rice lodging, road, bare land, and
background), the associated F1 scores are quite stable for each class. The
bare land class has the highest F1 score of 96.97%, whereas the road
class shows the lowest F1 score of 80.26%.

Table 6 shows the testing results for the 2017 and 2019 datasets.
Based on the testing results, the entire testing process can be performed
in around one minute, which is the most compelling evidence demon-
strating the real-time capability of EDANet. Fig. 8 represents testing
results from a subset of the 2019 field dataset. As shown in Fig. 8,
EDANet performs well in capturing rice lodging, rice paddy, and other
classes. Based on the results of the 2019 dataset, EDANet using RGB +
ExG + ExGR information illustrations the highest value in recall
(85.22%), accuracy (92.83%), and F1 score (78.51%). Therefore, the
EDANet using RGB + ExG + ExGR information is the final model that
has been applied in this study for further investigation in UAV scouting
simulation.

3.2. Scouting in simulation

The adaptive scouting process was evaluated in simulation using
autonomy cubes, a DJI P4P UAV profile, and a series of lodged per-
centage thresholds. Autonomy cubes were constructed from the Wufeng
rice crop dataset using the SoftwarePilot autonomy cube builder (Bou-
bin et al., 2019c). Autonomy cubes were created for images captured at
both 200 m and 50 m heights. Out of 215 Wufeng crop images captured
at 50 m, 73 contained no rice or exclusively rice that could be seen from
other waypoints, so the simulated UAV did not capture data at those
waypoints. The 200 m autonomy cube contained 12 images that were
able to encompass all 215 50 m images. An energy profile was created
for the P4P by profiling each simulated movement under real-world
conditions using SoftwarePilot. Ten lodged percentage thresholds were
also assigned for the simulator, denoting what estimated lodged per-
centage a region must have at 200 m in simulation to be investigated at
50 m, meaning that a 5% lodged threshold would only scout 50 m re-
gions showing 5% or greater lodging at 200 m. The lodged percentages
were chosen between 2.5% and 25% at intervals of 2.5%. The simulator
used EDANet to estimate lodged percentages.

Fig. 9 shows example results from one simulation comparing the

Table 5

Table 6
Model testing results for the 2017 and 2019 datasets (the highest value is marked
in bold).

 

 

Year Information Precision Recall Accuracy F1- Time
(%) (%) (%) score (sec)
(%)
2017 RGB 84.03 82.19 94.26 83.10 56
RGB + ExG 86.16 84.19 94.96 85.16 58
RGB +ExGR 84.42 85.77 94.84 85.09 61
RGB + ExG 83.34 86.99 94.78 85.13 64
+ ExGR
2019 RGB 72.71 38.27 88.30 50.15 55
RGB + ExG 93.46 56.45 92.70 70.39 59
RGB+ExGR = 82.24 52.72 90.98 64.25 60
RGB + ExG 72.78 85.22 92.83 78.51 65
+ ExGR

three methods where all methods begin on the same path, at the
southwest corner of the grid, and move immediately north. The number
of each flight action, total discharges, and lodged percentage prediction
of each method are reported. Note that the adaptive method’s Hamil-
tonian path is not included as a flight action. Fig. 9 also shows the route
taken by the adaptive approach. The adaptive approach originally fol-
lows the same route as the 200 m approach, sensing data at each 200 m
waypoint. Once all data is sensed, uncertain sections are found, and the
best possible waypoints are determined to explore them. A Hamiltonian
path between those waypoints is determined and is explored at 50 m by
the UAV.

3.3. Accuracy and scouting time comparison

The principal comparison points between the three approaches are
accuracy and time in Fig. 10. Fig. 10a compares a normalized accuracy
between 200 m and the adaptive scouting as they compare to 50 m
scouting. 200 m scouting has a normalized error of 24.2%, meaning that
an overall field scout at 200 m differs in predicted lodged percentage by
24.2% from a 50 m scout.

Adaptive scouting differs between 0.75% and 16.73% depending on
the lodged threshold, steadily increasing as the lodged threshold in-
creases. Until the lodged threshold exceeds 12.5%, the normalized error
between 50 m scouting and the adaptive scouting does not exceed 2%.
Higher lodged percentages, however, increase a normalized error by
5.03% to 16.73% due to their higher frequency to ignore largely lodged
regions of the field due to inaccuracies in the 200 m scout.

Fig. 10b shows the differences in UAV missions required to scout the
field between 50 m, 200 m, and the adaptive scouting. In the analysis, a
P4P would have access to extra batteries, and when the battery depletes,

EDANet model training results of F1 score and overall accuracy (OA) (the highest value is marked in bold).

Information Rice paddy (%) Rice lodging (%)
RGB 95.28 86.17
RGB + ExG 95.28 85.99
RGB + ExGR 95.24 85.87
RGB + ExG + ExGR 95.19 86.03

 

Road(%) Bareland (%) Background (%) OA (%)
83.02 96.97 96.94 94.87
81.10 96.86 96.58 94.60
81.80 96.48 96.55 94.54
80.26 96.51 96.46 94.45
M.-D. Yang et al.

(a)

 
 
 
 
 
 

 
 
 
 
 
 

 

(b)

 
 
 
 

 
 
 
 
 

(c1)

(c2)

(c3)

(c4)

 

Computers and Electronics in Agriculture 179 (2020) 105817

 
 
 
 
 
 

Legend

po Rice Paddy

p | Rice Lodging
aa Road
a Ridge
P| Background

 

Fig. 8. Model testing results demonstration. (a)original image, (b)ground truth, and (cl-c4) represent EDANet with RGB, RGB + ExG, RGB + ExGR, and RGB + ExG
+ ExGR information, respectively. (Red represents rice lodging, green represents rice paddy, and black represents other classes). (For interpretation of the references
to colour in this figure legend, the reader is referred to the web version of this article.)

the UAV battery would be changed, and scouting would resume. 200 m
scouting is considerably faster than either adaptive or 50 m scouting,
taking only 0.34 flights (at least one flight) to map the field. 50 m
scouting, on the other hand, took 2.43 total (at least three flights) flights

 

 

 

 

 

 

 

 

 

 

 

 

Simulation 50m 200m Adaptive
Attribute (T=2.5%)
Takeoff/Land 1 1 1
Left 10m 0 NA NA
Left 35m NA 0 0
Right 10m 9 NA NA
Right35m NA 1 1
. Forward 10m _= 103 NA NA
Aa Forward 35m NA 5 5
Backward 102 NA NA
10m
Backward NA 4 4
35m
Fly Up 150m NA 1 l
Fly Down NA 1 1
150m
Sense Data 142 11 29
Hover NA NA 29
UAV 2.34 0.32 1.60
Discharges
Predicted 26.1 32.4 25.9
Lodged
Percentage

to map the entire field. The adaptive scouting was able to map the field
in between 1.6 and 1.27 (at least two flights) flights depending on the
lodged threshold, saving one recharge period and mapping the field in
65%-52% the total time required by 50 m scouting.

2) Construct a Hamiltonian
path and capture data at
each waypoint

1) Identify lodged regions at
200m and select optimal
waypoints

    

4
id

  

Ds XN
~ ss x at be ss Sy

 

Bo ae

 

Fig. 9. Sample simulation results with the adaptive lodged threshold (T) set to 2.5%. Depicted is the simulated FAAS path for the adaptive approach at both 200 m

and 50 m.
M.-D. Yang et al.

S 5 30% < 3.00

Lu oO =

3 P 20% 2 2.00

N§& =

@ B 10% S 1.00

— n o

o> 0% z 0.00
ROSSRESSRR 3 pax
78a wo = oa

Lodged % Threshold

wee 50m Scouting

ese 200m Scouting
Adaptive Scouting

(a)

 

be
oO

Lodged % Threshold

mes 50m Scouting

ee 200m Scouting
mmm ACaptive Scouting

(b)

 

Computers and Electronics in Agriculture 179 (2020) 105817

 

Ww
5 3.00
8
s 2.00
a
° 1.00
8
€ 0.00
RPrRRrPNNN S OoOuWm FF FN NY W
NOUNON UO Zz € 2 ounauasd
oOo oO wm “SF FSFE S
Normalized Error
Vs. 50m Scan

@ 50m Scouting
v 200m Scouting

@ Adaptive Scouting

(c)

 

Fig. 10. a) Adaptive scouting is up to 99.25% accuracy compared to 50 m scouting, while 200 m scouting alone is 75.8% accuracy. b) Adaptive scouting takes at
most 35% less missions to completely scout the field as compared to 50 m scouting. c) Adaptive scouting balances the high speed of 200 m scouting with the accuracy

of 50 m scouting, sacrificing little accuracy for significant speed gains.

Fig. 10c shows the relationship between time and accuracy experi-
enced by each scouting method. Of all approaches, 200 m scouting is by
far the fastest but suffers from accuracy issues. On the other hand, 50 m
scouting is highly accurate but requires considerable execution time.
The adaptive scouting at low thresholds experiences less than 1%
normalized error compared to 50 m scouting but completes in 36% less
execution time. The adaptive scouting approach is able to decrease
scouting time and preserve accuracy due to the correlation between 200
m and 50 m lodged predictions.

As shown in Fig. 11, predicted lodging at 200 m and 50 m for highly
lodged regions are correlated, with a bias toward higher prediction rates
at 200 m. By following the overall correlation, we are able to scout at
200 m and successfully predict which regions contain lodging, but not
accurately predict the amount. By then scouting only those regions at 50
m, the adaptive approach can improve on total mission time without
losing significant accuracy.

The largest differences between 200 m and 50 m scouting predictions
can be found at low levels of lodging, where 200 m scouts predict lod-
ging where there is none or predict no lodging where there is some at 50
m. Many of these points are regions which contain smaller amounts of
rice crop, in lieu of buildings and roadways. 200 m scouting could
mispredict these regions as lodged or healthy rice to the detriment of the
overall scout, requiring either the scouting of unlodged regions or the
skipping of lodged regions. While these outlier points may be mis-
predicted as highly lodged or healthy, they generally encompass only a

35.00 f(x) = 73.33 x + 1.99

   

%G

S
S

%OT

N
S

%SGT
%GC
%OE
%GE
%Ov
%GV
%O0S

200m Predicted Lodged Rice %

 

@ Adaptive Approach Linear (Adaptive Approach)

Fig. 11. Lodged rice predictions at 200 m correlate with observed values at 50
m but are inaccurate enough to yield valuable results alone. By informing 50 m
scouting using 200 m results, high accuracy can be achieved while decreasing
scout times.

10

small percentage of the overall field. They, therefore, have little effect on
the overall performance of the adaptive scouting model, as demon-
strated by the results presented in Fig. 10. Handling outlier cases such as
these, however, should be addressed by future work.

3.4. Overlap and cost considerations of UAV scouting

A flight plan must be specifically made before executing the UAV
mission, and consists of parameter setting, including the required spatial
resolution of the photography, the camera focal length, the film format
size, (forward) overlap, sidelap, the flying height above the ground, the
ground speed of UAV, and the time interval between exposures. The
purpose of photography is a major consideration in the flight plan. In
this study, the overlap and the sidelap are required only for image
mosaic in the 200 m scouting. In the 50 m flight mission, a higher
overlap, larger than 67% of overlap and sidelap so that one feature point
and its corresponding points appear on at least three successive photos,
is required for image-based modeling. To increase robustness and ac-
curacy, the redundancy should be afforded with a large number of
mutually overlapping photos simultaneously, so-called multi-ray
photogrammetry, which requires a very high overlap (80%-90%) and
sidelap (up to 60%) (Lillesand et al., 2015). The overlap and the sidelap
are 85% and 85%, as well as 80% and 60% for 200 m and 50 m scouts,
respectively. Moreover, the total number of exposures necessary for a
mission should be computed prior. Each photo has an incremental area,
A, as

A = (1 — p)*h/S*(1 —q)*w/S = (1 — p)*(1 — q)*h*w*S~* (5)

p is the overlap, q is the sidelap, h is the height of the photo, w is the
width of photo, and S is the scale and shows an inverse relationship with
the flying height above the ground using the same focal length.

As the setting overlap in the previous flight plan, the ratio of the
numbers of total photos at 50 m scouting over 200 m scouting is 35 for a
designated area. Furthermore, the overlap can be reduced to 60% for a
200 m scouting that can increase the ratio of the total photos up to 71.

The cost of 50 m, 200 m, and adaptive scoutings varying with the
scouting area can be illustrated in Fig. 12. Based on a preliminary
market survey of crop scouting and DJI P4P flight statistics, we estimate
that 50 m and 200 m crop scouting cost $100USD and $500USD
respectively in Taiwan. According to the regulation of Taiwan Civil
Aviation Law, an out-of-sight flight that 200 m scouting may encounter
needs an extra supervisor standing at commanding heights, who is
responsible for connecting the nearby airport controlling center in case
of emergency, beside a UAV operator. Thus, the extra supervisor results
in a different initial cost between 50 m and 200 m scouting. In general,
the cost of 50 m and 200 m scouting increases with area coverage.
M.-D. Yang et al.

  
   
 
 
   
   
 

1500

50m Scouting
Cost=200+100A Adaptive Scouting

1200 , (200m Scouting + 50m Scouting)

1000

200m Scouting
Cost=500+10A

Estimated Cost (USD)

200 “== —=50m Scouting
om oan ome 200m Scouting
/ mmm Adaptive Scouting

A: Area(ha)

20

30
Area (ha)

40 50

Fig. 12. The estimated cost of 50 m, 200 m, and adaptive scoutings varying
with the scouting area.

Adaptive scouting combines the cost estimation at 200 m and 50 m and
depends on the area of fine and coarse coverages. In this case study, the
adaptive scouting combines one 200 m fight and two 50 m fights as one
mission to efficiently reduce the total cost and achieve the goal of lod-
ging identification, as shown in Fig. 12.

4. Discussion

As demonstrated in the results, we are able to construct a deep neural
network for lodged rice detection that outperforms prior work using
SegNet and FCN-AlexNet (Yang et al. 2020). The EDANet approach
classifies rice paddy at 95.28% accuracy using RGB, as compared to
SegNet at 91.49 and FCN-AlexNet at 92.77%. EDANet classifies lodged
rice at 86.17% accuracy compared to SegNet at 70% and FCN-AlexNet at
77.91%. Even with more information in the form of vegetation indices,
the best performance from prior work was garnered using FCN-Alexnet
yielding 93% rice paddy accuracy and 80.08% lodged rice accuracy.

The adaptive algorithm was able to maintain this newfound accu-
racy. The adaptive approach scouts at two levels, first estimating highly
lodged regions at high altitude, then confirming lodging at low altitude
at only those highly lodged areas as efficiently as possible. We were able
to maintain 99.25% accuracy using EDANet as compared to a complete
scout of the entire field by simply avoiding regions that showed less than
2.5% lodging at high altitude.

The adaptive approach allows for a considerable time and costs
savings compared to a complete scout of the crop field. Adaptive
scouting at optimal accuracy takes 35% less flight time to achieve and
saves precious UAV battery life. Flight time is important from a number
of perspectives, including urgency, resource savings, and labor costs.
Crop scouting for lodged rice is particularly sensitive to these factors.
Rice lodging generally only occurs in reasonable quantities during pe-
riods of high flooding and heavy rainfall, which often coincide with
other effects like power loss or limited labor availability and assessment
time, which make aerial scouting difficult. Furthermore, lodging must
be determined quickly to allow farmers to remove lodged rice or replant
crops and promptly receive government subsidies (Yang et al., 2017) so
that aerial scouting resources will be in high demand during these pe-
riods. This double effect of high demand and low resources makes the
time and energy savings of the proposed approach much more
consequential.

Scouting approaches also commonly utilize skilled independent pi-
lots or aerial photography companies to survey cropland and locate
lodging, which can be expensive. In a period of high volume for aerial
scouting, demand for pilots may also increase, raising prices or delaying

11

Computers and Electronics in Agriculture 179 (2020) 105817

scouts. The proposed approach is fully autonomous, requiring only
compute resources, UAVs, and labor for setting up and taking down
systems. This process could be done easily by farmers, especially if they
already use UAVs on the farm and own a reasonably powerful computer.
Because the proposed approach does not require human piloting, it costs
considerably less over time.

There are many available avenues for future work to improve our
neural network and approach. First and foremost, increased data
collection of lodged rice fields is imperative. Rice lodging, though
devastating, is not an everyday situation, so gathering lodging datasets
is difficult. Increasing the number of samples available will increase the
ability of machine learning techniques to accurately detect lodging, like
the proposed EDANet approach. Techniques to increase the accuracy of
the proposed approach or other approaches with higher lodged rice
detection accuracy are also valuable directions for future work.

The adaptive approach is not simply useful for rice lodging, but for
finding and counting any anomaly that can be detected using aerial
image analysis. Possible applications could include finding other crop
diseases or estimating crop yield but is also applicable to other areas of
aerial photography like infrastructure inspection or battlefield surveil-
lance. Applying this technique to other domains may yield superior re-
sults compared to simply scouting entire areas at low altitudes, as shown
here.

The most pressing avenue for future work is to take the proposed
approach out of the simulation and test it on an actual rice lodging
scenario. Additionally, many newly developed embedded edge
computing devices are lightweight and portable, such as Nvidia Jetson
TX2, AGX Xavier, or Xavier NX. These devices are suitable for real-time
onboard computing power on small drones with restricted space (Burger
et al., 2020), which can be useful to empower our approach. We plan to
address this in future work by using the SoftwarePilot framework for
fully autonomous aerial systems (Boubin et al., 2019c) and our EDANet
for lodged rice detection to implement the proposed approach to scout
crop fields in real-time.

5. Conclusions

Rice is a globally important crop that will be a necessary component
of the earth’s food supply for the foreseeable future. Rice lodging is a
threat to rice production, hurting yield and diminishing farmers’ in-
come. Assessing rice lodging should be more efficient because current
methods rely primarily on random manual sampling. This paper pre-
sents an autonomous scouting approach to estimate rice lodging using
machine learning and UAVs. The machine learning model using EDANet
is capable of identifying rice at 95.28% accuracy and lodging at 86.17%,
improving in prior work by 2.51% and 8.26%, respectively. The adap-
tive scouting approach, which scouts rice at multiple altitudes to target
lodged regions, in particular, maintained 99.25% lodged prediction
accuracy compared to a complete scan of the field at low altitude while
taking 35% less time. The adaptive scouting approach saves consider-
able money and time and provides a great opportunity to enhance rice
lodging assessment over a large area using deep learning techniques on
UAV images. The adaptive scouting approach is ready to be imple-
mented in lodging assessments to provide low-cost and in-time digital
maps. In the future, edge computing will be integrated into adaptive
scouting to identify field anomalies in real-time and complete multi-
scale imaging tasks in one flight.

CRediT authorship contribution statement

Ming-Der Yang: Conceptualization, Methodology, Supervision,
Formal analysis, Funding acquisition. Jayson G. Boubin: Methodology,
Software, Formal analysis, Writing - original draft. Hui Ping Tsai:
Conceptualization, Formal analysis, Methodology, Writing - original
draft, Writing - review & editing. Hsin-Hung Tseng: Conceptualization,
Methodology, Software, Visualization. Yu-Chun Hsu:
M.-D. Yang et al.

Conceptualization, Methodology. Christopher C. Stewart: Conceptu-
alization, Methodology.

Declaration of Competing Interest

The authors declare that they have no known competing financial
interests or personal relationships that could have appeared to influence
the work reported in this paper.

Acknowledgment

This work was funded in part by NSF Grants 1749501 and 1350941
with support from NSF CENTRA collaborations (grant 1550126) and the
NSF Graduate Research Fellowship (grant DGE-1343012). This work
was funded in part by the Ministry of Science and Technology, Taiwan,
under Grant Number 109-2634-F-005 -003 and MOST 104-2923-E-492
-002 -MY3.

References

Alam, M.R., Reaz, M.B.I., Ali, M.A.M., 2012. A review of smart homes-Past, present, and
future. IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and
Reviews) 42 (6), 1190-1203.

Atzori, L., Iera, A., Morabito, G., 2010. The internet of things: A survey. Comput. Netw.
54 (15), 2787-2805.

Basu, S., Woodard, R., 2016. Testing an ansatz for the leading secular loop corrections
from quantum gravity during inflation. Class. Quantum Gravity 33 (20), 205007.

Boubin, J., Chumley, J., Stewart, C., Khanal, S., 2019a. Autonomic computing challenges
in fully autonomous precision agriculture. Paper presented at the 2019 IEEE
International Conference on Autonomic Computing (ICAC) 11-17.

Boubin, J.G., Babu, N.T., Stewart, C., Chumley, J., Zhang, S., 2019b. Managing edge
resources for fully autonomous aerial systems. Paper presented at the Proceedings of
the 4th ACM/IEEE Symposium on Edge Computing 74-87.

Boubin, J., Stewart, C., Zhang, S., Babu, N. T., & Zhang, Z. (2019c). Softwarepilot
(https://www.reroutlab.org/softwarepilot/ed.).

Brown, M. E., & FuC. (2008). Climate. Food security under climate change. Science (New
York, N.Y.), 319(5863), 580-581.

Burange, A.W., Misalkar, H.D., 2015. Review of Internet of Things in development of
smart cities with data management & privacy. Paper presented at the 2015
International Conference on Advances in Computer Engineering and Applications
189-195.

Burger, A., Urban, P., Boubin, J., Schiele, G., 2020. An Architecture for Solving the
Eigenvalue Problem on Embedded FPGAs. Paper presented at the International
Conference on Architecture of Computing Systems.

Chu, Z., Yu, J., 2020. An end-to-end model for rice yield prediction using deep learning
fusion. Comput. Electron. Agric. 174, 105471.

Chu, T., Starek, M.J., Brewer, M.J., Masiane, T., Murray, S.C., 2017a. UAS imaging for
automated crop lodging detection: a case study over an experimental maize field.
Paper presented at the Autonomous Air and Ground Sensing Systems for Agricultural
Optimization and Phenotyping IT 10218, 102180E.

Chu, T., Starek, M.J., Brewer, M.J., Murray, S.C., Pruter, L.S., 2017b. Assessing lodging
severity over an experimental maize (Zea mays L.) field using UAS images. Remote
Sensing 9 (9), 923.

Dong, R., Pan, X., Li, F., 2019. DenseU-Net-Based semantic segmentation of small objects
in urban remote sensing images. IEEE Access 7, 65347-65356.

Gurevich, Y., Shelah, S., 1987. Expected computation time for Hamiltonian path
problem. SIAM J. Comput. 16 (3), 486-502.

Huang, G., Liu, Z., Van Der Maaten, L., Weinberger, K.Q., 2017. Densely connected
convolutional networks. Paper presented at the Proceedings of the IEEE Conference on
Computer Vision and Pattern Recognition 4700-4708.

Kamilaris, A., Prenafeta-Boldt, F.X., 2018. Deep learning in agriculture: A survey.
Comput. Electron. Agric. 147, 70-90.

Lillesand, T., Kiefer, R.W., Chipman, J., 2015. Remote sensing and image interpretation.
John Wiley & Sons, Inc., NJ, USA, p. 736 pages..

Liu, T., Li, R., Zhong, X., Jiang, M., Jin, X., Zhou, P., Liu, S., Sun, C., Guo, W., 2018.
Estimates of rice lodging using indices derived from UAV visible and thermal
infrared images. Agric. For. Meteorol. 252, 144-154.

12

Computers and Electronics in Agriculture 179 (2020) 105817

Lo, S., Hang, H., Chan, S., Lin, J., 2019. Efficient dense modules of asymmetric
convolution for real-time semantic segmentation. Proceedings of the ACM
Multimedia Asia on ZZZ 1-6.

Mardanisamani, S., Maleki, F., Hosseinzadeh Kassani, S., Rajapaksa, S., Duddu, H.,
Wang, M., Shirtliffe, S., Ryu, S., Josuttes, A., Zhang, T., 2019. Crop Lodging
Prediction from UAV-Acquired Images of Wheat and Canola using a DCNN
Augmented with Handcrafted Texture Features. Paper presented at the Proceedings of
the IEEE Conference on Computer Vision and Pattern Recognition Workshops.

Meyer, G.E., Neto, J.C., 2008. Verification of color vegetation indices for automated crop
imaging applications. Comput. Electron. Agric. 63 (2), 282-293.

Nelson, A., Setiyono, T., Rala, A.B., Quicho, E.D., Raviz, J.V., Abonete, P.J.,
Maunahan, A.A., Garcia, C.A., Bhatti, H.Z.M., Villano, L.S., 2014. Towards an
operational SAR-based rice monitoring system in Asia: Examples from 13
demonstration sites across Asia in the RIICE project. Remote Sensing 6 (11),
10773-10812.

Ogden, R.T., Miller, C.E., Takezawa, K., Ninomiya, S., 2002. Functional regression in
crop lodging assessment with digital images. J. Agricultural, Biological, and
Environmental Statistics 7 (3), 389.

Okuno, A., Hirano, K., Asano, K., Takase, W., Masuda, R., Morinaka, Y., Ueguchi-
Tanaka, M., Kitano, H., Matsuoka, M., 2014. New approach to increasing rice
lodging resistance and biomass yield through the use of high gibberellin producing
varieties. PLoS ONE 9 (2) e86870.

Ookawa, T., Hobo, T., Yano, M., Murata, K., Ando, T., Miura, H., Asano, K., Ochiai, Y.,
Ikeda, M., Nishitani, R., 2010. New approach for rice improvement using a
pleiotropic QTL gene for lodging resistance and yield. Nat. Commun. 1 (1), 1-11.

Papadomanolaki, M., Vakalopoulou, M., Karantzalos, K., 2019. A novel object-based
deep learning framework for semantic segmentation of very high-resolution remote
sensing data: Comparison with convolutional and fully convolutional networks.
Remote Sensing 11 (6), 684.

Pison, G., 2019. The population of the world (2019). Population & Societies 569 (8), 1-8.

Satyanarayanan, M., 2017. The emergence of edge computing. Computer 50 (1), 30-39.

Setter, T., Laureles, E., Mazaredo, A., 1997. Lodging reduces yield of rice by self-shading
and reductions in canopy photosynthesis. Field Crops Research 49 (2-3), 95-106.

Yang, M., Tseng, H., Hsu, Y., Tsai, H.P., 2020. Semantic segmentation using deep
learning with vegetation indices for rice lodging identification in multi-date UAV
visible images. Remote Sensing 12 (4), 633.

Yang, Q., Shi, L., Han, J., Zha, Y., Zhu, P., 2019. Deep convolutional neural networks for
rice grain yield estimation at the ripening stage using UAV-based remotely sensed
images. Field Crops Research 235, 142-153.

Yang, M., Huang, K., Wan, J., Tsai, H.P., Lin, L., 2018. Timely and quantitative damage
assessment of oyster racks using UAV images. IEEE J. Sel. Top. Appl. Earth Obs.
Remote Sens. 11 (8), 2862-2868.

Yang, M., Huang, K., Kuo, Y., Tsai, H.P., Lin, L., 2017. Spatial and spectral hybrid image
classification for rice lodging assessment through UAV imagery. Remote Sensing 9
(6), 583.

Yang, M., Su, T., Pan, N., Yang, Y., 2011. Systematic image quality assessment for sewer
inspection. Expert Syst. Appl. 38 (3), 1766-1776.

Yousefpour, A., Fung, C., Nguyen, T., Kadiyala, K., Jalali, F., Niakanlahiji, A., Kong, J.,
Jue, J.P., 2019. All one needs to know about fog computing and related edge
computing paradigms: A complete survey. J. Syst. Archit. 98, 289-330.

Lang, Y.Z., Yang, X.D., Wang, M.E., Zhu, Q.S., 2012. Effects of lodging at different filling
stages on rice yield and grain quality. Rice Sci. 19 (4), 315-319.

Vasisht, D., Kapetanovic, Z., Won, J., Jin, X., Chandra, R., Sinha, S., Kapoor, A.,
Sudarshan, M., & Stratman, S. (2017). Farmbeats: An IoT platform for data-driven
agriculture. Paper presented at the 14th USENIX Symposium on Networked Systems
Design and Implementation (NSDI 17), 515-529.

Wang, D., Li, W., Liu, X., Li, N., Zhang, C., 2020. UAV environmental perception and
autonomous obstacle avoidance: A deep learning and depth camera combined
solution. Comput. Electron. Agric. 175, 105523.

Woebbecke, D.M., Meyer, G.E., Von Bargen, K., Mortensen, D., 1995. Color indices for
weed identification under various soil, residue, and lighting conditions. Transactions
of the ASAE 38 (1), 259-269.

Zeng, D., Tian, Z., Rao, Y., Dong, G., Yang, Y., Huang, L., Leng, Y., Xu, J., Sun, C.,
Zhang, G., 2017. Rational design of high-yield and superior-quality rice. Nat. Plants
3 (4), 1-5.

Zhao, X., Yuan, Y., Song, M., Ding, Y., Lin, F., Liang, D., Zhang, D., 2019. Use of
unmanned aerial vehicle imagery and deep learning UNet to extract rice lodging.
Sensors 19 (18), 3859.

Zheng, H., Zhou, X., He, J., Yao, X., Cheng, T., Zhu, Y., Cao, W., Tian, Y., 2020. Early
season detection of rice plants using RGB, NIR-GB and multispectral images from
unmanned aerial vehicle (UAV). Comput. Electron. Agric. 169, 105223.
