    
    

   

ELSEVIER

é&

Artificial Intelligence 289 (2020) 103389

Contents lists available at ScienceDirect

Artificial Intelligence

Fo

 

www.elsevier.com/locate/artint

 

Real-time reasoning in OWL2 for GDPR compliance

Piero A. Bonatti**, Luca Ioffredo ”, Iliana M. Petrova”, Luigi Sauro °,

Ida R. Siahaan°

* Universita di Napoli Federico II, Italy
> CeRICT, Italy

 

ARTICLE INFO

Article history:

Received 19 April 2019

Received in revised form 31 July 2020
Accepted 17 September 2020
Available online 18 September 2020

Keywords:

Tractable OWL2 fragments
Structural subsumption
Import-by-query
Knowledge compilation
Semantic policy languages

ABSTRACT

This paper shows how knowledge representation and reasoning techniques can be used
to support organizations in complying with the GDPR, that is, the new European data
protection regulation. This work is carried out in a European H2020 project called SPECIAL.
Data usage policies, the consent of data subjects, and selected fragments of the GDPR are
encoded in a fragment of OWL2 called PL (policy language); compliance checking and
policy validation are reduced to subsumption checking and concept consistency checking.
This work proposes a Satisfactory tradeoff between the expressiveness requirements on
PL posed by the modeling of the GDPR, and the scalability requirements that arise from
the use cases provided by SPECIAL’s industrial partners. Real-time compliance checking
is achieved by means of a specialized reasoner, called PLR, that leverages knowledge
compilation and structural subsumption techniques. The performance of a prototype

GDPR implementation of PLR is analyzed through systematic experiments, and compared with

the performance of other important reasoners. Moreover, we show how P£ and PLR can
be extended to support richer ontologies, by means of import-by-query techniques. We
prove novel tractability and intractability results related to PL, and some negative results

about the restrictions posed on ontology import.
© 2020 The Authors. Published by Elsevier B.V. This is an open access article under the
CC BY license (http://creativecommons.org/licenses/by/4.0/).

 

1. Introduction

The new European General Data Protection Regulation! (GDPR), that has come into force on May 25, 2018, places strin-
gent restrictions on the processing of personally identifiable data. The regulation applies also to companies and organizations
that are not located in Europe, whenever they track or provide services to data subjects that are in the European Union.? In-
fringements may severely affect the reputation of the violators, and are subject to substantial administrative fines (up to 4%
of the total worldwide annual turnover or 20 million Euro, whichever is higher). Therefore, the risks associated to infringe-
ments constitute a major disincentive to the abuse of personal data. Given that the collection and the analysis of personal
data are paramount sources of innovation and revenue, companies are interested in maximizing personal data usage within
the limits posed by the GDPR. Consequently, data controllers (i.e. the personal and legal entities that process personal data)
are looking for methodological and technological means to comply with the regulation’s requirements efficiently and safely.

* Corresponding author.

E-mail address: pab@unina.it (P.A. Bonatti).
1 http://data.consilium.europa.eu/doc/document/ST-541 9-2016-INIT/en/pdf.
2 Cf. Article 3 of the GDPR.

https://doi.org/10.1016/j.artint.2020.103389
0004-3702/© 2020 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license
(http://creativecommons.org/licenses/by/4.0/).
PA. Bonatti, L. Ioffredo, I.M. Petrova et al. Artificial Intelligence 289 (2020) 103389

The European H2020 project SPECIAL’ is aimed at supporting controllers in complying with the GDPR. SPECIAL is tackling
several hard problems related to usability, transparency and compliance, see [13,9,34] for an overview. In this paper, we
focus on SPECIAL’s approach to the representation of data usage activities and consent to data processing, together with the
associated reasoning tasks related to the validation of data usage policies and compliance checking.

The management of the consent to data processing granted by data subjects plays a central role in this picture. The
GDPR is not concerned with anonymous data, nor data that do not describe persons (like astronomical data). The other data
(hereafter called personal data) must be processed according to the legal bases provided by the regulation. Some examples
of such legal bases include public interest, the vital interests of the data subject, contracts, and the legitimate interests of
the data controller, just to name a few.* These legal bases are constrained by a number of provisos and caveats that restrict
their applicability.? So, in practice, the kinds of personal data processing that are most useful for data-driven business are
almost exclusively allowed by another legal basis, namely, the explicit consent of the data subjects.° Thus, it is important to
encode consent appropriately, so as to record it for auditing, and give automated support to compliance checking.

Also the controller’s usage of personal data must be appropriately represented and stored, in order to fulfill the obligation
to record personal data processing activities,’ and in order to verify that such activities comply with the available consent
and with the GDPR.

SPECIAL tackles these needs by adopting a logic-based representation of data usage policies, that constitutes a uniform
language to encode consent, the activities of controllers, and also selected parts of the GDPR. A logic-based approach is
essential for achieving several important objectives, including the following:

e strong correctness and completeness guarantees on permission checking and compliance checking;

e ensuring the mutual coherence of the different reasoning tasks related to policies, such as policy validation, permission
checking, compliance checking, and explanations;

e ensuring correct usage after data is transferred to other controllers (i.e. interoperability), through the unambiguous
semantics of knowledge representation languages.

Some of SPECIAL’s use cases place challenging scalability requirements on reasoning. During the execution of the controllers’
data processing software, each operation involving personal data must be checked for compliance with the consent granted
by the data subjects. The frequency of such compliance checks may be significantly high, so SPECIAL needs to implement
the corresponding reasoning tasks in such a way that the time needed for each check does not exceed a few hundreds of
j4-seconds. For example, here is a real-world scenario provided by SPECIAL’s industrial partners.

Streaming Scenario Telecom providers, that nowadays are also Internet providers, receive from their base stations about
15000 call records per second, and receive about 850 millions of probing records per day from their wi-fi network (almost
10000 events per second). The data contained in the aforementioned records are of great interest for strategic applications
and services, such as location-based services and taylored recommendations; however, these are personal data, and the
European regulations on data protection prohibit the above usage without the data subject’s consent. Without it, even
storing the data temporarily, waiting for a batch process to discard the records that cannot be processed, is illegal. Then the
description of how each application processes the data and why, that we will call business policy in the following, must be
checked in real-time for compliance against the available consent for the record being processed, while the stream of data
is generated. The scenario is further complicated by the fact that each data subject can withdraw or modify her consent
anytime, and that she may selectively decide to opt in or out each processing option (e.g. a customer might accept only
location tracking, and not internet tracking).

We address real-time requirements by designing a specialized reasoner for the policy language.
After recalling the notions about description logics and their properties, that will be needed in the paper, our contribu-
tions will be illustrated in the following order.

e Section 3 shows how to encode usage policies and the relevant parts of the GDPR with a fragment of SROZQ(D)
(the logical foundation of OWL2-DL). The details of the encoding will be related explicitly to GDPR’s requirements.
Afterwards, we formally define PZ, that is, the fragment of SROZQ(D) used to encode data usage policies.

e Section 4 is devoted to the complexity analysis of reasoning in PL. We consider concept satisfiability and subsump-
tion checking, that constitute the core of policy validation and compliance checking. We will show that unrestricted PL
subsumption checking is coONP-complete. However, under a restrictive hypothesis motivated by SPECIAL’s use cases, sub-
sumption checking is possible in polynomial time. Tractability is proved by means of a specialized two-stage reasoner

3 https: //www.specialprivacy.eu/.

4 Cf. Article 6 of the GDPR.

> Of particular relevance here are the data minimization principle introduced in Article 5, and the limitations to the legitimate interests of the controller
rooted in Article 6.1(f).

6 Article 6.1(a).

7 Cf. Article 30 of the GDPR.
PA. Bonatti, L. Ioffredo, I.M. Petrova et al. Artificial Intelligence 289 (2020) 103389

called PLR, based on a preliminary normalization phase followed by a structural subsumption algorithm. A preliminary
account of this section has been published in [8].

Section 5 shows how to support richer ontology languages for the description of policy elements. The vocabularies for
policy elements are treated like imported ontologies by means of an import by query (IBQ) approach, that can be im-
plemented with a modular integration of the specialized reasoner for ZL with a reasoner for the imported ontology.
We prove that this integration method is correct and complete, and justify the restrictive assumptions on the imported
ontologies, by adapting and slightly extending previous results on IBQ limitations. Moreover, we show that under hy-
potheses compatible with SPECIAL’s application scenarios, the external ontology can be compiled into a PL ontology,
thereby reducing the IBQ approach to plain PL reasoning.

PL subsumption checking is experimentally evaluated in Section 6. After describing the implementation of PLR and
its optimizations, PLR’s performance is compared with that of other important engines, such as ELK [33], GraphDB
[25], Hermit [23], and RDFox [37]. For this purpose, we use two sets of experiments. The first set is derived from the
pilots of SPECIAL that have reached a sufficient development level, namely, a recommendation system based on location
data and internet navigation information, designed by Proximus, and a financial risk analysis scenario developed by
Thomson Reuters. The second batch of experiments is fully synthetic, instead, and contains increasingly large policies
and ontologies, in order to assess the scalability of PLR.

Section 7 concludes the paper with a final discussion of our results and interesting perspectives for future work. Related
work is heterogeneous (declarative policy languages, legal reasoning, tractable description logics, IBQ methods) so we dis-
tribute its discussion across the pertinent sections, rather than in a single dedicated section.

2. Preliminaries on description logics

Here we report the basics on the Description Logics (DL) needed for our work and refer the reader to [4] for further
details. The DL languages of our interest are built from countably infinite sets of concept names (Nc), role names (Np), indi-
vidual names (N)), concrete property names (Nr), and concrete predicates (Np). For brevity, individual names will sometimes
be called constants. A signature © is a subset of Nc UNR UN; UNg.®

We will use metavariables A, B for concept names, C, D for (possibly compound) concepts, R,S for roles, a,b for indi-
vidual names, f, g for concrete property names, and p for concrete predicates. Concepts are built from concept names and
from the concept constructors listed in Table 1. Similarly, roles are built from role names and from the role constructors
listed in Table 1. In the following the term expression refers to both concepts and roles.

An interpretation Z of a signature D is a structure J = (A“,-%) where A” is a nonempty set, and the interpretation
function -4, defined over ¥, is such that (i) A2 C A® if A ENc; (ii) R2 C A* x A® if R E Np; (iii) a? ¢ A® if aeEN;;
(iv) f2 C A* x A? if f © Ne, where A denotes the domain of the predicates in Np. The semantics of an n-ary predicate
p €Np is a set of tuples p? C (A”)". As usual, the pair (A?,Np) is called concrete domain.? In this paper we use AP = N
and unary concrete predicates ing,, where €,u € N, such that ine y = [¢,u]. To enhance readability we will abbreviate

ing y(f) to 4f.[@, u]. So an individual d € A# belongs to (Af.[¢,u])~ if, for some integer i € [£, u], (d,i) € fZ.

The third column of Table 1 shows how to extend the valuation -7 of an interpretation Z to compound DL expressions
and axioms. GCI stands for “general concept inclusion”. An interpretation Z satisfies an axiom @ (equivalently, Z is a model
of a) if Z satisfies the corresponding semantic condition in Table 1. When Z satisfies ~@ we write Z Ea. We will sometimes
use axioms of the form C = D, that are abbreviations for the pair of inclusions CC D and DEC.

A knowledge base K is a finite set of DL axioms. Its terminological part (or TBox) is the set of terminological axioms!” in
K, while its ABox is the set of its assertion axioms.

If X is a DL expression, an axiom, or a knowledge base, then %(X) denotes the signature consisting of all symbols
occurring in X, but concrete predicates. An interpretation Z of a signature & D> X(K) is a model of K (in symbols, Z — K)
if Z satisfies all the axioms in K. We say that K entails an axiom a (in symbols, K — @) if all the models of K satisfy a.
The subsumption problem consists in deciding whether K ECC D for given K, C, and D.

A pointed interpretation is a pair (Z,d) where d € A. We say (Z,d) satisfies a concept C iff d € C“. In this case, we write
(Z,d) EC.

2.1. The description logics used in this paper

The logic SRZO supports the SRZO constructors and axioms illustrated in Table 1. In a SRZQ knowledge base, in
order to preserve decidability, the set of role axioms should be regular and the roles S,S;,S2 simple, according to the
definitions stated in [28].!'! Horn-SRZQ further restricts SRZOQ GCls as specified in [38]. For simplicity, here we illustrate

8 Concrete predicates are deliberately left out due to their special treatment.

9 We are assuming - for brevity - that there is one concrete domain. However, this framework can be immediately extended to multiple domains.
10 See Table 1.

1 The definitions are omitted because they are not needed in our results.
PA. Bonatti, L. Ioffredo, I.M. Petrova et al. Artificial Intelligence 289 (2020) 103389

Table 1
Syntax and semantics of DL constructs and axioms.

Name Syntax Semantics

SRZO concept and role constructors (the latter recognizable by the word “role” in the name)

inverse role R- {(y,x) | (x,y) €R7}  (R ENr)

top T TE=At

bottom L 1F=9G

intersection CnD (CnND)* =CZN Dt

union CuD (CUuD)* =CtUD*

complement aC (—C)* = A* \ CF

existential restriction AR.C {d € A* | d(d,e) € R7 :e € C7}

universal restriction VR.C {de At | V(d,e) €R* :e€ C7}

number restrictions pan S.C {xe A* | #{y | (x,y) €S*AyeCt}oun} (K=<,>)
self 4S.Self {x € AF | (x,x) € S7}

Additional concept and role constructors of SROZQ (D) (the latter with the word “role” in the name)
universal role U Ut = A? x At

nominals {a} {a}? = {at} (aeEN))

concrete constraints p(fi, --. fn) {xeA* | Ave(A?)". (x, vi) € f7 (1 <i<n) and vep?}
SRTO terminological axioms T satisfies the axiom if:

GCI CED ct cDt

role disjointness disj(S1, S2) SENST =

complex role inclusions R10o...oR, CR R{0...0RT CR*

SRTO concept and role assertion axioms

conc. assrt. C(a) at ect
role assrt. R(a, b) (a, b)* € R*
Other terminological axioms expressible with the above axioms and used in low-complexity DLs
disjointness disj(C, D) C7 nN Dt =G
functionality func(R) R7 is a partial function
range range(R, C) Rt CA? x CF
Table 2
The Horn restriction of S7ZO GCIs (normal form).
C1NC2CD
AR.CCD
CCVR.D
CCAR.D
CC <1S.D
CC >n S.D

The above concepts C,C;,C2,D either belong to
Nc U{L, T}, or are of the form 4S.Self. Symbol S$ de-
notes a simple role [28].

only the normal form adopted in [39], see Table 2. Like all Horn DLs, Horn-SRZQ is convex, that is, K E Co £ Cy UC? holds
iff either K ECo EC, or KE CoE C2

The logic EL is a fragment of Horn-SRZQ that supports only atomic concepts and roles, T, m, and existential restric-
tions. Supported axioms are GCIs and assertions. We will denote with €£* the extension of €£ with -L and range axioms.
ELt+ denotes the extension of €£* with nominals, concrete domains, complex role inclusions, and range axioms.!* Sub-
sumption checking and consistency checking are tractable in €£ and €£L*. The same holds for E£** provided that concrete
domains have a tractable entailment problem and are convex, in the sense that — pi1(f1) V... VY Dn(fn) holds iff E pi(fi)
holds for some i €[1,n] [3]. €EL** provides the foundation for the OWL2-EL profile.!*

The logic DL-lite is a fragment of Horn-SRZQO that supports only inverse roles, unqualified existential restrictions (i.e.
concepts of the form 4R.T), GCIs and assertions. Moreover, complements (—) are allowed on the right-hand side of GCls.
DL-liter extends DL-lite with role inclusions of the form RCS and RE-S. DL-lite}* extends DL-lite by supporting M and
role inclusions of the form Rj E R2. Subsumption and consistency checking are tractable in both logics. DL-lite constitutes
the foundation of the OWL2-QL profile. '4

The logic SROZQ(D) supports all the constructs and axioms illustrated in Table 1. It is the description logic underlying
the standard OWL2-DL.

12 Range axioms must satisfy the restrictions described in Sec. 2.2.6 of https://www.w3.org/TR/owl2-profiles. We do not need those details in this paper.
13 https://www.w3.org/TR/owl2-profiles/#OWL_2_EL.
14 https://www.w3.org/TR/owl2-profiles/#OWL_2_QL.
PA. Bonatti, L. Ioffredo, I.M. Petrova et al. Artificial Intelligence 289 (2020) 103389

To fix ideas, in the following two subsections let K range over SROZQ(D) knowledge bases. However, the results and
definitions of those subsections hold also for the DLs that are not fragments of SROZQ(D), such as the logic supported by
CLASSIC [17] and the DLs with fixpoints [14].

2.2. The disjoint model union property

A knowledge base K such that &(K) ON; = @ enjoys the disjoint model union property if for all disjoint models Z and
J of K, their disjoint union ZW 7 = (AZ w AZ, -2%7) - where PZ°7 = P42 w PY for all PE Nc UNp UNF - Satisfies
K, too ({4], Ch. 5). This definition is extended naturally to the union |4)S of an arbitrary set S of disjoint models. The
disjoint model union property plays an important role in our results. It is broken by the universal role and nominals. The
main problem with nominals (and the reason of the prerequisite X(K’) ON; = @) is that if Z and J are disjoint, then for
all individual constants a € N, a’ £a*, so it is not immediately clear what a““7 should be. This problem can be resolved
for the constants occurring in ABoxes. Informally speaking, it suffices to pick the constants’ interpretation from an arbitrary
argument of the union. !°

Definition 2.1 (Generalized disjoint union). For all sets of mutually disjoint interpretations S and all Z € S, let 7 S be the
interpretation 7/ such that:

AM =|J{A7 | 7S)

p“ =| )(P7 | 78} for all PE Nc UNR UNE

a’ — qt for allaeN,.

If the terminological part of a knowledge base K has the (standard) disjoint model union property, then the generalized
union of disjoint models of XK is still a model of K:

Proposition 2.2. Let K = 7 UA, where T is the terminological part of K and A is its ABox. If T has the disjoint model union property
then for all sets S of mutually disjoint models of K, and for all Z € S, 7 SEK.

Proof. Let S and Z be as in the statement, and let U/ = I S. Note that &(7) NN, = 9, otherwise the disjoint union of
T’s models would not be defined and 7 would not enjoy the disjoint model union property, contradicting the hypothesis.
For all interpretations 7, let 7\N; denote the restriction of .7 to the symbols in Nc UNpr UN¢ (i.e. excluding the individual
constants in N,). Note that for all 7 €S, Z\N is a model of 7, because &(7) MN; = W. Therefore, by hypothesis, 4J{.7\N, |
J €S} is a model of 7. Clearly, W{7\N) | 7 € S} = (4% S)\Ni; as a consequence, also Ws is a model of 7. We are only
left to prove that U/ is a model of A. Consider an arbitrary assertion aw € A. Since the models in S are disjoint, and the
interpretation of constants in 2/ ranges over A“, it holds that a4“ « C™ iff a? «C4, (a4, b“) € RY iff (a+, b*) € R%, and
f4 a4) = f(a“) (f ©Ne). Moreover, Z is a model of A by hypothesis. It follows immediately that 7/ is a model of A.

2.3. Modularity and locality

A knowledge base XK is semantically modular with respect to a signature © if each interpretation Z = (A7, -“) over ¥ can
be extended to a model 7 = (AY,-”) of K such that AZ = A® and XY = X%, for all symbols X € D. Roughly speaking,
this means that K does not constrain the symbols of © in any way.

A special case of semantic modularity exploited in [21] is locality: A knowledge base XK is local with respect to a signature
x if the above 7 can be obtained simply as specified in the next definition.

Definition 2.3 (Locality). A knowledge base X is local with respect to a signature ¥ if each interpretation Z = (A“, -%) over
> can be extended to a model .7 = (AY, -”) of K by setting X% =@ for all concept and role names X € X(K) \ ¥.

Locality will be needed in Section 5, for the integration of ?£ knowledge bases with imported ontologies. In particular,
it is an essential ingredient of the completeness proof for IBQ reasoning.

3. Semantic encoding of data usage policies

SPECIAL’s policy language PL - that is a fragment of OWL2-DL - has been designed to describe data usage. Such de-
scriptions can be exploited to encode: (i) the consent to data processing given by data subjects, (ii) how the controller’s

15 The following formalization of this idea generalizes a proof technique used in [21, Lemma 1].

5
PA. Bonatti, L. Ioffredo, I.M. Petrova et al. Artificial Intelligence 289 (2020) 103389

internal processes use data, and (iii) selected parts of the GDPR that can be used to support the validation of the con-
troller’s internal processes. Moreover, PL is used to encode the entries of SPECIAL’s transparency ledger, that is a log of data
processing operations that can be queried by:

e data subjects, in order to monitor how their personal data are used by the controller and where they are transferred
to;

e data protection officers, in order to audit the behavior of the controller;

e the controllers themselves, in order to monitor their own internal processes.

The aspects of data usage that have legal relevance are clearly indicated in several articles of the GDPR and in the available
guidelines. They are mentioned, for example, in the specification of what is valid consent, what are the legal bases for
processing, what are the rights of data subjects, which aspects should be covered by national regulations, and the obligation
of controllers to keep a record of the processing operations that involve personal data (see, inter alia, Articles 6.1, 6.3, 6.4,
7, 15.1, 23.2, 23.2, 30.1). See also the section titled “Records should contain” in the guidelines for SMEs published on http://
ec.europa.eu/justice/smedataprotect/index_en.htm. That section describes how to fulfill the obligation to record the data
subjects’ consent to processing (Article 7) and, in particular, it specifies which pieces of information should be recorded.
According to the above sources of requirements, the main properties of data usage that need to be encoded and archived
are the following:

reasons for data processing (purpose);

which data categories are involved;

what kind of processing is applied to the data;

which third parties data are distributed to (recipients);
countries in which the data will be stored (location);
time constraints on data erasure (duration).

The above properties characterize a usage policy. SPECIAL adopts a direct encoding of usage policies in description logics,
based on those features. The simplest possible policies have the form:

dhas_purpose. P mM dhas_data.D m dhas_processing.O Mm Shas_recipient.R M (1)
dhas_storage(Shas_location.L M dhas_duration.T) .

All of the above roles are functional. Duration is represented as an interval of integers [t;, t2], representing a minimum and
a maximum storage time (such bounds may be required by law, by the data subject, or by the controller itself). The classes
P, D, O, etc. are defined in suitable auxiliary vocabularies (ontologies) that specify also the relationships between different
terms. The expressiveness requirements on the vocabularies and their design are discussed later, in Section 5. Until then,
the reader may assume that the vocabularies are defined by means of inclusions A C B and disjointness constraints disj(A, B), where
A, B are concept names. Such restrictions will be lifted later.

If the data subject consents to a policy of the form (1), then she authorizes all of its instances. For example if D =
DemographicData then the data subject authorizes -— in particular —- the use of her address, age, income, etc. as specified by
the other properties of the policy.

It frequently happens that the data controller intends to use different data categories in different ways, according to their
usefulness and sensitivity, so consent requests comprise multiple simple usage policies like (1) (one for each usage type). The
intended meaning is that consent is requested for all the instances of all those policies; accordingly, such a compound policy
is formalized with the union of its components. The result is called full (usage) policy and has the form:

P,U...U Pp (2)

where each P; is a simple usage policy of the form (1). Symmetrically, with a similar union, data subjects may consent to
different usage modalities for different categories of data and different purposes.

Example 3.1. A company - call it BeFit - sells a wearable fitness appliance and wants (i) to process biometric data (stored
in the EU) for sending health-related advice to its customers, and (ii) share the customer’s location data with their friends.
Location data are kept for a minimum of one year but no longer than 5; biometric data are kept for an unspecified amount
of time. In order to do all this legally, BeFit needs consent from its customers. The internal (formalized) description of such
consent would look as follows:
PA. Bonatti, L. Ioffredo, I.M. Petrova et al. Artificial Intelligence 289 (2020) 103389

(dhas_purpose.FitnessRecommendation Nn
dhas_data.BiometricData N
has_processing.Analytics
dhas_recipient.BeFit n
dhas_storage.dhas_location.EU)
Lu (3)
(Shas_purpose.SocialNetworking NM
dhas_data.LocationData Nn
has_processing. Transfer
dhas_recipient.DataSubjFriends
dhas_storage.(shas_location.EU MN dhas_duration.[y1, y5]).

Here y; and ys are the integer representation of one year and five years, respectively. If “HeartRate” is a subclass of
“BiometricData” and “ComputeAvg” is a subclass of “Analytics”, then the above consent allows BeFit to compute the average
heart rate of the data subject in order to send her fitness recommendations. BeFit customers may restrict their consent, e.g.
by picking a specific recommendation modality, like “recommendation via SMS only”. Then the first line should be replaced
with something like Shas_purpose.(FitnessRecommendation N Acontact.SMS). Moreover, a customer of BeFit may consent to
the first or the second argument of the union, or both. Then her consent would be encoded, respectively, with the first
argument, the second argument, or the entire concept (3). Similarly, each single process in the controller’s lines of business
may use only biometric data, only location data, or both. Accordingly, it may be associated to the first simple policy, the
second simple policy, or their union. In other words, (3) models the complete data usage activities related to the wearable
device, that may be split across different processes.

The usage policies that are actually applied by the data controller’s business processes are called business policies and
include a description of data usage of the form (1). Additionally, each business policy is labeled with its legal basis and
describes the associated obligations that must be fulfilled. For example, if the data category includes personal data, and
processing is allowed by explicit consent, then the business policy should have the additional conjuncts:

dhas_legal_basis.Art6_1_a_Consent nN
dhas_duty.GetConsent N dhas_duty.GiveAccess MN
dhas_duty.RectifyOnRequest N

dhas_duty.DeleteOnRequest

(4)

that label the policy with the chosen legal basis, and model the obligations related to the data subjects’ rights, cf. Chapter 3
of the GDPR. More precisely, the terms involving has_duty assert that the process modeled by the business policy includes
the operations needed to obtain the data subject’s consent (Shas_duty.GetConsent) and those needed to receive and apply
the data subjects’ requests to access, rectify, and delete their personal data.

Thus, business policies are an abstract description of a business process, highlighting the aspects related to compliance
with the GDPR and data subjects’ consent. Similarly to consent, a business policy may be a union BP; LU... BP, of simple
business policies BP; of the form (1) (4).

In order to check whether a business process complies with the consent given by a data subject S, it suffices to
check whether the corresponding business policy BP is subsumed by the consent policy of S, denoted by CPs (in sym-
bols, BPC CPs). This subsumption is checked against a knowledge base that encodes type restrictions related to policy
properties and the corresponding vocabularies, i.e. subclass relationships, disjointness constraints, functionality restrictions,
domain and range restrictions, and the like. Some examples of the actual axioms occurring in the knowledge base are:

func(has_purpose)
range(has_data, AnyData)
Demographic EC AnyData
Update LC AnyProcessing
Erase LC Update
disj(AnyData, AnyPurpose)

(recall that more general knowledge bases will be discussed later).

In order to verify that all the required obligations are fulfilled by a business process (as abstracted by the business
policy), selected parts of the GDPR are formalized with concepts like the following. The first concept states that a business
policy should either support the rights of the data subjects, or concern anonymous data, or it should fall under some of the
exceptional cases mentioned by the regulation, such as particular law requirements. The remaining requirements are not
listed here (they are replaced with an ellipsis):

(dhas_duty.GetConsent nN dhas_duty.GiveAccess lM...) U
dhas_data.Anonymous LI (5)
has_purpose.LawRequirementL!...
PA. Bonatti, L. Ioffredo, I.M. Petrova et al. Artificial Intelligence 289 (2020) 103389

The second example encodes the constraints on data transfers specified in Articles 44-49 of the GDPR:

has_storage.dhas_location.EU LU
dhas_storage.dhas_location.EULike L...

(6)

It states that data should remain within the EU, or countries that adopt similar data protection regulations. The ellipsis
stands for further concepts that model the other conditions under which data can be transferred to other nations (e.g.
under suitable binding corporate rules). Please note that the above concepts constitute only a largely incomplete illustration
of the actual formalization of the GDPR, that is significantly longer due to the special provisions that apply to particular
data categories and legal bases. The purpose of the above examples is conveying the flavor of the formalization. Its usage is
sketched below.

A business policy BP can be checked for compliance with the formalized parts of the GDPR by checking whether the
aforementioned knowledge base entails that BP is subsumed by the concepts that formalize the GDPR.

Example 3.2. The following business policy complies with the consent-related obligations formalized in (5) since it is sub-
sumed by it:

(dhas_purpose.FitnessRecommendation Nn
dhas_data.BiometricData N
has_processing.Analytics
dhas_recipient.BeFit n
dhas_storage.shas_location.EU n
4dhas_legal_basis.Art6_1_a_Consent) (7)
dhas_duty.GetConsentr... all the remaining concepts in (4)...)
Lu
(sShas_purpose.Sell Nn
dhas_data.Anonymous
has_processing. Transfer
dhas_recipient.ThirdParty) .

In particular, the two disjuncts of (7) are subsumed by the first two lines of (5), respectively. Note that the second simple
policy does not place any restrictions on location, so it allows data to flow to any country, including those that do not enjoy
adequate data protection regulations. However, this is compliant with the GDPR because data are anonymous.

The concepts in the range of existential restrictions may themselves be a conjunction of atoms, interval constraints and
existential restrictions. We have already seen in policy (3) that has_storage may contain a conjunction of existential restric-
tions over properties has_location and has_duration. Another example, related to SPECIAL’s pilots, concerns the accuracy of
locations, that can be modeled with concepts like:

dhas_data.(Location MN dhas_accuracy.Medium) .

Based on the above discussion, we are now ready to specify PL (policy logic), a fragment of OWL 2 that covers - and slightly
generalizes — the encoding of the usage policies and of the GDPR outlined above.

Definition 3.3 (Policy logic PL). A PL knowledge base K is a set of axioms of the following kinds:

func(R) where R is a role name or a concrete property;
range(S, A) where S is a role and A a concept name;
ACB where A, B are concept names;

disj(A, B) where A, B are concept names.

Simple PL concepts are defined by the following grammar, where A € Nc, RE Nr, f € Ne, and /! and u are integers:

C= A] Ll 3flu]|4rR.c| Cnc.

A (full) PL concept is a union Dj; Li... Dy of simple PL concepts (n > 1). PL’s subsumption queries are inclusions C EC D
where C, D are (full) PL concepts.

3.1. Discussion of the encoding

The formalization of policies as classes of data usage modalities addresses several needs.

8
PA. Bonatti, L. Ioffredo, I.M. Petrova et al. Artificial Intelligence 289 (2020) 103389

First, on the controller’s side, each instance of a process may slightly differ from the others. For example, different
instances of a same process may operate on data that are stored in different servers, possibly in different nations (this
typically happens to large, international companies). The concrete data items involved may change slightly (e.g. age may be
expressed directly or through the birth date; the data subject may be identified via a social security number (SSN), or an
identity card number, or a passport number). By describing storage location, data, and the other policy attributes as classes,
controllers can concisely describe an entire collection of similar process instances. With reference to the above examples,
classes allow to express that data are stored “somewhere in the EU” and “in the controller’s servers”; both age and birthdate
fall under the class of demographic data; SSN and document numbers can be grouped under the class of unique identifiers.

A second advantage of classes is that they support a rather free choice of granularity. For example, the classes that model
locations can be formulated at the granularity of continents, federations, countries, cities, zip-codes, down to buildings
and rooms. Subsumption naturally models the containment of regions into other regions. A flexible choice of granularity
helps in turning company documentation into formalized business policies, since it facilitates the import of the abstractions
spontaneously used by domain experts.

The third, and perhaps most important advantage is that classes facilitate the reuse of consent. The GDPR sometimes
allows to process personal data for a purpose other than that for which the data has been collected, provided that the new
purpose is “compatible” with the initial purpose.!° Compatibility cannot be assessed automatically, in general, because it is
not defined in the regulation; only a human with specific legal background can deal reliably with the involved subtleties.
However, by expressing purposes as classes, one can at least have the data subject consent upfront to a specified range
of “similar” purposes. Roughly speaking, the accepted class of purposes is like an agreement - between data subjects and
controllers - on which purposes are “compatible” in the given context. Also expressing the other policy properties as classes
is beneficial. If data subjects consent to wider classes of usage modalities, then the need for additional consent requests
tends to decrease; this may yield benefits to both parties, because:

1. data subjects are disturbed less frequently with consent requests (improved usability, better user experience);

2. the costs associated to consent requests decrease. Consider that sometimes the difficulties related to reaching out to the
data subjects, and the concern that too many requests may annoy users, make controllers decide not to deliver a service
that requires additional consent.

From a theoretical viewpoint, the class-based policy formalization adopted by SPECIAL is essentially akin to a well-
established policy composition algebra [10]. The algebra treats policies as classes of authorizations (each policy P is
identified with the set of authorizations permitted by P). In turn, authorizations are tuples that encode the essential
elements of permitted operations, such as the resources involved and the kind of processing applied to those resources.
Analogously, each PL policy like (1) denotes a set of reifications of tuples, whose elements capture the legally relevant
properties of data usage operations.

3.2. Related policy languages

Logic-based languages constitute natural policy languages, because policies are knowledge. First, note that policies encode
declarative constraints on a system’s behavior, that depend on metadata about the actors and the objects involved (e.g.
ownership, content categories), and an environment (as some operations may be permitted only in certain places, or at
specified times of the day, or in case of emergency). Semantic languages and formats have been expressly designed to
encode metadata, so standard knowledge representation languages can represent in a uniform way both policy constraints
and the metadata they depend on.

The second important observation is that - like knowledge and unlike programs - every single policy is meant to be
used for multiple, semantically related tasks, such as the following:

e permission checking: given an operation request, decide whether it is permitted;

e compliance checking: does a policy P fulfill all the restrictions requested by policy P2? (Policy comparison);

e policy validation: e.g. is the policy contradictory? Does it comply with a given regulation? Does a policy update
strengthen or relax the previous policy?

e policy explanation: explain a policy and its decisions.

The terse formal semantics of logical languages is essential in validating the correctness of the policies themselves and the
implementation of the above tasks, ensuring their mutual coherence. Moreover, when data are transferred under agreed
policies, it is crucial that both parties understand the policies in the same way. So unambiguous semantics is essential for
correct interoperability, too.

In the light of the above observations, it is clear that knowledge representation languages are ideal policy representation
languages. Indeed, both rule languages and description logics have already been used as policy languages; a non-exhaustive

16 See for example articles 5.1 (b) and 6.4.
PA. Bonatti, L. Ioffredo, I.M. Petrova et al. Artificial Intelligence 289 (2020) 103389

list is [49,30,48,32,11]. As noted in [7], the advantage of rule languages is that they can express n-ary authorization con-
ditions for arbitrary n, while encoding such conditions for n > 2 is challenging in DL. The advantage of DL is that all the
main policy-reasoning tasks are decidable (and tractable if policies can be expressed with OWL 2 profiles), while compli-
ance checking is undecidable in rule languages, or at least intractable, in the absence of recursion, because it is equivalent
to Datalog query containment. So a DL-based policy language is a natural choice in a project like SPECIAL, where policy
comparison is the predominant task.

The aforementioned works on logic-based policy languages focus on access control and trust management, rather than
data usage control. Consequently, those languages lack the terms for expressing privacy-related and usage-related concepts.
A more serious drawback is that the main reasoning task in those papers is permission checking; policy comparison (which
is central to our work) is not considered. Both Rei and Protune [32,11] support logic program rules. Therefore, as we pointed
out above, policy comparison is generally hard and possibly undecidable. This drawback makes such languages unsuitable
to SPECIAL’s purposes. Similarly, KAoS [48] is based on a DL that, in general, is not tractable, and supports role-value maps
— a construct that easily makes reasoning undecidable (see [4], Chap. 5). The papers on KAoS do not discuss how the policy
language is restricted to avoid this issue.

The terms used as role fillers in SPECIAL’s policies are imported from well established formats for expressing privacy
preferences and digital rights, such as P3P (the Platform for Privacy Preferences)!’ and ODRL (the Open Digital Right Lan-
guage).'® More general vocabularies will be discussed in Section 5. It is interesting to note that P3P’s privacy policies
— that are encoded in XML - are almost identical to simple PCL policies: the tag STATEMENT contains tags PURPOSE,
RECIPIENT, RETENTION, and DATA-GROUP, that correspond to the analogous properties of SPECIAL’s usage policies. Only
the information on the location of data is missing. The tag STATEMENT is included in a larger context that adds infor-
mation about the controller (tag ENTITY) and about the space of web resources covered by the policy (through so-called
policy reference files). All of these additional pieces of information can be directly encoded with simple P£ concepts. Similar
considerations hold for ODRL. The tag RIGHTS associates an ASSET (the analogue of has_data) to a PERMISSION that
specifies a usage modality. ODRL provides terms for describing direct use (e.g. play or execute), reuse (e.g. annotate or
aggregate), transfer (sell, lend, lease), and asset management operations (such as backup, install and delete, just to name
a few). These terms provide a rich vocabulary for specifying the has_processing property of SPECIAL’s policies. Also in the
case of ODRL, the tree-like structure of XML documents can be naturally encoded with PL concepts.

3.3. Related work on legal reasoning

Despite superficial similarities, SPECIAL’s policy framework and the many works on legal reasoning have different goals.
The survey [44] lists several applications of logic and reasoning to the legal domain that can be grouped as follows:

a. Supporting the legislators in writing less ambiguous, possibly normalized legal documents.

b. Modeling legal concepts and definitions.

c. Interpreting the law.

d. Modeling the debates and pleadings that take place in courts, and deriving legal qualifications.

The work on vocabularies carried out by SPECIAL and the DPVCG can be regarded as a streamlined version of (b), while the
use case of business policy validation based on GDPR’s partial formalization does not really match any of the above points.
Policy validation is less ambitious than legal reasoning; it is only aimed at checking whether the different properties of
the policy are mutually coherent (e.g. by checking that the legal basis matches the data category), and whether all relevant
parts have been included (such as the appropriate obligations in case of consent-based processing or data transfers outside
the EU). The latter is a way to check whether the human responsible has “ticked all the necessary boxes”, and by no
means tackles the legal reasoning required to assess whether the obligations have been actually and appropriately fulfilled;
according to our experience in SPECIAL, algorithms and ontologies are not yet trusted on this matter - especially due to the
severe consequences in case of wrong decisions.

Both business policy validation and compliance checking w.r.t. consent policies shall verify that business policies do
the right thing in all contexts while the literature on legal reasoning focuses on whether a legal qualification (such as an
obligation, a permission, the validity of a contract, etc.) holds in a specific situation [44]. This difference has remarkable
technical consequences: as we have already pointed out, validation in all contexts (i.e. policy comparison) is intractable in
rule-based languages (that are common in the works on legal reasoning, since the seminal paper [45]), and even undecidable
if rules are recursive [7]. The DL-based approach we adopted guarantees decidability and - under suitable hypotheses -
tractability, as shown in the following sections.

The ambitious goals of legal reasoning have been tackled with sophisticated formalisms, such as deontic and nonmono-
tonic logics, see for example [31,29,1,24]. Fortunately, the different goals of SPECIAL’s compliance checking make these
complications unnecessary. Simplicity is strategic for the project, since the personnel that is expected to write the business

17 http://www.w3.org/TR/P3P11.
18 https://www.w3.org/TR/odrl/.

10
PA. Bonatti, L. Ioffredo, I.M. Petrova et al. Artificial Intelligence 289 (2020) 103389

policies has no background on mathematical logic, deontic logic, nor nonmonotonic logic. The usability of SPECIAL’s simple,
form-like business policies has been successfully tested by one of the industrial partners of SPECIAL.

Formal ontologies based on DLs have been used to represent and reason over legal concepts, or as interchange formats
to merge different sources of legal information. An example of legal ontology is LKIF Core [27] which has been developed
in OWL1.1. LKIF Core follows a stratified approach defining an intentional layer on top of the legal layer. The intentional
layer models different aspects of intentional behavior such as actions, plans, beliefs, and intentions. The legal layer concerns
public acts, like norms, that have a legal relevance. Norms are further specialized in Right, Obligation, Permission, and
Prohibition, that are coherently related to normative qualifications such as Allowed, Disallowed, Obliged, etc.

Recent work on legal reasoning - leveraging deontic and nonmonotonic logics - has been expressly tailored to the
GDPR. The authors of [41,42] propose an ontology, PrOnto, aiming at supporting legal reasoning in general and compliance
checking w.r.t. the GDPR. PrOnto defines a taxonomy of basic concepts and roles occurring in the GDPR and is organized in
5 distinct modules: Data and Documents, Agent and Role, Data Processing, Purposes and Legal Basis, and Deontic Operators.

In [40] PrOnto and LegalRuleML (a semantics-neutral interchange format) have been included in a larger architecture for
developing GDPR-compliant cloud computing platforms for eGovernment. The graphic tool RAWE supports legal experts in
translating legal text into formal rules which can be applied to a BPMN description of an eGov service. Compliance with
the GDPR is then checked by the defeasible legal reasoning engine SPINdle. As a use case scenario, the article shows the
formalization of Art. 8 of the GDPR concerning parental consent.

Differently from SPECIAL, the framework proposed in [40-42] pursues the more ambitious goals of legal reasoning and
operates on a workflow-based representation of the controller’s activities, more complex than business policies. These
choices increase the cost of framework instantiation and rely on users with the necessary legal and logical background
for editing and verifying legal rules - two assumptions that are not aligned with SPECIAL’s reference scenarios. Further-
more, compliance checking is only static, and it does not address SPECIAL’s need for real-time compliance checking with
respect to the changing consent of data subjects. Summarizing, SPECIAL trades advanced legal reasoning capabilities for
usability and scalability.

4. Reasoning with PL

As explained in the introduction, some of the use cases of SPECIAL place challenging scalability requirements on the
compliance checker, that should be able to execute over 10* subsumption checks per second, as in the streaming scenario.
These scalability requirements have been addressed by finding a tradeoff between expressiveness and efficiency. The lan-
guage PCL - that is rich enough to encode the policies of interest - is also simple enough to be implemented very efficiently.
Intervals, however, are a source of complexity and must be suitably restricted. In this section, we are first going to prove
that unrestricted subsumption checking in PL is coNP-complete. Then we show that the structure of usage policies can
be exploited to make restrictive assumptions on the occurrences of intervals. Under such assumptions, we can prove that
an approach articulated in two stages - where first business policies are suitably normalized, then compliance with con-
sent policies is checked with a structural subsumption algorithm - is correct, complete, and tractable. Its scalability will be
experimentally assessed in Section 6.

We start by laying out the formal description and the theoretical properties of normalization and structural subsump-
tion. In particular, this section deals with the correctness and completeness of the two-stages method, and discusses the
computational complexity of arbitrary subsumptions and of the restricted, tractable case. We first prove the intractability of
unrestricted subsumption in PL.

Theorem 4.1. Deciding whether K / C EC D, where K is a PL knowledge base and C, D are PL concepts, is coNP-hard.'° This
statement holds even if the knowledge base is empty and C is simple.

Proof. Hardness is proved by reducing 3SAT to the complement of subsumption. Let S be a given set of clauses cj =
Liq V Liz V Liz (1 <i <n) where each Ljj is a literal. We are going to use the propositional symbols pj,..., Pm occurring
in S as property names in PL concepts, and define a subsumption C EC D that is valid iff S is unsatisfiable. Let C =
(4p1.[0, 1]n...N4pm.[0, 1]) and D = Lie (Lit OLjgn Liz), where each Lij encodes the complement of Lj; as follows:

i= Ap,.[0,0] if Li; = pr,
4 Apx.[1,1] if Lij =—pr.

The correspondence between the propositional interpretations J of S and the interpretations 7 of C C D is the following.
Given | and an arbitrary element d, define .7 = ({d}, -”) such that (d, 0) € py iff I(p;) = false, and (d, 1) € py otherwise.
By construction, (7,d) EC, and I ES iff (7,d) K D. Consequently, if S is satisfiable, then C CE D is not valid.
Conversely, if C E D is not valid, then there exist .7 and de A’ such that (7,d) EK CN-D. Define a propositional
interpretation I of S by setting I(p) = true iff (d,1) € py. By construction (and since d does not satisfy D in 7), IES,
which proves that if C C D is not valid, then S is satisfiable.

19 As customary, we assume a positional representation of integers.

11
PA. Bonatti, L. Ioffredo, I.M. Petrova et al. Artificial Intelligence 289 (2020) 103389

We conclude that the above reduction is correct. Moreover, it can be clearly computed in polynomial time. This proves
that subsumption is coNP-hard even if the knowledge base is empty and C simple.

Later on we will complete the characterization of ?£ subsumption by proving its membership in coNP (Theorem 4.13).

The above intractability result does not apply to SPECIAL’s usage policies because each simple usage policy contains at
most one interval constraint, namely, a specification of storage duration of the form Jhas_storage.dhas_duration.[¢, u]. We
are going to show that this property (actually, a slight generalization thereof) makes reasoning quite fast. More specifically, it
enables an efficient treatment of interval constraints based on a suitable interval normalization method. Such normalization
produces subsumption queries that satisfy the following property.

Definition 4.2 (Interval safety). An inclusion C EC D is interval safe iff, for all constraints 4f.[€,u] occurring in C and all
A f’.[@’, u’] occurring in D, either [2,u] C[¢’,u’], or [€, uJ N[@, uw] = 9.

Roughly speaking, interval safety removes the need for treating intervals like disjunctions; it makes them behave like
plain atomic concepts. Every inclusion can be turned into an equivalent, interval safe inclusion, using the following method.

Definition 4.3 (Interval normalization, splitp(C)). For each constraint 3f.[¢, u] in C, let x1 < x2 <--- <x; be the integers that
occur as interval endpoints in D and belong to [€,u]. Let x9 = @ and x;4; =u and replace 3f.[¢,u] with the equivalent
concept

r

L | (4f-[xi. xe] US [xi +1, X41 — 1) USF Deep, X41]. (8)
i=0

Then use distributivity of N over LI and the equivalence 4R.(Cj LI C2) =AR.Cy UAR.C2 to move all occurrences of LI to the
top level. Denote the result of this interval normalization phase with splitp(C).

Example 4.4. Let C=4f.[1,9]0A and D=4f.[5,12]. Then r=1 and x9 = 1, x1 = 5, X2 = 9 (12 falls outside [1,9] and is
ignored). According to (8), the concept 4f.[1,9] in C is replaced by the following union:

Af (1, 1uSf.[2,4]U5f.[5, 5] U5f.[6, 8] US f.[9, 9].

Then, after applying distributivity, we obtain the concept splitp(C) (that is a full PL concept):
(Af .[1,1]n A) uU Gf.[2,4]n A) uU (f.[5,5] 0 A)U(f.[6,8] nN A)UGf.[9,9] 0A).
The reader may easily verify that:

Proposition 4.5. For all ?L subsumption queries C CE D, splitp(C) is equivalent to C and splitp(C) CE D is an interval-safe PL
subsumption query.

In general, splitp(C) may be exponentially larger than C, due to the application of distributivity (e.g. this happens with
the concepts C and D in the proof of Theorem 4.1). However, as we have already pointed out, each simple policy has at
most one, functional concrete property so no combinatorial explosion occurs during interval normalization. Accordingly -
and more generally - the following proposition holds:

Proposition 4.6. Let C=C, UU... LC, be a PCL concept, and suppose that for alli = 1,...,n, the number of concrete properties
occurring in C; is bounded by a constant c. Then, for all concepts D, the size of splitp(C) is O(\C| - |D|°).7°

Note that C as a whole may still contain an unbounded number of interval constraints, as n grows, because the bound c
applies only to the individual disjuncts Cj.

The structural subsumption algorithm for PL’s subsumption queries accepts subsumptions whose left-hand side is fur-
ther normalized with respect to the given knowledge base K by exhaustively applying the rewrite rules illustrated in Table 3.
Such rules make contradictions explicit and merge functional properties. They clearly preserve equivalence, as stated in the
next proposition:

Proposition 4.7. If C-~ C’ then KK KC=C"’.

20 We denote the size of the encoding of an expression E with |E|.

12
PA. Bonatti, L. Ioffredo, I.M. Petrova et al. Artificial Intelligence 289 (2020) 103389

Table 3

Normalization rules w.r.t. KC. Intersections are treated as sets (the ordering of conjuncts
and their repetitions are irrelevant). ©* denotes the reflexive and transitive closure of
{(A, B) | (AE B) eK}.

1) LAD~Y L
2) SARL GL
3) Sf (LhuJ~ L ifl>u
A) (AR.D)N(AR.D'!) nD’ ~
4R.(D nD’) nD” if func(R) €
5) Af.fh,uijnaf.[b,u2]n D~
Af .[max(l, 12), min(u1, u2)]m D if fune(f) e€K

6) JAR.DOD!’~+3R.(DNA)ND’ if range(R, A) € K, and neither A
nor L are conjuncts of D
7) AinA2nD~> L if A; C* Aj, A2 C* AS, and

disj(A4, AS) K

 

 

The proof is trivial and left to the reader. It is easy to see that concepts can be normalized in polynomial time:
Lemma 4.8. Each PL concept C can be normalized w.r.t. a given PL knowledge base K in time O(|C|? - |K)]).

Proof. We take this chance to illustrate an algorithm which is similar to the one actually used in the implementation of
normalization. First C is parsed into a syntax tree T (time O(|C|)) where each conjunction of n concepts is modeled as a
single node with n children. Then the tree is scanned in a depth-first fashion, looking for nodes labeled with an existential
restriction in order to apply rule 4). For each such node v, if R is the involved role and func(R) € K, then the previous
siblings of v are searched looking for a node v’ with the same role R. If such a v’ is found, then the child C’ of v’ is
replaced with the intersection of C’ itself and the child of v, then v is deleted. This operation (including the functionality
test for R) takes time O(|K| + |C|) for each existential restriction. Thus, the exhaustive application of rule 4) needs time
O(|C|-|K|+|C|?). Rule 5) is dealt with similarly (but instead of merging children, the interval associated to v is intersected
with the interval associated to v’); the cost is the same. None of the other rules adds any new existential restrictions, so
rules 4) and 5) are not going to be applicable again in the rest of the algorithm.

Next, rule 6) is applied by searching the tree T for existential restrictions whose role R occurs in an axiom range(R, A) €
kK. For each of such nodes, A is added to the children as a new conjunct (if necessary). The cost for each existential
restriction is O(|K| + ]|C]|) (where |C| is the cost of verifying whether the existential restriction already contains A or _).
So the exhaustive application of rule 6) is again O(|C| -|K| + |C|*). The remaining rules can remove a range A only by
substituting it with 1, so rule 6) cannot be triggered again in the rest of the algorithm.

Finally, the nodes of T are visited in a depth-first fashion in order to apply rules 1), 2), 3), and 7).

Rule 7) is the most expensive. K is regarded as a labeled classification graph, where each node is labeled with an
atomic concept and with the disjointness axioms in which that concept occurs. The disjointness test between A, and A> in
rule 7) can be implemented by a relatively standard linear-time reachability algorithm, that climbs the classification graph
from A, and starts descending the classification whenever it finds a node labeled with disj(A‘,, A5), searching for Az. In
the worst case, this stage involves O(|C|*) searches (one for each pair Aj, Az in each conjunction), so its global cost is
O(IC|* - |K)).

Finally, note that rules 1-3 do not need to be iteratively applied. If C contains an empty interval [I,u] (1 > u), or an
occurrence of |, at any nesting level, then surely C can be rewritten to |. Therefore, it suffices to scan C once, looking for
empty intervals or L.

Since the cost of rule 7 dominates the cost of the other rules, normalization can be computed in time O(|C|? -
||). #

Normalized queries are passed over to a structural subsumption algorithm, called STS (Algorithm 1). It takes as inputs a
PL knowledge base K and an elementary PL subsumption C CE D:

Definition 4.9 (Elementary subsumptions). A ?£ subsumption C CE D is elementary (w.r.t. a PL knowledge base XK) if both C
and D are simple, C EC D is interval safe, and C is normalized w.r.t. K.

The full subsumption checking procedure (that applies to all ??£ subsumptions) is called PL Reasoner (PLR for short). It
is summarized in Algorithm 2.

PLR is correct and complete. We only state this result, whose proof is sketched in [8], since we are going to prove it in
a more general form for an extended engine that supports more expressive knowledge bases (Section 5).

13
PA. Bonatti, L. Ioffredo, I.M. Petrova et al. Artificial Intelligence 289 (2020) 103389

Algorithm 1: STS(X,C ED).

Input: A PL KB K and a PL subsumption C C D that is elementary w.r.t. IC
Output: true ifKECCD, false otherwise

Note 1: Below, we treat intersections like sets. For example, by C=C’ 4 C” we mean that either C=C’ or C’ is a conjunct of C
(possibly not the first one).

Note 2: C* denotes the reflexive and transitive closure of {(A, B) | (AE B) € Ky}.

1 begin

2 if C= 1 then return true ;

3 if D=A,C=A’nC' and A’ C* A then return true;

4 if D=Ff.[l,u] andC =3Ff.[Il',u’/]nC’ and! <I andu’ <u then return true ;
5 if D=4R.D’, C = GR.C’) NC” and STS(K, C’ CE D’) then return true ;

6 if D=D’nD"”, STS(K,C ED’), and STS(K, C CE D”) then return true ;

7 else return false ;

8 end

Algorithm 2: PLR(X, CCD).

Input: A PL KB K and a PL subsumption query C EC D
Output: true ifKECCD, false otherwise

1 begin
2 let C’ be the normalization of C w.r.t. K (with the rules in Table 3) ;
3 let C’ =splitp(C’) ;

// assume that C’=C,U...UCm and D=Dj,U...UD,

// check whether each Cj; is subsumed by some Dj;

4 for i=1,...,mdo

5 for j=1,...,n do

6 | if STS(K, C; © Dj) =true then skip to next i in outer loop;
7 end

8 return false

9 end
10 return true
11 end

Theorem 4.10. For all PL knowledge bases K and all PL subsumption queries q,
Kkeq iff PLR(K,q) =true.

With this result, we can prove that subsumption checking in PL becomes tractable if the number of interval constraints
per simple policy is bounded by a constant c (recall that in SPECIAL’s policies c = 1). First we estimate the complexity of
PLR.

Lemma 4.11. For all ?£ knowledge bases K and all PL subsumption queries CC D, PLR(K,C CE D) can be computed in time
O(|C C D\|*t! +|C C Di? - |K]), where c is the maximum number of interval constraints occurring in a single simple concept of C.

Proof. By Lemma 4.8 and Proposition 4.6, respectively, the complexity of line 2 of PLR is O(|C|? - ||) and the complexity
of line 3 is O(|C|-|D|°) = O(|C E D|‘t!). Now consider the complexity of the calls STS(K, C; © Dj;) in line 6. Each of them,
in the worst case, scans C; once for each subconcept of Dj, searching for a matching concept. Matching may require to
solve a reachability problem on the hierarchy C%*, so the cost of each call is O(|Dj;|-|C;|- |X|). If we focus on the outer loop
(lines 4-9) then clearly each subconcept of D is matched against all disjuncts of C, in the worst case. Then the overall cost
of the outer loop is O(|D|-|C|- |X|). By relating these parameters to the size of the query, it follows that the cost of the
outer loop is bounded by O(|C E Dj? - |K’|). This dominates the cost of line 2. So we conclude that the overall time needed
by PLR in the worst case is O(JC ED|St!+|CE DI? -|K]). Hf

Tractability immediately follows from Theorem 4.10 and Lemma 4.11:

Theorem 4.12. Let c be an integer, and Q, be the set of all PL subsumptions C, LU...LI Cy E D such that each C; contains at most c
interval constraints (i = 1,...,n). Then deciding whether a query in Q, is entailed by a PL knowledge base K is in P.

14
PA. Bonatti, L. Ioffredo, I.M. Petrova et al. Artificial Intelligence 289 (2020) 103389

We conclude this section by completing the characterization of the complexity of unrestricted ?£ subsumptions. The
following result, together with Theorem 4.1, proves that PL subsumption is coNP-complete.

Theorem 4.13. Deciding whether K K C CE D, where K is a PL knowledge base and C, D are (simple or full) PL concepts, is in coNP.

Proof. We prove the theorem by showing that the complement of subsumption is in NP. For this purpose, given a query
C CD, it suffices to choose nondeterministically one of the disjuncts C; in the left hand side of the query, and replace each
constraint 4f.[¢,u] occurring in C; with a nondeterministically chosen disjunct from (8). Call C; the resulting concept and
note that it is one of the disjuncts in splitp(C). Therefore, K A CCD iff K K splitp(C) EC D iff, for some nondeterministic
choice of C;, K AC; CD. Note that C; C D is interval-safe by construction. Then this subsumption test can be evaluated
in deterministic polynomial time by first normalizing C; w.r.t. K and then applying STS, that is complete for elementary
queries [8, Theorem 2]. It follows immediately that the complement of ?£ subsumption can be decided in nondeterministic
polynomial time, hence its membership in NP.

5. Supporting general vocabularies

SPECIAL has founded the “Data Privacy Vocabularies and Controls Community Group” (DPVCG),7'! a W3C group aimed at
developing privacy-related vocabularies. The purpose of this initiative is developing ontologies for the main properties of
usage policies and related GDPR concepts, with the contribution of a group of stakeholders that spans beyond SPECIAL’s
consortium. This group aims at developing upper ontologies, that can be later extended to meet the needs of specific
application domains.

We intend to put as few constraints as possible on the development of such standardized vocabularies, since it is difficult
to predict the expressiveness needs that may arise in their modeling - especially because standards usually change to
include new application domains and follow the evolution of the old ones. PL knowledge bases are too simple to address
this requirement. We already have evidence that it is useful to have roles whose domain is a vocabulary term, such as
the accuracy of locations (cf. Section 3); so, in perspective, we should expect the ontologies that define privacy-related
vocabularies to include at least existential restrictions (that cannot be used in PL knowledge bases, but are supported -
say — by the tractable profiles of OWL2). It is hard to tell which other constructs will turn out to be useful.

For the above reasons, we are going to show how to integrate PL and its specialized reasoner with a wide range of
ontologies, expressed with description logics that can be significantly more expressive than PL.

Our strategy consists in treating such ontologies - hereafter called external ontologies - as oracles. Roughly speaking,
whenever STS needs to check a subsumption between two terms defined in the external ontologies, the subsumption
query is submitted to the oracle. In the easiest case, the queries to the oracle can be answered with a simple visit to the
classification graph of the vocabularies. Of course this method, called import by query (IBQ), is not always complete [21,20].
In this section, we provide sufficient conditions for completeness.

More formally, let K and © be two given knowledge bases. The former will be called the main KB, and may use terms
that are axiomatized in O, that plays the role of the external ontology. For example, in SPECIAL’s policy modeling scenario,
K defines policy attributes - by specifying their ranges and functionality properties - while © defines the privacy-related
vocabularies that provide the fillers for policy attributes. Therefore, in SPECIAL’s framework, K is a PL knowledge base,
while © could be formulated with a more expressive DL. The reasoning task of interest in such scenarios is deciding, for a
given subsumption query g = (CCD), whether K UO - gq. Both C and D are PCL concepts that usually contain occurrences
of concept names defined in O.

SPECIAL’s application scenarios make it possible to adopt a simplifying assumption that makes oracle reasoning techni-
cally simpler [21,20], namely, we assume that neither K nor the query q shares any roles with ©. This naturally happens
in SPECIAL precisely because the roles used in the main KB identify the sections that constitute a policy (e.g. data cat-
egories, purpose, processing, storage, recipients), while the roles defined in © model the contents of those sections, e.g.
anonymization parameters, relationships between recipients (like ownership, employment relations), relationships between
storage locations (e.g. part-of relations), and the like.

This layered structure does not require arbitrary alternations of roles coming from the main KB and from the external
ontologies (more precisely, the roles occurring in the main KB need not occur within the scope of any role in X(Q)). As
a consequence, the roles of the external ontology can be allowed in the queries as syntactic sugar, as explained in the
following.

Remark 5.1. Let gq be a PL subsumption query, and Rw range over the roles occurring in ©. According to the above
discussion, assume that for all concept of the form 4R@.C occurring in q, C contains only roles from &(Q) (no alternation
of roles from the main KB and ©). Every such concept 4R@.C can be eliminated from q by replacing it with a fresh
atom A, and extending © with the axiom A=4JRo.C, under the mild assumption that the language of © supports such

21 www.w3.org/community/dpvcg/.

15
PA. Bonatti, L. Ioffredo, I.M. Petrova et al. Artificial Intelligence 289 (2020) 103389

equivalences. Let q’ and ©’ be the query and the ontology obtained by applying the above transformation for all Ro € X(O).
Clearly, by construction, O’ implies that the resulting query q’ is equivalent to q. Moreover, ©(O’) NNR = &(O) N Np» holds
by the assumption that the concepts C in 4Rw~.C contain only roles from X(Q). Now it is easy to see that the requirement
that the main KB should share no roles with ©’ is preserved by the transformation, since the main KB is not affected and
(O’) 1NR = &(QO) A Np. Due to the same equality, g’ contains no roles in ©(O’) because, by construction, it contains no
roles in &(Q). Summarizing, every query q where the roles in X&(X-) do not occur within the scope of the roles in X(Q)
can be transformed in polynomial time into an equivalent q’ that satisfies the requirement on role sharing, by means of a
simple extension of O.

5.1. On the completeness of IBQ reasoning

The IBQ framework was introduced to reason with a partly hidden ontology ©. For our purposes, IBQ is interesting
because instead of reasoning on K UO as a whole, each of the two parts can be processed with a different reasoner (so, in
particular, policies can be compared with a very efficient algorithm similar to STS). The reasoner for K may query © as an
oracle, using a query language QC consisting of all the subsumptions

A1,n...0N Am CE Am41 U...U An (9)

such that Aj,..., An are concept names. If n =m, then we stipulate that the right-hand side of the inclusion is |. We will
denote with pos(Q) all the queries to © that have a positive answer, that is:

pos(O) = {qe QlL|OFG}.
Remark 5.2. Each subsumption of the form (9) is equivalent to a concept (in)consistency check of the form:

Ayn... Amn-Am4y1n... 7A, CL. (10)

By [21, Theorem 2], such consistency checks (and, consequently, QL) constitute a fully general oracle query language, under
the assumption that K and the query gq share no roles with ©. By “fully general” we mean that it can be decided whether
KUO fq holds using only the axioms of K and the members of pos(Q).

The problem instances we are interested in are formally defined by the next definition.

Definition 5.3 (PL subsumption instances with oracles, PLSO). A PL subsumption instance with oracle is a triple (K, O,q)
where K is a PL knowledge base (the main knowledge base), O is a Horn-SRZO knowledge base (the oracle), and q is a
PL subsumption query, such that (X(C) U X(q)) N X(O) C Ne. The set of all @L subsumption instances with oracle will be
denoted by PLSO.

The restrictions on K, © and q will be motivated in depth in Section 5.5. We anticipate only two observations. First,
the restriction on the signatures is aimed at keeping the roles of © separated from those of K and gq, as discussed in
the previous section. The second observation is that the important properties of © are the absence of nominals and its
convexity with respect to QZ, in the following sense:

Definition 5.4 (Convexity w.r.t. OL). A knowledge base © is convex w.r.t. QL if for all subsumptions

q=A1N...NAmE Am4y1 U...U An

in OL, q € pos(©) iff there exists i¢ [m+ 1,n] such that (Ayn... Am CE Aj) € pos(Q). A description logic is convex w.r.t.
OC if all of its knowledge bases are convex w.r.t. OL.

Accordingly, in Definition 5.3, we required © to be in Horn-SRZQO because, to the best of our knowledge, this is the
most expressive description logic considered so far in the literature that is both nominal-free and convex w.r.t. OL.

The next lemma rephrases the original IBQ completeness result [21, Lemma 1] in our notation. Our statement relaxes the
requirements on © by assuming only that it enjoys the disjoint model union property (originally it had to be in SRZQ).
The proof, however, remains essentially the same.

Lemma 5.5. Let K and O be knowledge bases and a a GCI, such that

1. Kanda are in SROZQ(D) without U, where D is the concrete domain of integer intervals;
2. The terminological part of O enjoys the disjoint model union property;

16
PA. Bonatti, L. Ioffredo, I.M. Petrova et al. Artificial Intelligence 289 (2020) 103389

3. The terminological part T of K is local w.r.t. &(O);
4. (X(K) UZ(a@)) NZ(O) CNe.

Then C UO Ka iffkK Upos(O) Ka

Proof. We have to prove that under the above hypotheses K UO Ka iff K U pos(O) Ea. The right-to-left direction is
trivial since by definition © | pos(Q). For the other direction, by contraposition, assume that K U pos(Q) Fa. We shall
find a model NV of KUO such that VV a. Since a is of the form C C D, this means that for some de AX’, de (CN-=D)
The construction is similar to that used in [21, Lemma 1].

By assumption, K U pos(Q) has a model Z such that Z Fa, that is, there exists de A such that de (CN-=D)*. Now
we extend the interpretation Z over U(X) U X(@) to a model N of KUO.

We need some auxiliary notation: for each d € A%, let lit(d,Z) denote the set of all the literals L in the language of O
satisfied by d, that is,

lit(d, Z) = {L | (Z,d) EL and either L = A or L=—A, where AE Nc X(O)}.

Since Z — pos((), it follows that for all de A*, O IK | |lit(d, Z) © L (see Remark 5.2). Then, for all dé A®, there exists a
pointed interpretation (7%, d) of &(O) such that J - O and lit(d, Zq) = lit(d, Z). We may assume without loss of generality
that AY 7 A® = {d} and that AWN AW’ =G ifd sd’.

Let 7 be any of the above % and U= LW? {Jq | d € A“}. By hypothesis 2 and Proposition 2.2, U/ is a model of ©.
Moreover, by hypothesis 3, 0/ can be extended to a model M of 7, by setting X““ = @ for all predicates X € (X(K) U
Xu(a)) \ U(Q).

Finally, let \V be the interpretation such that:

AN =A (note that AZ c A™)
yv — X* forall symbolsX € (X(K) U X(@)) \ X(O)
~ | X™ forall symbols X € X(O).

The next part of the proof proceeds exactly as in [21, Lemma 1], in order to show that VV KE KUO. Note that by
definition MM and NV’ have the same domain and agree on the symbols in X&(©), therefore V is a model of O because M
is. So one is only left to prove that NW’ EX. For this purpose, first it is proved that

(«) for all C in the closure?” of K and a, CY =cZuU(c™ \ AZ).

The proof of (x) makes use of hypotheses 1 and 4. Then, using (x) and the fact that M is a model of 7, it can be shown
that M is a model of K. Almost all details of the proof of (x) and MEK can be found in [21]. Here we only have to
add the details for (x) concerning interval constraints (that are not considered in [21]). Let C=4f.[I, u]. By hypothesis 4,
f €(2(K) U X(@)) \ X(O). Then, by definition of VV and M, fn = f* and fm = #. Consequently, CN — ct and c™ =Q,

0 (x) obviously holds. -

For our formulation of this theorem, we only have to add the observation that («) implies also that de (CN —D)* Cc

(CHADY’, therefore VKa. &

Using the above lemma, we prove a variant of IBQ completeness for PLSO. The locality requirement of Lemma 5.5 is
removed by shifting axioms from K to O.

Theorem 5.6. For all problem instances m = (K,, O,q) € PLSO, let

= {a €K|a=range(R, A) ora = func(R) }
and let Of =OU(K\ K7~). Then

KUOKg iff K~ U pos(OF. JEQ
Proof. Since CUO =K7- U OF, it suffices to show that

kK” UOE gq iff K~ Upos(OZ) Eq

This equivalence can be proved with Lemma 5.5; it suffices to show that K™, OF and q satisfy the hypotheses of the
lemma. First note that K~ is a PL knowledge base and OF is a Horn-SRZO knowledge base (because, by definition of

22 The closure of a set of axioms X is the set of all (sub)concepts occurring in K.

17
PA. Bonatti, L. Ioffredo, I.M. Petrova et al. Artificial Intelligence 289 (2020) 103389

Table 4

+
Normalization rules for STSCX . Conjunctions are treated as sets (i.e. the ordering of conjuncts
is irrelevant, and duplicates are removed).

 

1) LnAD~ L

2) FRILL

3) Af .[l,ujJ~ 1 ifl>u

A) (AR.D)N(AR.D!)N D"” ~- 3RADMD’)nD” _ if func(R) € K~

5) Af.fh,ui)naf.[lb,u2] nD ~ df .[max(,,l2), min(u4, u2)]nD
if funce(f) € K~

6) JAR.DOD’~+3R.(DNA)ND’ if range(R, A) € K~ and
neither A nor are conjuncts of
D

7) Ayn... A,pnD~ L if Of RAIN...N Ane L

 

PLSO, K is in PL and O in Horn-SRZQ, and the axioms shifted from L£ to OF can be expressed in Horn-SRZQ,
too). Both PL and Horn-SRTZO are fragments of SROZQ(D) without U, therefore hypothesis 1 is satisfied by K~ and
OF. Moreover, both PL and Horn-SRZO enjoy the disjoint model union property, therefore hypothesis 2 is satisfied. Next
recall that (X(K) U X&(q)) N X(O) C Nc holds, by definition of PLSO. Since the axioms a € K \ K7 (transferred from K to
OF) contain no roles (they are of the form AC B or disj(A, B)), it follows that

(XK) U XG) NU(OF) SNe,

that is, hypothesis 4 holds. A second consequence of this inclusion is that K~ contains only axioms of the form range(R, A)
and func(A) such that R ¢ x(OF). They are trivially satisfied by any interpretation Z such that Rt = Q. Therefore K~ is
local w.r.t. X(O¢) and hypothesis 3 is satisfied. Ml

5.2. Extending ? L’s reasoner with IBQ capabilities

The integration of the PLR reasoner with external oracles relies on the axiom shifting applied in Theorem 5.6. Accord-
ingly, in the following, let K~ and OF be defined as in Theorem 5.6.

The next step after axiom shifting consists in replacing the relation C* used by the normalization rules and STS with
suitable queries to the oracle. This change concerns the normalization rules (Table 3) and STS. The new set of rules is given
in Table 4. We say that a PL concept C is normalized w.r.t. K and O if none of the rules in Table 4 is applicable.

Hereafter, ~» denotes the rewriting relation according to Table 4. Clearly, the new rules preserve the meaning of concepts,
in the following sense:

Proposition 5.7. If C~ C’ then K~ U pos(OX) EC =C’.
The notion of elementary inclusion is modified accordingly, by requiring normalization w.r.t. both K and O.

Definition 5.8. A PL subsumption C LC D is elementary w.r.t. K and O if both C and D are simple, C EC D is interval safe, and
C is normalized w.r.t. and O.

Then STS is integrated with the oracle © by replacing its line 3 as in the following algorithm STSOK. In the following,
we call a subconcept “top level” if it does not occur in the scope of any existential restriction.

. +
Algorithm 3: STSCx (C E D).
Input: Ontology OF (as defined in Theorem 5.6) and a PL subsumption C C D that is elementary w.r.t. K and O
Output: true if K~ U pos(OFX-) ECCD, false otherwise, where kK is defined as in Theorem 5.6
1 begin
2 if C= 1 then return true ;
3 if D=Aand(A,n...NAnpLA)eE pos(OFx), where Aj,..., An are the top-level concept names inC then return true ;
4 if D=Ff.[l,u] andC =3Ff.[Il',u’/]nC’ and! <I andu’ <u then return true ;
5 if D = 4R.D’, C= GR.C’) NC” and STSOCK (C’C D’) then return true ;
6 | if D=D’'nD"’,STSCK(C ED’), and STSCK(C ED”) then return true ;
7 else return false ;
8 end

Finally, the reasoner for general ?£ subsumptions with oracles can be defined as follows:

18
PA. Bonatti, L. Ioffredo, I.M. Petrova et al. Artificial Intelligence 289 (2020) 103389

Algorithm 4: PLRO(K, CC D).

Input: O, K and CCD such that 7m = (K,O,C CD) € PLSO
Output: true ifKUOECCLD, false otherwise

1 begin
2 construct KC” and OF as defined in Theorem 5.6 ;
3 let C’ be the normalization of C wrt. K and O (with the rules in Table 4) ;
4 let C” =splitp(C’) ;
// assume that C’=C,U...UCm and D=D,U...UD,
// check whether each Cj; is subsumed by some Dj;

5 for i=1,...,mdo
6 for j=1,...,n do
7 | if STSOK (Cj; © Dj) = true then skip to next i in outer loop;
8 end
9 return false
10 end
11 return true
12 end

The rest of this section is devoted to proving the soundness and completeness of PLR©. We will need a set of canonical
counterexamples to invalid subsumptions.

Definition 5.9. Let C4 | be a simple PL concept normalized w.r.t. K and ©. A canonical model of C (w.r.t. K and Q) is a
pointed interpretation (Z,d) defined as follows, by induction on the number of existential restrictions.

a. If C=([]j_y Ai) (M1 Jf j-[lj,uj]) (ie. C has no existential restrictions), then let Z = ({d},-*) where
e A* = {d} if ([]iL, Ai © A) € pos(OZ);

e f* ={G.uj)|j=1,...0}3
e all the other predicates are empty.

b. If the top-level existential restrictions of C are 4R;j.D; (i=1,...,m), then for each i=1,...,m, let (Zj,d;) be a canon-
ical model of D;. Assume w.l.o.g. that all such models are mutually disjoint and do not contain d. Define an auxiliary
interpretation 7 as follows:

e AY ={d,dy,...,dm};

e Ax = {d} if (Mis Ail A) E pos(O;), where Aj,..., An are the top-level concept names in C; all other concept names
are empty;

e f% ={(d,u)|4f_[l,u] is a top-level constraint of C};

e RY ={(d,d;) |i=1,...,m}.

Finally let Z be the union of J and all Z;, that is

At = AT Ul )a*
1

AT =AY UL JA% (AENc)
1

R* = RT U|_JR® (R © Nr UNf).
1

The canonical model is (Z, d).
Note that each C has a unique canonical model up to isomorphism. The canonical model satisfies K~, OF, and C:

Lemma 5.10. If C is a simple PL concept normalized w.r.t. K and O, and C # _L, then each canonical model (Z, d) of C enjoys the
following properties:

a. TEK~ Upos(OF);
b. (Z,d) EC.

Proof. By induction on the maximum nesting level £ of C’s existential restrictions.

If € =O (ie. there are no existential restrictions) then obviously (Z,d) EC by construction (see Definition 5.9.a). The
entailment ZK holds because K~ contains only range and functionality axioms, that are trivially satisfied since all
roles are empty in Z. In order to prove the base case we are only left to show that Z — pos(O;-). Suppose not, i.e. there

19
PA. Bonatti, L. Ioffredo, I.M. Petrova et al. Artificial Intelligence 289 (2020) 103389

exists an inclusion B, Nn... Bm, CA in pos(Ox. ) such that d € (B} NM... Bm)~ but d ¢ A~ (where d is the only member of
A“). By construction of L, de BY only if pos(Ox ) contains [yj _, Ai © B; for all j =1,...,m, where the A; are the top-level
concept names in C. These inclusions, together with B}N...N Bm, CA, imply by simple inferences that [];_, Aj © A must
be in pos(O;), too. But then A” should contain {d} by definition (a contradiction). This completes the proof of the base
case.

Now suppose that £ > 0. By induction hypothesis (I.H), we have that all the submodels (Z;,d;) used in Definition 5.9.b
satisfy D;. Then it is immediate to see that (Z,d) EC by construction. We are only left to prove that Z satisfies all axioms
ain kK U pos(OF% ).

Ifa = func(R). then rewrite rules 4) and 5) make sure that C contains at most one existential restriction for R, so 7
satisfies a. Since all Z; satisfy aw by I.H., Z satisfies a, too.

If ~w = range(R, A), then rule 6) makes sure that for each top-level concept of the form 4R.D; in C, Dj = Di nA. Then,
by I.H., Uj, dj) HR A and, consequently, a is satisfied by Z.

Finally, if @ is an inclusion in pos(O;-), then d satisfies it by the same argument used in the base case, while the other
individuals in A~ satisfy w@ by LH.

Another key property of the canonical models of C is that they characterize all the valid elementary subsumptions whose
left-hand side is C:

Lemma 5.11. [f C € D is elementary w.r.t. K and O, C 4 1, and (Z, d) is a canonical model of C, then

KT U pos(OF% JECCD iff Z,d) ED

Proof. (Only If part) Assume that K— U pos(Ox ) ECC D. By Lemma 5.10.a, we have Z | Ko U pos(Ox ), so by assumption
C4 c D#. Moreover, by Lemma 5.10.b, d<€ C4 C D®. Therefore (Z,d) EK D.
(If part) Assume that (Z,d) E D. We are going to prove that K~ U pos(O%. ) E CCD by structural induction on D.

If D=A (a concept name), then d € A~ by assumption. Then, by construction of Z, there must be an inclusion
([]j-1 Ai & A) € pos(OFX-), where Aj,..., An are the top-level concept names of C. This implies that both EC E[]j_, A
and pos(OF% ) EP], 4: C A hold, hence K- U pos(O*% JECED.

If D= D,nN Dz, then (Z,d) K D; (i=1, 2), therefore, by induction hypothesis, K~ U pos(O*% )ECCD; (i=1,2), hence
K- U pos(O*% JECCED.

If D = 3R.Dj, then for some d; € A“, (d,d;) € RZ and (Z;, d;) K D1, where (Z;, dj) (by construction of Z) is the canonical
model of a concept C (Occurring in a top-level restriction 4R.C; of C. It follows that ECC AR.C; and (by induction
hypothesis) K— U pos(OF¥ )EC, E Dy, hence K- U pos(O*% JECCED.

If D=f.[¢,u], then for some wu’ € [£,u], (d,u’) € ft. By construction of Z, C must contain a top-level constraint
df .[¢’, u’], so by interval safety (that is implied by the assumption that C E D is elementary), [@’, u’] C [¢,u]. Then ECE
D. @

Moreover, by means of canonical models, one can prove that interval safety makes the non-convex logic PL behave like
a convex logic.

Lemma 5.12. For all interval safe PL subsumption queries q = (C 1U...UCm CO D,uU...uUD n) such that each C; is normalized w.r.t.
K and O, the entailment — U pos(OF ) Eq holds iff for alli € [1, m] there exists j € 1, n] such that K~ U pos(OF JEG E Dj.

Proof. Let KB abbreviate K7 U pos(OF% ). By simple logical inferences, these two facts hold: (i) KB Eq iff KB EC C
Lj Dj; holds for all i € [1, m], (ii) if KB FE C; € Dj; holds for some j €[1,n], then KB ECE Lia Dj. So we are only left
to show the converse of (ii): assuming that for all j €[1,n], KB AC; CD; holds, we shall prove that KB KC EC Lia Dj.

By assumption and Lemma 5.11, the canonical model (Z,d) of C; is such that (Z,d) — —D; for all j ¢ [1,n]. Therefore
(Z,d)E- 7-1 D;. Moreover, (Z,d) satisfies both AB and C; by Lemma 5.10. Then Z and d witness that KB AC CE

Now that the semantic properties are laid out, we focus on the algorithms. Roughly speaking, the next lemma says that
STS©k decides whether the canonical model (Z,d) of C satisfies D.

Lemma 5.13. If C EC D is elementary w.r.t. K and O, C 4 1, and (Z, d) is the canonical model of C, then
STSCK(C EC D) =true iff (Z,d) ED.

20
PA. Bonatti, L. Ioffredo, I.M. Petrova et al. Artificial Intelligence 289 (2020) 103389

Proof. By structural induction on D. If D =A (a concept name), then by definition STSCK (CC D)=true iff there exists
an inclusion Te Aj CA in pos(O;) such that the A;’s are the top-level concept names in C (see line 3 of Algorithm 3).
By def. of Z, this holds iff d € A~, that is, (Z,d) K D. This proves the base case.

If D = D, 1M Do, then the lemma follows easily from the induction hypothesis (see line 6 of Algorithm 3).

If D =AR.Dj, then STSCx (CC D)=true iff: (i) C has a top-level subconcept 4R.C1, and (ii) STSCK (Cj © Dj) =true
(see line 5). Moreover, by definition of Z, (Z,d) EK D holds iff fact (i) holds and: (ii) (Zj,d;) H D;, where (Zj,dj) is a
canonical model of C;. By induction hypothesis, (ii) is equivalent to (ii’), so the lemma immediately follows.

If D=Ff.[€, u], then STSCx (CC D)=true iff the following property holds:

C has a top-level subconcept If .[@’, u’] such that [¢’, u’] C [2, u] (11)

(see line 4). We are only left to prove that (11) is equivalent to (Z,d) E D.

Property (11) implies (by construction of Z) that (d,u’) € f% and wu’ €[2, ul], that is, (Z,d) K D.

Conversely, if (Z,d) | D, then there exists u’ € A~ such that (d,u’) € f2 and wu’ € [¢, u]. Then, by construction of Z, C
must have a top-level subconcept if .[¢’, u’]. By interval safety (that is implied by the hypothesis that C CE D is elementary),
the fact that [¢’, u’] and [£, u] have u’ in common implies [€’, u’] € [€, u]. Therefore, (11) holds. This completes the proof.

We are now ready to prove that PLR® is correct and complete.

Theorem 5.14. Let (K, O,C CE D) be any instance of PLSO. Then

PLRO(K,CC D)=true iff KCUOECED.

Proof. D is of the form D;U...LI Dy. Let Cj U...Cm be the concept C” computed by lines 2 and 3 of PLR®. We start by
proving the following claim, for all i=1,...,m and j=1,...,n:

STSCK (C; E Dj) =true iff K~ Upos(Ot) ECE Dj. (12)

There are two possibilities. If C; = L, then clearly C~ U pos(OF) FE C; £ Dj; and sTsOK (Cj; © Dj) = true (see line 2 of
Algorithm 3), so (12) holds in this case. If C A 1, then note that C; EC Dj is elementary w.r.t. K and © by construction of
C” (which is obtained by splitting the intervals of the normalization of C w.r.t. K and ©). Then (12) follows immediately
from Lemmas 5.11 and 5.13.

By (12) and convexity (Lemma 5.12), we have that lines 5-11 of Algorithm 4 return true iff K7 U pos(OF) EC” CD.
Moreover, C” can be equivalently replaced by C in this entailment, by Proposition 5.7 and Proposition 4.5. The resulting

entailment is equivalent to CK UO ECL D by Theorem 5.6. It follows that Algorithm 4 returns true iff CUOECCD. &
PLR® runs in polynomial time, modulo the cost of oracle queries.

Lemma 5.15. PLR (K, C E D) runs in time O(|C E D|**! + |C E D|? - |K)) using an oracle”? for pos(O;-), where c is the maximum
number of interval constraints occurring in a single simple concept of C.

Proof. Each query to the oracle triggered by the application of normalization rule 7 or by line 3 of STSCx counts as one
step of computation, according to the definition of time complexity for oracle machines. Then, by the same arguments used
in the proof of Lemma 4.11, the computation of the normalization steps in lines 2 and 3 of PLR® takes time O(|C\? -|K| +
|C| -|D|°), while the loops spanning over lines 5-9 take time O(|D|-|C|- |X|). The lemma follows by expressing the size of
C and D in terms of |C C D| (as in Lemma 4.11).

As a consequence of the above lemma, the classes of subsumption instances where c is bounded can be decided in
polynomial time, modulo the cost of oracle queries.

Definition 5.16. For all non-negative integers c, let PLSO;, be the set of PLSO instances (K,O,C CE D) such that the
maximum number of interval constraints occurring in a single simple concept of C is bounded by c.

Theorem 5.17. For all c, PLSO¢ is in PPO xr),

Computing the consequences of ©, in general, is intractable, although © is restricted to Horn-S?ZQ knowledge bases.
For other Horn DLs, however - like the profiles of OWL2 and their generalizations €£t* and DL-lite}* _- subsumption

23 Here we mean the notion of “oracle” used in the definition of oracle machines and related complexity classes [43].

21
PA. Bonatti, L. Ioffredo, I.M. Petrova et al. Artificial Intelligence 289 (2020) 103389

checking is tractable. By Theorem 5.17, the tractability of convex oracles extends to reasoning in PL with such oracles.
More precisely, it suffices to assume that membership in pos(Ox~) can be decided in polynomial time, since in that case

pposx) — P. This is what happens when © is in €£++ and DI-lite/*,, since the axioms shifted from K to O (ie. OF \ O)
can be expressed both in €£** and in DL-lite, therefore OF is in the same logic as ©. This is formalized as follows:

Definition 5.18. For all integers c > 0, let PLSOP* be the set of instances of PLSO, whose oracle is in DL.

seg H
DL-litep orn

and PLSO,- are in P.

ott

Corollary 5.19. For all c > 0, PLSO®

It can also be proved that the normalization rules in Table 4 may be used as a policy validation method, to detect
unsatisfiable policies.

Theorem 5.20. Let (KC, O,q) bea PLSO instance and C bea PL concept such that &(C) N X(O) C Ne.

1. APL concept C = C1 U...UCp is unsatisfiable w.r.t. KU O iff C; ~* L for alli € [1,n].74
2. Under the above hypotheses, PL concept satisfiability testing w.r.t. K U O is in ppos(Ox) (hence in P if O belongs to a tractable
logic).

Proof. By Proposition 5.7 and Lemma 5.10, C is satisfiable w.r.t. C— Upos(Ox) iff C; ~»* L does not hold for some i € [1, n].
Moreover, by Theorem 5.6,

K~ Upos(OZ) ECE L iff KCUORCEL.

Point 1 immediately follows. Next, note that normalization can be computed in polynomial time using an oracle for pos(O;-).
This can be shown with a straightforward adaptation of the proof of Lemma 4.8 that takes into account the oracle queries
in rule 7 (the details are left to the reader). Then Point 2 follows from the complexity of normalization and Point 1.

5.3. Related tractability and intractability results

PL knowledge bases are in OWL2-RL, a Horn fragment of OWL2; they are also in the extensions of €£ and DL-lite with
functional roles. Answering ?£ subsumption queries is equivalent to solving query containment problems with respect
to PL knowledge bases, where the queries are the translation of PL concepts into formulae of first-order logic.*? Such
formulae are instances of the class of queries investigated in [46], called extended faceted queries. Core faceted queries (or
simply faceted queries, abbreviated with FQ) are formulae with one free variable, built from unary and binary predicates
using V, A, and 4; moreover, variables are restricted so that each faceted query equals the translation of a DL concept built
from LI,m, and 3. A faceted query is conjunctive if it contains no occurrences of Vv; the set of conjunctive faceted queries is
denoted by CFQ. The class of unions of faceted queries (UCFQ) consists of all the faceted queries where V may occur only at
the top level (i.e. it cannot be nested inside the other constructs). Extended faceted queries support a class Comp of operators
for number comparison, a class of special predicates Agg for computing aggregates, and predicates Next, Nextt for traversing
chains of binary relations. Different subclasses of extended FQ can be denoted by £L[], where L € {FQ, CFQ, UCFQ} specifies
the restrictions on v, and X C {Comp, Agg, Next, Nextt} specifies which additional predicates are supported. For example,
the class of all extended faceted query is denoted by FQ[Comp,Agg,Next,Next* |]. Extended faceted queries are more general
than the translation of ZL subsumptions in the following ways:

e disjunctions can be nested within conjunctions;
e queries may contain the special predicates for aggregates, Next, and Nextt.

The class of queries corresponding to PL concepts, where disjunction may occur only at the top level and the above special
predicates are not allowed, is UCFQ{[Comp] (unions of conjunctive faceted queries with comparison operators).

The results of [46] show that deciding query containment in FQ (i.e. the class of faceted queries without special pred-
icates nor comparison operators) is coNP-complete, even if the knowledge base is empty; hardness is proved by nesting
disjunctions within conjunctions.

Without such nesting (i.e. if we restrict to UCFQ), query containment may be tractable even if the knowledge base is
nonempty. In particular, the containment of a query Q in Q’ can be reduced to query answering as follows: first introduce
a fresh individual name a, then extend the knowledge base with a set of assertions that make Q (a) true (possibly by adding

24 As usual, ~+* denotes the reflexive and transitive closure of ~>.
2° The translation of concepts into first-order formulae can be found in [4, Chapter 4] and [19].

22
PA. Bonatti, L. Ioffredo, I.M. Petrova et al. Artificial Intelligence 289 (2020) 103389

additional fresh constants); finally evaluate Q’ and check whether a belongs to the answer [19]. Top-level disjunctions can
be dealt with by exploiting convexity, as we do in this paper. The combined complexity of UCFQ answering is in P in many
cases, see [6,5] for tractability results that apply to knowledge bases formulated in OWL2-EL and OWL2-QL, and to queries
that are slightly more general than CFQ. Therefore the containment of UCFQ can be decided in polynomial time when the
knowledge base belongs to these profiles.

The above reduction of containment, however, is not applicable to queries that contain special predicates.*° Indeed, [46,
Lemma 5] proves that query containment in CFQ[Next,Next*] is coNP-complete even if the knowledge base is empty. Ad-
ditionally, due to the relationships between query containment and concept subsumption, our Theorem 4.1 implies that
query containment in UCFQ|Comp] is coNP-hard, even if the knowledge base is empty and the leftmost query is conjunc-
tive. Moreover, Theorem 4.12 shows that a constant bound on the number of comparisons per conjunctive query suffices
to restore tractability, for all nonempty PL knowledge bases. Theorem 5.17 extends the tractability of UCFQ[Comp] with
bounded intervals to all the combinations of PL knowledge bases with oracles formulated in any tractable fragment of
Horn-S7Z O (under the restrictions of Definition 5.3).

PL with oracles in €£* can also be regarded as a tractable extension of €£ with functionality axioms and non-convex
concrete domains in the queries. Unrestricted combinations of such constructs are generally intractable, when the knowledge
base - as in our subsumption instances - is nonempty and contains unrestricted GCIs.

More precisely, in the extension of EL with functional roles, subsumption checking is EXPTIME-complete, in general
[3]. A tractability result for empty TBoxes is reported in [26, Fig. 4]; however, in the same paper, it is proved that even
with acyclic TBoxes, subsumption is coNP-complete. Accordingly, OWL2-EL does not support functionality axioms, so PL
knowledge bases cannot be encoded in this profile.

The tractability of an extension of €£ with non-convex concrete domains (like intervals) has been proved in [26], under
the assumption that the TBox is a set of definitions of the form A =C, where each A is a concept name and appears in the
left-hand side of at most one definition.

An extended analysis of the tractability threshold for the DI-lite family can be found in [2]. The results most closely
related to our work are the following.

The data complexity of query answering raises at the first level of the polynomial hierarchy if DL-lite7* is extended with
functional roles. Knowledge base satisfiability becomes EXPTIME-complete (combined complexity). Under three syntactic
restrictions [2, Ajy-A3] and the unique name assumption, both of the above reasoning tasks remain tractable. Nevertheless,
OWL2-QL - that is founded on one of the simplest members of the DL-lite family - does not support functional roles,
therefore it cannot be used to encode PL knowledge bases.

PL knowledge bases with oracles in €£* or DL-lite}* are in Horn-SHOZQ with (reuse)-safe roles [18,19]. This logic is
tractable, and the role safety restriction replaces the modularity requirement of IBQ approaches.*’ By means of the results
of [18,19], PL knowledge bases with oracles in €£* and DL-lite}* can be translated into a Datalog program in polynomial
time, preserving fact entailment. Then, subsumption checking can be reduced to conjunctive query answering as explained
above. Recall, however, that this reduction does not apply to subsumptions with interval constraints; so the tractability
results of [18,19] do not imply our results for P£ subsumptions.

The most expressive knowledge representation language enjoying a complete structural subsumption algorithm - to the
best of our knowledge - is CLASSIC [17], that supports neither concept unions (UI) nor qualified existential restrictions
(4R.C). If unions were added, then subsumption checking would immediately become coNP-hard (unless concrete domains
were restricted) for the same reasons why unrestricted subsumption checking is coNP-hard in PL (by Theorem 4.1). On the
other hand, CLASSIC additionally supports qualified universal restrictions (that strictly generalize PL’s range restrictions),
number restrictions, and role-value maps, therefore it is not comparable to PL. The complexity of the extensions of PL
with CLASSIC’s constructs is an interesting topic for further research.

5.4. Compiling oracles into PL knowledge bases

Note that pos(O;-) might be compiled, i.e. computed once and for all, so as to reduce oracle queries to retrieval. After
such knowledge compilation, PLR° could run in polynomial time, no matter how complex O’s logic is, provided that the
subset of pos(O;-) queried by PLR® (i.e. the part of pos(O;-) that should be pre-computed) is polynomial, too.

This is not always the case. The conjunctions of classes | ]; Aj that may possibly occur in the left-hand side of subsump-
tion queries are exponentially many in the signature’s size, and each of them may potentially occur in a query to the oracle.
So, in order to limit the space of possible oracle queries and reduce the partial materialization of pos(O;-) to a manageable
size, we have to limit the number of concepts that may occur in the left-hand side of subsumption queries.

Fortunately, in SPECIAL’s use cases, the subsumption queries C LC D that implement compliance checks have always a
business policy on the left-hand side, and the set of business policies of a controller is rather stable and not large. So the
prerequisite for applying oracle compilation is satisfied. We are further going to show that the oracle can be compiled into

26 As far as Comp is concerned, the problem is that the arguments of comparison operators are numbers, so the idea of instantiating the atoms of Q with
fresh individual names is not applicable.
27 Of course, without modularity, query answering cannot be split among two specialized reasoners for the main part and the oracle, respectively.

23
PA. Bonatti, L. Ioffredo, I.M. Petrova et al. Artificial Intelligence 289 (2020) 103389

a plain, oracle-free PL knowledge base, therefore the IBQ framework can be implemented with the same efficiency as pure
PEL reasoning.

We start the formalization of the above ideas by defining the restricted class of problem instances determined by the
given set of business policies BP.

Definition 5.21. For all sets of PL concepts BP, let PLSO(BP) be the set of all (K,O,C E D) €e PLSO such that C € BP.

The first step of the oracle compilation consists in transforming business policies so as to collapse each conjunction of
concept names into a single concept name. We say that the result of this transformation is in single-atom form, which is
recursively defined as follows:

Definition 5.22. A simple PL concept C is in single-atom form if either

1. C is of the form ((]j", 3fi-[li, ui]) 0 he, 4R;.C;), where m,k > 0, and each C; is in single-atom form, or
2. C is of the form An ({ je, afi-lli, ul) 7 he, 4R;.C;) where m,k > 0, and each C; is in single-atom form.

A full PL concept Cy U...LUCy is in single atom form if C;,...,Cy are all in single atom form.

The given business policies can be transformed in single atom form in linear time:

Proposition 5.23. For all finite sets of concepts BP there exist a set of concepts BP* in single atom form, and a knowledge base O*
that belongs to both € £ and DL-litepo-n, such that for all (K,O,C & D) € PLSO(BP) there exists an equivalent problem instance
(KK, OUO*,C* CD) € PLSO(BP"), that is:

KUOKCLED iffK{UOUO*KC*ED.
Moreover, BbP* and O* can be computed in time O(|BP)).

Proof. For all C ¢ BP, we obtain the corresponding concept C* by replacing each intersection of multiple concept names
in C with a single fresh concept name, whose definition is included in ©*. More precisely, if C=C, U...LiC, then for all
j=1,...,n, replace each

n m k
cj=( Jad] [afi uid) ([ ]ARi-Di
i= i=1 i=1
such that n> 1 with
m k
Cr =Bn({ ]afi-lk. ud) ]3Ri.DF),
i=1 i=1
where B is a fresh concept name and each D* is obtained by recursively applying the same transformation to Dj.
The knowledge base ©%* is the set of all the definitions B = (yj Aj) such that B is one of the fresh concepts introduced
by the above transformations and [Ti A; is the intersection replaced by B.
Finally, let BP* be the set of concepts C* = C} U...UC; obtained with the above procedure. Clearly, by construction,
KUOUO* —C=C*%, for all Ce BP. Moreover, K UO U ©* is a conservative extension of K U O. Therefore

KUOKCEDiffKUOUO*KCLED
iff CUOUO*EC*ED.

Concerning complexity, bP* and O* can be computed with a single scan of BP; the generation of the fresh concepts B,
the replacement of []j_ Ai and the generation of the definition for B take linear time in |C;|. Therefore BP* and O* can
be computed in time O(|BP]|).

By the above proposition, we can assume without loss of generality that BP is in single atom form. Note that the
ontologies K and Q, in a typical application scenario, do not change frequently. So we can fix them and assume that the
concepts in bP are already normalized w.r.t. K and ©. The set of problem instances with fixed K and O is defined as
follows:

PLSO(K, O, BP) ={(K’, 0’, CCD) € PLSO|K' =K, O' =O, andC € BP}.

24
PA. Bonatti, L. Ioffredo, I.M. Petrova et al. Artificial Intelligence 289 (2020) 103389

The compilation of K and O into a single PL knowledge base is defined as follows:

comp(K,O)=K~ U{AC B| (ACB) € pos(O;Z)}.

The correctness of oracle compilation is proved by the next theorem.

Theorem 5.24. Let K and O be two knowledge bases in PL and Horn-SRT Q, respectively, and let BP be a set of PL concepts in
single atom form and normalized w.r.t. K and O. Then, for all (K,O,C E& D) €e PLSO(K, O, BP),

PLRO(K, CC D) =PLR(comp(K, O),C CD).

Proof. Since C is already normalized w.r.t. K and © by hypothesis, line 3 of PLR? computes the identity function (i.e.
C’ =C). It is easy to see that line 2 of PLR does the same. First, note that the two versions of rules 4 and 6 (in Table 3
and Table 4) apply to the same set of functionality and range axioms, since func(R) € comp(K, O) = func(R) € K~ and
range(R, A) € comp(K, O) © range(R, A) € K~ (by definition of comp). So there are no additional axioms in comp(K, O)
that may trigger rules 4 or 6 in PLR. Second, since C is in single atom form by hypothesis, rule 7 of Table 3 never applies.
The other normalization rules are the same for PLR? and PLR. We conclude that lines 2 and 3 of PLR® and PLR produce
the same concept C” = splitp(C).

Consequently, the loops in lines 5-9 of PLR© and lines 4-8 of PLR return the same result, too. To see this, it suffices to
show that

STS°K (C E Dj) =STS(comp(K, ©), Cj E Dj). (13)

The only difference between STSOx and STS is in their line 3. The membership tests executed by STSOCx in line 3 are
all of the form (Aj EC A) € pos(O;-), because Cj; is in single atom form (this follows from the hypothesis that C is in single
atom form). For the same reason, STS in line 3 checks whether A, C* A. The two tests are equivalent by definition of comp,
therefore (13) holds and the theorem is proved.

Remark 5.25. Note that the size of comp(K, ©) is at most quadratic in the size of K UO, and that PLR runs in polynomial
time if the number of interval constraints per simple policy is bounded. Therefore, under this assumption - and after
comp(K, ©) has been computed - subsumption queries can be answered in polynomial time. If O uses expressive constructs
from Horn-SRZQ, then their computational cost is confined to the compilation phase only, that is essentially a standard
classification of OF.

A caveat on the size of comp(K, ©) is in order, here. If the given set of policies BP is not in single atom form, then
O must be replaced by O U ©*, as shown in Proposition 5.23, where the size of O* is O(|6P|). Therefore the size of
comp(K, OUO*) may grow quadratically with |6?P]|. This relationship shows the influence of 6b’s size on the complexity of
the oracle compilation approach. So, unfortunately, oracle compilation is not always possible. For example, in the application
of PL to data markets illustrated in the conclusions, we currently see no general criterion to restrict the space of possible
queries as required by the compilation method.

Remark 5.26. Using the compilation approach, the soundness and completeness of PLR follow easily from the soundness
and completeness of PLR®, according to which K K q holds if and only if PLR%(K,q) = true. So it suffices to show that
PLR(K, q) = PLR®°(K,q). Note that comp(K, @) is simply the closure of K with respect to inclusions (that is, comp(K, 9)
preserves the relation C* associated to K’). This fact and Theorem 5.24, respectively, imply that

PLR(K, q) = PLR(comp(K, #), q) = PLR” (K, q).

Similarly, the equality PLR(K, q) = PLR“(K,q) and the correspondence between the closure C* of the inclusions in K
and those in comp(K, %), immediately imply the following corollary of Theorem 5.20:

Corollary 5.27. Let K be a PL knowledge base.

1. APL concept C=C; LU... LI Cp is unsatisfiable w.r.t. K iff Cj; ~ 1 for alli € [1, n].
2. PL concept satisfiability w.r.t. K can be checked in polynomial time.

5.5. On the limitations posed on PLSO
In this section we briefly motivate the restrictions posed on PL subsumption problems with oracles (PLSQO). We start
with the requirements on the oracle. Recall that O should be convex w.r.t. Q£ and should not use nominals. Convexity

w.r.t. OL is essential for tractability, as shown by the next result.

25
PA. Bonatti, L. Ioffredo, I.M. Petrova et al. Artificial Intelligence 289 (2020) 103389

Theorem 5.28. If O is not convex w.r.t. QL and enjoys the disjoint model union property, then there exists a PL knowledge base K
such that deciding whether K UO EC CD holds, given an interval-safe PL subsumption query C CE D, is co-NP hard.

Proof. We are proving coNP-hardness by reducing 3SAT to the complement of subsumption. By hypothesis, pos(Q) contains
an inclusion

Ayn...N An By uU...UBm (14)

such that none of the inclusions Aj Mm... A, C B; belongs to pos(Q), for i=1,...,m. Without loss of generality, we can
further assume that A,Nn...N A, € BaU...UBm is not in pos(Q) (if not, then discard some B; from (14) until the right-hand
side is a minimal union entailed by A; N...7 An). Now let K be the following set of inclusions, where A’ and B’ are fresh
concept names:

A’CA; (i=1,...,n)

BjCB’ (j=2,...,m).
Note that K UO - A’C B, UB’, by construction of K and (14). We are going to represent the truth values true and false
with B, and B’, respectively.

Let S be any instance of 3SAT, and let pj,..., px be the propositional symbols occurring in $. We assume without loss of
generality that p;,..., px do not occur in K nor in ©. Each positive literal p; is encoded by e(p;) = 4p;.B;, while negative
literals =p; are encoded by e(—p;) = 4p;.B’. Then the negation of S is encoded by

D=|_|f{e(L1) ne(L2) me(L3) | Li V Lz V L3 € S}.
(where each L; is the literal complementary to L;). We claim that the non-entailment

KUOK (| |Api-A) ED (15)

1

holds iff S is satisfiable (note that the above subsumption query is interval-free, hence trivially interval safe). To prove
the “only if’ part, assume that (15) holds, that is, there exists a pointed interpretation (Z,d) such that ZTE KUO,de

(11; 3p;.A’)~ and d ¢ D¥. Since KUO ([],; 3p;-A’) © Gpi-B1) LU p;.B’) holds for each symbol pj, there exists dj ¢ A*
such that (d, dj) € pr and either dj € Bt or d; € (B’)~. Construct a truth assignment o for S by setting

true ifdj ¢ Bt,

0 (Pi) = | ice if dj ¢ BY (therefore dj € (B’)*).

Since d ¢ D#, each clause L1 V Lz V L3 of S contains a literal p; or —p; such that, respectively, d; € Bt or d; € (B’)“, so o
satisfies the literal, by definition. It follows immediately that o satisfies S.

Conversely, suppose that S is satisfied by a truth assignment o. We are going to construct a pointed interpretation (Z, d)
that witnesses (15). Recall that neither AyM...M A, C By nor Ayn...M An C B2U...U Bm belong to pos(Q). Then © has
two disjoint models M; and Mp such that for some d; ¢ A™' and dz « A™2,

dj €(Ayn...N An)“ =i =1,2)
d, ¢ BM"
do é (By U... Bm)”.
The union U = M, ™ Mj is still a model of O by hypothesis, and it can be extended to a model 7 of K UO by setting:
AY = A4
(A) = (Ain... An)?
(B')Y =(B2U...UBm)” .
Finally, we extend 7 to the witness Z as follows. First let A = AY and choose any de A”. For all symbols p; define:
Pi ={(d.d1)} if (pi) = false,
pr ={(d,d2)} otherwise.

Note that d belongs to ([ ], 4pi-A’ ) by construction, so we are only left to prove that d ¢ D~. By assumption, each clause
in S contains a literal L satisfied by o. If L =—pj;, then pr = {(d,d)}, therefore d¢ (Ap;.B1)~ = e(L)®. Similarly, if L = pj,
then p? = {(d,d2)}, therefore d ¢ (Ap;.B’)* =e(L)*. It follows immediately thatd ¢ D7. I

26
PA. Bonatti, L. Ioffredo, I.M. Petrova et al. Artificial Intelligence 289 (2020) 103389

Note that the above theorem shows that reasoning can be intractable even if K and © are fixed.

The requirement that nominals must not occur in oracles is needed for completeness. Our algorithm PLR°- and the
other IBQ methods where oracle queries are consistency tests of the form (10), or the equivalent inclusions of the form (9)
— are generalized by the following definition, that accounts for the shifting of axioms from K to O.

Definition 5.29. Let PZ be a set of problem instances of the form (K, O,q), where K and © are knowledge bases and q is
an inclusion. A shifting IBQ mechanism for PZ is a pair of functions (s,r) such that for all (K, O,q) € PTZ:

1. s(K) CK,
2. r(s(K), pos(O U(K \ s(K))),q) =true iff KLUOKq.

Informally speaking, s determines which axioms are shifted from K to O, and r is the IBQ reasoner that decides entail-
ment using the modified knowledge bases. Shifting IBQ mechanisms do not exist if O may use nominals.

Theorem 5.30. Let DCL be a description logic that supports nominals and disjointness axioms. Let PT be any set of problem instances
that contains all (K, O,q) such that K = 9%, O is a DL knowledge base, and q is an € CL inclusion.*® There exists no shifting IBQ
mechanism for PT.

Proof. Let K =@ and g =3R.(ANB)NARA(ANB)EC A’. Let

O71 = {disj(B, B)},
O2 = {disj(B, B), AC {a}}.

Note that both (KX, O1,q) and (K, O2,q) belong to PZ.
It can be easily verified that pos(Q,) = pos(O2); in particular, the two sets contain all the inclusions of the form A; nm
... Am C By U...U By such that:

e either the inclusion is a tautology (i.e. some concept name occurs both in the left-hand side and in the right-hand side),
e or both B and B occur in the left-hand side.

However, KUQ, kK q, while KUO - gq. The latter fact holds because due to the nominal {a}, both 3R.(ANB) and 4R.(AMB)
should have the same role filler, that cannot satisfy the disjoint concepts B and B at the same time. It follows that q is
trivially satisfied because its left-hand side is equivalent to 1.

Now suppose that a shifting IBQ mechanism (s,r) for PZ exists; we shall derive a contradiction. By condition 2 of
Definition 5.29,

r(s(K), pos(O1 U(K \ s(K))), gq) = false (16)
r(s(K), pos(O2 U(K \ s(K))), gq) = true. (17)

However, K = s(K) =@ and consequently:

r(s(K), pos(O1 U (K \ s(K))), q) =r(J, pos(O1), q)
=1(Y, pos(O2), q)
=T1(s(K), pos(O2 U(K \ s(K))), g)
which contradicts (16) and (17). @
Remark 5.31. The above result complements the analogous negative result [20, Theorem 4] that applies to knowledge bases

K with infinity axioms (while PL knowledge bases have the finite model property). On the other hand, [20, Theorem 4]
covers also more expressive oracle query languages.

The proof of the above negative result is based on the limited expressiveness of the oracle query language QC. A similar
consideration applies to the requirement that (©) may share only concept names with X(K-) and X(q). Without this

assumption, PLR® is not complete. More generally:

Theorem 5.32. Let PZ be a set of problem instances that contains all (K’, O, q) such that K = @, O is an EL knowledge base and q is
an € £L inclusion (possibly sharing roles with ©). There exists no shifting IBQ mechanism for PTZ.

28 We use ECL inclusions to strengthen our result, since they are a special case of PL subsumption queries.

27
PA. Bonatti, L. Ioffredo, I.M. Petrova et al. Artificial Intelligence 289 (2020) 103389

Proof. Let K = @, g = (AR.A CAS.A), O1; = @ and O2 = {q}. Note that

e pos(Q;) = pos(Q2z) (both contain all and only the tautological inclusions of the form (9));
e KUO} q;
e KUO2 Kg.

Then the assumption that a shifting IBQ mechanism for PZ exists leads to a contradiction, by the same argument used in
Theorem 5.30.

In the light of the above negative results, a natural question is whether an oracle query language more expressive than
OL would remove the need for the restrictions on nominals and roles. Note that IBQ mechanisms for shared roles have
already been introduced in [20]. For a fragment of €£, there exists an IBQ algorithm that terminates in polynomial time.
Nominals are not allowed, but shared roles are, under suitable conditions.

In order to support more expressive oracle queries, PLRC and STSCx should be extensively changed, though. The proofs
of the above negative results reveal that the simple treatment of existential restrictions in STSCx should be replaced with
a more complex computation, involving oracle queries, and it is currently not clear how significantly such changes would
affect the scalability of reasoning and the possibility of compiling oracles into PL knowledge bases. Given that scalability is
one of SPECIAL’s primary requirements, and that there is no evidence that shared roles are needed by SPECIAL’s application
scenarios (cf. Remark 5.1), we leave this question as an interesting topic for further research.

6. Experimental assessment

In this section we describe a Java implementation of PLR and compare its performance with that of other popular
engines. We focus on PLR (as opposed to the more complex PLR® ) because SPECIAL’s application scenarios are compatible
with the oracle compilation into a PL knowledge base illustrated in Section 5.4. The implementation and experimental
evaluation of PLR®, that may be interesting in other applications of PL, lie beyond the scope of this paper.

SPECIAL’s engine is tested on two randomly generated sets of inputs. The first set is based on the knowledge base and
policies developed for Proximus and Thomson Reuters. Consent policies are generated by modifying the business policies,
mimicking a selection of privacy options from a list provided by the controller. This first set of test cases is meant to assess
the performance of the engines in the application scenarios that we expect to arise more frequently in practice. The second
set of experiments, that makes use of larger knowledge bases and policies, is meant to predict the behavior of the engines
in more complex scenarios, should they arise in the future.

The implementation of PLR and its optimizations are described in the next subsection. Then Section 6.2 illustrates the
test cases used for the evaluation. Finally, Section 6.3 reports the results of the experiments.

6.1. Prototype implementation and optimization

PLR is implemented in Java and it is distributed as a .jar file. The reasoner’s class is named PLReasoner, and supports
the standard OWL APIs, version 5.1.7. The package includes a complete implementation of PLR, including the structural
subsumption algorithm STS, and the preliminary normalization phases, based on the 7 rewrite rules and on the interval
splitting method for interval safety.

The interval splitting method has been refined in order to reduce the explosion of business policies. The reason for
refinements can be easily seen: if a business policy contains interval [1,10] and a consent policy contains [5, 10], then the
method illustrated in (8) splits [1, 10] into the (unnecessarily large) set of intervals

[1,1], [2,4], [5,5], [6,9], [10, 10],

that cause a single simple policy to be replaced with 5 policies. Note that for interval safety the splitting [1,4], [5, 10]
would be enough. While (8) is convenient in the theoretical analysis - because it has a simpler definition and it does not
increase asymptotic complexity - a more articulated algorithm is advisable in practice. Here we only sketch the underlying
idea: each interval end point is classified based on whether it occurs only as a lower bound, only as an upper bound, or
both. A singleton interval is generated only for the third category of endpoints, while the others are treated more efficiently.
In particular, in the above example, 1 and 5 occur only as lower bounds; this allows to generate non-singleton sub-intervals
that have 1 and 5 as their lower bound. Moreover, 10 occurs only as an upper bound; this allows to create a non-singleton
sub-interval where 10 is the upper bound. Accordingly, the refined splitting algorithm generates only the two intervals [1, 4]
and [5, 10].

Several other optimizations have been implemented and assessed. The corresponding versions of PLR are described
below:

28
PA. Bonatti, L. Ioffredo, I.M. Petrova et al. Artificial Intelligence 289 (2020) 103389

PLR c

The normalization steps (lines 2 and 3 of PLR) are one of the most expensive parts of the reasoner. In order to reduce
their cost, two caches are introduced. The first cache stores the business policies that have already been normalized w.r.t.
K (line 2 of PLR). In this way, the seven rewrite rules are applied to each business policy only once; when the policy is
used again, line 2 simply retrieves the normalized concept from the cache. This optimization is expected to be effective in
SPECIAL’s application scenarios because only business policies need to be normalized, and their number is limited. So the
probability of re-using an already normalized policy is high, and the cache is not going to grow indefinitely; on the contrary
its size is expected to be moderate.

Similarly, a second cache indexed by the two policies C and D stores the concepts splity(C) already computed (thereby
speeding up line 3 of PLR, that is, the interval splitting step needed for interval safety).

PLR 2n, PLR c 2n

PLR 2n normalizes both C and D with the seven rewrite rules, before computing splitp(C). Since the rewrite rules may
merge and delete the intervals of D, this optimization potentially reduces the number of splitting points and, consequently,
the size of splitp(C). We denote with PLR c2n the version of PLR that exploits both the caches of PLR c and applies double
normalization, as PLR pre.

PLR pre, PLR pre 2n

Sometimes the two normalization phases can be pre-computed. When the set of business policies and the set of intervals
that may occur in consent policies are known in advance, the seven rules and interval splitting can be applied once and
for all before compliance checking starts. For example, intervals are available in advance when the minimum or maximum
storage time are determined by law, or when the duration options available to data subjects when consent is requested are
specified by the data controller. This version of the engine is designed for such scenarios. The given set of business policies
is fully normalized before compliance checking starts, and stored in the caches supported by PLR c. During compliance
checking, lines 2 and 3 only retrieve concepts from the caches. In this way the cost of a compliance check is almost
exclusively the cost of STS. This version of PLR will be evaluated by measuring compliance checking time only; preliminary
normalizations are not included.

6.2. Test case generation

The first set of test cases is derived from the business policies developed for the pilots of Proximus and Thomson Reuters;
these policies will be denoted with Ppys and Prpr respectively.

In each compliance check Pg E Pc, Pg is a union of simple business policies randomly selected from those occurring
in the pilots’ policy (Ppxg or Ptr). Since Pg describes the activity of a business process of the data controller, the random
choice of Pg essentially corresponds to a random distribution of the controller’s data processing activities (abstracted by
the simple policies) across its business processes.

The consent policy Pc is the union of a set of simple policies PL (1=1,...,n) randomly selected from the pilots’ policy,
and randomly perturbed by replacing some vocabulary terms with a different term. The random selection mimicks the opt-
in/opt-out choices of data subjects with respect to the various data processing activities modeled by the simple policies.
Similarly, the random replacement of terms simulates the opt-in/opt-out choices of the data subject w.r.t. each component
of the selected simple policies. More precisely, if the modified term occurring in PL is a superclass (resp. a subclass) of
the corresponding term in the original business policy, then the data subject opted for a broader (resp. more restrictive)
permission relative to the involved policy property (e.g. data categories, purpose, and so on).

In this batch of experiments, the knowledge base is always SPECIAL’s ontology, that defines policy roles and the tempo-
rary vocabularies for data categories, purpose categories, etc. The size and number of this batch of experiments is reported
in Table 5. The number of randomly generated business policies is higher in one case because Ppxg has more simple poli-
cies than Prr: the ratio is 20 generated policies per simple policy. Queries have been obtained by generating 100 consent
policies for each business policy. Table 5 reports also the average number of simple policies per generated policy and its
standard deviation. The size of each policy is limited by SPECIAL’s usage policy format: at most one interval constraint per
simple policy, and nesting depth 2.

In the second set of experiments, both the ontologies and ?£L subsumptions are completely synthetic, and have in-
creasing size in order to set up a stress test for verifying the scalability of SPECIAL’s reasoner. Fifteen ontologies have been
generated: five for each of the three sets of parameters 01-03 reported in Table 6. The same table reports the parameters
used to generate the PL concepts occurring in the queries, according to two size specifications: P1 and P2.

Note that approximately half of the roles and concrete properties are functional, and half of the roles have a range
axiom. Ontologies have been generated by randomly distributing classes over approximately log(#classes) layers. Then the
specified number of disjointness axioms have been generated, by picking classes on the same layer. Finally, about 2 - #classes
inclusions have been created, mostly across adjacent layers, in such a way that no class became inconsistent. The ratio

29
PA. Bonatti, L. Ioffredo, I.M. Petrova et al. Artificial Intelligence 289 (2020) 103389

Table 5
Size of the test cases inspired by the pilots.

Proximus (PXS)

Thomson Reuters (TR)

 

 

 

 

Ontology
inclusions 186 186
disj 11 11
range 10 10
func 8 8
classification hierarchy height 4 4
Business policies
# generated policies 120 100
avg. simple pol. per full pol. 2.71 2.39
std. dev. 1.72 1.86
Consent policies
# generated policies 12,000 10,000
avg. simple pol. per full pol. 3.77 3.42
std. dev. 2.02 2.03
Test cases
# generated queries 12,000 10,000
Table 6
Size of fully synthetic test cases.
Ontology size O1 O02 03 Concept size Pl P2
classes 100 1,000 10,000 max #simple pol. per full pol. 10 100
roles 10 50 100 max #top-level inters. per 10 20
concrete properties 10 25 50 simple subconcept
func 10 37 75 max depth (nesting) 4 9
range 5 25 50 avg. #simple pol. per full pol. 6.8 50.1
_ avg. depth 2.4 5
avg. disj 3 31 298
avg. inclusions 211 2224 23418 Simple policy size
avg. classification 8 10 14 avg. #intersections 10.6 25.8
hierarchy height avg. #intervals 3.7 9

between the number of inclusions and the number of classes is similar to the ratio that can be observed most frequently in
real ontologies, cf. [36,35,33].

We have generated 100 concepts of size P1 and 1000 of size P2, picking interval endpoints from [0,365] (one year, in
days). Each set has been split into business and consent policies (resp. 30% and 70% of the generated policies), that have
been paired randomly to generate test queries. The number of queries of size P1 generated for each ontology is 50. Let
#int be the maximum number of interval constraints per simple policy after normalization w.r.t. the 7 rules*® (for a given
business policy). The number of queries of size P2 generated for each ontology and each business policy with #int <5 is 10.
The maximum number of queries for each ontology and each #int > 5 has been limited to 40, in order to keep the length of
the experiments within a reasonable range. In this case, we maximized the number of different business policies occurring
in the selected queries.

For each ontology K, the business policies have been selected from the available K--consistent policies. Furthermore,
whenever possible, queries have been selected in such a way that the number of positive and negative answers are the
same. Table 6 illustrates the average size of the generated policies for each parameter setting. We have not limited the
number of interval constraints, in order to analyze the behavior of PLReasoner as the number of intervals per simple policy
grows (if it is not bounded then PL subsumption query answering is coNP-hard). The maximum nesting level occurring in
the generated policies is approximately [log, (max disjuncts)].

6.3. Performance analysis

The experiments have been run on a server with an 8-cores processor Intel Xeon Silver 4110, 11M cache, 198 GB RAM,
running Ubuntu 18.04 and JVM 1.8.0_181, configured with 32 GB heap memory (of which less than 700MB have been
actually used in all experiments). We have not exploited parallelism in the engine’s implementation.

29 The reason for measuring #int after normalization is explained later.

30
PA. Bonatti, L. Ioffredo, I.M. Petrova et al. Artificial Intelligence 289 (2020) 103389

Avg. time per subsumption

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

_ 3 7 T T T T T I
PXS ‘To 58. = Hermit |
: = PLR
2 L
TR 0.81
p_.o; a 11.8 L
5.44
61 L
P1-O2 4.57
ss 58.2 |
PLOS : 14.66 l l l |
0 10 20 30 40 50 60
milliseconds

Fig. 1. Comparisons on small/medium policies.

P2-O1: Avg. time per subsumption query
| | | |

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

al. 0 8 Hermit |

10°F |0o PLR |
2 L

6 10° = 4
oO cE
9 C

10? E z

1 2 3 4 5

# intervals per simple policy

Fig. 2. Impact of interval number per simple policy - large policies.

First we compare PLR with Hermit, the only reasoner - among those we selected for comparison - that directly supports
subsumptions with intervals.°° We start by illustrating the results for the test cases with small and medium policies. Fig. 1
shows that PLR is faster than Hermit, over these test sets, even if no optimization is applied. The size of the ontology affects
the performance of Hermit more than PLR’s (see the results for 01, O2, and O3).

The good performance of PLR over PXS and TR had to be expected, given that the policies involved in these test
sets are SPECIAL’s usage policies, that by definition contain at most one interval constraint per simple policy, of the form
dhas_duration.[£, u]. Let #int denote the maximum number of intervals per simple policy after applying the rewrite rules,
and recall that the size of splitp(C) may grow exponentially with #int. We have not limited #int, while generating the
synthetic policies in P1 and P2, to see how the number of intervals affects the performance of PLR (recall that if #int
is unbounded, then ?£ subsumption is coNP-complete). We measured the value of #int after applying the rewrite rules,
because they can collapse and delete intervals, thereby reducing the complexity of the subsequent interval splitting phase
and the size of splitp(C). After the application of the seven rules, the maximum #int over the business policies occurring
in P1’s queries is 9. Fig. 1 shows that the potential combinatorial explosion of splitp(C) does not frequently occur with
these policies. The probability of splitting a single interval into many sub-intervals is evidently not high. On the contrary,
a combinatorial explosion is clearly observable in the test sets with large policies (P2); Fig. 2 illustrates the results for the
smallest synthetic ontologies (O01).

Then we analyzed the effects of the optimizations described in Section 6.1. Their effectiveness over small and medium
policies is illustrated by Fig. 3. The normalization of consent policies (2n) brings no benefits with small policies (actually,
it slightly decreases the engine’s performance, compare PLR 2n with PLR, and PLR c 2n with PLR c). Its benefits start
to be visible with medium policies. The cache of normalized policies (PLR c) is the best option on small policies. On
medium policies, the combination of the caches with the normalization of consent policies (PLR c 2n) is the most effective
optimization.

Over large policies (P2), the normalization of consent policies (2n) is essential to mitigate the combinatorial explosion
of splitp(C), as shown in Fig. 4. The versions of PLR that do not normalize D become impractical already for #int = 3,
while the computation time of PLR 2n and PLR c 2n moderately increases. This behavior can be explained by observing the
effects of normalization on this test set: after the application of the rewrite rules, the average number of intervals is about
10 times smaller, which reduces the probability of an exponential growth of splitp(C).

30 See also Remark 6.1 below.

31
PA. Bonatti, L. Ioffredo, I.M. Petrova et al.

Avg. time per subsumption

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

0.58 T T T T T T
0.41 = PLR
PXS 0.76 = PLRc
Ho AA = PLR2n
, = PLRc 2n
0.81
0.57
TR i 0.91
0.6
5.44
4.9
P1-O1 3.54
2.97
4.57
3.67
P1-O2 "| EE) 4.32
MN 2.56
14.66
12.15

 

 

 

°° SS 2

 

 

 

ss |
0 2 4 6

8 10 12 14 16
milliseconds

Fig. 3. Effectiveness of optimizations on small/medium policies.

P2-O1: Avg. time per subsumption

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

95.4 T T T T
L- 24.6
25.9
GR 24.2
61.5
> 60.7
> (31.5
= GE 29.5
Q
2
G 291.1
Bs 302.6
3° ET 55.9
4 Cas
>
5
z
Fk
* a 53
a 43.5
= PLR
= PLRc
5 = PLR2n
63.5 = PLR 2n
Ms
0 50 100 150 200 250 300

Fig. 4. Effectiveness of optimizations on large policies and small ontologies.

milliseconds

390

Artificial Intelligence 289 (2020) 103389

Next, in Fig. 5, we compare the best version of the engine over medium/large policies (i.e. PLR c 2n) with Hermit. The
optimizations delay the effects of combinatorial explosions until #int = 7. After this threshold, Hermit becomes faster.

Finally, we analyzed the effectiveness of business policy pre-normalization (pre). Recall that this approach is feasible
in practice only if both the business policies and the intervals that may occur in consent policies are known in advance,
and do not change frequently. The effects of pre-normalization on small and medium policies is remarkable: PLR pre is
approximately one order of magnitude faster than Hermit, as shown in Fig. 6. Over pilot-inspired tests, pre-normalization
brings the average time per subsumption query well below 500 p-seconds.

The effects of pre-normalization quickly disappear over large policies. Fig. 7 shows that the explosion of splitp(C) makes
it necessary to apply also the normalization of consent policies to delay combinatorial effects (see PLR pre 2n). However,
for #int = 8, PLR pre 2n is slower than Hermit, so pre-normalization does not deal with the combinatorial explosion better

than PLR c 2n.

32
PA. Bonatti, L. Ioffredo, I.M. Petrova et al. Artificial Intelligence 289 (2020) 103389

P2-O2: Avg. time per subsumption

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

T T T
149.3 = Hermit
| 31.7 = PLR 2n | >
> | 150.2 |
ME 33
3. 148.6 |
_ > (E383
oO
2 4 150 L
2 EE 543s
&
Be | 158.7 |
2° | 70.2
$ 149.4
5 ° | TT 96.4 )
z
a 146.1
EE 104.6
3. 152.9 L
a 272.4
9. 147.8
i 268.2
| l l l l | l
0 50 100 150 200 250 300
milliseconds

Fig. 5. Hermit vs PLR with caches and double normalization.

Avg. time per subsumption

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

rot =, Hermit
PXS |] 0.44 = PLRc I
, = PLR pre
4
|{) 0.57 |
TR 0.6
| 0.47
11.3
4.9
P1-O1 im 2.97
i 2.28
16.1
3.67
P1-02 i 2.56 |
1.7
58.2
12.15
7 4.15 l l l l l l
0 10 20 30 40 10) 60
milliseconds

Fig. 6. Effectiveness of business policy pre-normalization on small/medium policies.

PLR can also be compared with ELK - a specialized reasoner for the tractable profile OWL2-EL - by exploiting the simple
structure of PXS. The policies in this test set do not contain any intervals and are natively normalized (they never contain
more than one subconcept 3R.C with the same role R). For these reasons, PXS can be correctly processed by ELK, although
it supports neither intervals nor functionality axioms.

Using ELK, the average time per subsumption query is 3.11 milliseconds; therefore all versions of PLR are significantly
faster. Such difference in performance may be partially due to the cost of initializing and maintaining ELK’s indexing struc-
tures for the efficient application of the inference rules illustrated in [33]. Moreover, the worst-case complexity of ELK’s
algorithm is higher than PLR’s (O(n?) vs. O0(n?)).

In order to test GraphDB, each subsumption query C EC D has been translated as explained in Section 5.3, i.e. by asserting
C(a) in the knowledge base (where a is a fresh individual), and transforming D is into a SPARQL query to check whether
D(a) is entailed. Recall that this reduction is not applicable when C contains intervals, therefore GraphDB is tested on PXS

33
PA. Bonatti, L. Ioffredo, I.M. Petrova et al. Artificial Intelligence 289 (2020) 103389

P2-O2: Avg. time per subsumption

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

We 22.7 mm PLR pre
1-7 28.2 = PLR pre 2n | -
149.3 =, Hermit
es 5”
27 30.5 |
150.2
ss 9:
37 34.1 I
148.6
>
CS DTP
2 44 53.5 +
2 150
a
&
5 5 72.8 L
o 158.7
oS
2
2 6 104 I
a 149.4

 

 

74 117.3 I

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

146.1
8 | 303.1 +
152.9
94 289.5 |
147.8
| l l l l l |
0 50 100 150 200 250 300

milliseconds

Fig. 7. Effectiveness of business policy pre-normalization on large policies.

only.*! The cost of asserting C(a) in the KB, the cost of translating D into SPARQL, and the cost of parsing the SPARQL
query are not included in the measurement. The average time per query calculated in this way is 16.84 ms, so PLR is
significantly faster on this test set. It should be considered that GraphDB is optimized for relatively small, user-generated
queries on large ABoxes, while SPECIAL’s scenarios involve a huge number of large, automatically generated queries on very
small ABoxes.

Next we processed PXS with RDFox, by Oxford Semantic Technologies. For this purpose, ?£ subsumptions have been
translated into SPARQL queries with the same reduction used for GraphDB. Computation time does not include the cost of
the assertions C(a) and the cost of the translation of D. On average, RDFox takes 1.03 ms per compliance check. Also in this
case, it should be remarked that - similarly to GraphDB - RDFox is optimized for small, user-generated queries on large
ABoxes, while SPECIAL’s scenarios exhibit opposite features.

The response time of RDFox does not include the cost of computing the logical consequences of the KB, that are materi-
alized when C(a) is asserted. On the other hand, measurements include the parsing of SPARQL queries. So the performance
of RDFox can be improved by caching the queries, in order to parse them only the first time they are processed.

Remark 6.1. According to Oxford Semantic Technologies, it may be profitable to leverage RDFox’s generality and replace
the standard reduction to query answering used in our experiments with a Datalog meta-interpreter that implements the
method for PL subsumption checking introduced in Section 4. Such meta-interpreter would process a reified representation
of PL concepts and make use of Datalog extensions such as comparison operators, aggregates (for interval splitting), and
equality (to encode functionality axioms). A first advantage of this implementation is that it can answer all PL queries
(while the standard reduction is not applicable to subsumptions with intervals). Another potential advantage, in terms of
performance, is that RDFox can materialize and incrementally update the subsumption predicate. A potential disadvantage
is the expected size of the materialization as the number of business and consent policies grows. Concerning PLR, its
performance can be improved by adopting RDFox’s implementation choices, in particular (i) re-engineering PLR in Ct’,
and (ii) exploiting parallelism. Independently from performance considerations, our experimental results on PLR prove that
real-time subsumption checking in PL can be achieved without necessarily resorting to complex proprietary technology.
This fact fosters adoption - a topic that is further discussed in the conclusions.

We have also considered Konclude, a general reasoner that is very competitive on standard classification benchmarks

[47]. Konclude does not support intervals, therefore it has been tried on PXS only. Konclude integrates a tableau algorithm
with completion-based saturation - for pay-as-you-go behavior - and adopts a wide range of optimizations. The current

31 On the other hand, unlike GraphDB, PL is not able to express all SPARQL queries.

34
PA. Bonatti, L. Ioffredo, I.M. Petrova et al. Artificial Intelligence 289 (2020) 103389

version, however, is focused on classification tasks; streams of ?L subsumptions can be processed only at the cost of
repeating the classification of the knowledge base for each query. This prevents a fair comparison with Hermit and PLR (in
our tests, Konclude is slower than both).

7. Conclusions

We have introduced the description logic PL in order to formalize the data usage policies adopted by controllers as
well as the consent to data processing granted by data subjects. Checking whether the controllers’ policies comply with the
available consent boils down to subsumption checking between P£ concepts. PL can also formalize parts of the GDPR;
then, by means of subsumption checking, one can automatically check several constraints on usage policies such as, for
example:

e Are all the required policy properties specified?
e Are all the required obligations specified?
e Is the policy compatible with GDPR’s constraints on cross-border data transfers?

PEL queries supports interval constraints of the form 3f.[2, u] in order to model limitations on data storage duration. This
feature affects convexity, and hinders a direct use of the query answering techniques for Horn DLs.

PL has been made as simple as possible in order to address two requirements. First, it should be usable by people
with no logical or legal background. One of our industrial partners successfully assessed the usability of PL, by verifying
that its employees can write correct business policies. Second, the frequency of compliance checks can be high, so PL
query answering should be extremely fast and scalable. Despite the simplicity of PL, general PL subsumption checking
is coNP-complete, due to the interplay of interval constraints and concept union. However, reasoning becomes tractable
by requiring that each simple policy on the left-hand side of the subsumption query should contain a bounded num-
ber of interval constraints - a restriction that is naturally satisfied by SPECIAL’s usage policies, consent policies, and in
the formalization of the GDPR. Under this assumption, subsumption checking can be split into a polynomial-time normal-
ization phase and a subsequent subsumption check that can be carried out by a fast, structural subsumption algorithm
(STS).

The scalability of the complete algorithm (PLR) has been experimentally assessed. Some of the test sets consist of
realistic policies and ontologies, derived from SPECIAL’s pilots. Such policies and ontologies are small, so we generated also
synthetic stress tests, where policies and ontologies are significantly larger than what we expect in real GDPR compliance
scenarios. Our tests show that PLR is significantly faster than Hermit on small and medium policies. This had to be expected,
since Hermit is not specialized on PL and constructs a hypertableau at each subsumption check. The performance of
PLR can be further improved by caching normalized policies (PLR c). With this solution, PLR takes around 500 pseconds
per subsumption check, over the test sets inspired by SPECIAL’s pilots (PXS and TR). By pre-normalizing business policies
(PLR pre), the average cost per subsumption check can be further reduced to 333 psec (PXS) and 487 sec (TR).°2

Over large policies (P2), the probability of observing a combinatorial explosion during interval splitting grows, and the
performance of PLR exhibits an exponential decrease as #int grows (where #int is the average number of intervals per
simple business policy measured after applying the seven rewrite rules). This phenomenon is unavoidable, unless P = NP,
because PL subsumption checking is coNP-hard if #int is unrestricted. However, by normalizing also consent policies,
combinatorial effects are mitigated (because normalization may merge different intervals), and PLR c2n turns out to be
faster than Hermit for #int < 8.

PLR has been compared also with ELK, GraphDB, and Konclude, using only a subset of the test cases because these
engines cannot answer P£ queries with intervals. Being specialized on PL queries, PLR turns out to be faster than these
engines, too. PLR is also faster than RDFox, when the standard reduction of subsumption to query answering is adopted.°°
Alternatively, it seems possible to implement PLR’s reasoning method in Datalog, and evaluate the Datalog program with
RDFox (see Remark 6.1). Investigating this approach is an interesting topic for further research.

In perspective, the expressiveness needed to encode the vocabularies of data categories, purposes, recipients, etc. is going
to exceed the capabilities of PL. For this reason, we have shown how to integrate the compliance checking method based
on PLR with reasoners for logics more expressive than PL. The integration is based on the import by query approach. If the
“external” ontology © that defines vocabulary terms is in Horn-S7ZQ, and if the main knowledge base K and the given
subsumption query share only concept names with ©, then algorithm PLR© - an adaptation of PLR that calls a reasoner
for © - is sound and complete. If © additionally belongs to a tractable DL, then subsumption checking is tractable in the
IBQ framework, too. The restriction on roles can be partly lifted by allowing queries to mention the roles occurring in O,
provided that if R € X&(Q), then the existential restrictions 4R.C may contain only roles in X(Q).

32 This speed allows to process only about 20% of the base station events and 33% of the wi-fi probing events generated every second in the streaming
scenario. SPECIAL addresses this issue by running multiple compliance checks in parallel, by means of a big data architecture; see for example [12,34] for
more details.

33 See also the optimization options discussed in Section 6.

35
PA. Bonatti, L. Ioffredo, I.M. Petrova et al. Artificial Intelligence 289 (2020) 103389

We have also illustrated a different implementation strategy, based on a pre-compilation of K and © into a single PL
knowledge base comp(K, ©), whose size is polynomial in the size of K UO and in the number of business policies. Com-
pliance checks are computed in polynomial time, after compilation, even if O belongs to an intractable logic. Moreover,
pre-compilation allows to exploit the implementation of PLR, whose scalability has been assessed in Section 6. This ap-
proach works well in SPECIAL’s use cases because the number of business policies is usually small, and K, ©, and the
business policies are relatively stable and persistent. Unfortunately, the above assumptions cannot be made in general, for
all potential applications of PL.

Such applications include also the representation of licenses, which constitute a fundamental aspect of data markets. The
application context is in some respect analogous to SPECIAL’s: PL concepts should encode the usage restrictions that apply
to datasets, multimedia content, and so on. In this case, however, the policies that can be reasonably assumed to belong to
a limited set are those associated to sellers, that occur on the right-hand side of subsumptions, while the left-hand side can
hardly be restricted. This hinders the compilation-based approach, and may require a direct implementation of PLR®, that
is, the general IBQ reasoner for PL. Such implementation and its experimental assessment are interesting topics for further
research.

PL can also naturally encode electronic health records (EHRs). In this case, the top-level properties of PL queries
encode the sections of EHRs - according, say, to the HL7 standard - while some of the sections’ contents can be specified
with SNOMED terms. The IBQ framework allows to process PL queries with PLR°, and reduce the cost of SNOMED to
oracle calls, consisting of linear time visits to its classification graph. The efficiency of the structural subsumption reasoner
is very promising in this context, that is challenging for all engines due to the remarkable size of SNOMED. We plan to try
PLR® to increase the performance of the secure view construction reported in [15].

The simplicity of PLR makes it possible to embed PCL reasoning in objects with limited scripting capabilities. For exam-
ple, one of SPECIAL’s partners has programmed PL compliance checking as a smart contract in an Ethereum blockchain.
In this way, the creation of new entries in the blockchain is subject to compliance with a specified policy. This is also an
example of how simplicity may foster adoption: SPECIAL’s policy framework is not tightly bound to any specific technology
or components, and it can be easily integrated in a variety of systems.

SPECIAL’s deliverables comprise dashboards for controllers, data subjects, and data protection officers. We are going to
support these user interfaces by developing explanation algorithms for helping data subjects in understanding policies and
their decisions. The idea is leveraging the simple structure of PL concepts and axioms to generate high-level, user-friendly
explanations.

On the theoretical side, our results on the complexity of PL queries are novel, as discussed in Section 5.3, and extend
the available tractability and intractability results for extended faceted queries. The negative result on oracles with nominals
(Theorem 5.30) extends a result of [20] to logics that (like PL) enjoy the finite model property, and to IBQ mechanism
where the axioms of the main knowledge base K may be shifted to the imported ontology O.

There are further interesting topics for future work. For example, we currently do not know whether the requirement
that (X(K-) U X(q)) N X(O) C Ne can be relaxed without affecting tractability (under appropriate hypotheses).

Another interesting line of research consists in tracing the tractability threshold in the family of logics obtained by
extending PL with CLASSIC’s constructs, with particular attention to number restrictions, role-value maps, and nominals.
Preliminary results have been published in [16].

Last but not least, from a theoretical perspective, it will be interesting to see to what extent PLR’s pre-processing can
be adapted to extend Horn DLs with interval constraints without affecting tractability. We expect the interplay of number
restrictions and intervals to increase the complexity of reasoning.

Declaration of competing interest

We wish to confirm that there are no known conflicts of interest associated with this publication and there has been no
significant financial support for this work that could have influenced its outcome.

Acknowledgements

This research is funded by the European Union’s Horizon 2020 research and innovation programme under grant agree-
ment N. 731601. The GDPR compliance use case — here sketched with (5), (6), and Example 3.2 - is due to Benedict Whittam
Smith (Thomson Reuters).

References

[1] G. Antoniou, N. Dimaresis, G. Governatori, A modal and deontic defeasible reasoning system for modelling policies and multi-agent systems, Expert
Syst. Appl. 36 (2) (2009) 4125-4134.

[2] A. Artale, D. Calvanese, R. Kontchakov, M. Zakharyaschev, The DL-lite family and relations, J. Artif. Intell. Res. 36 (2009) 1-69.

[3] F. Baader, S. Brandt, C. Lutz, Pushing the EL envelope, in: IJCAI-05, Proceedings of the Nineteenth International Joint Conference on Artificial Intelligence,
Professional Book Center, 2005, pp. 364-369.

[4] F. Baader, D. Calvanese, D.L. McGuinness, D. Nardi, P.F. Patel-Schneider (Eds.), The Description Logic Handbook: Theory, Implementation, and Applica-
tions, Cambridge University Press, 2003.

36
PA. Bonatti, L. loffredo, I.M. Petrova et al. Artificial Intelligence 289 (2020) 103389

[5] M. Bienvenu, M. Ortiz, M. Simkus, G. Xiao, Tractability guarantees for DL-lite query answering, in: Eiter et al. [22], pp. 41-52.

[6] M. Bienvenu, M. Ortiz, M. Simkus, G. Xiao, Tractable queries for lightweight description logics, in: IJCAI 2013, Proceedings of the 23rd International
Joint Conference on Artificial Intelligence, Beijing, China August 3-9, 2013, 2013, pp. 768-774.

[7] P.A. Bonatti, Datalog for security, privacy and trust, in: Datalog Reloaded - First International Workshop, Datalog 2010. Revised Selected Papers, Oxford,
UK, March 16-19, 2010, in: Lecture Notes in Computer Science, vol. 6702, Springer, 2010, pp. 21-36.

[8] P.A. Bonatti, Fast compliance checking in an OWL2 fragment, in: Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelli-
gence, IJCAI 2018, July 13-19, 2018, ijcai.org, 2018, pp. 1746-1752.

[9] PA. Bonatti, B. Bos, S. Decker, J.D. Fernandez, S. Kirrane, V. Peristeras, A. Polleres, R. Wenning, Data privacy vocabularies and controls: semantic web
for transparency and privacy, in: Proceedings of the Workshop on Semantic Web for Social Good Co-Located with 17th International Semantic Web
Conference, SW4SG@ISWC 2018, in: CEUR Workshop Proceedings, vol. 2182, CEUR-WS.org, 2018.

[10] PA. Bonatti, S. De Capitani di Vimercati, P. Samarati, An algebra for composing access control policies, ACM Trans. Inf. Syst. Secur. 5 (1) (2002) 1-35.

[11] P.A. Bonatti, J.L. De Coi, D. Olmedilla, L. Sauro, A rule-based trust negotiation system, IEEE Trans. Knowl. Data Eng. 22 (11) (2010) 1507-1520.

[12] P.A. Bonatti, S. Kirrane, Big data and analytics in the age of the GDPR, in: 2019 IEEE International Congress on Big Data, BigData Congress 2019, IEEE,
2019, pp. 7-16.

[13] P.A. Bonatti, S. Kirrane, A. Polleres, R. Wenning, Transparent personal data processing: the road ahead, in: Computer Safety, Reliability, and Security -
SAFECOMP 2017 Workshops, ASSURE, DECSoS, SASSUR, TELERISE, and TIPS, Proceedings, in: Lecture Notes in Computer Science, vol. 10489, Springer,
2017, pp. 337-349.

[14] P.A. Bonatti, A. Peron, On the undecidability of logics with converse, nominals, recursion and counting, Artif. Intell. 158 (1) (2004) 75-96.

[15] P.A. Bonatti, I.M. Petrova, L. Sauro, Optimized construction of secure knowledge-base views, in: Proceedings of the 28th International Workshop on
Description Logics, in: CEUR Workshop Proceedings, vol. 1350, CEUR-WS.org, 2015.

[16] P.A. Bonatti, I.M. Petrova, L. Sauro, A richer policy language for GDPR compliance, in: Proceedings of the 32nd International Workshop on Description
Logics, in: CEUR Workshop Proceedings, vol. 2373, CEUR-WS.org, 2019.

[17] A. Borgida, P.F. Patel-Schneider, A semantics and complete algorithm for subsumption in the CLASSIC description logic, J. Artif. Intell. Res. 1 (1994)
277-308.

[18] D. Carral, C. Feier, B. Cuenca Grau, P. Hitzler, I. Horrocks, EL-ifying ontologies, in: Automated Reasoning - 7th International Joint Conference, IJCAR 2014,
Held as Part of the Vienna Summer of Logic, VSL 2014, Proceedings, Vienna, Austria, July 19-22, 2014, 2014, pp. 464-479.

[19] D. Carral, C. Feier, B. Cuenca Grau, P. Hitzler, I. Horrocks, Pushing the boundaries of tractable ontology reasoning, in: The Semantic Web - ISWC 2014 -
13th International Semantic Web Conference, Proceedings, Part II, 2014, pp. 148-163.

[20] B. Cuenca Grau, B. Motik, Reasoning over ontologies with hidden content: the import-by-query approach, J. Artif. Intell. Res. 45 (2012) 197-255.

[21] B. Cuenca Grau, B. Motik, Y. Kazakov, Import-by-query: ontology reasoning under access limitations, in: IJCAI 2009, Proceedings of the 21st International
Joint Conference on Artificial Intelligence, 2009, pp. 727-732.

[22] T. Eiter, B. Glimm, Y. Kazakov, M. Krétzsch (Eds.), Informal Proceedings of the 26th International Workshop on Description Logics, Ulm, Germany, July
23-26, 2013, CEUR Workshop Proceedings, vol. 1014, CEUR-WS.org, 2013.

[23] B. Glimm, I. Horrocks, B. Motik, G. Stoilos, Z. Wang, Hermit: an OWL 2 reasoner, J. Autom. Reason. 53 (3) (2014) 245-269.

[24] G. Governatori, F. Olivieri, A. Rotolo, S. Scannapieco, Computing strong and weak permissions in defeasible logic, J. Philos. Log. 42 (6) (2013) 799-829.

[25] R.H. Giiting, Graphdb: modeling and querying graphs in databases, in: J.B. Bocca, M. Jarke, C. Zaniolo (Eds.), VLDB’94, Proceedings of 20th International
Conference on Very Large Data Bases, Santiago de Chile, Chile, September 12-15, 1994, Morgan Kaufmann, 1994, pp. 297-308.

[26] C. Haase, C. Lutz, Complexity of subsumption in the €£ family of description logics: acyclic and cyclic tboxes, in: ECAI 2008 - 18th European Confer-
ence on Artificial Intelligence, Proceedings, in: Frontiers in Artificial Intelligence and Applications, vol. 178, IOS Press, 2008, pp. 25-29.

[27] R. Hoekstra, J. Breuker, M.D. Bello, A. Boer, LKIF core: principled ontology development for the legal domain, in: Law, Ontologies and the Semantic Web
- Channelling the Legal Information Flood, 2009, pp. 21-52.

[28] I. Horrocks, O. Kutz, U. Sattler, The even more irresistible SROIQ, in: Proceedings, Tenth International Conference on Principles of Knowledge Represen-
tation and Reasoning, AAAI Press, 2006, pp. 57-67.

[29] J.F. Horty, Agency and Deontic Logic, Oxford University Press, 2001.

[30] S. Jajodia, P. Samarati, M.L. Sapino, V.S. Subrahmanian, Flexible support for multiple access control policies, ACM Trans. Database Syst. 26 (2) (2001)
214-260.

[31] A.J.I. Jones, M.J. Sergot, On the characterization of law and computer systems: the normative systems perspective, in: J.-J.C. Meyer, R.J. Wieringa (Eds.),
Deontic Logic in Computer Science: Normative System Specification, Wiley, 1993, pp. 275-307, chapter 8.

[32] L. Kagal, T.W. Finin, A. Joshi, A policy language for a pervasive computing environment, in: 4th IEEE International Workshop on Policies for Distributed
Systems and Networks, POLICY, IEEE Computer Society, June 2003, p. 63.

[33] Y. Kazakov, M. Krétzsch, F. Simancik, The incredible ELK - from polynomial procedures to efficient reasoning with EL ontologies, J. Autom. Reason.
53 (1) (2014) 1-61.

[34] S. Kirrane, J.D. Fernandez, W. Dullaert, U. Milosevic, A. Polleres, P.A. Bonatti, R. Wenning, O. Drozd, P. Raschke, A scalable consent, transparency and
compliance architecture, in: The Semantic Web: ESWC 2018 Satellite Events, Revised Selected Papers, in: Lecture Notes in Computer Science, vol. 11155,
Springer, 2018, pp. 131-136.

[35] N. Matentzoglu, S. Bail, B. Parsia, A corpus of OWL DL ontologies, in: Eiter et al. [22], pp. 829-841.

[36] B. Motik, R. Shearer, I. Horrocks, Hypertableau reasoning for description logics, J. Artif. Intell. Res. 36 (2009) 165-228.

[37] Y. Nenov, R. Piro, B. Motik, I. Horrocks, Z. Wu, J. Banerjee, Rdfox: a highly-scalable RDF store, in: M. Arenas, O. Corcho, E. Simperl, M. Strohmaier, M.
d’Aquin, K. Srinivas, P.T. Groth, M. Dumontier, J. Heflin, K. Thirunarayan, S. Staab (Eds.), The Semantic Web - ISWC 2015 - 14th International Semantic
Web Conference, Proceedings, Part II, Bethlehem, PA, USA, October 11-15, 2015, in: Lecture Notes in Computer Science, vol. 9367, Springer, 2015,
pp. 3-20.

[38] M. Ortiz, S. Rudolph, M. Simkus, Worst-case optimal reasoning for the horn-dl fragments of OWL 1 and 2, in: Principles of Knowledge Representation
and Reasoning: Proceedings of the Twelfth International Conference, KR 2010, AAAI Press, 2010.

[39] M. Ortiz, S. Rudolph, M. Simkus, Query answering in the horn fragments of the description logics SHOIQ and SROIQ, in: IJCAI 2011, Proceedings of the
22nd International Joint Conference on Artificial Intelligence, IJCAI/AAAI, 2011, pp. 1039-1044.

[40] M. Palmirani, G. Governatori, Modelling legal knowledge for GDPR compliance checking, in: Legal Knowledge and Information Systems - JURIX 2018:
the Thirty-First Annual Conference, Groningen, the Netherlands, 12-14 December 2018, 2018, pp. 101-110.

[41] M. Palmirani, M. Martoni, A. Rossi, C. Bartolini, L. Robaldo, Legal ontology for modelling GDPR concepts and norms, in: Legal Knowledge and Informa-
tion Systems - JURIX 2018: the Thirty-First Annual Conference, Groningen, the Netherlands, 12-14 December 2018, 2018, pp. 91-100.

[42] M. Palmirani, M. Martoni, A. Rossi, C. Bartolini, L. Robaldo, Pronto: privacy ontology for legal reasoning, in: Electronic Government and the Information
Systems Perspective - 7th International Conference, Proceedings, EGOVIS 2018, Regensburg, Germany, September 3-5, 2018, 2018, pp. 139-152.

[43] C.H. Papadimitriou, Computational Complexity, Academic Internet Publ., 2007.

37
PA. Bonatti, L. loffredo, I.M. Petrova et al. Artificial Intelligence 289 (2020) 103389

[44] H. Prakken, G. Sartor, Law and logic: a review from an argumentation perspective, Artif. Intell. 227 (2015) 214-245.

[45] M.J. Sergot, F. Sadri, R.A. Kowalski, F. Kriwaczek, P. Hammond, H.T. Cory, The British nationality act as a logic program, Commun. ACM 29 (5) (1986)
370-386.

[46] E. Sherkhonov, B. Cuenca Grau, E. Kharlamov, E.V. Kostylev, Semantic faceted search with aggregation and recursion, in: The Semantic Web - ISWC
2017 - 16th International Semantic Web Conference, Proceedings, Part I, Vienna, Austria, October 21-25, 2017, 2017, pp. 594-610.

[47] A. Steigmiller, T. Liebig, B. Glimm, Konclude: system description, J. Web Semant. 27-28 (2014) 78-85.

[48] A. Uszok, J.M. Bradshaw, R. Jeffers, N. Suri, PJ. Hayes, M.R. Breedy, L. Bunch, M. Johnson, S. Kulkarni, J. Lott, KAoS policy and domain services: towards
a description-logic approach to policy representation, deconfliction, and enforcement, in: 4th IEEE International Workshop on Policies for Distributed
Systems and Networks, POLICY, IEEE Computer Society, June 2003, pp. 93-96.

[49] T.Y.C. Woo, S.S. Lam, Authorizations in distributed systems: a new approach, J. Comput. Secur. 2 (2-3) (1993) 107-136.

38
