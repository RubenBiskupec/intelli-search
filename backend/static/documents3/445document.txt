Lu et al. Hum. Cent. Comput. Inf. Sci.
https://doi.org/10.1186/s13673-020-00215-z

(2020) 10:10 © Human-centric Computing

and Information Sciences

RESEARCH Oy oT-Ta waa -55 4

®

Exploring coupled images fusion based cuz
on joint tensor decomposition

Liangfu Lu'’®, Xiaoxu Ren?, Kuo-Hui Yeh?, Zhiyuan Tan* and Jocelyn Chanussot?

 

*Correspondence:

liangfulv@tju.edu.cn; jocelyn.

chanussot@gipsa-lab.
grenoble-inpfr

School of Mathematics,
Tianjin University,

Tianjin 300350, China

° GIPSA lab, Grenoble-INP
38402 Saint Martin d’Heres
Cedex, France

Full list of author information
is available at the end of the
article

 

Q) Springer Open

Abstract

Data fusion has always been a hot research topic in human-centric computing and
extended with the development of artificial intelligence. Generally, the coupled data
fusion algorithm usually utilizes the information from one data set to improve the
estimation accuracy and explain related latent variables of other coupled datasets. This
paper proposes several kinds of coupled images decomposition algorithms based on
the coupled matrix and tensor factorization-optimization (CMTF-OPT) algorithm and
the flexible coupling algorithm, which are termed the coupled images factorization-

optimization (CIF-OPT) algorithm and the modified flexible coupling algorithm
respectively. The theory and experiments show that the effect of the CIF-OPT algorithm
is robust under the influence of different noises. Particularly, the CIF-OPT algorithm can
accurately restore an image with missing some data elements. Moreover, the flexible
coupling model has better estimation performance than a hard coupling. For high-
dimensional images, this paper adopts the compressed data decomposition algorithm
that not only works better than uncoupled ALS algorithm as the image noise level
increases, but saves time and cost compared to the uncompressed algorithm.

Keywords: Data fusion, Coupled image, Machine learning, Tensor decomposition, Al

 

Introduction
Image data fusion has been a hot research topic in neuroscience, metabonomics and
other fields, and has been widely used in real life. The coupled data fusion algorithm usu-
ally utilizes the information of one data set to improve the estimation accuracy and the
interpretation of related potential variables of other data sets. With the development of
electronic and imaging technology, it is difficult to find accurate data for digital images
for human beings, such as medical science [1], information remote sensing and so on. In
this situation, people hope to primitively analyze mass images and select the informa-
tion quickly and effectively by more convenient calculation way. Moreover, traditional
data processes mechanisms are less efficient when faced with large amounts of data in
human-centric computing. And we apply the tensor structures to represent massive data
to solve above problems in this paper because of its multi-dimensional property.
Multi-source image data fusion refers to making the comprehensive image analy-
sis for the image data obtained from different acquisition devices (known as multi-

source heterogeneous image data), so as to achieve complementary information from

© The Author(s) 2020. This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing,
adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and
the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material
in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material
is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the
permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http://creativeco
mmons.org/licenses/by/4.0/.
Lu et al. Hum. Cent. Comput. Inf. Sci. (2020) 10:10 Page 2 of 26

different information sources, and finally obtain clearer, more informative and higher
quality fused images. It is that we can use different types of electronic data collec-
tion sensors to manage, analyze and integrate resources efficiently to provide clearer
images to humans. However, multi-source heterogeneous image data analysis is now
facing many problems. Complex data objects have multiple dimensions, and how to
depict the relationship between them through data analysis is one of the challenges to
solve urgently.

For example, we cannot utilize a general matrix to express the spectral image as
there are multiple spectral band, (e.g. the mode 3 axis), where each spectral band rep-
resents a color image matrix. And we can see that multi-channel images have natural
tensor structures from the above case. Moreover, the superposition of image matrix
can be seen as a video if the mode 3 axis represents time, and above two tensor struc-
tures are shown in Figs. 1 and 2. Therefore, tensor can express multiple relationships
in the real world, while this paper studies image fusion based on tensor analysis,
which can abstractly describe the interaction mechanism between multiple aspects
of image data. In addition, tensor structure has strong expression ability and compu-
tational properties, so it is very meaningful to study tensor analysis of images. Tensor
decomposition is a very significant knowledge content, which can preserve the struc-
tural characteristics of the original image data [2].

What’s more, multi-source heterogeneous semantics are much more rich. How to
build a generalization model that integrates multi-source data or discover the cor-
relation between them is another challenge for multi-source heterogeneous images.
In this paper, we generally use couplings to refer to the correlation between hetero-
geneous images. When doctors make the diagnosis for a patient’s brain, they can get
some images of the patient’s brain from a variety of ways, as shown in Fig. 3. And

 

Mode 1 (spatial column)

 

Mode 2 (spatial row)

 

 

Fig. 1 The tensor structure of the multispectral image

 

 

Mode 1 (spatial column)

Mode 2 (spatial row)

Fig. 2 The tensor structure of the video

 

 
Lu et al. Hum. Cent. Comput. Inf. Sci. (2020) 10:10 Page 3 of 26

 

 

Diagnose

=

Assosiation

  

 

 

Fig. 3 The diagnosis process for a patient's brain
\ J

 

 

 

 

Fig. 4 The task diagram of hyperspectral hyper-resolution
\ )

whether there is a coupling between these brain images, and how to combine them
to determine the etiology of patients are the questions to be discussed in this paper.
In addition, for the fusion of hyperspectral images and multispectral images, the pur-
pose is to fuse the information in the same scene to generate fusion image with large
amount of information and high quality, as shown in Fig. 4. Similarly, what is the cor-
relation between the information contained in these spectral images and how to com-
bine complementary information to get a clearer image is also the significance of this
paper.

The outline of this paper is organized as follows. In “Related work” section, related
work about coupled images fusion is discussed. And we mainly describe some basic
notations and definitions on tensors in “Tensor and related notation” section. In “Cou-
pled image fusion” section, the proposed coupled image fusion algorithms are pre-
sented. Moreover, the experimental results on algorithms are shown in “Experiments
and results” section. Finally, we give some conclusions and future research directions we

need to study next.

Related work

Recently, motivated by the tensor nuclear norm(TNN), Pan Zhou and Canyi Lu pro-
posed a novel low-rank tensor factorization method for efficiently solving the 3-way
tensor completion problem, which can recover the synthetic data, inpainting images
and videos with superior performance and efficiency [3]. For hyperspectral images, ten-
sor decomposition can make full use of space and inter spectral redundancy between
images, compressing the high spectral image and extracting the related feature infor-
mation fast and high-quality [4-6]. Chia-Hsiang Lin et al proposed a convex optimiza-
tion-Based coupled nonnegative matrix factorization algorithm for hyperspectral and
multispectral data fusion [7]. Li and Dian proposed a coupled sparse tensor factoriza-
tion (CSTF)-based approach for fusing hyperspectral images and multispectral images
Lu et al. Hum. Cent. Comput. Inf. Sci. (2020) 10:10 Page 4 of 26

to obtain a high spatial resolution hyperspectral image [8]. In addition, they consider
high spatial resolution hyperspectral image (HR-HSI) as a 3D tensor and redefine the
fusion problem as the estimation of a core tensor and dictionaries of the three modes [9].
Veganzones and Cohen proposed a Canonical Polyadic decomposition (CP) algorithm
based on hyperspectral images, which was used to solve the problem of blind source
signal separation [4]. They suggested to solve this problem as a low dimensional con-
strained tensor decomposition and applied kinds of fast decomposition of large nonneg-
ative tensors which allowed a major speed up in the computation of the decomposition
[10].

In the past few years, there have been many researches on the application of CP
decomposition in image. In [11, 12] used the CP decomposition into image compression
and classification. Marcella Astrid et al used the CP decomposition into Convolutional
Neural Networks (CNNSs) to solve the image classification tasks [13]. Bauckhage intro-
duced discriminant analysis to higher order data(i.e. color images) for classification [14].
For hyperspectral and multispectral images (i.e. multi-source heterogeneous data), kinds
of methods exploits the Bayesian framework [15-17] to fuse such images. Rodrigo and
Jeremy proposed a Bayesian framework to define flexible coupling models for joint ten-
sor decompositions of multiple datasets [18, 19]. They cast the problem of data fusion as
the analysis of latent variable. And the latent models between data are coupled through
subsets of their variables, where the coupling refers to the relationship between these
variables subset. That is, there is a coupling relationship between the factor matrix after
the tensor decomposition. In this paper, we hope to use the coupling relation between
images to solve the problem, improving the accuracy and interpretability of the latent
variables related to the other data set from the information of one data set through joint
tensor decomposition algorithm.

In application, data analysis from different data sources needs to be handled the heter-
ogeneous datasets (i.e. a matrix or a high-order tensor) [20, 21]. Recently, matrix factori-
zation and tensor-based factorization have been successfully applied to multi-frame data
restoration [22—25], recognition [26, 27], unmixing [28] and data fusion [18], etc. For the
data analysis of some coupled matrices and tensors, corresponding coupled matrix and
tensor factorization-optimization algorithm (i.e. CMTF-OPT) was proposed in [29]. The
numerical experiments showed that The CMTF algorithm had better performance than
CP algorithm in data recovery at a certain level of noise.

Similarly, the higher order coupled tensor decomposition problem was also studied in
[10]. Model showed better performance in coupled tensor decomposition in the experi-
ments. Rodrigo and Jérémy studied the coupling relationship between different data and
the data decomposition algorithms under coupling, which showed that the decomposi-
tion algorithm based on coupled data had better convergence and the calculation of the
algorithm took less time than alternating least squares (ALS) algorithm [18]. So using
the coupling relations between images is the necessary measure and work to decom-
pose images. Moreover the algorithms in [18, 29] are not used to the coupled images.
And S. Li and R. Dian do not make full use of the coupling relationship between images
and use this coupling relation to accelerate the operation of the algorithm and restore
the coupled image data [8]. Therefore, this paper proposes the coupled image data
Lu et al. Hum. Cent. Comput. Inf. Sci. (2020) 10:10 Page 5 of 26

decomposition algorithms based on the CMTF-OPT algorithm [29] and the coupled
tensor data decomposition algorithm [18].

Tensor and related notation

In the nineteenth century, Gauss and Riemann put forward the concept of tensors in the
study of differential geometry. In 1916, Einstein applied tensors to the study of the general
relativity, which made tensor analysis to be an important tool in continuum mechanics,
theoretical physics and other disciplines. In 2005, characteristic polynomial was proposed
for the first time in real symmetric tensor by Qi, and he presented the definition of the
eigenvalues [30].

In order to study the data fusion between the coupled images better and simplify the
presentation, this paper first introduces some of the following symbols and definitions.
For the general tensor, this paper uses the calligraphic letters to represent them e.g. 1’, the
matrix is denoted by capital letters e.g. X, and the scalar (or. vector) is represented by low-
ercase, e.g. x. The mode-n matricization of a tensor V € R*/2**4N is denoted by X(y),
which can reduce the dimension of the tensor. For a matrix A € R!*/, vectorization is to
expand the matrix by column, forming a JJ Column vector, that is

a)
vec(A)= | : | ER’. (1)

ay
Given two matrices A € R/** and B € R’*4, the Khatri-Rao product is denoted as
A © B, and the calculation results is a matrix of size JJ x K and defined by

AOB=[a4@b, a2 @b2. --- ax @bx), (2)

where ® is the Kronecker product.
Given two tensors A, B € R!*2**4n, the Hadamard product denoted as A « B, and

the calculation results is a matrix of size J x J, i.e.

a11b\ a\2b12 +--+ ayby
a21b2) d22b22 +++ daby

Ax B= , , (3)
ayiby, ajobj2 --- ayby

Given two tensors A,B €« R“*2**4N,the inner product is defined as the sum of the

product of its elements, i.e.

i tb

In
(A, B) = Ss” Ss” ute Ss” Nizig: in Viji2: in» (4)

=lip=1 = in=l

we usually use ’o’ to represent the outer product.
Let matrix A = (4jj)mxn € C’””””, the Frobenius norm is defined as
Lu et al. Hum. Cent. Comput. Inf. Sci. (2020) 10:10 Page 6 of 26

1
2

WA lle= {SS lagi? | - (5)

i=1 j=1

Tensor decomposition

In applications, the general tensor decomposition models can be divided into two cate-
gories, which are the Canonical Polyadic/PARAFAC decomposition (e.g. CP decomposi-
tion) and the Tucker decomposition model. The canonical decomposition was originally
proposed by Carroll and Chang [31] and PARAFAC (parallel factors) by Harshman [32]
separately. In 1966 Tucker [33] proposed the Tucker model. In particular, the CP decom-
position model is a special case of the Tucker decomposition model. At the time, models
were put forward to extract data characteristics from psychological tests. For the general
matrix model, we can extract the potential information of matrix data, such as hyper-
spectral data fusion and blind source separation, by means of singular value decomposi-
tion of matrix, nonnegative matrix decomposition and so on. Similar to the idea of low
rank approximation of matrix, researchers also want to extract latent information from
tensor model data by means of tensor decomposition model.

For a tensor ¥ € R1*/2*""*4Nv, the CP decomposition is expressed as

R
XS Tia ca 0---0a\) = fA; AP, A%,..., A], (6)
r=1

where R is a positive integer, A” is called the factor matrix, which is a combination of

rank one vector a\”, e.g.
A” = [a as,...,a], (7)

forn = 1,2,...,N,A€ Ral” € Rx, AM © Rinxk
Especially, for the three order tensor X € R/*/**, the CP decomposition is expressed

as

R
X& So dra Oo b, OCr = [A; A, B, C], (8)

r=1

wherer = 1,2,:--,R,A€ R¥,a,€ Rb, € Rc € RB.
Here, the column of factor matrix A, B and C is normalized to 1, and /, is the weight. If

the weight is assigned to the factor matrix, the CP decomposition can also be showed as
X= (A,B,C). (9)

Now we define D, composed of 4, is R x R x R order diagonal tensor, so the equation

can be transformed into

X = (A,B,C) - D,. (10)
Lu et al. Hum. Cent. Comput. Inf. Sci. (2020) 10:10 Page 7 of 26

Coupled image fusion
Coupled data fusion
Data fusion, also known as collective data analysis, has been a hot topic in different
fields. Data analysis from multiple sources has attracted considerable people in the Net-
flix Grand Prix. The goal is to accurately predict movie ratings. In order to get better
ratings, additional data sources supplement the user score, such as the label informa-
tion has been used. And the collective matrix factorization (CMF) proposed by Singh
and Gordon [34] is based on the correlation between data sets, and the coupling matrix
is factored simultaneously. Many researchers have paid their more attention to image
fusion technique based on pulse coupled neural network. Literature [35] described the
models and modified ones. As to the multi-focus image fusion problem, Veshki et al. uti-
lized the sparse representation using a coupled dictionary to address the focused and
blurred feature problem for higher quality [36]. In order to create spectral images with
high spectral and spatial resolution, Yuan Zhou et al [37] proposed a fusion algorithm by
combining linear spectral unmixing with the local low-rank property by extracting the
abundance and the endmembers of Hyperspectral images usually have high spectral and
low spatial resolution. Conversely, multispectral images.

For two matrices X « R‘*™”, Y € R/*4, the general CMF decomposition model is
established by minimizing the following objective function

f(U,V,W) =|| X — Uv! [2+ | Y- Uw! |2, (11)

where the matrices U € R!**, V ¢ R“** and W € R“** are the factor matrices, R is the
number of factors. In particular, because there exists a large number of high-order data,
the data fusion between the coupled tensor and the matrix is discussed below.

For a tensor X € R!*/** and a matrix Y ¢ R’*™, the general coupled tensor and
matrx decomposition model is established by modifying the above objective function

f (A,B,C, V) =|| X — (A,B,C) ||2 + || Y—AV™ 2, (12)

where the matrices A € R’**, B € R/** and C € R*** are factor matrices obtained by
CP decomposition of the tensor %.

Alternating Least Squares Algorithm for coupled matrix and tensor factorization
(CMTF-ALS) algorithm is proposed in [29]. The algorithm based on ALS is simple, small
and effective. However, the convergence of the algorithm based ALS is not good with the
missing data [38]. On the other hand, it is more robust to solve all CP factor matrices
with an optimized algorithm, and is more easily extended to the missing data set [39].
Therefore, for high order data sets, with the support of the algorithm proposed in [29],
this paper presents some coupled image decomposition algorithms, which describe the
coupling analysis of heterogeneous image data sets.

Coupled tensor decomposition algorithm

CIF-OPT algorithm

The main purpose of this paper is exploring data fusion between coupled images. In gen-
eral, images are stored in terms of tensor or matrix. Based on the CMTF optimization
(CMTF-OPT) algorithm in [29], a coupled images factorization-optimization(CIF-OPT)
Lu et al. Hum. Cent. Comput. Inf. Sci. (2020) 10:10 Page 8 of 26

algorithm is proposed. We firstly consider matrix image and N-order tensor image
with one mode in common, where tensor image is decomposed through CP model and
matrix image is decomposed through matrix decomposition.

Given a tensor image V € R!*2**4N and a matrix image Y € R!!*™ which have the
nth mode in common, where nv € {1,...,N}. Without loss of generality, we assume that
two images coupled in the third mode, and the common latent structure in these images
can be extracted by CIF-OPT algorithm. The objective function of the coupled analysis

between the two image datasets is as follow

fAM,A,..., ACV) =I ¥— [AAA] E+ LY - AVE le,
(13)

In order to solve the above optimization problem, we can calculate its gradient and solve
it by using any first order optimization algorithm of [40]. Next, this paper will discuss
the gradient of the objective function, the first item of the function (11) is written as

fi =| ¥ —[A%,A®,--- AC] Ile, (14)
the second item of the function (11) is recorded as
fo =| Y-A@V" |g. (15)

Let S = [A,A™,..., A“ Land the specific forms of the partial derivative of ff with

respect to A are as below

df, _j
sad = SH — XGA, (16)
where i = 1,2,...,N.The matrices A and V ¢ R“*¥are factor matrices obtained by

matrix decomposition of the matrix Y.
AW = AW) Q---O ACD © AG-D © AW. (17)

The specific forms of the partial derivative of f) with respect to AY and V can be com-

puted as
Of2 — f -YV+AC?V'V, for i=n, 18
AD 10, for ién. (18)
oe = —YTA® 4 VAO"A®, (19)

Combined with the above calculation results, we can calculate the objective function f

af _ afi , oh af a

dA® ~~ aA®M * 9A0’ AV AV

 

 

 

— -yTa®O 4 ya a, (20)

Finally, this paper calculates the gradient of the optimization function f, and its specific

form is a vector e.g.
Lu et al. Hum. Cent. Comput. Inf. Sci. (2020) 10:10 Page 9 of 26

of
vec (<n)

Vf = vee( sh) . (21)

vee( i)

where the length of the vector is P = R NL ,Un +M), which can be formed by vector-
izing the partial derivatives with respect to each factor matrix and forming a column
vector.

For some missing data sets, coupling analysis can still be carried out. The implemen-
tation of the algorithm can ignore missing data, and only analyze the known data ele-
ments to find the tensor or matrix model. And we applied it to the missing image and
restored the original image based on the proposed coupled image decomposition algo-
rithm through the another coupled image, which refer to [29].

Flexible coupling models

Rodrigo and Jérémy proposed the flexible coupling models based on the joint decompo-
sition of Bayesian estimation in [18]. They mainly present two general examples of cou-
pling priors such as joint Gaussian priors and non Gaussian conditional distributions.
For two tensors with noisy measurements )Y and y, Y is a second tensor (e.g. matrix)
which can be the SVD Y = UEV! +E, and y is a third order tensor which can be writ-
ten VY = (A,B,C) -+¢ via CP decomposition, where E and ¢ are the noisy array.

Let 6 = vec({U; ©; V"]) and Q = vec(A ; B; C). Here we assume the parameters 0
and @ are random and consider that the coupling between them is flexible, for instance,
we could have V = B, or V = WB for a known transformation matrix W. Under the
some simplifying hypotheses underlying the Bayesian approach, the Maximum a poste-

riori estimator (MAP) estimator is given as the minimizer of the following cost function

arg min (6,0) = —log p(Y | 6) — log p(Y | 6) — log p(6,@ ). (22)

where p(6,0 ) is the joint probability density function, p() | 0) and py | 0’) are the
conditional probabilities.

Given two CP models Y = (A; B; C) and y= (A: B; C) with dimensions J, J, K and
I,J, K and number of components (i.e. number of matrix columns) R and R respec-
tively. Considering the coupling occurs between matrices C and C. Rodrigo and Jérémy
illustrate this framework with three different examples: general joint Gaussian, hybrid
Gaussian and non Gaussian models for the parameters in [18]. This paper only discusses
the second example (e.g. the hybrid Gaussian model), and the other two cases are not
considered by us. If readers are interested, you can refer to the literature [18].

If there is no prior information about some parameters, the joint Gauss modeling is
not enough. On the contrary, we consider that these parameters are deterministic, while
other parameters are still random Gauss priors. We call this model a hybrid Gaussian
model. In fact, it only covers one scene which is factor matrix C is coupled to C another

by a transformation matrix, this coupled relation can be written by
Lu et al. Hum. Cent. Comput. Inf. Sci. (2020) 10:10 Page 10 of 26

HC=HC4YI, (23)

where H and H are transformation matrices, I is noisy of independent and identically
distributed (i.i.d.) Gaussian with matrix C, e.g. T ~ N(0, a2).

Under the assumption of hybrid Gaussian model [8], the MAP estimation is obtained
by minimizing the following cost function, that is, transforming function (22) into

/ 1] 1] / / / / 1] / /
1(0,0) = | Y-(A.B,© |lE + IY - (A,B,C) |g + | HC-HC (lz,
On On Oc
(24)

a. Hybrid gaussian modeling and alternating least squares (ALS) algorithm

To minimize the above objective functions, standard algorithm matched with convex
optimization can be used, Rodrigo and Jérémy proposed the modified version of the
alternating least squares (ALS) which is widely used and easy to implement. We will

refrain on detailing above algorithms.

Using the above algorithm to initialize the original tensor, the factor matrices are gen-
erated randomly and the tensor is formed by the tensor product operation between
the factor matrices. Finally, we can estimate the effectiveness of the algorithms by
comparing the mean square error between the factor matrices obtained by the above
coupling tensor decomposition algorithms of the noisy tensor and the original factor
matrices. If we apply the above algorithms to image, we need to initialize the original
image, that is, generating the original factor matrices. In this paper, we use the fol-

lowing algorithm (i.e. Algorithm 1) to generate coupled images.

In this paper, the ALS algorithm is used to initialize the image, we modify the objec-
tive function and algorithm in [18] as follows:

10,0) = SY (ABO) Dy B+
nN ; . 1 nN - (25)
— (A,B,C)-D, lz + || HC-HC Ile.

Cc
In order to apply ALS algorithm, it’s necessary to calculate its gradient with respect
to every factor matrix and set it to zero. For coupled factors C and C, this algorithm
only considers updating them simultaneously, which requires to solve the following

linear equations [8]:
/ 1] 1] / /
Mvec([C; C ]) = vec| | YayD; sz YayD | J, (26)
On On

where M = [Mj1,Mj2; Mz}, M22], D = (B© A)'(BOA),D =(B OA)! (B OA)
and
Lu et al. Hum. Cent. Comput. Inf. Sci. (2020) 10:10 Page 11 of 26

1 T 1 ar
Mi = >lr®HH+—D Ok,
O

 

Cc N

1] 'T / 1] 'T
M22 = —lr® HOH + =D @ Ik;

“] (27)
M2 = —~5lr ® H'H,

c

1 'T
M1 = ——zlr®H H.
O

c

Algorithm 1. Algorithm for generating coupled images

 

step1: For two images, reading the image data with the image reading
function(Im2double) in MATLAB to generate the tensor V, 1’.
step2: Applying CP decomposition algorithm (CP-ALS) to obtain Go,
bo, Co, Dr, Gg, bo, &, D,

step3: For simplification, absorbing the diagonal tensor D,. and D.. in

r*

Go and dip to obtain Ag and Ap. Using the coupling factor o, and Co
to initial factor matric Cy , e.g.

Co = op toe * (7%, R®);
step4: Using tensor product for Ao, bo, Co and Ao, bo, Co to obtain
new tensors. Then the noise is added to the tensors to have coupled
images J, y.

* This footnote is a zero mean white Gaussian matrix.
> This footnote is the rank in tensor decomposition.

 

b. Joint tensor decomposition of high dimensional coupled images

For the actual high-dimensional images, a high dimensional coupled image decom-
position algorithm is proposed. It is assumed that the coupling relationship between
images is as follow:

C=C4TI, (28)

where I is an i.i.d. Gaussian matrix with variance of each element o2 and C has col-
umns of given norm. If we disregard the coupling of the tensors, a common method
to retrieve the CP models is to compress the data arrays, decomposing the com-
pressed tensors, and then uncompress the obtained factors matrices, which is a more
computationally efficient way.
Lu et al. Hum. Cent. Comput. Inf. Sci. (2020) 10:10 Page 12 of 26

For a three-order tensor X € R!*/**,the tucker decomposition is expressed as

P Q R
VX STI gprtip 0 vg ow, = [G: U,V, WI, (29)

p=1 q=1 r=1

where U € R!*?,V € R’*2, and W € RX** are the factor matrices ,which are usu-
ally orthogonal. The positive integers P, Q, and R are the number of components (ie.,
columns) in the factor matrices U, V, and W, respectively. The tensor G € R?*@*4
is called the core tensor. Tucker decomposition is a high-order principal component
analysis, which represents a tensor as a core tensor multiplied by a matrix along each

mode.

If we assume two tensors are noiseless, i.e.

P Q R
XX Ss” Ss” S = Spqrigve wy = (U,V,W)G,
p=1 q=1 r=1
> OR (30)
Xe Ss” Ss” Soe qr VG Wr — (U,VLW')G',
p=1 q=1 r=1

In this section, we consider the decomposition algorithm of the coupled high dimen-
sional images. The high dimensional image is decomposed into the low dimensional
core tensor through the Tucker decomposition, and then decomposing the two core
tensors by CP decomposition to get the factor matrices, the compressed CP models
will reduce the cost and consumption of the calculation. There exists the relationship
below.

G © (Ac, Bes Cc), G_ © (A,B. C,), (31)

The factor matrix of the original tensor can be solved by matrix multiplication with

less computation.
(U,V, W)G = (UA;, VB,, WC,), A = UA;, B = VB,,C = WC, (32)

It is assumed that the coupling relationship between noiseless tensors in the com-

pressed space as
WC. =WC,+P (33)

However, if one tensor is noisy(ie. )/),there exists the similarity coupling in the com-

pressed dimension
C=C, +I, (34)

where [, is a matrix of same dimensions as C, and with Gaussian i.i.d. entries of vari-
ance. The hybrid objective function in the compressed space is modified to the fol-
lowing objective function, which can be solved using the ALS algorithm.
Lu et al. Hum. Cent. Comput. Inf. Sci. (2020) 10:10 Page 13 of 26

/ / / / 1 /
G —(A,,B,,C,) ||? + || Ce —C, lp

4] > 1
YT (6,0 ) — o2 | G —_ (Ac, Be, Co) lz +
nN (i
(35)

= |
On

For the factorization of some coupled images, we expect that the factor matrices
obtained by factorization algorithm can be shown by images. That means to mini-
mize the objective function under the constraint of nonnegative conditions. The MU
algorithm is usually used for nonnegative matrix factorization [10].

 

Algorithm 2. Joint tensor decomposition algorithm for the coupled images

 

step1: For two images, 7, Xx’.
step2: Applying tucker decomposition algorithm to obtain

PQ &R
XD DE DL Ipgrlp 0 Uq 0 Wr = (U,V, W)G,
p=l1q=1r=1
p’ Q’ R’ ) ) , , / roo
Yr S> S> dD IpqrUp © Ug 0 W, = (U,V ,W )G,
p=lq=lr=1

step3: Decomposing the two core tensors by CP decomposition to get the factor matrices
G = (Ac, Be, Ce), 9’ © (A,B, C,),
step4: Solving the hybrid objective function using the ALS algorithm.
T(0,0') = ge || G — (Ac, Be, Ce) |B +o IG — (A. Be, C.) lls +g || Ce — ©. IIB

 

Experiments and results

The main idea of this paper is applying the above coupled data fusion algorithms to deal
with the image. It is well known that the stored data values of images are ordinarily large.
If the tensor decomposition algorithm is applied directly to the coupled image data, the
error is a big problem, which makes us use the command Jm2double in Matlab to scale

the values to reduce the numerical error in program operation.

CIF-OPT algorithm

In this section, the coupled matrix tensor decomposition method is applied to multi-
spectral and panchromatic images. The original images which are the low spatial resolu-
tion multispectral image located in Beijing, China and the corresponding high spatial

resolution panchromatic image are as follows.

 

 

 

 

Fig. 5 The multispectral image of area |
X /
Lu et al. Hum. Cent. Comput. Inf. Sci. (2020) 10:10 Page 14 of 26

 

 

 

Fig.6 The panchromatic image of area |
Ne

 

 

 

Fig. 7 The multispectral image of area II
XX

 

 

 

 

Fig.8 The panchromatic image of area II

The experimental data are captured from Airborne Visible Infrared Imaging Spectrome-
TER (AVIRIS) in Beijing. The AVIRIS data can provide 224 spectral segments with a spatial
resolution of 20 m, covering a spectral range of 0.2 ~ 2.4 m, and its spectral resolution is
10 nm. The size of multispectral and panchromatic images of area I which are shown in
Figs. 5 and 6 are 300 x 300 x 3. and 300 x 300 pixels respectively. The size of multispectral
and panchromatic images of area II which are shown in Figs. 7 and 8 are 256 x 256 x 3
and 256 x 256 pixels respectively. The multispectral and panchromatic image data of area
I are read and initialized by MATLAB, and stored as tensor V € R300*39*3 and matrix
Y € R°00300. And the tensors of area II are generated in the same way.

According to the data generation of the CIF-OPT algorithm, the original data are sampled
from the multispectral and panchromatic images, and the initial factor matrix is obtained
by the ALS algorithm. Using the tensor product and the matrix multiplication to calculate
the noiseless initial tensor and matrix. Without losing generality, we set the coupled factor
matrix between tensor and matrix to C. In order to study the performance of the algorithm

better, experiments are carried out under different noise levels.
Lu et al. Hum. Cent. Comput. Inf. Sci. (2020) 10:10 Page 15 of 26

Adding noise to the obtained tensor ¥ € IR?°°*3°0*3 and the matrix Y € R?0*3°? after

initializing the images, e.g.

ILA, B, C]ll

Xx = A,B,C + N ————,
DN Wi

(36)
where NV ¢€ R900*300x3 is the stochastic Gaussian noise tensor, 7 is used to control the
noise level. Similarly, the Gaussian noise is added to the matrix Y, that is,
T
||AV~ ||

Y =AV! +7N ; (37)
IN|

 

where N € R°°°*? is the stochastic Gaussian noise matrix, 7 is used to control the noise
level.

In this experiment, four different noise levels are set, which are 0, 0.1, 0.25, and 0.35
respectively. As the terminating condition of the CIF-OPT algorithm, it needs to be
satisfied

_ e+ — Sk

Rs 10-8, (38)

Vf
where fis the objective function, in addition, the maximum number of function values
and iteration number is set to 10* and 10° respectively. In the process of experiment, the
termination condition of algorithm depends on the change of function value before and
after iteration.

The main purpose of this section is to apply the CIF-OPT algorithm to the coupled
multispectral and panchromatic images and the specific results are shown in Table 1.
From Table 1, it can be seen that the CIF-OPT algorithm has the similar fusion effect for
different images, which shows that the algorithm has a certain robustness. The fusion
effect will not change dramatically as the vary of image order and data elements. More-
over, the number of iterations does not alter greatly with the increase of order, which
proves the feasibility of decomposition for coupled images.

The change from coupled data to the coupled image decomposition algorithm shows
the iteration times and the maximum number of functions that CIF-OPT algorithm
needs to convergence is larger than CMTF-OPT algorithm. The results are inevitable,
because the coupled image needs to be initialized and converted to the coupled data
to achieve the algorithm when the coupled image is decomposed. Therefore, the con-
vergence of algorithm requires more iteration times. Accordingly, by observing the

Table 1 Comparison of decomposition algorithms on different areas

 

 

n Area Iter FuncEvals f

0.10 1 521 1073 0.0098158
2 942 2693 0.0097922

0.25 1 842 1702 0.0583453
2 302 632 0.0581043

0.35 1 442 924 0.1080817
2 422 883 0.1077908

 
Lu et al. Hum. Cent. Comput. Inf. Sci. (2020) 10:10 Page 16 of 26

 

0.12

—O— CMTF-OPT algorithm
—=— ACMTF algorithm

0.1

° °
oO oO
Oo eo

Target function value

o
oO
K

 

0.1 0.15 0.2 0.25 0.3 0.35
Different noise levels

 

 

Fig.9 Comparison of objective function values under different noise levels
X

 

      

 

0.2

1
—*— AICT algorithm
0.16
0.14
0.12
0.1

0.08

Target function value

0.06

0.04

0.02

 

1 1 1 1
0 0.1 0.2 0.3 0.4 0.5
Different noise levels

 

 

Fig. 10 Comparison of objective function values under different noise levels

experiment of adding noise to the coupled image, it can be seen that the proposed algo-
rithm can realize the decomposition of the coupled image, and the decomposition effect
is better than the CMTF-OPT algorithm under the certain noise level. Consequently, the
above results prove the feasibility of coupled image decomposition.

Another ACMTF algorithm for coupling image decomposition conducted the same
noise level experiment for region I, and compared with CMTF-OPT algorithm. The
results are shown in Fig. 9. It can be seen that ACMTF algorithm is superior to CMTF-
OPT algorithm in different noise levels. Therefore, based on the same parameters and
noise conditions, this paper conducts the same noise level experiment for another ACIF
algorithm of coupled image, and compares the target function value, iteration times,
error and other parameter results between the two algorithms. The fusion effect under
different noise levels is shown in Fig. 10. Experimental results show that CIF-OPT algo-
rithm is more effective than ACIF algorithm when the added noise is less than 0.2. This
is different from the data fusion effect of the two algorithms in the coupled data, and
with the increase of noise level, the performance of the two algorithms in the fusion
Lu et al. Hum. Cent. Comput. Inf. Sci. (2020) 10:10 Page 17 of 26

 

1600 : RSSNICIF-OPT algorithm
: [F=== JACIF algorithm

1400

1200

 
  
    

—
SQ
Oo
Oo

800

Iteration times

600

400

200

—LLLLLLLLLLLLL LLL LLL LLELLLELLLLLLLLLLLLL
LLL LLL LLL LLL LLL LLLL LLL

LLL LLL LLL LLL LLL LLLLLL EN
CMLLLLLLLLLL LLL LLL LLL LLLLLLLLLLL LDN
VALLLLLLLL LLL LL LLL LLL LLL
LLLLLSLLLLL LLL LLL LLL]

O LEISLILELILELLLLLLLLLLLEL
LLLP LLLL LLL

1 0.2 0.3 0.4
Different noise levels

o
on

Fig. 11 Comparison of iteration times in different regions
\ J

 

 

 

1.25

RSSNCIF-OPT algorithm
FEJAcIF algorithm

1 p ¥CMTF-OPT algorithm
EZZAACTMF algorithm

Error value
° o
mo o

o
S

0.2

PPP III IP eee ee eee eerie eebeeeieeeed
bbb bbbbbbe beds
CP PPP PPP PEP EE P EP EP Eo Eo ELE EEE ELL LLL LLL LLL)

eo EE PEEL PEPE LEA
Pree e eee eee eee eee eel
Oo oo Lhd

  

Ok Lk LL kh bdhd
RS SS

AAI

Pe ZZ
pss = «|
Oe eee eee
Loo]

BAAAA
SSS)
BON
Be

PSSA

& 6555508323344
On [See Re eee eee

— boca

0.2 0.3
Different noise levels

 

 

Fig. 12 Comparison of the error values in different noise levels
\ J

effect is almost the same, which shows that the improved image decomposition algo-
rithm does not have better advantages than CIF-OPT algorithm.

In this paper, the number of iterations required for algorithm convergence is compared
as shown in Fig. 11. It can be seen from Fig. 11 that the number of iterations required for
ACIF algorithm to converge is more than CIF-OPT algorithm in most cases, and the
running time from reaching convergence condition to algorithm termination is longer
when the algorithm is running. In order to comprehensively consider various factors,
this paper calculates the fusion errors of the four algorithms to comprehensively com-
pare the accuracy of the algorithm for data decomposition. See Fig. 12 for the specific
results.

Figure 12 shows that to some extent, the decomposition effect of the coupled image
is better than that of the coupled data, but the error of the decomposition algorithm
of the coupled data has a certain stability, and the error difference is lower than that of
the decomposition algorithm of the coupled image. For the two algorithms of coupled
image decomposition, when the noise level is lower than 0.25, the error value of the two
Lu et al. Hum. Cent. Comput. Inf. Sci. (2020) 10:10 Page 18 of 26

 

 

1500 T T 7 1 -

JArea |
BSS88] Area ll

220]

LEO OL?

1000 fF

ox

x

POO OOS

sd

IR

Iteration times
OOS

500 fF

satatatatatatatate

i
woh

rer

POCOOCCOLL

>

 

  

LeeeeeeS reece eS eee Sco ece oc oete ce eee oe ete eC G

   

 

0.2
Different noise levels

on

  

 

 

 

1.8

1.67

1.27

0.87

0.47

0.27

 

 

The difference of objective values in different regions

0 0.1 0.2 0.3 0.4 0.5 0.6 0.7
Different noise levels

 

 

Fig. 14 The coupled image Y”
X

algorithms is unstable, and the error value of Fig. 12 is small. Therefore, with the increase
of noise level, the error value of CIF-OPT algorithm is very close to that of ACIF algo-
rithm. So for the coupled image decomposition algorithm, CIF-OPT algorithm shows
better fusion effect at low noise level, and the error difference and the number of itera-
tions required for algorithm convergence are less.

The above algorithm is mainly based on the comparison of the result parameters of
region I. We compare the iterations of the algorithm and the difference between the
objective function values for two different regions based on CIF-OPT algorithm, and the
results are shown in Figs. 13 and 14. It can be seen that there is no obvious linear rela-
tionship between the number of iterations and the image size. Because the magnitude of
Fig. 14 is very small, the objective function values of the two regions are very close, that
is to say, the function optimal value of CIF-OPT algorithm will not change significantly
due to the difference of image size and pixel.

Based on the proposed CIF-OPT optimization algorithm, the multispectral images of
the missing data coupled with the panchromatic image are restored. That is, all the data
Lu et al. Hum. Cent. Comput. Inf. Sci. (2020) 10:10

 

 

0.015 —

Estimated value

-0.005 -

 

 

 

-0.01 ! ! ! !
0.01 -0.005 0 0.005 0.01 0.015 0.02

True value
Fig. 15 Data estimation with 25% missing data

 

 

 

0.06
0.04
0.02

0

-0.02

Estimated value

-0.04

-0.06

 

-0.08
-0.04 -0.02 0 0.02 0.04

True value
Fig. 16 Data estimation with 50% missing data

 

 

 

Fig. 17 The uncoupled original image

 

of the panchromatic image are known. The specific results of the algorithm are shown in
Figs. 15 and 16. Where the missing data of this experiment occurred in area II and the
recovered data is the transformed data, not the original image data. By observing the
data curve recovered by the CIF-OPT algorithm, it is known that the data recovery effect

Page 19 of 26
Lu et al. Hum. Cent. Comput. Inf. Sci. (2020) 10:10 Page 20 of 26

 

 

 

Fig. 18 The coupled image Y
XX

 

Doo
Doo
Doo
Doo

 

 

Fig. 19 The coupled image Y
XX

of the coupled image with 25% missing data is better than the effect of image with 50%
missing data. That is, the correlation between real value and estimated value is stronger
when the percentage of missing data is 25%, and the linear slope is closer to 1.

Straightforward hybrid Gaussian coupled decomposition
We consider the straightforward hybrid Gaussian coupling model C = C +I.
And we select the small images inside the red frame as the uncoupled original ten-
sors of Algorithm 1 in Fig. 17. The two CP models are generated by these images
with dimensions J =I =J =J =30, K=K =3and R=R =8, eg. Y,y. Then
through simplification and adding Gaussian noise and different coupling inten-
sity to J, y to obtain the new tensors J, Y' The original tensor images are shown
in Figs. 18 and 19. And the new tensor Y is almost noiseless o,, = 0.001, while y
has some noise o,, = 0.1. The coupled images were generated by Algorithm 1, and
decomposed by the ALS algorithm (i.e. Alg. 1) in [8]. Alg. 1 is applied to estimate the
CP models under 400 different noise and coupling realizations. We also evaluate the
total MSE on the C and C factors and the total MSE for an ALS algorithm. And the
total MSE on a factor, for example the total MSE on C with N, different noise reali-
zations is (1/N,) Se eh SNE (Ch — cr), where Cr is the factor estimated in
the n-th noise realization.

Due to the different coupling intensity of the image, we used the above algorithms

to decompose the image and get the mean square error of the factor matrix C for
Lu et al. Hum. Cent. Comput. Inf. Sci. (2020) 10:10 Page 21 of 26

 

 

 

( >)
107 F PET
—x— MSE on C - Flexible coupling
—C— MSE on C - Hard coupling
O- ©
1 \
10° £
lw S*o Q
a \ / x
= / zk
sz \ /
g * ea | a Uk
\ \ / KO DO

 

 

10° 107 104 10°
Coupling intensity 1/ om

 

 

Fig. 20 Total MSE for the factors Cand € with different algorithms
XX

different coupling intensity. We can see that the factor matrix is generally better
estimated by increasing the coupling density while applying a hard coupling(i.e.
C =C) in Fig. 20, since more information comes from the clean tensor through the
coupling. For a flexible coupling, instead of the mean square error decreases while
1/o¢ > 107. And in the interval 1/0, € [10; 10*], the flexible coupling model has bet-
ter estimation performance than the hard couplings. For 1/o, > 10*, the flexible
couplings works better than a hard coupling.

Compressed coupled decomposition

For high-dimensional images, the compressed data decomposition algorithm is
adopted in this paper. The selected images are the Lena noised images which are as
follows in Figs. 21 and 22. The tensors are generated by the following two images with
dimensions [=I =J =J = 256, K =K =3 and P =50, Q = 40. For the coupled

compression decomposition algorithm of large images, the number of decomposed

 

 

 

Fig. 21 The coupled image ¥
X

 

 

 

 

Fig. 22 The coupled image ””
X
Lu et al. Hum. Cent. Comput. Inf. Sci.

(2020) 10:10

 

 

 

 

 

 

 

XX S

components is not well defined. Therefore, under the condition of the same coupling
density (1/0, = 10%), we selected the best number of components based on the MSE
on factor matrix C. The experimental results are shown in Fig. 23, which showed that
the mean square error of factor matrix is the smallest when R = 3. So later in this
paper, R = 3 as the best number of components is used for other experiments. Fac-
tor matrices are generated by CP decomposition algorithm similarly to the previ-
ous example. The matrix C is coupled with factor matrix C with additive zero mean

Gaussian noise of variance o2. Where

 

 

a det(C — C) 39)
. det(y,R) |’
3 | T e T T T T T T T T T |

 

 

 

0 05 1 #15 2 25 3 35 4 45
Coupling intensity 10°

 

 

 

Fig. 24 Total MSE for the factors Cand C in the compressed space
X

 

 

 

 

0 05 1 #15 2 25 3 35 4 45
Coupling intensity x 10°

 

 

Fig. 25 Total MSE for the factors Cand C in the uncompressed space
NS

C >)
7 1
6.5 | —*- ALS ?
6 L —©-- coupled uncompressed ALS /
—+— coupled compressed ALS /
5.5 p ls
O 5+ h lL
c [ 4
a i is
wa 4 /! \\ //
= 3.57 fo oN OY
& 3 / / \ /
o 2.5) i! ¥
> /
2r /
* 1.5 + A - *
. Jf x \ “ eR L ae
TF LY ~ oF a— *
ost we _ oF
0 L
0 1 2 3 4 5 6 7 8 9 10
Components
Fig. 23 Decomposition performance of three algorithms under different ranks

Page 22 of 26
Lu et al. Hum. Cent. Comput. Inf. Sci. (2020) 10:10 Page 23 of 26

 

 

5 T T T T T T T

 

—*- ALS *
—©-- coupled uncompressed ALS
4 —*— coupled compressed ALS 1

MSE onC

 

 

 

 

 

 

 

 

4 6 8 10 12 14 16 18 20
SNR(Y)
Fig. 26 Reconstruction MSE of noisy factor C with different algorithms
. J
( \
0.0445
2 0.044
(= 0.0435
0.043
0.0425 ~,
0 1 2 3 4
Coupling intensity x 10°

 

 

Fig. 27 Computation time in the compressed space
XX S

and y is a zero mean white Gaussian matrix. The data array Y is almost noiseless
Oo, = 0.001, while Y’ has some noise o,, = 0.1.We compare the performance of the cou-
pled algorithm in the compressed space and the uncompressed space. Results for 20
iterations of the coupled algorithms are shown in Figs. 24 and 25. Compression was
computed with randomized SVD from [41]. And initializations were given by two cou-
pled uncompressed ALS with 1000 iterations, themselves initialized by decomposing
images.

As shown in the picture, the compression and ALS algorithms show similar perfor-
mance in the case of coupling, and the decomposition accuracy of the two algorithms
decreases with the increase of the coupling density.

Then we study the relationship between noise and algorithm estimation perfor-
mance. The SNR for ) is set to 22 dB, and it varies from 4 dB to 20 dB for Y' Where

Ri +02)
To2 ’

nN

/ R
SNR = 101 ———..
(Y ) 08107 Jo2 (40)

SNR(Y) = 10logi0
We compare the performance of the coupled algorithm in the compressed space and the
uncompressed space, as well as standard ALS in the uncompressed space. Note that in
Fig. 26, when the SNR < 18 dB, uncoupled ALS algorithm works better than the remain-
ing two algorithms. As the noise level increases, for SNR > 18 dB, the uncoupled ALS
algorithm decreases estimation performance in both coupled and compression cases.
Lu et al. Hum. Cent. Comput. Inf. Sci. (2020) 10:10 Page 24 of 26

 

0.325

 

0 05 1 15 2 25 3 35 4 45
Coupling intensity 10°

 

 

Fig. 28 Computation time in the uncompressed space
\ J

On the run time of the algorithm, Figs. 27 and 28 show the clear difference in
computation time between kinds of decomposition algorithms. We can see that the
compression decomposition algorithm obviously saves time and cost compared to
the uncompressed algorithm which may be rather slow. As the noise level increases,
uncoupled ALS decreases estimation performance in both coupled and compression
cases. In addition, hybrid coupling model is only verified in Gaussian condition to
show its effectiveness and we will do other experiments in the future to demonstrate

the versatility of the algorithm.

Conclusions

In this paper, we propose two algorithms for coupled image decomposition, which mainly
utilize the CMTF-OPT algorithm and the flexible Bayesian model in the coupled data
decomposition. For the proposed CIF-OPT algorithm, the corresponding experiments
show that the effect of the coupled image decomposition under the influence of differ-
ent noise is robust, and the fusion effect is better than the CMTF-OPT algorithm, which
shows that the coupled images decomposition algorithm is feasible. In addition, because
the expression of a phenomenon can be different from all kinds of data sets, the link set of
data decomposition should be flexible. Therefore, this paper presents the modified flexible
Bayesian model. From the experiments of it, we can easily see that the factor matrix could
be estimated better by increasing the coupling density. And from the aspect of algorithm,
the flexible coupling model has better estimation performance than the hard coupling mod-
els. Moreover, a coupled data compression scheme is derived from tensor images of large
data sets. As the noise level increases, uncoupled ALS decreases estimation performance
in both coupled and compression cases. On the run time of the algorithm, the compression
decomposition algorithm obviously saves time and cost compared to the uncompressed
algorithm. In fact, the image matrix is nonnegative. Therefore, when considering the cou-
pled image decomposition algorithm, adding non negative constraints is our work in the
future.

Acknowledgements

The authors would like to thank the editors and anonymous reviewers. This work was partially supported by the National
Natural Science Foundation of China under No. 51877144. This work was supported in part by MOST under contracts
109-2634-F-259-001— through Pervasive Artificial Intelligence Research (PAIR) Labs, Taiwan R.O.C.

Authors’ contributions
LL, ZT and JC contributed in the innovation ideas and theoretical analysis. XR and KHY helped to perform the analysis
with constructive discussions and carry out experiments. All authors read and approved the final manuscript.

Funding
This work was partially supported by the National Natural Science Foundation of China under No. 51877144.

Availability of data and materials
Not applicable.
Lu et al. Hum. Cent. Comput. Inf. Sci. (2020) 10:10 Page 25 of 26

Competing interests
The authors declare that they have no competing interests.

Author details

School of Mathematics, Tianjin University, Tianjin 300350, China. 2 College of Intelligence and Computing, Tianjin Uni-
versity, Tianjin 300350, China. > Department of Information Management, National Dong Hwa University, Hualien 97047,
Taiwan. * Edinburgh Napier University, School of Computing, Merchiston Campus, Edinburgh EH10 SDT, Scotland, UK.

? GIPSA lab, Grenoble-INP. 38402 Saint Martin d’Heres Cedex, France.

 

Received: 17 July 2019 Accepted: 4 February 2020
Published online: 27 March 2020

References

1. Sui J, AdaliT, Yu Q, Calhoun V (2012) A review of multivariate methods for multimodal fusion of brain imaging data. J
Neurosci Methods 204:68-81

2. Wang D, Zhou J, He K, Liu C (2009) Using tucker decomposition to compress color images. Int Congress Image
Signal Process 1—9:1408-1412

3. ZhouPLuC, Lin Z, Zhang C (2016) Tensor factorization for low-rank tensor completion. IEEE Trans Image Process
27(3):1152-1163

4. Veganzones MA, Cohen JE, Farias RC, Chanussot J, Comon P (2016) Nonnegative tensor CP decomposition of hyper-
spectral data. IEEE Trans Geosci Remote Sens 54:2577-2588

5. Zhang K,Wang M, Yang SY, Jiao LC (2018) Spatial-spectral-graph-regularized low-rank tensor decomposition for
multispectral and hyperspectral image fusion. IEEE J Sel Top Appl Earth Observ Remote Sens 11(4):1030-1040

6. Li H, LiWB, Han GN, Liu F (2018) Coupled tensor decomposition for hyperspectral pansharpening. IEEE Access
6:34206-34213

7. Lin CH, Fei M, Chi CY, Hsieh CH (2018) A convex optimization-based coupled nonnegative matrix factorization
algorithm for hyperspectral and multispectral data fusion. IEEE Trans Geosci Remote Sens 56(3):1652-1667

8. LIS, Dian R, Fang L, Bioucas-Dias JM (2018) Fusing hyperspectral and multispectral images via coupled sparse tensor
factorization. IEEE Trans Image Process 27:4118-4130

9. Li ST, Dian RW, Fang LY et al (2018) Fusing hyperspectral and multispectral images via coupled sparse tensor factori-
zation. IEEE Trans Image Process 27(8):4118-4130

10. Cohen J, Farias RC, Comon P (2014) Fast decomposition of large nonnegative tensors. IEEE Signal Proc Lett
22:862-866

11. Shashua A, Levin A (2001) Linear image coding for regression and classification using the tensor-rank principle.
Comput Vis Pattern Recognit 1:42-49

12. Aidini A, Tsagkatakis G, Tsakalides P (2019) Compression of high-dimensional multispectral image time series using
tensor decomposition learning. in: IEEE EUSIPCOEUSIPCO

13. Astrid M, Lee SI, Seo BU (2018) Rank selection of Co-decomposed convolutional layers with variational Bayesian
matrix factorization. In: IEEE ICACTICACT

14. Bauckhage C (2007) Robust tensor classifiers for color object recognition. Int Conf Image Anal Recognit
4633:352-363

15. Hardie RC, Eismann MT, Wilson GL (2004) MAP estimation for hyperspectral image resolution enhancement using
an auxiliary sensor. IEEE Trans Image Process 13:1174-1184

16. Wei Q, Dobigeon N, Tourneret JY (2016) Fast fusion of multi-band images based on solving a Sylvester equation.
IEEE Trans Image Process 23:1632-1636

17. Akhtar N, Shafait F, Mian A (2015) Bayesian sparse representation for hyperspectral image super resolution. Proc IEEE
Conf Comput Vis Pattern Recognit 12:3631-3640

18. Farias RC, Cohen JE, Comon P (2016) Exploring multimodal data fusion through joint decompositions with flexible
couplings. IEEE Trans Signal Process 64:4830-4844

19. Huang YG, Cao LB, Zhang J, Pan L, Liu YY (2018) Exploring feature coupling and model coupling for image source
identification. IEEE Trans Inf Forensics Secur 13(12):3108-3121

20. Banerjee A, Basu S, Merugu S (2006) Multi-way clustering on relation graphs. Siam Int Conf Data Mining
127:145-157

21. Yu FW,Wu XX, Chen JL, Duan LX (2019) Exploiting images for video recognition: heterogeneous feature augmenta-
tion via symmetric adversarial learning. IEEE Trans Image Process 28(1 1):5308-5321

22. Jiang TX, Huang TZ, Zhao XL, Deng LJ, Wang Y (2017) A novel tensor-based video rain streaks removal approach via
utilizing discriminatively intrinsic priors. In: Proc. IEEE Conf. Comput. Vis. Pattern Recognit. pp 4057-4066

23. Zhang K, Wang M, Yang S, Jiao L (2018) Spectral-graph-regularized low-rank tensor decomposition for multispectral
and hyperspectral image fusion. IEEE J Sel Topics App! Earth Observ Remote Sens 11:1030-1040

24. Jiang TX, Huang TZ, Zhao XL, Ji TY, Deng LJ (2018) Matrix factorization for low-rank tensor completion using Frame-
let prior. Inf Sci 436-437:403-417

25. Bengua JA, Phien HN, Tuan HD, Do MN (2017) Efficient tensor completion for color image and video recovery: low-
rank tensor train. IEEE Trans Image Process 26:2466-2479

26. Jia C, Shao M, Fu Y (2017) Sparse canonical temporal alignment with deep tensor decomposition for action recogni-
tion. IEEE Trans Image Process 26:738-750

27. Jia C, Fu Y (2016) Low-rank tensor subspace learning for RGB-D action recognition. IEEE Trans Image Process
25:4641-4652

28. Qian Y, Xiong F, Zeng S, Zhou J, Tang YY (2017) Matrix-vector non-negative tensor factorization for blind unmixing of
hyperspectral imagery. IEEE Trans Geosci Remote Sens 55:1776-1792

 

 
Lu et al. Hum. Cent. Comput. Inf. Sci. (2020) 10:10 Page 26 of 26

29.

30.
31.

32.

33.

34.

35.

36.

37,

38.

39.

 

Acar E, Kolda TG, Dunlavy DM (2011) All-at-once optimization for coupled matrix and tensor factorizations. Comput-
ing Research Repository-CORR

Qi L (2005) Eigenvalues of a real supersymmetric tensor. J Symb Comput 40:1302-1324

Carroll JD, Chang JJ (1970) Analysis of individual differences in multidimensional scaling via an n-way generalization
of "Eckart-Young” decomposition. Psychometrika 35:283-319

Harshman RA (1970) Foundations of the PARAFAC procedure: Models and conditions for an “explanatory” multi-
model factor analysis. In: Ucla Working Papers in Phonetics 16:1-84

Tucher LR (1963) Implications of factor analysis of three-way matrices for measurement of change. University of
Wisconsin Press, Madison, pp 122-137

Singh AP, Kumar G, Gupta R (2008) Relational learning via collective matrix factorization. In: ACM SIGKDD interna-
tional conference on knowledge discovery and data mining. pp 650-658

Wang Z, Wang S, Zhu Y (2016) Review of image fusion based on pulse-coupled neural network. Arch Comput
Methods Eng 23(4):659-671

Veshki FG, Vorobyov SA (2017) Multi-focus image fusion using sparse representation and coupled dictionary learn-
ing. 1(1):1-25

Yuan Z, Feng LY, Hou CP, Kung SY (2017) Hyperspectral and multispectral image fusion based on local low rank and
coupled spectral unmixing. IEEE Trans Geosci Remote Sens 55(10):5997-6009

Buchanan AM, Fitzgibbon AW (2005) Damped newton algorithms for matrix factorization with missing data. In: IEEE
computer society conference on computer vision and pattern recognition. pp 316-322

Tomasi G, Bro R (2006) A comparison of algorithms for fitting the PARAFAC model. Comput Stat Data Anal
50:1700-1734

Ho C, Basdogan C, Srinivasan M. Numerical optimization: [M]. 2006.

11. Halko N, Martinsson PG, Tropp J (2011) Finding structure with randomness: probabilistic algorithms for constructing

approximate matrix decompositions. SIAM Rev 53(2):217-288

Publisher’s Note

Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.

 

Submit your manuscript to a SpringerOpen”®
journal and benefit from:

> Convenient online submission

> Rigorous peer review

> Open access: articles freely available online
> High visibility within the field

> Retaining the copyright to your article

 

Submit your next manuscript at > springeropen.com

 

 

 
