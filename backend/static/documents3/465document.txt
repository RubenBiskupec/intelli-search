Mara et al. Journal of Cloud Computing: Advances, Systems Jou rnal of Cloud Computing:
and Applications (2020) 9:47 Ad Syst d Applicati
https://doi.org/10.1186/s13677-020-00188-5 VANCES, sYStEMS and APPHCatlons

 

Research Open Access

CRUPA: collusion resistant user ®
revocable public auditing of shared datain ~~
cloud

Geeta C. Mara!”, Usharani Rathod?, Shreyas Raju R. G.2, Raghavendra S.2, Rajkumar Buyya?, Venugopal K. R47,
S.S. lyengar? and L. M. Patnaik®

 

Abstract

Cloud repository is one of the most important services afforded by Cloud Computing where information is
preserved, maintained, archived in distant servers and made available to the users over the Internet. Provided with the
cloud repository facilities, customers can organize themselves as a cluster and distribute information with one
another. In order to allow public integrity auditing on the information stored in semi-trusted cloud server, customers
compute the signatures for every chunk of the shared information. When a malicious client is repudiated from the
group, the chunks that were outsourced to the cloud server by this renounced customer need to be verified and
re-signed by the customer present in the cluster (i.e., the straightforward approach) which results in huge
transmission and reckoning cost for the customer. In order to minimize the burden of customers present in the
cluster, in the existing scheme Panda, the semi-trusted Cloud Service Provider (CSP) is allowed to compute the

Re — sign key. Further, the CSP audits and re-signs the revoked customer chunks by utilizing the Re — sign key. So, it is
easy for the CSP by colluding with the revoked customer to find the secret keys of the existing customer. We
introduce a novel Collusion Resistant User Revocable Public Auditing of Shared Data in Cloud (CRUPA) by making use
of the concept of regression technique. In order to secure the secret keys of the existing customers from the CSP, we
have allowed the information proprietor to compute the Re — sign key using the regression technique. Whenever the
information proprietor revokes the customer from the cluster, the information proprietor computes the Re — sign key
using the regression technique and sends to the CSP. Further, the CSP audits and re-signs the revoked customer
chunks using the Re — sign key. The Re — sign key computed by the information proprietor using regression method is
highly secure and the malicious CSP cannot find the private information of the customers in the cluster. Besides, our
mechanism achieves significant improvement in the computation cost of the Re — sign key by information proprietor.
Further, the proposed scheme is collusion resistant, supports effective and secure customer repudiation,
multi-information proprietor batch auditing and is scalable.

Keywords: Cloud computing, User revocation, Public auditing, Proxy re-signatures, Multi-information proprietor
batch auditing, Regression method

 

 

*Correspondence: geetacmara@gmail.com

'Department of Computer Science and Engineering, University Visvesvaraya
College of Engineering, Bangalore University, Bengaluru-560001, Karnataka,
India

Full list of author information is available at the end of the article

© The Author(s). 2020 Open Access This article is licensed under a Creative Commons Attribution 4.0 International License, which
G) Springer O pen permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit
— to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The
images or other third party material in this article are included in the article’s Creative Commons licence, unless indicated
otherwise in a credit line to the material. If material is not included in the article’s Creative Commons licence and your intended
use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the
copyright holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0/.
Mara et al. Journal of Cloud Computing: Advances, Systems and Applications

Introduction

Cloud repository is one of the significant services pro-
vided by cloud computing [19]. It empowers the informa-
tion possessor to deploy their information to the cloud
server. Many distributed computing service suppliers have
been developed, such as Google App Engine, Dropbox
that satisfies the requirement for data repository and high
performance computation. With information repository
and sharing services, customers are permitted to update
and distribute the information saved in the distributed
server in any place and at any moment [7]. Yet, security
of the information has become a severe issue and one
of the worrying factors of the information security is the
integrity of the deployed information in the distributed
server. Even though the cloud repository suppliers accom-
plish a trustworthy and secure repository maintenance to
the customers, the honesty of deployed information might
be adulterated due to the negligence of people or disrup-
tion of the hardware/software [25]. Apart from inherent
hazards, external attacker can further impair the integrity
of the deployed information in the cloud. Hence, public
integrity verification is required to assure the customers
that the deployed information is precisely deployed in
the cloud. Presently, optical networks [34, 35] have been
deployed all over the globe for efficient information com-
munication.

Numerous mechanisms have been suggested based on
miscellaneous procedures [17, 42, 43] that assure the
integrity of deployed information in an untrustable cloud.
In all these mechanisms, signatures on every chunk of
shared information are estimated by the Information pro-
prietor (JP) and he deploys the information and the equiv-
alent signatures to the distributed server, that permits the
IP and public examiner to examine the integrity of the
information in the distributed server without fetching the
complete deployed information. Still, a large number of
the earlier mechanisms deal with the case of individual
information, that implies the JP is the only modifier, who
possesses the private key and can modify the information.
Researchers are motivated to address the issue in cross
domain areas such as Wireless Sensor Networks [28] and
the Internet of Things [22].

Wang et al. [38] introduced Oruta, a public examin-
ing convention for distributed information in the cloud
employing ring signatures. The scheme conserves identity
privacy of the customers in the cluster from the pub-
lic verifier at the time of verification. The limitation is
that the mechanism does not bolster traceability and data
freshness. Wang et al. [37] introduced Knox, based on
cluster signatures that can conserve the identity secrecy
of customers from the public verifier. The limitation of
the Knox scheme is that the customers need to distribute
their private value with the public verifier and customer
repudiation is expensive.

(2020) 9:47 Page 2 of 18

Wang et al. [39] proposed public verifying mechanism
to bolster effective customer repudiation utilizing inter-
mediary re-signatures, that acknowledge the distributed
server to transform the signatures estimated by the repu-
diated customer into signatures of the current customer
within the cluster. The cloud knows in advance the re-
signing keys of any two customers in the cluster. This pro-
cedure leads to the following two severe security issues.
Initially, a mischievous CSP may immediately transform
signatures between two customers utilizing the re-signing
keys. Further, conspiracy amidst the cloud and the repu-
diated customers might disclose the private keys of all the
current customers in the cluster. The reckoning cost of
verification increases with the size of the cluster.

Considering these two security problems of [39], we
propose a novel Collusion Resistant User Revocable Pub-
lic Auditing of Shared Data (CRUPA) mechanism. By
using regression tools, we permit the /P to estimate the
Re — sign key and transmit to the distributed server. As the
Re — sign key is computed by the JP, it is not possible for
the malicious cloud to trace out the secret parameters of
the existing customers.

Motivation: In the exisiting scheme [39], the semi-
trusted CSP is allowed to figure out the Re — sign key
by employing the secret keys of the existing customers
in the cluster. Since the CSP knows the secret keys of
the customers, it is very easy for the CSP to know and
retrieve the sensitive data cached in the server. More-
over, when the revoked customer colludes with the CSP,
they can further hack or misuse the information cached
in the distributed server. Hence the existing scheme [39]
is not secure and is not collusion resistant. Motivated to
secure the Re — sign key from the semi-trusted CSP, in the
proposed scheme, after revoking the malicious customer
from the cluster the JP who is the head or manager of
the respective cluster is allowed to compute the Re — sign
key using regression method such that the key computed
is highly secure. Then, the JP transmits the Re — sign
key to the CSP and allows him to audit the revoked cus-
tomer chunks and re-signs the chunks using the Re — sign
key. Since the semi-trusted CSP receives the Re — sign
key by the JP, it is not possible for the CSP to learn
the private keys of the customers present in the clus-
ter and the information stored in the server is highly
secure. We have enhanced the existing system to multi-
ple clusters with the respective information proprietors’
scenario.

Contributions: In this paper we introduce Collusion
Resistant User Revocable Public Auditing (CRUPA) of
Shared Data scheme that reduces the computation cost
of the Re — sign key using regression method by the JP
that is highly secure and also supports multiple clusters
with their respective JP. Specifically, our contributions are
outlined as follows:
Mara et al. Journal of Cloud Computing: Advances, Systems and Applications

(i) Secure Re — sign key generation: The IP, manager of
the respective clusters is allowed to compute the
Re — sign key securely using the regression method.

(ii) Effective and secure customer repudiation: Once a
malicious customer is repudiated from the cluster by
the JP, the chunks signed by the repudiated customer
can be effectively re-signed. On behalf of the existing
customers, the CSP efficiently and securely audits
and re-signs the repudiated customer chunks using
the Re — sign key sent by the JP and the repudiated
customer can no longer estimate the valid signatures
on the shared information.

(iii) Privacy preserving and collusion resistant: The CSP
(possess the Re — sign key sent by the JP), by
colluding with the revoked customer, cannot find the
secret keys of the existing customers from the
Re — sign key. Thus, the scheme preserves the
privacy of the customers and is collusion resistant.

(iv) Public auditing: The Third Party Auditor (TPA)
audits the requests sent by every JP of all the clusters
individually called as individual auditing. The TPA
also performs multi-information proprietor batch
auditing for the requests of all [Ps simultaneously.

(v) Scalability: Cloud information is effectively
distributed among the existing customers of multiple
clusters.

Organisation: The rest of the paper is arranged as
follows: Related works and Background work are dis-
cussed in “Related works” section. Several preliminaries
are introduced in “Preliminaries” section. Problem defini-
tion, System model are discussed in “Problem statement”
section. Mathematical Model using Regression Method,
Security Analysis and Adversary Model are explained
in “Mathematical model” section. Scheme details of
Collusion Resistant User Revocable Public Auditing of
Shared Data in Cloud (CRUPA) and the construction
of Homomorphic Authenticable Proxy Re-signature
Scheme (HAPS) using Regression Method are discussed
in “The algorithm” section. In “Performance evaluation”
section, Performance Evaluation results are analysed and
“Conclusions” section contains the Conclusions.

Related works

Provable Data Possession [1], authorizes the auditor to
publicly validate the integrity of information without
fetching the whole information. Improving their earlier
work for dynamic operations on data, Ateniese et al. [2]
constructed another PDP scheme using symmetric keys.
This scheme does not support public verification. Erway
et al. [11] suggested dynamic verifiable information pos-
session mechanism by using authorized lexicons. Zhu et
al. [47] introduced a public verifying scheme that uses the
chunk format to reduce the depository of signatures. The

(2020) 9:47 Page 3 of 18

mechanism uses Index Hash Table (JHT) that empowers
customers to perform effective operations. Tian et al. [32]
introduced a non-repudiation dynamic verifiable infor-
mation possession scheme. The scheme supports identity
authentication and non-repudiation. The disadvantage of
the mechanism is that it does not support batch audit-
ing. Wu et al. [40] present a Non-Repudiable Provable
Data Possession with Designated Verifier (DV — NRPDP)
scheme. The scheme addresses the non-renunciation
issue and resolves the controversy among the clients and
distributed repository servers. The disadvantage of the
scheme is that it has high reckoning cost of examining a
proof.

Raghavendra et al. [23] have presented a reliable multi-
proprietor information distribution for effective associa-
tion in the cloud. The advantage of the scheme is that
the repository space is efficiently utilized and has reduced
the time to query documents from the cloud. The draw-
back is that the convention does not bolster multi-media
documents. Tian et al. [30] introduced a public veri-
fying mechanism for secure cloud repository utilizing
Dynamic Hash Table (DHT). The proposed mechanism
supports dynamic data verification, privacy preservation
and batch verification. Dynamic Hash Table (DHT) is
used to archive the details of the data for verification and
as a result it accomplishes prompt verification and effec-
tive data restoration. The limitation is that the scheme
does not support different types of cloud data.

Luo et al. [20] have presented a public validation con-
vention for the integrity of collaborative information with
pervasive and conspiracy resistant customer repudiation.
Polynomial based validation marks are generated that
support secure and compelling public validation. The
cumulative overhead of the examining scheme is compar-
atively small. Tian et al. [31] have introduced an extensive
public verification mechanism for distributed informa-
tion in cloud. The mechanism supports the customer’s
identity privacy, information privacy and identity tracka-
bility. The drawback of the mechanism is that it has larger
communication cost.

Dong et al. [10] have achieved data confidentiality
against the semi-trusted cloud. They designed a pro-
tected, adequate and flexible data co-ordinated scheme.
The mechanism does not accomplish information con-
sistency. Yaun and Yu [46] have designed an auditing
mechanism for distributed data sharing utilities illus-
trated by multi-user alterations, public auditing, adequate
user repudiation and pragmatic reckoning auditing per-
formance. The mechanism overcomes customer imper-
sonation assault. The limitation is that it does not realize
dependability and error detection .

Geeta et al. [13] have performed extensive review on
the latest methods in information auditing and secu-
rity in cloud computing. Shen et al. [26] have suggested
Mara et al. Journal of Cloud Computing: Advances, Systems and Applications

an effective public verification convention. The proposed
convention supports batch verification, blockless verifi-
cation and lazy update. The limitation of the scheme is
that the transmission cost is more in verification phase.
Zhu et al. [48] have presented a secure anti-conspiracy
information sharing mechanism for dynamic clusters in
the cloud. The repudiated customer cannot fetch the orig-
inal document though he conspires with the CSP. The
proposed mechanism bolsters guaranteed key allocation,
fine-grained access control and safe customer repudia-
tion. Li et al. [18] have presented a security model and
a formal definition for Ciphertext Policy-Attribute-Based
Encryption (CP — ABE) scheme with effective attribute
repudiation. The proposed mechanism is secure against
conspiracy attack launched by the prevailing customers
and the renunciated customers. The limitation of the
scheme is that it takes more time in the Setup phase.

Yang et al. [44] have designed a framework for public
auditing for shared information in distributed repository
supporting identity secrecy and trackability. The mech-
anism achieves data privacy by utilizing blind signature
method. The limitation is that the mechanism incurs lit-
tle overhead to accomplish the identity trackability. Hall
et al. [14] have presented a protocol which achieves the
cryptographic definition of security, when the only out-
put are the regression coefficient estimates. The protocol
guarantees the confidentiality of the input information.
Homomorphic encryption is utilized in constructing the
protocol for regression analysis. Chen et al. [8] intro-
duced two conventions that can authorize protected and
effective outsourcing of linear regression problems to
the cloud. The conventions are efficient and also pre-
serves the client’s data confidentiality. The drawback of
the mechanism is that it does not support to identify prac-
tical problems related to computation outsourcing to the
cloud.

Verifiable data proprietorship mechanism [29] provides
trustworthiness and individuality in an active, multi-user
framework. By exploiting trustworthy hardware on the
server, forking and rollback intrusions are discarded. The
proposed design does not consider load stabilizing over
various servers. Venugopal et al. [36] have proposed a
number of soft computing techniques for security require-
ments. Jin et al. [16] have introduced the integrity auditing
scheme that supports public verifiability, efficient data
dynamics and fair disputes arbitration. Fair arbitration
protocols are designed so that any possible dispute can be
fairly settled. The scheme incurs reasonable overhead of
data dynamics and dispute arbitration.

Dong et al. [9] have suggested a confidentiality preserv-
ing and secure data collaboration procedure in distributed
computing. The convention does not leak any features of
the clients to the cloud. The procedure is adequate and
has low overhead. The mechanism is not executed on

(2020) 9:47 Page 4 of 18

real cloud platform. A comprehensive analysis of miscel-
laneous data trustworthiness procedures for distributed
computing has been carried out by Garg and Bawa [12].
They have examined that the maximum of the prevailing
procedures concentrate on integrity checks to distinctive
data depository strategy. Simulations are carried out on
C++ platform [33].

Raghavendra et al. [24] have proposed an effective token
creation method, that enhances immune and productive
label construction phase. A systematic composition is
refined to encode the ordered keywords for secure label
construction. The method reduces the cost of the infor-
mation proprietor. Xu et al. [41] have introduced multi-
authorization proxy re-encoding method. The scheme
greatly reduces the computation cost of the creation of
key constituents and the termination of the customers
retrieving authority. The algorithm needs prolonged com-
putation duration Setup phase.

Hwang et al. [15] have outlined a group signature mech-
anism supporting the manageable connectivity. The con-
vention supports reliability properties for e.g., confiden-
tiality and connectivity. Privacy is not preserved by global
linkability. Yu et al. [45] have suggested a distributed data
integrity auditing with identity privacy-conserving con-
vention for mobile cloud repository. The scheme affords
anonymity to Third Party Auditor (TPA) and reliable
label-updation. The mechanism incurs minimum reckon-
ing, transmission and repository overhead.

Shen et al. [27] outlined a distant information integrity
auditing mechanism that realizes information distribution
with sensitive information hiding. Authors have utilized a
sanitizer that is used to sanitize the sensitive information
of the document. The mechanism supports information
data sharing with sensitive information hiding. The limi-
tation of the mechanism is that the computation cost of
TPA in proof verification is more.

Table 1 shows the comparison of recent existing
schemes for Public Honesty Verification with Group Cus-
tomer Repudiation.

Background work

Wang et al. [39], have suggested public auditing scheme
for the integrity of shared information with adept cus-
tomer repudiation. By exploiting the concept of agent
re-signatures, the cloud is permitted to re-sign revoked
customer chunks on behalf of current customers at the
time of customer repudiation, to prevent current cus-
tomers to retrieve and re-sign chunks by themselves.
Further, the public examiner examines the integrity of
the distributed information without retrieving the entire
information from the cloud, though CSP re-signs few
chunks of distributed information. The scheme also sup-
ports batch auditing. The limitation of the scheme is that
it is does not preserve the privacy of the customers in
Mara et al. Journal of Cloud Computing: Advances, Systems and Applications

(2020) 9:47

Table 1 Comparison of mechanisms for Public Honesty Verification with group customer repudiation

Page 5 of 18

 

Authors

Concept

Performance

Advantages

Disadvantages

 

Tian et al. 2019 [31]

Shen et al. 2019 [27]

Jin et al. 2018 [16]

Tian et al. 2017 [30]

Xu et al. 2016 [41]

Wang et al. 2015 [39]

CRUPA

Public auditing for distributed
cloud data with adept and reliable
cluster management

Individuality-based integrity
auditing and information sharing
with sensitive information hiding
for reliable cloud repository.

Dynamic and public auditing with
fair negotiation for cloud
information.

Public auditing mechanism for
protected cloud repository based
on Dynamic Hash Table (DHT).

Multi-authority inter-mediary
re-encryption based on CPABE for
distributed repository system.

Public auditing for shared
information with adept user
renunciation.

Collusion Resistant User Revocable
Public Auditing of Shared Data in
Cloud(CRUPA)

The computational cost is
significantly reduced in the
verification phase.

The computation costs of TPA and
CSP is higher with the increase of
challenged blocks.

The scheme introduces additional
overhead of data dynamics

The scheme has lower costs of
storage, Communication and
computation.

MPRE — CPABE reduces the
estimation cost of the creation of
key components.

No communication overhead to
existing customers during
customer repudiation, cloud has
reduced computation cost.

Significant improvement in
computation cost of Re — sign key
by information proprietor, low

Supports individuality
privacy, data privacy and
individuality trackability.

Supports information
sharing with sensitive
information hiding.

Supports public
verifiability, efficient data
dynamics and fair disputes
arbitration.

Achieves higher updating
efficiency and secure
auditing.

Small reckoning cost of
key allocation.

Secure customer
repudiation, public
auditing.

Supports multi-owner
batch auditing, efficient
customer revocation.

Low
communication
cost.

Computation
cost of TPA in
proof verification
is high.

Reasonable
overhead of data
dynamics and
dispute
arbitration.

Does not support
various types of
cloud data.

Additional
computational
period in Setup
phase.

Collusion of
repudiated
customer and
cloud.

Average auditing
time cost is more.

processing time in Setup phase.

 

the cluster and is not collusion resistant i.e., the revoked
customer colludes with the cloud.

Preliminaries
This section discusses the foundations of our approach
and are outlined below:

Bilinear map:
Consider two cyclic multiplicative groups G and Gr of
prime order p.e: G* G > Gy is a bilinear map with the
subsequent properties [6]:

e Bilinear: for all u, v € Gj anda, b € Zp,

e(u", v?)=e(u, v)*>

e Non — degeneracy: e(g, g) € 1;

e Computability: An effective algorithm prevails for
estimating map e.

Computational Diffie-Hellman (CDH) Problem: Given
g, 2%, g” € G for unknown a, b € Z,, to estimate g@.

Homomorphic authenticators
Homomorphic authenticators [1], permit a public valida-
tor to examine the integrity of information distributed
in the cloud server without fetching the complete infor-
mation. The properties of homomorphic authenticable
signature mechanism are as follows:

Let the signer’s public/secret key pair be (pj, s;), 01 is
the signature on chunk 5, € Zy, and /2 is the signature on
chunk bz € Zp.

e Blockless auditability: Given p; and p2, two arbitrary
values 61, B2 in Zp and a chunk b’= 61b1+Bh2b2 € Zp,
an auditor audits the accuracy of chunk b’ without the
knowledge of b; and by.

e Non-flexibility: Given b; and b2, p; and 2, two ran-
dom values £1, B2 in Zp and a chunk b'= B1b1+B2b2€E Zp,
a customer without secret key (s,), is unable to produce a
legitimate signature p’ on chunk D’ by joining ~, and po.

Blockless auditability permits an auditor to examine the
integrity of information hosted on the distributed server
by generating the linear aggregation of all the chunks via
a challenge-and-response convention. Hence the verifier
need not download the whole information from the cloud.
Non-flexibility illustrates that alternative entities who do
not possess appropriate secret keys are unable to create
legitimate signatures on combination of chunks by using
the signatures that they possess.

Proxy re-signatures

Proxy re-signatures [4] permit a semi-trusted intermedi-
ary to accomplish as an interpreter of signatures amidst
two customers. Conventional proxy re-signature mech-
anisms [3, 4], do not support blockless auditability, if
we utilize these intermediary re-signature mechanisms
in the public verification schemes, then the auditor has
to retrieve the whole information to verify the integrity,
that necessarily decreases the effectiveness of verification.
Hence, we utilize Homomorphic Authenticable Proxy
Mara et al. Journal of Cloud Computing: Advances, Systems and Applications

Re-signature (HAPS) [39] mechanism, that satisfies block-
less auditability and non-flexibility. In our paper, after
repudiating malicious customer, the JP of respective clus-
ters computes the Re — sign key and transmits it to the
CSP. After acquiring the Re — sign key, the CSP checks the
integrity of the revoked customer chunks and signs these
chunks utilizing the Re — sign key sent by the JP.

Regression co-efficient

Regression co-efficient is an estimation of an independent
variable in terms of the other. If pz, and sz are co-related,
the best fitting straight line in the least square sense gives
a reasonably good relation between public key px and
secret key sx. Similarly, in our scenario, the regression co-
efficient secures the public key pz and secret key sx of the
Re — sign key.

Problem statement

Problem definition

Given a cloud storage model consisting of CSP, TPA and
multiple clusters with their respective Information Propri-
etor’s, the main objectives are:

(i) Secure Re — sign key generation: The JP, manager of
the respective clusters is allowed to compute the
Re — sign key securely using the regression method.

(ii) Effective and secure customer repudiation: Once a
malicious customer is repudiated from the cluster by
the JP, the chunks signed by the repudiated customer
can be effectively re-signed. On behalf of the existing
customers, the CSP efficiently and securely audits
and re-signs the repudiated customer chunks using
the Re — sign key sent by the JP and the repudiated
customer can no longer estimate the valid signatures
on the shared information.

(iii) Privacy preserving and collusion resistant: The CSP
(possess the Re — sign key sent by the JP), by
colluding with the revoked customer, cannot find the
secret keys of the existing customers from the
Re — sign key. Thus, the scheme preserves the
privacy of the customers and is collusion resistant.

(iv) Public auditing: The Third Party Auditor (TPA)
audits the requests sent by every JP of all the clusters
individually called as individual auditing. The TPA
also performs multi-information proprietor batch
auditing for the requests of all Ps simultaneously.

(v) Scalability: Cloud information is effectively
distributed among the existing customers of multiple
clusters.

Assumptions
(i) CSP is a semi-trusted entity.
(ii) Private channels (e.g., SSL) exist between each pair of
entities.

(2020) 9:47 Page 6 of 18

System model

As demonstrated in Fig. 1, the system framework com-
prises of three objects: the Cloud Service Provider (CSP),
the TPA and multiple clusters with respective JP. The CSP
provides information repository and distribution services
to the customers. The TPA aims to audit the integrity of
distributed information via challenge-and-response con-
vention with the CSP. Each cluster consists of an JP and
various customers in the cluster. The JP is the head or
manager of the cluster (group of customers). The JP gener-
ates the private keys and public keys for all the customers
in the cluster (See Function 1: GenerateKey). The IP also
creates the Customer List (CL). The IP of the respective
cluster generates and distributes information with other
customers in the cluster through the cloud. Both the JP
and customers in the cluster can retrieve and update the
distributed information. The distributed information is
divided into range of chunks. A customer in a cluster
modifies a chunk by carrying out an insert, delete and
update operations on the chunk.

Considering that the CSP is a semi-trusted party, it
obeys the rules and does not corrupt the integrity of
the information passionately as a mischievous attacker.
However, it might also deceive the auditor regarding
the inaccuracy of the distributed information so that
the prominance of its information services is retained.
Normally, the inaccuracy of shared information might be
due to hardware/software breakdown or human misinter-
pretation. Because of these aspects, the customers do not
totally rely on the cloud with the integrity of distributed
information.

The integrity of the distributed information is pre-
served by appending a signature to every chunk of the
shared information, that is estimated by anyone of the cus-
tomer’s present in the cluster. Particularly, when the JP
originally generates the shared information in the cloud,
the total signatures on the shared data are estimated by
the JP. Hereafter, when a customer changes a chunk,
this customer additionally requires to sign the revised
chunk with his secret key. By distributing the data amidst
the cluster of customers, distinct chunks may be signed
by various customers due to modifications by distinct
customers.

While the customer in the cluster leaves or miscon-
ducts, the cluster has to remove this customer. Usually,
as the originator of the shared information, the JP acts
as the cluster manager and he has an authority to repu-
diate the customer from the cluster. When a customer is
removed, the signatures computed by this eliminated cus-
tomer become insignificant to the cluster, and the chunks
signed by this renunciated client ought to be re-signed
by the prevailing user’s secret key, so that the accuracy of
the complete distributed information is validated with the
public keys of the current customers.
Mara et al. Journal of Cloud Computing: Advances, Systems and Applications

(2020) 9:47 Page 7 of 18

 

Update Block

 

Download Block

Data Owner's

 

» Se

Revoked Users

 

Fig. 1 Cloud storage model

XX

Mathematical model

Computation of re-sign key (Tre_key) by the information
proprietor using regression method:

In the existing scheme [39], the authors have allowed the
semi-trusted CSP to estimate the Re — key utilizing the
secret keys of the existing customers in the cluster. Thus,
it is very easy for the CSP to know and access the sensi-
tive data cached in the server. Moreover, when the revoked
customer colludes with the CSP, they can further hack or
misuse the information cached in the cloud server. Hence,
the existing scheme [39] is not secure and is not collusion
resistant.

In the proposed scheme, we have not allowed the semi-
trusted CSP to compute the Re — sign key. In order to
secure the secret keys of the existing customers, we have
allowed the JP of the respective clusters to compute the
Re — sign key (Tre—key) using the regression method. When
a customer is repudiated from the cluster, the JP of the
respective cluster computes the Re — sign key and trans-
mits to the CSP. The CSP receives the Re — sign key,
verifies and re-signs the revoked customer chunks with
the Re — sign key sent by the JP.

The Information Proprietor (JP) uses secret key t; and
public key (pk;) of customers c; and c; respectively. The
identities of customers c; and c; are id; and id; respec-
tively where (i,j) € [1,c]. H is a hash function with H:
{0,1}* —+ G,. The computation of Re — sign key using
regression technique is as follows:

Audit Request

Audit Response

Cloud Server

   
 
  

Public Auditor

 

In order to secure secret key and public key, the JP substi-
tutes t; and pkj, along with hash of id of i” customer and
id of j customer in the variables a, and a2 respectively.
a1=(H(id;)) 733 a9=(H(id))pk;

By using a; and az compute Xj, Y; and Z, :

Xy = 2(a1)%; Yy = 2(X4)®; Z) = X1-N

The following steps shows the computation of Re — sign
key (Tre—key) using the Regression method:

Xo = 2(Y1)” ; Yo = 2(X1)® 3 Zo = X2-Y2

S(X) = X41 +X9; S(Y) = Y1+Y9; S=Z] +Z9

mX=SX/2; mY=SY/2; mZ=SZ/2

SX? = (X1)*+(X2)?; SY? = (Y1)?+(Y2)?;

SZ=(Z1)*+(Z2)*

5X? = §(X?/Z)-(mX)”

dY? = S(Y?/Z)-(mY)”

6Z? = S(Z7/Z)-(mZ)?

TRe-key = 2 E 4 4)/ (2v/5x?5 y2 4 4) | (1)

where A=65(X2)+5(Y7)+6(Z7).

The Re — sign key (TRe—key) Computed consists of
secret key and public key implicitly and the key is
highly secure where it is difficult for the semi-trusted
CSP or the revoked customer to break the key and
know the secret keys of the existing customers in the
clusters.
Mara et al. Journal of Cloud Computing: Advances, Systems and Applications

Security analysis

Theorem 1 The CSP by colluding with the revoked cus-
tomer, will not be able to find the secret keys of the existing
customers from the Re — sign key.

Proof In the proposed scheme, the JP is the manager of
the cluster. The /P generates the secret keys and the public
keys of all the customers present in the cluster [See Func-
tion 1: GenerateKey]. In order to secure the secret key (t;)
and public key (pk;), the JP substitutes t; and pk;, along
with hash of id of i” customer and id of j” customer in
the variables a, and a2 respectively [See “Mathematical
model” section]. Further in the regression technique, a
and a2 are substituted in X; and Y;. This procedure con-
tinues, and the final Re — sign (TRe—key) Eq. 1, consists
of secret key and public key implicitly and the Re — sign
key computed is highly secure and the CSP will not be
able to break this key. The steps in the computation of
Re — sign key using the regression technique proves that
the regression technique tightly secures the secret key and
the public key and hence it is impossible for the adversary
by colluding with the CSP to find the secret key and public
key of the customers present in the cluster. O

Let us assume that the revoked customer (malicious
customer) colludes with the mischievous CSP. Now the
CSP is possessing the Re — sign key sent by the JP. The CSP
and the malicious customer tries to break the Re — sign
key and know the secret keys of the existing customers in
the cluster. If they succeed then CSP and malicious cus-
tomer would have achieved their goal of possessing the
secret key. But, it is not possible for both CSP and the
revoked customer to break the Re — sign key and extract
the secret key as the Re — sign key is computed by the IP
using regression technique which is a powerful tool that
efficiently secures the secret key and does not allow any
adversary by colluding with the CSP to find the secret key
from the Re — sign key.

Adversary model

Figure 2 shows the adversary model. The model consists of
three entities: Cluster of customers with their respective
IP, Cloud Service Provider (CSP) and Third Party Audi-
tor (TPA). The JP, manager of the cluster monitors all
the activities of the customers prevailing in the cluster.
From Fig. 2, it is observed that if any one of the customer
present in the cluster performs unwanted activity i.e., the
malicious customer tries to retrieve the sensitive informa-
tion or tries to hack the data, these activities are traced
out by the JP. The JP immediately retrieves his creden-
tials and revokes the malicious customer from the cluster.
Further, the JP computes the Re—sign key using the regres-
sion technique and sends to the CSP. After receiving the

(2020) 9:47 Page 8 of 18

Re — sign key, the CSP audits and re-signs the revoked cus-
tomer chunks using the Re — sign key. Next, the revoked
customer might collude with the CSP [See Fig. 2], and tries
to find the secret keys of the customers present in the clus-
ter. Since, the Re — sign key is computed by the /P using
regression technique, it is not possible by the CSP or the
revoked customer to break the Re — sign key and find the
secret keys of the customers. Hence the proposed scheme
preserves the privacy of the customers and is collusion
resistant.

In the existing scheme [39], the semi-trusted CSP is
permitted to compute the Re — sign key. So, the mis-
chievous CSP colludes with the revoked customer and
tries to attack or hack the sensitive information cached
in the cloud server. Hence, the existing scheme does not
preserve the privacy of the customers and is not collusion
resistant.

The semi-trusted CSP is permitted to compute the
Re — sign key. So, it is easy for the CSP by colluding with
the revoked customer to find the secret keys of the exist-
ing customer and they (CSP and revoked customer) can
access the information cached in the cloud server. Hence
the existing scheme is not collusion resistant.

The algorithm

System setup

Let Gj, Gz and Gy be multiplicative groups of prime
order p, g be a generator of Go, ec: G, * G > Gr
be a bilinear map. H(-) is a secure map-to-point hash
function:({0, 1}‘—> G,) that map strings consistently to
G ,. Another hash function h(-): Gj Zp, maps group ele-
ment of G; evenly to Z,. The overall number of chunks
in the distributed information is m and the distributed
information is represented as S =(by, bg,.....by). The total
number of customers in the cluster is c.

The Algorithm 2, CRUPA (Collusion Resistant User
Revocable Public Auditing of Shared Data in Cloud) con-
sists of two phases:

Phase I: Secure Re-signing of Revoked Customer Blocks
by CSP.

Phase IT: Secure Multi-Information Proprietor Cluster
Auditing for Shared Information by the Third Party Audi-
tor.

Phasel: secure re-signing of revoked customer blocks by
CSP

The Function 1: GenerateKey illustrates the generation of
secret and public key parameters of the system. There are
D Information Proprietors ([P’s) of the respective clus-
ters in the system, and each Information Proprietor d
has a document Fy=(bq), ......bg,,) to be deployed in the
distributed server, where d € { 1.,....D }. For a specific
Mara et al. Journal of Cloud Computing: Advances, Systems and Applications (2020) 9:47 Page 9 of 18

 

 
 

Cloud Service
Provider

  
   
 
 

B
D
Information Proprietors

  

an)

aa ah
Revoked or
malicious
customers

Group of customers
ee

 

Fig. 2 Adversary model

Audit proof

 

Audit request

  

Third Party Auditor

 

 

Information Proprietor d, the private key is s,=tg€ Zp and
the corresponding public specifications are (vg, wg, Za, Ja).
Every IP of their respective clusters generate secret keys
and public keys for all their existing customers in the clus-
ter. He also creates the Customer List (CL) that comprises
the id's of all the existing customers in their clusters.
Every IP, d € {1,....D}, encrypts all the chunks of his file
Fy and computes signatures for all these chunks. JP sends
(Fa, b) to the CSP, where $={px ;}1 < i < n. Now the exist-
ing customers of all the clusters retrieve their respective
chunks, perform modifications, sign with their secret key
(t) and upload to the server as described in the function
SignatureGen [See Algorithm 2, Phasel, Part I]. IP is an
authorized person and keeps track of all the customers
activities in his cluster. During this process, when anyone
of the existing customer is found malicious or the term of
his/her membership is expired, then the JP has the right
to revoke this customer and withdraw all his credentials.
When a customer is repudiated, the signatures com-
puted by this eliminated client are insignificant to the
group, and the chunks that were formerly signed by this
repudiated customer should be verified for integrity and
re-signed. In the proposed scheme, the JP revokes the
malicious customer from the cluster, computes the !Re —
sign key (Tre—key) utilizing the regression method as in
Eq. 1, and transmits it to the CSP. After obtaining the
Re — sign key (Tre—key) the CSP checks the integrity of the
revoked customer chunks and re-signs with the tre_xey as

illustrated in the function Resignature [See Algorithm 2,
Phase I, Part II]. The proposed scheme is highly secure,
i.e., it is very difficult for the semi-trusted CSP to retrieve
the secret keys of the existing customers from the Re—sign
key (Tre—key). By colluding with the revoked customer, the
CSP cannot find the secret keys of the existing customers’
as the !Re—sign key is computed by the JP. Hence, the pro-
posed scheme is collusion resistant, and provides secure
integrity auditing of the revoked customer chunks by the
CSP.

Phasell: secure multi-information proprietor cluster
auditing for shared information by the third party auditor.
In the proposed system model, the JP's of respective clus-
ters create the auditing request and sends to the TPA. The
TPA executes the function ClusterChal [See Algorithm 2,
Phasell, Part land Part II] generates challenge={(i, €;)}i cE
to the respective /P’s auditing requests and delivers to the
CSP. Upon accepting the challenge from TPA, for every IP,
d (d € {1,.....D}), the CSP responds to the TPA with the
storage proof {p, {Xahi <a <p: {idisej}ic E}-

The public verifier executes ClusterVerify [See Algo-
rithm 2, Phasell, Part II], and validates the accuracy of
proof of storage acknowledged by the cloud. The public
verifier efficiently performs multi-information proprietor
auditing and sends the auditing proof to the respective
IP. The multi-information proprietor auditing consider-
ably decreases the transmission cost of the server and the
Mara et al. Journal of Cloud Computing: Advances, Systems and Applications

Function 1: GenerateKey

Function: Generates the system public and secret
parameters.

Input: c, d), global parameter (g, Gi, Z,*)

Output: pk;, skj, CL, (vg, Wa; Sas Ja)

Assume d€(1.,....D) information proprietors of their

respective clusters in the system.

Choose random elements t € Zp, Je G,

Compute v=g" and w=J*

For a particular information proprietor d, the secret

key, sk=tge Zp

Corresponding public parameters are (vg, Wa, Za;

Jaj=(e, Ja; &) Ja) where J € G

Respective information proprietor of each cluster

generates the public and secret parameters for

existing customers as:

Start:

for each i upto c.

Generate random number 7; from Z,”.

10 Compute Public key pkj=g".

11 Assign Private key skj= 7;.

12 End.

13 d, of respective clusters creates CL.

14 CL is public and signed by d.

—

SP WO WN

11

a

Ni

ce

\o

So

—

Qo

computation cost of the public verifier. For the public
verifier’s challenge request, Challenge= {(i,&;)}; <5, the
CSP utilizes the bilinear aggregate signature [5], and
sends one group element p instead of {pg}; < qa < p. Thus,
the communication cost on the server side has been
greatly reduced. At the same time, combining D auditing
equations into one helps to decrease the number of expen-
sive pairing operations from 2D, as individual verification
requires D + 1 pairing operations. Hence, reasonable
amount of verification time of public verifier is saved.

Construction of homomorphic authenticable proxy
re-signature scheme (HAPS) using regression method

In the existing scheme, Wang et al. [39], proposed Homo-
morphic Authenticable Proxy Resignature (HAPS) mech-
anism. This scheme has five functions: KeyGen, Re — key,
Sign, Re — sign and Verify. In the function Re — key of
the HAPS mechanism, they have used the Re — key com-
puted by the CSP [39]. They have allowed the semi-trusted
CSP to estimate the Re — key employing the secret keys
of the existing customers in the cluster. Thus the semi-
trusted CSP, who has the knowledge of the secret keys of
the existing customers can have access to the information
cached in the cloud server. Further, the CSP may collude
with the repudiated customer and perform mischievous
activity on the data. Hence, the limitation of the scheme

(2020) 9:47 Page 10 of 18

is that it is not collusion resistant ie., CSP and the repu-
diated customer can find the secret keys of the existing
customers.

In our paper, we have used Homomorphic Authenti-
cable Proxy Resignature (HAPS) [39] mechanism. This
scheme has five functions: KeyGen, Re—key, Sign, Re—sign
and Verify. In the function Re — key [See Algorithm 1],
we have used the Re — sign key (Tre—key) computed by
the JP in Eq. 1. The Homomorphic Authenticable Proxy
Resignature scheme using regression method does not
allow the semi-trusted CSP to compute the Re — sign key.
Whereas the JP is allowed to estimate the Re — sign key
(TRe—-key) as illustrated in Eq. 1, utilizing the regression
method and then it sends to the CSP. Since the Re — sign

Algorithm 1: Homomorphic Authenticable Proxy
Re-signature Scheme (HAPS) using Regression
method
Let G1, G2 be two groups of order p, g be a generator
of G1, e: G,*G, — Gp bea bilinear map, w be
another generator of G,. The global parameters are
(e, p, G1, Go, g, w, H) where H is a hash function
with H:(0,1) > Gy}.
Input: 7;. by € Zp and id, where k € [1,n], w, and

—

TRe—key
Output: pz, py‘?
KeyGen:
Customer c; selects random number 7; from Z,*
Assigns Private key skj= 1;
Computes Public key pkj=g"
Re-key:
IP computes the Re — sign key (Tre—key) using
regression method [eq. no.1]
(TRe—key)=2[(A +4)/(2,/sigX?sigY? + 4) ]
Sign:
Existing customer c; generates the signature (p;) on
block b; as:
10 pe=(H(idg) wk)™
11 Re-sign:
12 CSP (Proxy) verifies the integrity and re-signs the
revoked customer chunks as:
The CSP (proxy) first verifies that e(p,, g)=
((H (idx) w**), pke).
14 If the auditing result is 0, the agent outputs L
is Otherwise, the JP computes Re — sign key (Tre—key)
using regression method and sends to the CSP
(proxy) to re-sign the revoked customer chunks.
CSP (proxy) re-signs the revoked customer chunks
as px Rte) =(H (idx) wf
17 Verify:

N QD OF *»& W WS

o @

So

N

1

Qo

Ss

1

aN

is The verifier outputs 1, if e(p, g)= e(H(id) w?, pki)
and 0 otherwise
Mara et al. Journal of Cloud Computing: Advances, Systems and Applications

Algorithm 2: CRUPA: Collusion Resistant User

Revocable Public Auditing of Shared Data in Cloud

1

wo N

N QD Oo ©

Phase I: Secure Re-signing of Revoked Customer Blocks by

CSP

Input: 7;, t7, by € Zp, id, where k € [1,1], J, d, D, Fa, bai:
cj and Te,

Output: px; Pais Px?

Part I: SignatureGen

Every information proprietor d, divides his file Fz into

(bg,1; ».....Dd,n) blocks, where d € { 1,....D }.

Computes signature pq; on every block bg;:

pai=(H (idi) Ja’ti)"@ € G (i=1....2)

IP sends (Fz, @) to the CSP, where $={pxi}1 <i <n

Existing customers c; in every cluster generates the

signature (ox) on block bx as:

8 for each bx with id.

\o

10

11

12

13

14

15

16

17

18

19
20

21
22

23

24.

25

26
27

Compute px= (H(idx) J’).

end for

Part II: ReSignature

CSP verifies the integrity and re-signs the revoked
customer blocks as: ;

The CSP first verifies that e(o,, g) = ((H (idx) J°k), pke).
If the auditing result is 0, the CSP outputs L

else [P computes Re — sign key Tre_key using regression
method and sends to the CSP to re-sign the revoked
customer block.

CSP re-signs the revoked customer blocks

Pk ("Re-key) =(H(idg)J?*)7

The JP performs re-siging, removes customer U's id
from CL, and signs a new CL.

Phase IT: Secure Multi-Information Proprietor Cluster
Auditing for Shared Information by Third Party Auditor
Input: d, E, Challenge

Output: Auditing message, verification message

Part I: ClusterChal

The TPA creates verification message as follows: For
every cluster’s, [P d's auditing request, the TPA selects a
arbitrary gq element subset E={ €1,....e,} of set {1,7 }. For
every element i € E, the TPA selects arbitrary value 1j.
The TPA delivers the challenge={ (i, §;)}; « ¢ to the CSP.
Part II: ClusterProof

Upon securing the challenge, for every IP d

(d € {1,.....D}), the CSP computes:

Xd= doje, Vi ba, and p=T]7_1(T]i20, Pai")

The CSP responses the TPA with {, {xa}1 < d < p»{idi, ei}
ic E}

Part III: ClusterVerify TPA accepts the storage proof
from the CSP and approves the response by analyzing the
verification equation:

e(o, 8) =T124 e(I Tze, [H(idi)]®.0a), va)

If the output is 1, the TPA considers that the sincerity of
total chunks in shared information S is appropriate, else
the TPA outputs 0.

(2020) 9:47 Page 11 of 18

key (Tre—-key) is estimated by the JP, it is not possible
for the CSP to find the secret keys of the existing cus-
tomers. Hence the proposed scheme satisfies blockless
verifiability, non-flexibility and is also collusion resistant
i.e., the semi-trusted CSP cannot collude with the revoked
customer.

Table 2 presents the Summary of the Notations used in
the Algorithm 2.

Performance evaluation

To evaluate our proposed mechanism, a prototype sys-
tem is implemented utilizing Java with Java Pairing-Based
Cryptography Library (jPBC) [21] and the experiments are
conducted on a PC with windows 7, Intel(R) Core(TM)
i5-5200U, CPU @2.20GHz, 8GB RAM. In the following
experiments, we assume the size of element in G, or Zy is

Table 2 Summary of the Notations used in the Algorithm 2

 

 

Notation Description

G,,G Multiplicative groups of prime order p

g Generator polynomial of G,

H(-) Secure map-to-point hash function

h(-) hash function maps cluster element of G
consistently to Zp

tagr Tag of file F

Pk Public key

Sk Secret key

T] Signature on block 6;

n Total number of chunks in shared data

S Shared information

C Total number of customers in a cluster

dij Information proprietor of 1*° cluster

CL Customer List

bk k" block

idx k*" block identifier

E Subset of g random blocks

TRe—key Re-sign key

poy The-Key) Re-Signature on revoked customer's. k‘

block

Public (Va, Wd, Gd: Jd)

parameters

Fa, i File owned by information proprietor (d1) of
i” cluster

op Set of signatures on entire chunks in dis-
tributed information.

Exp G One exponentiation in G

Mul G One multiplication in G,

Pair Pairing operation on e: G; * G2 > GF

m-MulExp'¢ tm term exponentiations )7j=1'"g%

 
Mara et al. Journal of Cloud Computing: Advances, Systems and Applications

| p |=160 bits. The size of an element of Z, is | g |=80 bits.
The size of each chunk is 4KB.

Communication Cost: The proposed mechanism is a
secure and efficient customer revocation mechanism. The
existing customers in every cluster are relieved from the
burden of verifying the revoked customer chunk and
hence the communication cost of all the existing cus-
tomers in every cluster is reduced. While performing
auditing, the TPA retrieves only the combination of all the
chunks (Challenge) instead of the complete information,
therefore the communication cost of the TPA is saved. The
size of the verification message is {(i,&)}; - g¢ is e.(| m|+|
q|) bits. The size of the verification proof {p, {xa}1 <d <p>
{id;, e;} ; < E} is (2c.|p| + e.(\id|) where c is the number of
current customers in each cluster, e is the number of chal-
lenged chunks, the size of an element in G, is | p| and the
size of a chunk identifier is |id| . The overall transmission
cost of a verifying task is d(2c.|p| + e.(|id|+|n|+|q|)) bits
where d is the number of information proprietors, || is
the size of element of set [1,7].

Computation Cost: The computation cost of an indi-
vidual signature of a chunk is about 2Exp G,+ Hash
G,+Mul G,. As illustrated in the Re — Signature
function [See Algorithm 2, Phase 1, Part II] of the
proposed scheme, the CSP initially checks the accu-
racy of the initial signature on a chunk and a fresh
signature is estimated on the same chunk using Re —
sign key. The computation cost of the CSP to re-sign a
chunk is MulG,+HashG,+2Exp G,+2Pair. The proof of
storage response generated by the CSP consists of the
aggregated signatures and linear combination of sampled
chunks. After receiving the proof of storage from the

(2020) 9:47 Page 12 of 18

CSP, the computation cost for verification by an auditor is
e-MulExp' ¢(\&;|)+Hash®o+Mul? ¢+Exp’¢(|p|)+Pair2o.g

The time taken by the JP to estimate the Re — sign key
(TRe—-key) is as shown in Fig. 3. The computation time is
independent of the size of the cluster. The JP takes the keys
from two existing customers and computes the Re — sign
key (Tre—key) [Eq. 1]. Hence the time cost remains the
same throughout. In comparison to the Panda scheme,
the computation cost is reduced as we have allowed JP
of the respective clusters to compute the Re — sign key
and send to the CSP. But in the Panda mechanism, the
CSP estimates the Re — key and re-signs the revoked user
blocks, hence the computation cost increases.

The performance comparison between CRUPA and
Panda schemes during customer revocation is shown in
Fig. 4. In the proposed mechanism, the CSP securely and
efficiently re-signs the respective cluster’s revoked cus-
tomer chunks and also saves the prevailing customer's
reckoning and correspondence resources. As depicted in
Fig. 4 the CSP in CRUPA re-signs 500 chunks in 11s while
CSP in Panda takes 15 s, nearly 30 percent improvement.

The JP computes and delivers the Re — sign key (Tre—key)
to the CSP. The time taken by the CSP to re-sign the
revoked user chunks in CRUPA is less as compared to the
Panda scheme [see Fig. 5.]. In Panda scheme, the CSP
computes the Re — key as well as re-signs the revoked cus-
tomer chunks. But in our scheme, CSP’s computation cost
is completely reduced as CSP receives the Re — sign key
(TRe—key) by the JP and only re-signs the revoked customer
chunks. Hence our mechanism is secure and effective.

The system model that we have proposed consists of
multiple clusters with their respective /P. Figure 6 shows

 

Computation overhead (s)

Fig. 3 Computation of Re — sign key by Information Proprietor

 

 

Number of revoked customers

CRUPA ——
PANDA [39] —=—

 

 
Mara et al. Journal of Cloud Computing: Advances, Systems and Applications

(2020) 9:47 Page 13 of 18

 

Revocation time (s)

0 100 200

 

Fig. 4 Revocation time with re-signing of blocks by the CSP

XX

the batch auditing for single cluster and multiple clusters
compared with the existing schemes. When TPA receives
individual customer’s auditing requests, the average audit-
ing time taken by the TPA is more i.e., 290ms [27] [see
Fig. 6]. By allowing the TPA to carry out the verification
for cluster of customers auditing requests simultaneously
i.e., single cluster auditing, then the average auditing time
taken by the TPA in CRUPA is less (269ms) compared to
Panda scheme [39] (272ms). In CRUPA, the TPA’s average
auditing time cost is slightly more for multi-information
proprietor cluster auditing.

Considering the TPA generates the different number
of challenged information chunks, we respectively show
the computation cost of the TPA and that of the CSP in

 

CRUPA ——
PANDA [39] —=—

300 400 500

k: the number of re-signed blocks

integrity auditing phase in Figs. 7, 8 and 9. The compu-
tation overhead of the TPA during proof verification is as
shown in Fig. 7. The computation overhead of TPA during
proof verification in Shen scheme [27] ie., for individual
customers proof of possession sent by CSP to TPA varies
from 0.3s to 12.5s while in CRUPA (single batch), it varies
from 0.1s to 5.97s and for multiple batch, it varies from
0.19s to 7.67s. TPA takes more time to provide the verifi-
cation proof for the individual customers proof of posses-
sion sent by the CSP. When multiple cluster dataowners
sends auditing requests, the TPA randomly chooses a set
of chunks i.e., generates challenge set and sends it to the
CSP. Now, the CSP sends a single proof of possession for
the received challenge set to the TPA. Hence, the time

 

Re-signing time (s)

0) 100 200
k: the number of re-signed blocks

 

Fig. 5 Re-signing time of the blocks by Cloud Service Provider

XX

 

CRUPA ——
PANDA [39] —*—

300 400 500

 

 
Mara et al. Journal of Cloud Computing: Advances, Systems and Applications

(2020) 9:47 Page 14 of 18

 

300

295

290

285

280

275

Average auditing time (ms)

270
265

260
0 5 10 15

Fig. 6 Impact of t on average auditing time (ms) per task where c=10

 

 

CRUPA-SB
CRUPA-MB
Panda-SB [39]
Shen-Ind [27]

20 25 30 35 40
t: the total number of auditing tasks where c=10

 

taken by the TPA to verify the proof in batch auditing (sin-
gle and multiple clusters) is less compared to individual
auditing.

Compared with the time of proof verification, the time
of challenge generation increases slowly [see Fig. 8], just
varying from 0.013s to 0.546s in [27] while in CRUPA
(multiple clusters) it varies form 0.011s to 0.32s and for
single cluster it varies from 0.001s to 0.15s. The time
of challenge generation by the TPA in CRUPA is less
compared to Shen scheme [27]

Figure 9 shows the computation cost of CSP during
proof generation. The computation cost of CSP is more
in Shen scheme [27], as CSP provides proof for the indi-
vidual customer’s challenged chunks. In the proposed

scheme, TPA performs batch auditing. The TPA sends
the challenge set for single batch or multiple batch audit-
ing to the CSP. Now, the CSP provides proof of posses-
sion of the challenged blocks present in the challenge
set i.e., the CSP takes less time to provide proof of pos-
session for batch auditing as compared to the individual
auditing.

The processing time for different block numbers [see
Fig. 10] in the Setup phase [30] is more compared to
the CRUPA scheme. In the Setup phase of DHT — PA
scheme, the CSP computes the tag for each uploaded
blocks (i.e., TagGeneration phase) that includes the com-
munication cost and computation cost while in CRUPA,
the JP performs processing of all the blocks. Thus, the

 

14

12

10

The computation overhead of TPA (s)

 

Fig. 7 Computation overhead of TPA during proof verification

 

LE

Shen-Ind [27] —*;>
0 200 400 600 800 1000
The numbers of challenged blocks

CRUPA-MB —+—
CRUPA-SB ——

 

 

 
Mara et al. Journal of Cloud Computing: Advances, Systems and Applications

(2020) 9:47 Page 15 of 18

 

The computation overhead of TPA (s)

Fig. 8 Computation overhead of TPA during challenge generation

 

XX

processing time for different block numbers in CRUPA is
less compared to DHT — PA scheme.

Conclusions

In this paper, we have introduced a Collusion Resistant
User Revocable Public Auditing (CRUPA) of distributed
information in the cloud. The JP of the respective revoked
customer cluster computes the Re — sign key (Tre—key)
using regression method and transmits it to the cloud
server. The computation cost of Re — sign key (tTre—key)
using regression method by the JP has been significantly
reduced. The algorithm supports effective and secure
customer repudiation. Once the JP of the respective
clusters revokes the customer, the CSP verifies the
revoked customer chunks and securely re-signs with the

 

The numbers of challenged blocks

CRUPA-MB —+—
CRUPA-SB ——
Shen-Ind [27] —*—

 

Re — sign key (Tre—key) that allows the proposed scheme
to be collusion resistant. Further, the algorithm supports
multi-information proprietor batch auditing. The TPA in
CRUPA takes less time to perform single batch auditing
compared to the existing scheme. The proposed scheme
is scalable as cloud information is effectively distributed
among the existing customers of multiple clusters. Exten-
sive experimental results demonstrate the efficiency and
effectiveness of Collusion Resistant User Revocable Pub-
lic Auditing (CRUPA) scheme. The processing time taken
by the JP in the Setup phase is low. The computation cost
of TPA and CSP is low in the integrity auditing phase.
The limitation of the mechanism is that it has a slightly
more auditing cost for multi-information proprietor batch
auditing.

 

The computation overhead of CSP (s)

 

Fig. 9 Computation overhead of CSP during proof generation

XX

Ez

The numbers or shallenoed blocks

 

CRUPA-MB —+—
CRUPA-SB ——
Shen-Ind [27] ——

 
Mara et al. Journal of Cloud Computing: Advances, Systems and Applications

(2020) 9:47 Page 16 of 18

 

Processing time (s)

 

Fig. 10 Processing time for different block numbers in the Setup phase

 

50 100 150

CRUPA ——
DHT-PA [30] —*—

200 250 300
Block number

 

Footnote

The 1Re — sign key computed by the information pro-
prietor using the regression technique mentioned in this
paper must be considered as an indication. Since, the
Re — sign key is computed by the JP using regression tech-
nique, it is not possible by the CSP by colluding with the
revoked customer to break the Re — sign key and find the
secret keys of the customers. Hence the proposed scheme
preserves the privacy of the customers and is collusion
resistant. Further, the proposed scheme supports effec-
tive and secure customer repudiation, multi-information
proprietor batch auditing and is scalable.

Abbreviations

CRUPA: Collusion resistant user revocable public auditing; HAPS:
Homomorphic authenticable proxy re-signature; CSP: Cloud service provider;
TPA: Third party auditor; jPBC: Java pairing-based cryptography library

Acknowledgments
We sincerely thank the Reviewers and the Editor for their valuable suggestions.

Authors’ contributions

GM carried out the experimental design, data analysis, interpretation,
mathematical model design, and drafted the manuscript. UR carried out the
mathematical model design, SR participated in the experimental design, RS
participated in design of the study and performed the experimental analysis,
RB participated in the design of the study and approved the final manuscript,
VK participated in its design and coordination and approved the final
manuscript, SS participated in design, conceptualization and approved the
final manuscript and LM participated in conceptualization, implementation
and approved the final manuscript.

Authors’ information

GeetaCM, is a research scholar in the department of Computer Science and
Engineering, University Visvesvaraya College of Engineering, Bangalore
University, Bengaluru. She has received B.E. degree in Electronics and
Communication from Basaveshwara College of Engineering, Bagalkot,
Karnataka, India and M.E degree in Information Technology, from Bangalore
University, Bengaluru, Karnataka, India. Her areas of interest are Cloud
Computing, Cloud Security and Wireless Sensor networks. She is a student
member of the IEEE.

UshaRani is a PG student in the department of Computer Science and
Engineering, University Visvesvaraya College of Engineering, Bangalore
University, Bengaluru. She has received B.E. degree in Computer Science and
Engineering from Rao Bahadur Y Mahaballeshwarappa Engineering College,
Karnataka, India and M.E degree in Computer Science and Engineering, from
Bangalore University, Bengaluru, Karnataka, India. Her areas of interest are
Cloud Computing, BigData Analytics and IT Security.

Shreyas Raju RG is a UG student in the department of Computer Science and
Engineering, University Visvesvaraya College of Engineering, Bangalore
University, Bengaluru. He is currently pursuing B.E. degree in Information
Science and Engineering. He has received diploma in Computer Science and
Engineering, from Govt. Polytechnic, Chintamani, Karnataka, India. His areas of
interest are Cloud Computing, Internet of Things, Cloud Security and
E-Commerce. He is member of International Association of Engineers (/AENG).
Raghavendra S is a Associate Professor in the department of Computer Science
and Engineering, Vivekanand a College of Engineering and Technology,
Puttur. He received his Bachelor degree in Computer Science and Engineering
from BMS Institute of Technology, Visvesvaraya Technological University,
Bengaluru and Masters degree from R V College of Engineering, Visvesvaraya
Technological University, Bengaluru. Dr. Raghavendra S has authored over 20
publications and his research interests include Cloud Computing, Applied
Cryptography and Internet of Things. He is serving as editorial board member
and Guest editor for a number of prestigious journals, like Elsevier, Springer,
KJIP. He is a member of the IEEE.

Rajkumar Buyya is a Redmond Barry Distinguished Professor and Director of
the Cloud Computing and Distributed Systems (CLOUDS) Laboratory at the
University of Melbourne, Australia. He has authored over 625 publications and
seven text books including Mastering Cloud Computing published by
McGraw Hill, China Machine Press, and Morgan Kaufmann for Indian, Chinese
and international markets respectively. He is one of the highly cited authors in
Computer Science and Software Engineering worldwide (h-index=1 36,
98,500+ citations). Software technologies for Cloud Computing developed
under his leadership have gained rapid acceptance and are in use at several
academic institutions and commercial enterprises in 40 countries around the
world. Dr. Buyya is recognized as a Web of Science Highly Cited Researcher in
2016, 2017 and 2018 by Thomson Reuters, a Fellow of IEEE, and Scopus
Researcher of the Year 2017 with Excellence in Innovative Research Award by
Elsevier for his outstanding contributions to Cloud Computing.

Venugopal KR is currently the Vice Chancellor, Bangalore University, Bengaluru.
He obtained his Bachelor of Engineering from University Visvesvaraya College
of Engineering. He received his Masters degree in Computer Science and
Automation from Indian Institute of Science, Bangalore. He was awarded Ph.D
in Economics from Bangalore University and Ph. D in Computer Science from
Indian Institute of Technology, Madr as. He has a distinguished academic
career and has degrees in Electronics, Economics, Law, Business Finance,

 
Mara et al. Journal of Cloud Computing: Advances, Systems and Applications

Public Relations, Communications, Industrial Relations, Computer Science and
Journalism. He has authored and edited 72 books on Computer Science and
Economics, which include Petrodollar and the World Economy, C Aptitude,
Mastering C, Microprocessor Programming, Mastering C++ and Digital Circuits
and Systems etc., He has filed 101 patents. During his three decades of service
at UVCE he has over 900 research papers to his credit. His research interests
include Computer Networks, Wireless Sensor Networks, Parallel and
Distributed Systems. He is a Fellow of IEEE and ACM Distinguished Educator.

About the Authors

S S lyengar is currently Ryder Professor, Florida International University, USA.
He was Roy Paul Daniels Professor and Chairman of the Computer Science
Department of Louisiana State University. He heads the Wireless Sensor
Networks Laboratory and the Robotics Research Laboratory at USA. He has
been involved with research in High Performance Algorithms, Data Structures,
Sensor Fusion and Intelligent Systems, since receiving his Ph.D degree in 1974
from MSU, USA. He is Fellow of IEEE and ACM. He has directed over 40 Ph.D
students and 100 post graduate students, many of whom are faculty of Major
Universities worldwide or Scientists or Engineers at National Labs/Industries
around the world. He has published more than 800 research papers and has
authored/co-authored 6 books and edited 7 books. His books are published by
John Wiley and Sons, CRC Press, Prentice Hall, Springer Verlang, IEEE Computer
Society Press etc.. One of his books titled Introduction to Parallel Algorithms
has been translated to Chinese. He is a Fellow of IEEE and a Fellow of ACM.

L M Patnaik is currently Senior Scientist, Consciousness Studies Program,
National Institute of Advanced Studies, Indian Institute of Science, India. He
was a Vice Chancellor, Defence Institute of Advanced Technology, Pune, India
and was a Professor since 1986 with the Department of CSA, Indian Institute of
Science, Bengaluru. During the past 35 years of his service at the Institute he
has over 1150 research publications in refereed International Journals and
Conference Proceedings. He has received twenty national and international
awards; notable among them is the IEEE Technical Achievement Award for his
significant contributions to High Performance Computing and Soft
Computing. His areas of research interest have been Parallel and Distributed
Computing, Mobile Computing, CAD, Soft Computing and Computational
Neuroscience. He is a Fellow of all the four leading Science and Engineering
Academies in India; Fellow the Academy of Science for the Developing World
and a Fellow of IEEE.

Funding

This work is funded by Technical Education Quality Improvement Programme
(TEQIP)(World Bank) University Visvesvaraya College of Engineering, Bengaluru
and the University of Melbourne, Australia.

Availability of data and materials
Data sharing not applicable to this article as no datasets were generated or
analysed during the current study.

Competing interests
The authors declare that they have no competing interests.

Author details

'Department of Computer Science and Engineering, University Visvesvaraya
College of Engineering, Bangalore University, Bengaluru-560001, Karnataka,
India. *Department of Computer Science and Engineering, University
Visvesvaraya College of Engineering, Bengaluru, India. ?Cloud Computing and
Distributed Systems (CLOUDS) Lab, School of Computing and Information
Systems, The University of Melbourne, Melbourne, Australia. *Bangalore
University, Bengaluru, India. 7Department of Computer Science and
Engineering, Florida International University, Miami, USA. °INSA, National
Institute of Advanced Studies, Indian Institute of Science Campus, Bengaluru,
India.

Received: 28 May 2019 Accepted: 2 July 2020
Published online: 26 August 2020

References

1. Ateniese G, Burns R, Curtmola R, Herring J, Kissner L, Peterson Z, Song D
(2007) Provable Data Possession at Untrusted Stores. In: Proceedings of
the 14th ACM Conference on Computer and Communications Security.
pp 598-609. https://doi.org/10.1145/1315245.1315318

20.

21.

22.

23.

24,

25.

26.

(2020) 9:47 Page 17 of 18

Ateniese G, Di Pietro R, Mancini LV, Tsudik G (2008) Scalable and Efficient
Provable Data Possession. In: Proceedings of the 4th International
Conference on Security and Privacy in Communication Networks. ACM.
pp 1-9. https://doi.org/10.1145/1460877.1460889

Ateniese G, Hohenberger S (2005) Proxy Re-signatures: New Definitions,
Algorithms, and Applications. Proc 12th ACM Conf Comput Commun
Secur:310-319

Blaze M, Bleumer G, Strauss M (1998) Divertible Protocols and Atomic
Proxy Cryptography. Int Conf Theory Appl Cryptographic Tech:127-144.
https://doi.org/10.1007/bfb00541 22

Boneh D, Gentry C, Lynn B, Shacham H (2003) Aggregate and Verifiably
Encrypted Signatures from Bilinear Maps:416-432. https://doi.org/10.
1007/3-540-39200-9_26

Boneh D, Lynn B, Shacham H (2004) Short Signatures from the Weil
Pairing. J Cryptol 17(4):297-319

Buyya R, Yeo CS, Venugopal S, Broberg J, Brandic | (2009) Cloud
Computing and Emerging IT Platforms: Vision, Hype, and Reality for
Delivering Computing as the 5th Utility. Futur Gener Comput Syst
25(6):599-616

Chen F, Xiang T, Lei X, Chen J (2014) Highly Efficient Linear Regression
Outsourcing to a Cloud. IEEE Trans Cloud Comput 2(4):499-508

Dong X, Yu J, Luo Y, Chen Y, Xue G, Li M (2014) Achieving an Effective,
Scalable and Privacy-Preserving Data Sharing Service in Cloud
Computing. Comput Secur 42:151-164

Dong X, Yu J, Zhu Y, Chen Y, Luo Y, Li M (2015) SECO: Secure and Scalable
Data Collaboration Services in Cloud Computing. Comput Secur
50:91-105

Erway CC, KUp¢t A, Papamanthou C, Tamassia R (2015) Dynamic Provable
Data Possession. ACM Trans Inf Syst Secur (TISSEC) 17(4):213-222

Garg N, Bawa S (2016) Comparative Analysis of Cloud Data Integrity
Auditing Protocols. J Netw Comput Appl 66:17-32

Geeta CM, Raghavendra S, Buyya R, Venugopal KR, lyengar SS, Patnaik LM
(2018) Data Auditing and Security in Cloud Computing: Issues,
Challenges and Future Directions. Int J Comput (UC) 28(1):8-57

Hall R, Fienberg SE, Nardi Y (2011) Secure Multiple Linear Regression
based on Homomorphic Encryption. J Off Stat 27(4):669

Hwang JY, Chen L, Cho HS, Nyang D (2015) Short Dynamic Group
Signature Scheme Supporting Controllable Linkability. IEEE Trans Inf
Forensic Secur 10(6):1109-1124

Jin H, Jiang H, Zhou K (2018) Dynamic and Public Auditing with Fair
Arbitration for Cloud Data. IEEE Trans Cloud Comput 6(3):680-693

LiJ, Yan H, Zhang Y (2018) Certificateless Public Integrity Checking of
Group Shared Data on Cloud Storage. IEEE Trans Serv Comput. https://
doi.org/10.1109/tsc.2018.2789893

Li J, Yao W, Han J, Zhang Y, Shen J (2017) User Collusion Avoidance
CP-ABE with Efficient Attribute Revocation for Cloud Storage. IEEE Syst J
12(2):1767-1777

Liu F, Tong J, Mao J, Bohn R, Messina J, Badger L, Leaf D (2011) NIST Cloud
Computing Reference Architecture. NIST Spec Publ 500(2011):1-28

Luo Y, Xu M, Fu S, Wang D, Deng J (2015) Efficient Integrity Auditing for
Shared Data in the Cloud with Secure User Revocation. In:
Trustcom/BigDataSE/ISPA, IEEE, vol. 1. pp 434-442. https://doi.org/10.
1109/trustcom.2015.404

Pairing Based Cryptography (PBC) Library. http://crypto.stanford.edu/
pbc/,2014..

Pattar S, Buyya R, Venugopal KR, lyengar S, Patnaik L (2018) Searching for
the loT Resources: Fundamentals, Requirements, Comprehensive Review,
and Future Directions. IEEE Commun Surv Tutor 20(3):2101-2132
Raghavendra S, Doddabasappa PA, Geeta CM, Buyya R, Venugopal KR,
lyengar SS, Patnaik LM (2016) Secure Multi-Keyword Search and Multi-User
Access Control over an Encrypted Cloud Data. Int J Inf Process 10(2):51-61
Raghavendra S, Geeta CM, Buyya R, Venugopal KR, lyengar SS, Patnaik LM
(2015) MSIGT: Most Significant Index Generation Technique for Cloud
Environment. In: Proceedings of the Annual IEEE India Conference
(INDICON). pp 1-6. https://doi.org/10.1109/indicon.2015.7443531

Ren K, Wang C, Wang Q (2012) Security Challenges for the Public Cloud.
IEEE Internet Comput 16(1):69-73

Shen J, Shen J, Chen X, Huang X, Susilo W (2017) An Efficient Public
Auditing Protocol with Novel Dynamic Structure for Cloud Data. IEEE
Trans Inf Forensic Secur 12(10):2402-2415
Mara et al. Journal of Cloud Computing: Advances, Systems and Applications

27. Shen W, Qin J, Yu J, Hao R, Hu J (2019) Enabling Identity-Based Integrity
Auditing and Data Sharing with Sensitive Information Hiding for Secure
Cloud Storage. IEEE Trans Inf Forensic Secur 14(2):331-346

28. Tarannum S, Aravinda B, Nalini L, Venugopal KR, Patnaik LM (2006) Routing
Protocol for Lifetime Maximization of Wireless Sensor Networks. In:
International Conference on Advanced Computing and Communications.
IEEE. pp 401-406. https://doi.org/10.1109/adcom.2006.4289925

29. Tate SR, Vishwanathan R, Everhart L (2013) Multi-User Dynamic Proofs of
Data Possession using Trusted Hardware. In: Proceedings of the Third
ACM Conference on Data and Application Security and Privacy.
pp 353-364. https://doi.org/10.1145/2435349.2435400

30. Tian H, Chen Y, Chang CC, Jiang H, Huang Y, Chen Y, Liu J (2017)
Dynamic-Hash-Table Based Public Auditing for Secure Cloud Storage.
IEEE Trans Serv Comput 10(5):701-714

31. Tian H, Nan F, Jiang H, Chang CC, Ning J, Huang Y (2019) Public Auditing
for Shared Cloud Data with Efficient and Secure Group Management. Inf
Sci 472:107-125

32. Tian JF, Guo RF, Jing X (2019) Stern-Brocot-based Non-Repudiation
Dynamic Provable Data Possession. IEEE Access. https://doi.org/10.1109/
access.2019.2916173

33. Venugopal KR, Buyya R (2013) Mastering C++. McGraw-Hill Education,
New Delhi

34. Venugopal KR, Rajan EE, Kumar PS (1998) Performance Analysis of
Wavelength Converters in WDM Wavelength Routed Optical Networks.
In: Proceedings. Fifth International Conference on High Performance
Computing (Cat. No. 98EX238). IEEE. pp 239-246. https://doi.org/10.1109/
hipc.1998.737994

35. Venugopal KR, Rajan EE, Kumar PS (1999) Impact of Wavelength
Converters in Wavelength Routed All-Optical Networks. Comput
Commun 22(3):244-257

36. Venugopal KR, Srinivasa KG, Patnaik LM (2009) Soft Computing for Data
Mining Applications. Springer. https://doi.org/10.1007/978-3-642-00193-2

37. Wang B, Li B, Li H (2012) Knox: Privacy-Preserving Auditing for Shared
Data with Large Groups in the Cloud. Int Conf Appl Crypt Netw
Secur:507-525. https://doi.org/10.1007/978-3-642-31284-7_30

38. Wang B, Li B, Li H (2014) Oruta: Privacy-Preserving Public Auditing for
Shared Data in the Cloud. IEEE Trans Cloud Comput 2(1):43-56

39. Wang B, Li B, Li H (2015) Panda: Public Auditing for Shared Data with
Efficient User Revocation in the Cloud. IEEE Trans Serv Comput 8(1):92-106

40. Wu TY, Tseng YM, Huang SS, Lai YC (2017) Non-Repudiable Provable Data
Possession Scheme with Designated Verifier in Cloud Storage Systems.
IEEE Access 5:19333-19341

41. XuX, Zhou J, Wang X, Zhang Y (2016) Multi-Authority Proxy
Re-encryption Based on CPABE for Cloud Storage Systems. J Syst Eng
Electron 27(1):211-223

42. YanH, LiJ, Han J, Zhang Y (2016) A Novel Efficient Remote Data
Possession Checking Protocol in Cloud Storage. IEEE Trans Inf Forensic
Secur 12(1):78-88

43. YanH, LiJ, Zhang Y (2019) Remote Data Checking with a Designated
Verifier in Cloud Storage. IEEE Syst J. https://doi.org/10.1109/jsyst.2019.
2918022

44. YangG, Yu J, Shen W, Su Q, Fu Z, Hao R (2016) Enabling Public Auditing
for Shared Data in Cloud Storage Supporting Identity Privacy and
Traceability. J Syst Softw 113:130-139

45. YuY, NiJ, Xia Q, Wang X, Yang H, Zhang X (2016) SDIVIP2: Shared Data
Integrity Verification with Identity Privacy Preserving in Mobile Clouds.
Concurr Comput Pract Experience 28(10):2877-2888

46. Yuan J, Yu S (2015) Public Integrity Auditing for Dynamic Data Sharing
with Multi-User Modification. IEEE Trans Inf Forensic Secur
10(8):1717-1726

47. ZhuY,Wang H, Hu Z, Ahn GJ, Hu H, Yau SS (2011) Dynamic Audit Services
for Integrity Verification of Outsourced Storages in Clouds. In:
Proceedings of the 2011 ACM Symposium on Applied Computing.
pp 1550-1557. https://doi.org/10.1145/1982185.1982514

48. Zhu Z, Jiang R (2015) A Secure Anti-Collusion Data Sharing Scheme for
Dynamic Groups in the Cloud. IEEE Trans Parallel Distrib Syst 27(1):40-50

Publisher’s Note
Springer Nature remains neutral with regard to jurisdictional claims in
published maps and institutional affiliations.

(2020) 9:47 Page 18 of 18

 

 

Submit your manuscript to a SpringerOpen®
journal and benefit from:

> Convenient online submission

> Rigorous peer review

> Open access: articles freely available online
> High visibility within the field

> Retaining the copyright to your article

 

Submit your next manuscript at > springeropen.com

 

 
