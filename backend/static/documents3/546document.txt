Kersloot et al. Journal of Biomedical Semantics (2020) 11:14 | f
https://doi.org/10.1186/s13326-020-00231-z Journa O
Biomedical Semantics

REVIEW Oy ola

Natural language processing algorithms ®
for mapping clinical text fragments onto ~~
ontology concepts: a systematic review
and recommendations for future studies

Martijn G. Kersloot'* @, Florentien J. P. van Putten’, Ameen Abu-Hanna', Ronald Cornet! and Derk L. Arts!”

 

Abstract

Background: Free-text descriptions in electronic health records (EHRs) can be of interest for clinical research
and care optimization. However, free text cannot be readily interpreted by a computer and, therefore, has
limited value. Natural Language Processing (NLP) algorithms can make free text machine-interpretable by
attaching ontology concepts to it. However, implementations of NLP algorithms are not evaluated
consistently. Therefore, the objective of this study was to review the current methods used for developing
and evaluating NLP algorithms that map clinical text fragments onto ontology concepts. To standardize the
evaluation of algorithms and reduce heterogeneity between studies, we propose a list of recommendations.

Methods: Two reviewers examined publications indexed by Scopus, IEEE, MEDLINE, EMBASE, the ACM Digital
Library, and the ACL Anthology. Publications reporting on NLP for mapping clinical text from EHRs to
ontology concepts were included. Year, country, setting, objective, evaluation and validation methods, NLP

algorithms, terminology systems, dataset size and language, performance measures, reference standard,
generalizability, operational use, and source code availability were extracted. The studies’ objectives were
categorized by way of induction. These results were used to define recommendations.

Results: Two thousand three hundred fifty five unique studies were identified. Two hundred fifty six studies
reported on the development of NLP algorithms for mapping free text to ontology concepts. Seventy-seven
described development and evaluation. Twenty-two studies did not perform a validation on unseen data and
68 studies did not perform external validation. Of 23 studies that claimed that their algorithm was
generalizable, 5 tested this by external validation. A list of sixteen recommendations regarding the usage of
NLP systems and algorithms, usage of data, evaluation and validation, presentation of results, and
generalizability of results was developed.

(Continued on next page)

 

 

* Correspondence: m.g.kersloot@amsterdamumc.n|

"Amsterdam UMC, University of Amsterdam, Department of Medical
Informatics, Amsterdam Public Health Research Institute Castor EDC, Room
J1B-109, PO Box 22700, 1100 DE Amsterdam, The Netherlands

*Castor EDC, Amsterdam, The Netherlands

© The Author(s). 2020 Open Access This article is licensed under a Creative Commons Attribution 4.0 International License,
which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give
appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if

changes were made. The images or other third party material in this article are included in the article's Creative Commons
licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons
licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain
permission directly from the copyright holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0/.
The Creative Commons Public Domain Dedication waiver (http://creativecommons.org/publicdomain/zero/1.0/) applies to the
data made available in this article, unless otherwise stated in a credit line to the data.
Kersloot et al. Journal of Biomedical Semantics (2020) 11:14

(Continued from previous page)

Page 2 of 21

Conclusion: We found many heterogeneous approaches to the reporting on the development and evaluation of NLP
algorithms that map clinical text to ontology concepts. Over one-fourth of the identified publications did not perform
an evaluation. In addition, over one-fourth of the included studies did not perform a validation, and 88% did not

perform external validation. We believe that our recommendations, alongside an existing reporting standard, will
increase the reproducibility and reusability of future studies and NLP algorithms in medicine.

Keywords: Ontologies, Entity linking, Annotation, Concept mapping, Named-entity recognition, Natural language
processing, Evaluation studies, Recommendations for future studies

 

Background

One of the main activities of clinicians, besides providing
direct patient care, is documenting care in the electronic
health record (EHR). Currently, clinicians document clin-
ical findings and symptoms primarily as free-text descrip-
tions within clinical notes in the EHR since they are not
able to fully express complex clinical findings and nuances
of every patient in a structured format [1, 2]. These free-
text descriptions are, amongst other purposes, of interest
for clinical research [3, 4], as they cover more information
about patients than structured EHR data [5]. However,
free-text descriptions cannot be readily processed by a
computer and, therefore, have limited value in research
and care optimization.

One method to make free text machine-processable is
entity linking, also known as annotation, ie., mapping
free-text phrases to ontology concepts that express the
phrases’ meaning. Ontologies are explicit formal specifica-
tions of the concepts in a domain and relations among
them [6]. In the medical domain, SNOMED CT [7] and
the Human Phenotype Ontology (HPO) [8] are examples
of widely used ontologies to annotate clinical data. After
the data has been annotated, it can be reused by clinicians
to query EHRs [9, 10], to classify patients into different
risk groups [11, 12], to detect a patient’s eligibility for clin-
ical trials [13], and for clinical research [14].

Natural Language Processing (NLP) can be used to
(semi-)automatically process free text. The literature indi-
cates that NLP algorithms have been broadly adopted and
implemented in the field of medicine [15, 16], including
algorithms that map clinical text to ontology concepts
[17]. Unfortunately, implementations of these algorithms
are not being evaluated consistently or according to a pre-
defined framework and limited availability of data sets and
tools hampers external validation [18].

To improve and standardize the development and evalu-
ation of NLP algorithms, a good practice guideline for
evaluating NLP implementations is desirable [19, 20].
Such a guideline would enable researchers to reduce the
heterogeneity between the evaluation methodology and
reporting of their studies. Generic reporting guidelines
such as TRIPOD [21] for prediction models, STROBE
[22] for observational studies, RECORD [23] for studies

conducted using routinely-collected health data, and
STARD [24] for diagnostic accuracy studies, are available,
but are often not used in NLP research. This is presum-
ably because some guideline elements do not apply to
NLP and some NLP-related elements are missing or un-
clear. We, therefore, believe that a list of recommenda-
tions for the evaluation methods of and reporting on
NLP studies, complementary to the generic reporting
guidelines, will help to improve the quality of future
studies.

In this study, we will systematically review the
current state of the development and evaluation of
NLP algorithms that map clinical text onto ontology
concepts, in order to quantify the heterogeneity of
methodologies used. We will propose a structured list
of recommendations, which is harmonized from exist-
ing standards and based on the outcomes of the re-
view, to support the systematic evaluation of the
algorithms in future studies.

Methods

This study consists of two phases: a systematic review of
the literature and the formation of recommendations
based on the findings of the review.

Literature review

A systematic review of the literature was performed
using the Preferred Reporting Items for Systematic re-
views and Meta-Analyses (PRISMA) statement [25].

Search strategy and study selection

We searched Scopus, IEEE, MEDLINE, EMBASE, the As-
sociation for Computing Machinery (ACM) Digital Library,
and the Association for Computational Linguistics (ACL)
Anthology for the following keywords: Natural Language
Processing, Medical Language Processing, Electronic Health
Record, reports, charts, clinical notes, clinical text, medical
notes, ontolog*, concept*, encod*, annotat*, code, and cod-
ing. We excluded the words ‘reports’ and ‘charts’ in the
ACL and ACM databases since these databases also contain
publications on non-medical subjects. The detailed search
strategies for each database can be found in Additional file
2. We searched until December 19, 2019 and applied the
Kersloot et al. Journal of Biomedical Semantics (2020) 11:14 Page 3 of 21

filters “English” and “has abstract” for all databases. More- the resulting titles and abstracts and selected publica-
over, we applied the filters “Medicine, Health Professions, _ tions that fitted the criteria described below.

and Nursing” for Scopus, the filters “Conferences”, “Jour- Inclusion criteria were:

nals”, and “Early Access Articles” for IEEE, and the filter

“Article” for Scopus and EMBASE. EndNote X9 [26] and e Medical language processing as the main topic of

Rayyan [27] were used to review and delete duplicates. the publication

The selection process consisted of three phases. In the e Use of EHR data, clinical reports, or clinical notes
first phase, two independent reviewers with a Medical e Algorithm performs annotation
Informatics background (MK, FP) individually assessed e Publication is written in English

MEDLINE EMBASE ACL
(n = 1291) (n = 1235) (n = 178)

Identification
Records identified through
database searching
(n = 4280)

Records after duplicates
removed
(n = 2355)

Screening

Records screened (1) Records excluded on title
_ and abstract
(n = 2355) (n = 2099)

Records excluded due to
lack of evaluation
(n = 65)

Records screened (2)
(n = 256)

Eligibility
Full-text articles assessed Full-text articles excluded
for eligibility (n = 114)
(n = 191)
Algorithm does not use
ontology concepts (n = 44)

Implementation not described
(n = 16)

Does not use EHR data,
clinical reports or clinical notes
(n = 14)

Not a paper (n = 14)
Full text not available (n = 10)

MLP not the main topic of the
paper (n = 9)

Does not evaluate (n = 3)
Duplicate (n = 3)

Not in English (n = 1)

Included

Studies included in
qualitative synthesis
(n =77)

Fig. 1 PRISMA flow diagram

 
Kersloot et al. Journal of Biomedical Semantics

(2020) 11:14

Table 1 Induced objective tasks with their definition and an example

Page 4 of 21

 

Induced NLP task(s)

Description

Example

 

Concept detection '
Event detection
Relationship detection
Text normalization

Text summarization

Classification
Prediction

Identification

Software development

Software evaluation

Assign ontology concepts to phrases in free
text (i.e, entity linking or annotation)

Detect events in free text

Detect semantic relationships between
concepts in free text

Transform free text into a single canonical
form

Create a short summary of free text and
possible restructure the text based on this
summary

Assign categories to free text

 

Create a predictive model based on free text

Identify documents (e.g., reports or patient
charts) that match a specific condition
based on the contents of the document

Develop new or build upon existing NLP
software

Evaluate the effectiveness of NLP software

“Systolic blood pressure” can be represented as SNOMED-CT
concept 271649006 | Systolic blood pressure (observable entity) |

“Patient visited the outpatient clinic in January 2020" is an
event of type Visit.

The concept Lung cancer in “This patient was diagnosed with
recurrent lung cancer” is related to the concept Recurrence.

"This patient was diagnosed with influenza last year.” becomes
"This patient be diagnose with influenza last year.”

“Last year, this patient visited the clinic and was diagnosed with
diabetes mellitus type 2, and in addition to his diabetes, the
patient was also diagnosed with hypertension” becomes

“Last year, this patient was diagnosed with diabetes mellitus
type 2 and hypertension”.

A report containing the text “This patient is not diagnosed
yet” will be assigned to the category Undiagnosed.

Predict the outcome of the APACHE score based on the
(free-text) content in a patient chart.

Find all patient charts that describe patients with hypertension
and a BMI above 30.

A new algorithm was developed to map ontology concepts
to free text in clinical reports.

The mapping algorithm has an F-score of 0.874.

 

"Also known as Medical Entity Linking and Medical Concept Normalization

Some studies do not describe the application of NLP in

study’s methods. Therefore, we defined the following exclu-

their study by only listing NLP as the used method, instead _ sion criteria:
of describing its specific implementation. Additionally,
some studies create their own ontology to perform NLP
tasks, instead of using an established, domain-accepted

ontology. Both approaches limit the generalizability of the

e Implementation was not described
e Implementation does not use an existing established
ontology for encoding

Table 2 Induced objective categories with their definition and associated NLP task(s)
Induced NLP task(s)

Concept detection

 

Induced category Definition

 

Computer-assisted coding Perform semi-automated annotation (i.e., with a human in the loop)

Information comparison Concept detection Compare extracted structured information to information available in free-text form
Event detection

Relationship detection

Information enrichment Concept detection Extract structured information from free text and attach this new information to the source
Event detection

Relationship detection

Text normalization

Text summarization

Information extraction Concept detection Extract structured information from free text
Event detection

Relationship detection

Classification Use structured information to classify free-text reports, predict outcomes, or identify cases
Prediction

Identification

Prediction

Software development Develop new NLP software or evaluate new or existing NLP software

and evaluation

Software development
Software evaluation

Text normalization Transform free text into a new, more comprehensible form

Text summarization

Text processing

 
Page 5 of 21

14

(2020) 11

Kersloot et al. Journal of Biomedical Semantics

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

[Z7] SoA VA Aq pasn ‘saA (6 +0 |2A2|) SIWN MON ys||6u3 UMO WO SPJOIAI |eI!U!|D Papejas A|WWOpPUeY SIEMYOS VAC! :SHEd YSN vLOc PUA
(spedsqe jeuinof jed!ul|D uoljenjers
Youeas /\E>!160j01g) UO!D9]|09 S28} DHT‘, snduos pue

aINJeJaU| Ul Palpuap! (6unsixe BYVYS ‘. (OLOZ) snduod abuayjeys WA JUeUdojaAep uewuysn

[Or] SeaA siaded Jayjo ul pasn ‘sa, SIwn +) Mea ysijOuy = 6ulsixy /ZQZI ‘4 SNCIOD aseasip |GON ‘, edorsoig BIEMYOS O YSN ZLOZ -JaUWAaq
"SJ9JUDD |LDIIPSW JUDJALJIP UONDeIXS

[Sr] SoA De1S!| JON OdH Ma ysi|6u3 UMQ INOJ WOW eJeP JUalTed jes JO Sjas XIS UOMCUNOJU O YSN 6L0Z Yjolassiag
(Ounsixe suodal ssoiboud UOIDeIX9

[vv] pejs!| 10 pois!| JON SIWN +) Ma ysifuy — bulasixy pue saveuuns abseypsip jeudsoy UOEWUOJU (OLOZ) VA/ZQZ! epeue) LOC ufinig 3d
ODeUWeIBIA ysi|6uq UONDeI1Xe

[fy] apodopneasd Ul payuawWa|dul ‘So, VYGpew Mo + uelje}| UMQ = SUOda (SUOIDeaJ Hrup asiaApe) Ubasibi/ UOIJEUUOJU O Ajey 8107 IGWO>D
Alysi6a1 & ayejndod 0} (Bunsixe UO!DeX9

[Zr] pas] 10 pasn aq |IIM 1 ‘eA JO SIWnN +) Me ysi|Ouq UMO suodas Welbolpsed0yr UOIJEUUOJU O YSN S00Z Buny>
(6unsixe ABojolpei pue ‘Oude UO!De11X9

[Lv] psjsl| 10 pelsl| 10 SIWN +) Ma ysifouy — bulsixy ‘D4 ‘sauewuuns abseypsiq :e1eq 1D! UONeWUOJU (7 LOZ) |eAFWas YSN 9LOC Aapoy)
3|qeoi\dde (AbojoduO pue ‘ABojoiydau ‘Abojoyeday UONDeIXS

[or] 10 pa}sI| 10 SIWN  bunsix3 uel|e}| UMQ ‘ABo|OJegelp ‘ABo|o!psed) sayOu Jed!Ul|D UOMCUNOJU ON Ajey 9107 O}JaWUeIelYD
(Bunsixe juswWY US

[6¢] pals!| 10 pals!| 10 SIWN +) MeaN ysi|6uq UMQ -Ssejou ssauboid pue saueuuins abieydsiq UOIEUUOJU ON YSN 9LOZ uayD
a\qeadde uolDe11xe

[9¢] 10 palsi| 10 Siwn  6burnsix3 ysi|Ouq UMQ suodeal JuswUedep AdUusbhiaWF UOIJEUUOJU ON YSN vO00Z uewidey>
uolenjers
pue
jUaWCdO|aAsp

[Z€] Poys!| JON pois!| JON W-6-C)| MEN ys|fouz  Gunsix3 , d9sedep III DIWIN IEMYOS ON aN SLOc Bulpes
ajqeaidde UOMEUWUOJU! uonoexe

[9¢] JON pes!| ION ID GaWONS | bulsix4 ysiueds UMO JUPAJA1 JSOLW, UUM SA}OU ed!UI|D UOIEWUOJU| ON uleds OLOZ ose
ajqeaijdde bunsix3 < (0102) Jaselep e6ualjeys uonoexe

[S€] JON ON SIWN = Bulsixy ysfOuZ = + UMO VVC! pue selieuuns abieyrsiq UONPUUOJU| ON YSN SLOC uelog

sjuaijed |e}Da10|09

JO} aued Jo Ayenb (bunsixa J9DULD JEIDIJOJOD uonaeixe

[ve] pels!| JON PeAO0duu! 0} pa} ‘SoA SIWN +) MeN URLS UMO UMOU YIM S]Uaed JO SSJOU JedIUl|D UOIEWUOJU| ON Aueuea 6102 Jag
ajqeaijdde juawudojarap (UPWLUAD) STW uonaeixe

[e€] JON JEPUN IIIS ‘eA JO ‘(ysii6U3) 1 GAWONS — bulisix3 UeWUIEa — BUlIsIXy 2 (EL0Z) SNCIOD 4471D/eyVUS UONEUUOJU| ON Auewas) 9107 194999
peuue|d uonoexe

[7] ing ‘ON palsi| 10 1D GSWONS MAN ysi|6uz UMO SJ9}9] YNSUOD sed aAeI|ed UOIEWUOJU| ON YSN €L0Z yeueg

doo

pasiadns-uewny ul (UO!eZI|EWOU JUSWUY DUS

[L€] pals] ION 1) paquia 0} wile ‘Jah jo 40} 15-GAWONS) Gd! MON ysiueds UMO SJUSUUNIOP YHA UONeWUOJU| ON uleds gL0z exnly
a\qeadde JUSWUYDWUS

[og] JON pays|| 30 SIwn — bunsixg ysifouz — Hulys!xy , SAGIOD JHVOUSYg = ——-UONJUOJU| ON AN 9L0z IMezzeuly

3PoOd sDunos (WUONXY ‘1D
SVL -GAWONS ‘HS®W ‘DNIOT

O} SHUI ‘W609! / WD01G031 ‘OL = (6unsixe UONIexXo

[67] A|UO ‘ON paisi}ION = -GDd! ‘SDdDH ‘LdD) SIWN~—s ++) MON ysi|6uq UMOQ e1eq asnoyaseM e1eq Jed!ul|D UONEWUOJU| ON YSN 6L0Z JeUssy
apo> wa}sks abenbue; dAIDa{[qo

Jeu a21n0s asn u| *sKS “Wah pasn ejeq jasejeq ulbio eyeg pa2npu| abuayjeyD AyjunoD> sea), Joyiny

 

AMUNOD pue ‘A]U} UedA YOUINe Isulf Jay] Pue SUOHed]GNd papnydu| € ajqeL
Page 6 of 21

14

(2020) 11

Kersloot et al. Journal of Biomedical Semantics

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

ajqeaijdde Hunsixy sppensqe Yoda asey payyaqnd uoloexe
[79] JON P24sl| JON OdH  bunsix3 ys[UZ + UMC + SUONNIISU! JUSJAY!P LUO SBJOU |eI!Ul|D UO!NeUWUOJU| ON YSN 6L0C nV]
(bulsixe seseqeiep YHF OM)
[71] Pals! ION Pe1s!| 1ON LWWONXY '6-Gd1 ‘SIWN = +) MeN ysi|Ou3 UMO WO ejep paunjonuysun pue pains = UOHedIJISSe|D ON VSN 9LOZ uaJ6uly
VYdpew (6unsixe uoDelxe
[£9] pels!| JON P24Sl| JON ‘LD GAWONS ‘SIWN +) MEN ys||u3 UMQ SSJOU YHI UO!eWUOJU| ON YSN 6L0C ']
uoljnpoid oO} WJONXY = (6ulsixe S}S|| uosUedwos
[79] apodopneasd SAOW 0} SuR|d ‘9A JON ‘ID GEAWONS ‘SIWN s+) MEN ysi|Ouq UMQ —- UONDsaid aHJeydsIP Pue sajou jed!Ul|D UOHEWJOJU| ON YSN SLOZ 1
uoljenjers
pue
anjer (6unsixe juawdojarap
[19] pals] ION — Si! BAOId ©} sey |\Ns ‘O aiNJe|DUBWON-Uebul, +) Ma UPUUS5 UMO Apnijs ||-JSVg WO Siayje] eseydsiq BIEMYOS O Aueuwua 610 Huey
(Bunsixe UOI]DeX9
[09] SoA pals!| 10 ID GaWONS ~~ +) Me ysi|6u3 UMO sueyd JaduUeD Hun (|Jad |;eWS-UON) UO!EUNOJU ON spuevayleN 6102 JOo|s1ay
uolDe1xe
[6S] pels!| ION pa}SI| 10 SIWN ‘LaWoy Ma UedJOy UMQ saueuuuuns abieypsiq UOIEUUOJU O ePdIOY 6007 Huey
HSsew (6unsixe uoDelxe
[8S] pels!| JON P2s|| 10 ‘LD GAWONS ‘SIWN +) Me ys|fOuy  Gunsix3 g (CLOZ) snduod abualjeyd 7qZ! UO!EWUOJU (ZL0Z) 792! YSN €LOC |EPUIf
Buljas aed Aveuuud
[ZS] Pas!| JON Deals! ION Dd! ‘SIWN ‘LD-G3WONS Ma yang UMO 8 Ul Sjuaijed Jo sajou uol}e]|NSUC>D UOIDIPAd ON spueveayIeN SlOZ wWoopusbHooH
BHunseay juswWY US
[9S] apodopnasg /JUawdojeAap UI |IIIs ‘oO SIWwA  bunasixy ysi|6u3 UMO suodal abew! Abojolpey UO!EUNOJU O VSN L100 USI3H
Hulpoo
paysisse
[SS] polsl| JON P2}S!| 0 DI 'SIWN M2eN ysjouy — ulsix3 JOSeLEP |II-DIWIW -Jayndwo ON uouegs] L107 2M |2H
aqeadde UolDe11 x9
[7S] JON ajqeoijdde jo 1D GAWONS ‘SIWN Busi ys|fOuy  Gunsix3 z (€L0Z) sNdiod 44719 /eNVYS UO!eWUOJU| ON eeASNY 910C  YopezuesseH
ajqeaidde aseqeyep jed!uljD |euCHeU YA aU} WO
[eS] JON P2s|| 10 SIWN = bunsixy ys!|6uq UMO sueJajan UeIs!UeYOJy pue bel] Jo saION —_ UO!eDIJISSe|D ON YSN €LOC ple}
JUSWUYIUS Jezejes
[ZS] pals!| ION pals!| 10 W)-6-CD MeN ysiueds UMQ SpJOdaJ JUalTeEd WO} 1X9} DSoubeIG UO!EWNOJU| ON uleds €|0¢ PaYIIOI!ODH
Yd
SSGD e Olu! pelesbalu! ‘TDD ‘HSEW ‘DLV {LD SPlODaJ JeD!|PauW uoloexe
[1S] pels!| ION aq ||IM ‘eA JO GAWONS ‘WDD ‘01-dD MeN ydual4 UMQ juaswuedsp Ausbhiawea pezueIndwoy UONEWUOJU| ON aouel4 1102 JalQued
JUSWY DUS
[0S] Pas!| JON Pa}sI| 10 W)-6-dD MeN asenbnyod UMQ YH 24} WO saposida ynpe juaedu| UOIEWUOJU| ON leOnuod €102 ore
uolpelxe
[677] P2ls!| ON Pe}s!| 0 6-d) MON ysjoug — ulsix3 py sedep III DIWIW UONeUWUOsU| ON AN 6L0C sIJe4
SDURIII9AUNS asned
Yeap auul}-|eaJ Je8uU
JO} YyeaH Jo ANsiuly suodes Asdoyne JUSWUYIUS
[Sr] pals} 10N = asabnuod Aq pasn ‘sa, OL-dD| MeN aseanbnuod UMQ pue ‘SUIJaIING Jed/UI|D ‘SayedJWad YJeaq UO!EWNOJU| ON lebnucd gl0z aueng
uoljenjersd
ainqonuyseyu} Hulyndwo>y pue
pUue SIEWUOJU| sad} JUaWNDOP JUSNbealJ ISOWW ay} = JUBLUOjaAEP (OLOZ)
apo> wa}sks abenbue; dAIDa{[qo
Jeu 321N0S asn u} *sKs “Wa pasn ejeq jasejeq ulbio ejeg pa2npu| abuayjeyD AyjunoD sed) Joyiny

 

(panuljuoy) Aiyunod pue ‘aja Wesh YOY Ne Isulf Joy] PUe SUOHed|GNd pepnpu| € ajqeL
Page 7 of 21

14

(2020) 11

Kersloot et al. Journal of Biomedical Semantics

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

[£9] SoA snowed Aq pasn ‘so, SIwn MON ysi|6uy = + UMO VA/ZGZ! ay] WOY sevens abieydsiq BIEMYOS ZZ! ‘sued VSN 8LOz |eSAOS
uoloexe
[73] SoA Jah 10 1D GAWONS MeN ysiueds UMO suodal abieydsip ADuabHJewe |ed/UI|9 UONEWUOJU| O uleds 6102 OURLOS
a\qeadde JUSWUYDWUS
[Le] 1ON palsi| 10 Siwn  6burnsix3 ysi|Ouq UMQ sejou ssaiboud Auojejnquie Abojolpie> UOHEUNOJU| O YSN 3002 I]0S
uoDelxe
[og] SOA Pa}sI| 10 UJONXY M2N ysi|Ou3 UMQ —- SUO!IJUDW- UONLDII|PSW YM Sa}OU Jed!Ul|D UOIEWUOJU| O VSN LOZ UYOS
aqeadde UolDe11 x9
[62] JON P2s|| 10 1D GAWONS ‘SIWN Bushy ys!|6uy UMO syualed UOlsusadAY WO Se}OU YH UO!eWUOJU| O YSN 6L0C ||| QUBOYS
ajqeaijdde (v LOZ)
[11] JON Pe}s!| 0 SIWN = bulsix3 ys|6uz  Gunsix3 1, (LOZ) snduod abualjey> 7qz! — UONedIJIsse|> YYPSHLA/CAC! YSN SLOC SPEAIYS
Youeas
aiNjesayl| Ul Payuap! WJONXY (Bulsixe uoloexe
[82] SaQ Siaded Jayo ul pasn ‘sa, ‘1D GAWONS ‘SIWN +) Me ys!|6uq UMO AWA PY} Wolf SOJOU [EIIU![D JO JESQNS UONEWUOJU] — (8007 ‘9007) 747! YSN OLOC PAOARS
ajqeaidde xa71pey 1D peay panleda1 OyM saydepesdy uosUedwos
[ZZ] 10 palsl| 10 ‘ID GaWONS ‘SIWN ~ bul~Asixy ysi|Ou3 UMO UUM sjuaied JO} SiajUNODUS GJ UOIEWUOJU| O VSN 6L0Z neassnoy
(Ounsixe uolDeXxa
[9/] peIs!| 10 pe}s!| 10 6-G)| ‘SIWN +) Me ys|fOuy  Gunsix3 < (0L07Z) sndiod abualjey> vA/zqz! UONeUWUOJU| (OL0Z) VA/ZQ9Z! YSN LLOC SUaqoy
WJONXY (6uljsixe uolpelxe
[SZ] pels!| 10 P2lS!| JO ‘1D GAWONS ‘SIWN s+) Me ysjoug — ulsix3 9 (8002) sndiod abualjeyd 7qZ! UOIEWUOJU| Oo epeue) 8l0c inbaieay
saluue Hulsse.0ud
[rZ] palsl| 10 Pa}SI| 10 qa Ma ysiueds UMO papsjes Ajwopuel s[q snosue}uods xo] O uleds g10z Zal8d
uolDe1xe
[eZ] Pe}s|| }0 P2}S!| 0 1D GAWONS ‘SIWN Mo ys|fouz  Gunsix3 ¢ (OL0Z) sndiod abuayjey> VA/ZQ2! UO!EWUOJU| (0L0Z) WA/Z9Z! eyensny LLoc PLIed
z (€L0Z) STID/AYVHS “ (OL0Z)
a\qeaidde sndiod abualjeyd VA/ZZ! ‘UO WOJU! Uo}De11xe
[ZZ] JON Po4sl| JON SIWN — Bulasixq ysjouy — ulsix3 JEU2 JEd!UlD ‘spedsqe paywqnd UO!EWUOJU| ON AN SLO? YH||9Q
Bulpoo
(bulsixe palsisse
[LZ] Paasi| ION Parsi} ON ~=WY-OL-CdI ‘1D GAWONS +) MEN ys!|6uq UMO Sa]OU ssaiHoud je1dsoH ~JayndwoD ON eyeasny gloz UaAnBN
a|qeoi|dde asNOYyaleM e}ep uolae xe
[02] JON Pe}s!| 0 OdH ‘SIWN = Sulasixg ys!/6uy UMOQ JOJUD) [PIIU!|D HIN WO SOOU Jed!Ul|") UONEWUOJU| ON YSN 6L0C CIUSI|
(bulsixe uoDelxe
[69] P2ls!| ON P2s|| 10 SIWN +) MEN ys|fOuy  Gunsix3 < (OL0Z) sndiod abualjey> v/AV/z7qz! UONeUWUOJU| (OL0Z) VA/ZQ9Z! 92UeI4 LL LOC pJeuly\|
aINJONAYSeAJUI
Ydjeasead Ul UONeIHSjU! uoDelxe
[89] paasl| ION 3|qissod ‘aA Jo SIWwn MON ys|fOuy  Gunsix3 , (6002) iesejep abua|jeyd 7GZ! —-_ UONEWOJU (6002) @q2z! VSN OLOZ alyshol/\
ao1peid 1D. (bunsixe yun Jejndseaolpsed e Ul JUSWY DUS
[29] P2ls!| JON Ul Hulse} ‘Jah Jo CAWONS “(0 [9429]) SINN +) MEN ys!|6uq UMOQ — SqUaledU! YNpe WUOJ sJUSWWNDOP |ed!Ul| UO!NeUWUOJU| ON YSN 900¢ alishay\
sjeudsoy
ajdiyjnw ul yeafoid uo (bulsixe uoloexe
[99] pels!| JON HUPOM AjjUsUIND ‘Sax 1D GaWONS ‘SIWA s+) MON ysi|Ou3 UMO suodal Abojouyed UOIEWUOJU| ON VSN LOZ on]
a\qeadde uolDe11xe
[S9] JON Po4sl| JON 1D GAWONS ‘SIWN Bulsixg ys!|Oug UMO suodas Abojoyjed Uawu|Dads-a|6uls UONeUWUOJU| ON YSN 6002 amo]
apo> wa}sks abenbue; dAIDa{[qo
Jeu 321N0S asn u} *sKs “Wa pasn ejeq jasejeq ulbio ejeg pa2npu| abuayjeyD AyjunoD sed) Joyiny

 

(panuljuoy) Aiyunod pue ‘aja Wesh YOY Ne Isulf Joy] PUe SUOHed|GNd pepnpu| € ajqeL
Page 8 of 21

14

(2020) 11

Kersloot et al. Journal of Biomedical Semantics

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

[201] pos! JON JOYIO U! Paqudsap ‘so, ‘WUONXY “1D GSWONS Mo ys!j6u3 UMO sjuaned Gy pue ddOD SIEMYOS O YSN LLOC NOYZ
juawudojarap squle|duuoD uonaeixe
[LOU] pals] 1ON JapUN |S ‘ON SIWN Ma ys||6uy UMQ ysealq YM sjuaed Jo splodayY UO!EWNOJU| O YSN 9002 NOUzZ
(spelsge INIMIGAW) sndiod yIN3D uonaeixe
[001] pols!| JON pos!| JON SIWN Me ysijbuy = unsixy pue . (0L0Z) sndiod abuayjey> WAVZqZ! UONPUUOJU| O YSN ELC bueyz
(6unsixe syuodas ABojouyed
[66] pals!| ION pes!| ION SIWN +) Me ys!|6u3 UMQ  jea|Bins JaDUeD Jseaq PUe Sa}OU SSAIBOJg —- UONJEdIJISSe|D O YSN 8LOZ Hue7
(Bunsixe
[86] (HOS) ued pais! 1ON SIWn +) Me ysijOuy = unsixy 9, (80072) snduod abualjeyd 7QZ! UOND1Pad fe) VSN 6102 oe,
pUeWWLWOD
aul|
PURLUWUOD suodal
[/6] ‘SOK pals} 10 SIWN  bunsixg ys||6u3 UMO Hulbew! [> JuawWUedsp AuabhieWy UONDIPald O YSN €LOZ Aepey
a|qeoi|dde juawdojavap aseqejyep dAljeAad
[96] 10 Japun jas ‘O SIWN  bunsix3 ys||6uy UMQ DN@YIUAS BY} WO sased juaHed DYN —- UONJedyISSeID O YSN LLOZ nx
uonoexe
[S6] pejs!| 10 pe)sl| 10 OL-CD! ‘WD-6-CD! M2eN ysj6uz = Sunsixy , d9sedep III DIWIN UO!NeEWUOJU| O PUI) 6102 3lX
uonoexe
[v6] Pelsl| 10 pe)sl| 10 SIWN M2eN ys!j6u3 UMO YJ WO seys JusWyeo | UONEUWNOJU| O YSN 6102 JO/EM
a\qeadde
[€6] 10 pejsl| 10 SIWN ‘1D GAWONS = Bunsixy ys!j6u3 UMQ sUodal |} sey —- UO!JeIIJISSe|D) O YSN 8L0c PIDE\\
a|qeoi|dde SUOda Jed/UI|D JaYIO + Sa]OU JUaWUUeCdap
[76] 10 payst| 10 xaTpeY ‘1D GIWONS = BulsixJ ys!j6u3 UMO Auablate ‘suodes ABo|oIpey —_UO/eDIJISSe|D 0 VSN 6102 AOUIYDIYE/
Adewueyd
[16] pals] 10 yt asn 0} pedxe ‘Jah JO Ol-dD| MON asoueder UMO Wolf eyep AJO\siy UOIed1PaW IIUOI}D9|4 UONDIPald O ueder 98102 Insn
(Ounsixe uolDeXxa
[06] SoA pa}sI| 10 SIWN +) MeN ysijouy =Bunsixy < (0L0Z) sndiod abualjeys vAVzaZz! UONEWUOJU| O wuinibjeg 6107 sudy|N |
SUSIA JUaWUedap ADUsHJaWAa UONDeIXe
[68] pals!| ION pals!| 10 SIWN MAN ysi|6u3 UMQ JP JO} SAUJUS 3X9} JULE|AWOD JalyD UO!EWNOJU| O YSN 00Z SIOACL |
910¢ pue
[39] Pas!| JON Pa}SI| 10 WDD MAN Udual4 UMQ  SLOZ UseMjJeq USM suOdeas Adodsopuy — UO JedIJISSe|D O a0uel4 8l0z SIOUJ9 |.
(sayedyIUaD Yeap JO Hulpod
|eUo4olg (Ol-dD)) (6ulsixe OL-GdI) Dalds5 + (sjeqe| bruup vAWs UO!DENX9
[9] SoA Y4|S Ul ajgeylene ‘so, SaIBO|OUIWA SIWA s+) MAN yduel4 6uysixy + say peisge INIIGIW Yyous4) Deen UOIEWUOJU| ON a0uel4 8lOz Aelfpauydeud]
3|qeoi\dde UOIDeIX9
[98] JON pois!| JON SIWN = Bulsixy ys||Ou3 UMO SIV YUM sjuaied qjnpe jo sase> UO!NeEWUOJU| ON UeMIe| 8LOZ buns
sjuaned Janued UODeNXS
[Sg] SoA De1S!| JON 1D GSWONS MAN ysi|6u3 UMQ  ajejsoid pue jseaiq Jo sucdas ABojouled UONEWUOJU| ON YSN €L0Z SSNPS
xa pey (bunsixe UODeNXS
[v8] SOQ paisl| JON ‘NDGAW ‘SIWN SVWYL +) MeN ys||Ou3 UMO sjualed jo suodas |Yy)— UONELUOJU ON AN SLOZ pIseds
(7 LOZ)
UoHenjeAas — WAI-WAS ‘(€ LOZ)
saiique SJUBLUNDOP JEDIU!|D YOOW ‘S9]OU USIA DIUL|D pue 4471D/e4vUS
JeLASNpul pue suO!INyysuU! Hunsix3 yuaizedino '. (OL0Z) snduod abualjeyd uetudojansp ‘(OLOZ + 6002)
apo> wa}sks abenbue; dAIDa{[qo
Jeu a21n0s asn u| *sKS “Wah pasn ejeq jasejeq ulbio eyeg pa2npu| abuayjeyD AyjunoD> sea), Joyiny

 

(panuljuoy) Aiyunod pue ‘aja Wesh YOY Ne Isulf Joy] PUe SUOHed|GNd pepnpu| € ajqeL
Page 9 of 21

14

(2020) 11

Kersloot et al. Journal of Biomedical Semantics

sjuatjyed SJI}aqeIP JO SUOYOD 3214} WO S2}OU [eIIUI|D pasapso AjjeulpnyHuoy :(~LOZ) sndiod aHuayjeyr ZZ! “LL
sjuaijyed DNaqeip pue WYHIaMJaAO Jo SaeWLUNS abJeYSIP :(800Z) sNdiod abuajeyr Z7QZ! ‘OL

saeuiluns abseupsip jeydsoy palynuapl-ap :(600Z) Jesejep abuajeyd 7qZ! ‘6

saeuiuns abseupsip (7107) sndiod abuayjey> 7qZ! °g

SSEQEIEP || DIWIW FY} WO sajoU }xX9}-3aJJ [eEDIUI]D PayluUaplap :snduod ayyys *Z

speisqe pawqnd :sndiod aseasip |GON ‘9

sydedsqe dIJIJUBIDS JedIHOjOIG pue saded jin} jed1Hojolg ‘s}x9} do14 JedI|PAWW :sndiod adodsolg °¢

Ayjeyow pue ‘sodas bulbew! ‘sajou JaaiBbased ‘suoljedipaw ‘sainpadoid ‘sijnsai sa} Asoyesoge| ‘sjuawainseaw UBIs [eUA ‘sd1IydesHowap :}8Se3eP II|-DIWIW ‘V
syodai ssaiboud pue saueuiuuns abieydsip :(OL0Z) Jaseep aHuayjeyd WA/ZQZ! “€

SWOdad jed1/Ul]D aAIeUeU :(€ LOZ) SNdIOD 449D/ENVUS ‘Z

sapriUe ainjesa}l] Pue (SYHJ) SP1OIas YYeay DUOIDaja WO’ SOdas aAIyeUeU :sNdiOD 4HDOUDU “1

 

 

 

a|qeo\dde SaPOD2|0Y soeuiuns uolae xe
[E01] JON P24sl| ON L1H ‘1D GSAWONS = Oulsixg ys!|6u3 UMQ abseydsip PU Sa}OU UO!ss!LUpPY UONeUWUOsU| ON YSN vLOC NOYZ
uoljenjersd
sjas anjea pue
([E0L) Jaded L1H ‘GOW “Idd ‘SIWN juaudo|arep
apod wa}sks abenbue; dAIa{[qo
Jeu 321N0S asn u} *sKs “Wa pasn ejeq jasejeq ulbio ejeg pa2npu| abuayjeyD AyjunoD sed) Joyiny

 

(panuljuoy) Aiyunod pue ‘aja Wesh YOY Ne Isulf Joy] PUe SUOHed|GNd pepnpu| € ajqeL
Kersloot et al. Journal of Biomedical Semantics

(2020) 11:14

Table 4 Included publications and their evaluation methodologies

Page 10 of 21

 

 

 

 

Author Year Ref. std. Validation External Generalizability ° Ref

Afshar 2019 Existing EHR Hold-out validation (train, No No, validation is needed [29]
data test, development)

Alnazzawi 2016 Existing External ShARe/CLEF, NCBI disease, Yes, achieves competitive [30]
annotated Heart failure and pulmonary performance on other corpora
corpus embolism corpora

Atutxa 2018 Manual Hold-out validation (train, No Yes, easily portable to other [31]
retrospective test, development) languages
review

Barrett 2013 Manual 10-fold cross validation Multiple datasets (different Yes, expect that it is generalizable [32]
annotations provider)

Becker 2016 Existing Not used No Not listed [33]
annotated
corpus

Becker 2019 Manual Hold-out validation (train, No Not listed [34]
annotations test, development)

Bejan 2015 Manual External i2b2 data (2010) Yes, good performance on the [35]
annotations i2b2 dataset, even though not

optimized on it

Castro 2010 Manual Not used No Not listed [36]
annotations

Catling 2018 Existing Hold-out validation (train, No Not listed [37]
annotated test, development)
corpus

Chapman 2004 Manual Not used O Yes, generalizable to other domains [38]
annotations within and outside of bio surveillance

Chen 2016 Manual 10-fold cross validation O Not listed [39]
annotations

Chiaramello 2016 Manual Not used O Not listed [40]
annotations

Chodey 2016 Existing Hold-out validation (train, No Not listed [41]
annotated test)
corpus

Chung 2005 Manual Hold-out validation (train, Reports from a second Not listed [42]
annotations test) hospital

Combi 2018 Manual Not used No Not listed [43]
annotations

deBruijn 2011 Existing 15-fold cross validation No Not listed [44]
annotated
corpus

Deisseroth 2019 Manual Hold-out validation (train, Data from a second Yes, it can be immediately incorporated [45]
annotations test) hospital into clinical practice

Demner- 2017 Existing External Multiple datasets Not listed [46]

Fushman annotated
corpus

Divita 2014 Manual Not used No Not listed [47]
annotations

Duarte 2018 Manual Hold-out validation (train, Second dataset Not listed [48]
annotations test)

Falis 2019 Existing Hold-out validation (train, No Yes, method is not specific to an [49]
annotated test, development) ontology, and could be used for a graph
corpus of any formation

Ferrao 2013 Existing EHR Hold-out validation (train, No Not listed [50]
data test)

Gerbier 2011 Manual Hold-out validation (train, No Yes, it could also serve other types of [51]

annotations

test)

clinical decision support systems
Kersloot et al. Journal of Biomedical Semantics (2020) 11:14 Page 11 of 21

Table 4 Included publications and their evaluation methodologies (Continued)

 

 

 

 

Author Year Ref. std. Validation External Generalizability ° Ref

Goicoechea 2013 Manual Hold-out validation (train, No Not listed [52]

Salazar annotations test)

Hamid 2013 Manual 10-fold cross validation = No Possible, the classifier may be [53]
annotations applicable in academic hospital

samples

Hassanzadeh 2016 Existing Hold-out validation (train, No Not applicable [54]
annotated test)
corpus

Helwe 2017 Existing Hold-out validation (train, No Not listed [55]
annotated test, development)
corpus

Hersh 2001 Manual Hold-out validation (train, No Not listed [56]
annotations test)

Hoogendoorn 2015 Existing EHR 5-fold cross validation No Not listed [57]
data

Jindal 2013 Existing Hold-out validation (train, No Yes, broad applicability [58]
annotated test)
corpus

Kang 2009 Manual Hold-out validation (train, No Yes, extensible to other languages [59]
annotations test)

Kersloot 2019 Manual Hold-out validation O Possible, but external validation [60]
annotations (development, test) is needed

Konig 2019 Existing EHR Not used O Still to be tested [61]
data

Li 2015 Manual 10-fold cross validation O Not listed [62]
annotations

Li 2019 Existing Hold-out validation (train, No Not listed [63]
annotated test, development)
corpus

Lingren 2016 Manual Hold-out validation (train, No Not listed [12]
annotations test, development)

Liu 2019 Manual Not used No (but multiple datasets / No, limited because of NYP/CUIMC [64]
annotations non-trained) and Mayo notes.

Lowe 2009 Manual Hold-out validation (train, No Yes, has the potential to index other [65]
retrospective test) classes of clinical documents
review

Luo 2014 Existing EHR 10-fold cross validation No No, challenging, not currently working [66]
data on it

Meystre 2006 Manual Not used No Not listed [67]
retrospective
review

Meystre 2010 Existing Hold-out validation (train, No Not listed [68]
annotated test)
corpus

Minard 2011 Existing Hold-out validation (train, No Not listed [69]
annotated test, development)
corpus

Mishra 2019 Manual Not used No Not listed [70]
annotations

Nguyen 2018 Existing EHR Not listed No Not listed [71]
data

Oellrich 2015 Existing External Multiple datasets Not listed [72]
annotated
corpus

Patrick 2011 Existing 10-fold cross validation No Yes, adaptable to different requirements [73]
annotated in clinical information extraction and
Kersloot et al. Journal of Biomedical Semantics (2020) 11:14 Page 12 of 21

Table 4 Included publications and their evaluation methodologies (Continued)

 

 

 

 

 

 

Author Year Ref. std. Validation External Generalizability ° Ref
corpus classification by choosing relevant feature
sets
Pérez 2018 Existing Hold-out validation (train, No Yes, extensible to different hospital-sections [74]
annotated test, development) and hospitals
corpus
Redategui 2018 Existing Not used No Not listed [75]
annotated
corpus
Roberts 2011 Existing Hold-out validation (train, No Not listed [76]
annotated test)
corpus
Rousseau 2019 Manual Not used O Not listed [77]
annotations
Savova 2010 Manual 10-fold cross validation O Yes, implemented in several applications 78]
annotations
Shivade 2015 Manual Hold-out validation (train, No Not listed [11]
annotations test)
Shoenbill 2019 Manual Hold-out validation (train, No Yes, can allow further evaluation and [79]
annotations test) improvement in care delivery models
and treatment approaches to multiple
chronic illnesses
Sohn 2014 Manual Hold-out validation (train, No Yes, with adaptions: create flexible [80]
annotations test, development) mechanism for adaptation process
Solti 2008 Manual Hold-out validation (train, No Not listed [31]
annotations test)
Soriano 2019 Manual Not listed O Not listed [82]
annotations
Soysal 2018 Existing Hold-out validation (train, No Yes, can be used to quickly develop [83]
annotated test) customized clinical information extraction
corpus pipelines
Spasi¢ 2015 Manual Hold-out validation (train, No Not listed [84]
annotations test)
Strauss 2013 Manual Not used No Yes, can be shared between institutions [85]
annotations and used to support clinical +
epidemiological research
Sung 2018 Manual Not listed No Not listed [86]
annotations
Tchechmedjiev 2018 Existing Hold-out validation (train, No Yes, but not universally [87]
annotated test, development)
corpus
Ternois 2018 Existing EHR 5-fold cross validation + No Not listed [88]
data Hold-out validation (train,
test)
Travers 2004 Manual Not used No Not listed [89]
retrospective
review
Tulkens 2019 Existing Hold-out validation (train, No Not listed [90]
annotated test, development)
corpus
Usui 2018 Manual Not used O Not listed [91]
annotations
Valtchinov 2019 Manual Not used O No [92]
annotations
Wadia 2018 Manual Not used O Not listed [93]
annotations
Walker 2019 Manual Hold-out validation O Yes, it can be incorporated in [94]

 

 
Kersloot et al. Journal of Biomedical Semantics

(2020) 11:14

Table 4 Included publications and their evaluation methodologies (Continued)

Page 13 of 21

 

 

Author Year Ref. std. Validation External Generalizability ° Ref
retrospective (development, test) institutional data warehouse
review

Xie 2019 Existing Hold-out validation (train, No Not listed [95]
annotated test, development)
corpus

Xu 2011 Manual Hold-out validation (train, No Yes, generable approach to combine [96]
annotations test) information from heterogeneous data

sources in EHRs

Yadav 2013 Manual Not used No Yes, should be broadly applicate to [97]
annotations outcomes of clinical interest

Yao 2019 Existing Hold-out validation (train, No Not listed [98]
annotated test)
corpus

Zeng 2018 Manual 5-fold cross validation + No Yes, potential to be replicated [99]
annotations Hold-out validation (train,

test)

Zhang 2013 Existing External Two different sets with Yes, can be adapted to different [100]
annotated same settings semantic categories and text genres
corpus

Zhou 2006 Manual 5-fold cross validation No Not listed [101]
annotations

Zhou 2011 Manual Hold-out validation (train, No Not listed [102]
retrospective test)
review

Zhou 2014 Manual Not used No Not listed [103]

annotations

 

* As reported by authors

e Not published in a peer-reviewed journal (except for
ACL and ACM publications)

In the second phase, both reviewers excluded publica-
tions where the developed NLP algorithm was not evalu-
ated by assessing the titles, abstracts, and, in case of
uncertainty, the Method section of the publication. In the
third phase, both reviewers independently evaluated the
resulting full-text articles for relevance. The reviewers
used Rayyan [27] in the first phase and Covidence [28] in
the second and third phases to store the information
about the articles and their inclusion. In all phases, both
reviewers independently reviewed all publications. After
each phase the reviewers discussed any disagreement until
consensus was reached.

Data extraction and categorization
Both reviewers categorized the implementations of the found
algorithms and noted their characteristics in a structured
form in Covidence. The objectives of the included studies
and their associated NLP tasks were categorized by way of
induction. The results were compared and merged into one
result set.

We collected the following characteristics of the stud-
ies, based on a combination of TRIPOD [21], STROBE

[22], RECORD [23], and STARD [24] statement ele-
ments (see Additional file 3): year, country, setting, ob-
jectives, evaluation methods, used NLP systems or
algorithms, used terminology systems, size of datasets,
performance measures, reference standard, language of
the free-text data, validation methods, generalizability,
operational use, and source code availability.

List of recommendations

Based on the findings of the systematic review and ele-
ments from the TRIPOD, STROBE, RECORD, and
STARD statements, we formed a list of recommenda-
tions. The recommendations focus on the development
and evaluation of NLP algorithms for mapping clinical
text fragments onto ontology concepts and the reporting
of evaluation results.

Results

The literature search generated a total of 2355 unique
publications. After reviewing the titles and abstracts, we
selected 256 publications for additional screening. Out of
the 256 publications, we excluded 65 publications, as the
described Natural Language Processing algorithms in
those publications were not evaluated. The full text of the
remaining 191 publications was assessed and 114
Kersloot et al. Journal of Biomedical Semantics

Table 5 Characteristics of the included studies

(2020) 11:14

Page 14 of 21

 

 

 

 

 

Description n (%) References

Main objective

Information extraction 45 (58%) [29, 32-36, 38, 40-45, 49, 51, 58-60, 63-66, 68-70, 72, 73, 75,
76, 78-80, 82, 84-87, 89, 90, 94, 95, 100, 101, 103, 104]

Information enrichment 9 (12%) [30, 31, 39, 48, 50, 52, 56, 67, 81]

Classification 8 (10%) [11, 12, 53, 88, 92, 93, 96, 99]

Software development and evaluation 6 (7.8%) [37, 46, 47, 61, 83, 102]

Prediction 4 (5.2%) [57, 91, 97, 98]

Information comparison 2 (2.6%) [62, 77]

Computer-assisted coding 2 (2.6%) [55,71]

Text processing 1 (1.3%) [74]

Part of challenge

i2b2 10 (13%) [11, 44, 47, 58, 68, 69, 73, 76, 78, 83]

(Informatics for Integrating Biology and the

Bedside)

Entire system 8 (10%) [11, 44, 58, 68, 69, 73, 76, 78]

Parts of the system 2 (2.6%) [47, 83]

SemEval (Semantic Evaluation) 2 (2.6%) [41, 83]

Entire system 1 (1.3%) [41]

Parts of the system 1 (1.3%) [83]

ShARe/CLEF 1 (1.3%) [83]

(Shared Annotated Resources/Conference and

Labs of the Evaluation Forum)

Parts of the system 1 (1.3%) [83]

Dataset: language

English 60 (78%) [11, 12, 29, 30, 32, 35, 37-39, 41-47, 49, 53, 55, 56, 58,
60, 62-73, 75-81, 83-86, 89, 90, 92-104]

Spanish 5 (6.5%) [31, 36, 52, 74, 82]

French 3 (3.9%) [51, 87, 88]

German 3 (3.9%) [33, 34, 61]

Italian 2 (2.6%) [40, 43]

Portuguese 2 (2.6%) [48, 50]

Dutch 1 (1.3%) [57]

Japanese 1 (1.3%) [91]

Korean 1 (1.3%) [59]

Dataset: Origin

Data present in institute 55 (71%) [12, 29, 31, 32, 34-36, 38-40, 42, 43, 45, 47, 48, 50-53, 56, 57,
59-67, 70, 71, 74, 77-86, 88, 89, 91-94, 96, 97, 99, 101-103]

Existing dataset 25 (33%) [11, 30, 33, 35, 37, 41, 44, 46, 49, 55, 58, 64, 68, 69, 72, 73, 75,
76, 83, 87, 90, 95, 98, 100, 104]

Included reference to dataset 21 (27%) [11, 30, 35, 37, 41, 44, 46, 49, 55, 58, 64, 72, 75, 76, 83, 87, 90,
95, 98, 100, 104]

Training of algorithm

Trained 47 (61%) [11, 12, 29, 31, 32, 34, 37, 39, 41, 42, 44, 45, 48-53, 55-59, 62, 63,
65, 66, 68, 69, 73, 74, 76, 78-84, 87, 88, 90, 95, 96, 98, 99, 104]

Not listed 3 (3.9%) [30, 101, 102]

Development of algorithm

Use of development set 16 (21%) [12, 29, 31, 34, 37, 49, 55, 60, 63, 69, 74, 80, 87, 90, 94, 95]

Not listed

4 (5.2%)

[30, 82, 83, 101]
Kersloot et al. Journal of Biomedical Semantics

(2020) 1

1:14

Table 5 Characteristics of the included studies (Continued)

Page 15 of 21

 

 

 

Description n (%) References

Used NLP system or algorithm

New NLP system or algorithm 29 (38%) [31, 32, 37, 43, 45, 47-52, 55, 57, 59, 68, 73, 74, 80, 82, 83,
85, 88, 89, 91, 94, 95, 100-102]

New NLP system or algorithm with existing 25 (33%) [12, 29, 34, 39, 41, 42, 44, 46, 58, 60-63, 66, 67, 69, 71, 75,

components 76, 78, 84, 87, 90, 98, 99]

Existing NLP system or algorithm 23 (30%) [11, 30, 33, 35, 36, 38, 40, 53, 56, 64, 65, 70, 72, 77, 79, 81,
86, 93, 96, 97, 103, 104]

Use in practice

Plans to implement / still under development 12 (16%) (31, 33, 51, 56, 62, 66-68, 82, 91, 96, 101]

and testing

Implemented in practice 10 (13%) (34, 42, 43, 46-48, 78, 83, 87, 102]

Availability of code

Published algorithm or source code 15 (20%) [31, 45-47, 60, 78, 80, 82-85, 87, 90, 97, 98]

Pseudocode in manuscript 3 (3.9%) [43, 56, 62]

Planning to publish algorithm or source code 1 (1.3%) [32]

Not applicable, used an existing system 20 (26%) [11, 30, 33, 35, 36, 38, 40, 53, 64, 65, 70, 72, 77, 79, 81,
86, 93, 96, 103, 104]

publications did not meet our criteria, of which 3 publica- The induction process resulted in eight categories and

tions in which the algorithm was not evaluated, resulting ten associated NLP tasks that describe the objectives of
in 77 included articles describing 77 studies. Reference the papers: computer-assisted coding, information com-
checking did not provide any additional publications. The parison, information enrichment, information extraction,
PRISMA flow diagram is presented in Fig. 1.

Table 6 Evaluation methods of the included studies

prediction, software development and evaluation, and text

 

 

 

Description n (%) References

Evaluation: Reference standard

Manual annotations 40 (52%) [11, 12, 32, 34-36, 38-40, 42, 43, 45, 47, 48, 51-53, 56, 59, 60, 62, 64, 70, 77-82,
84-86, 91-93, 96, 97, 99, 101, 103]

Existing annotated corpus 24 (31%) [30, 33, 37, 41, 44, 46, 49, 55, 58, 63, 68, 69, 72-76, 83, 87, 90, 95, 98, 100, 104]

Existing EHR data 7 (9.1%) [29, 50, 57, 61, 66, 71, 88]

Manual retrospective review 6 (7.8%) [31, 65, 67, 89, 94, 102]

Evaluation: Validation

Hold-out validation 40 (52%) [11, 12, 29, 31, 34, 37, 41, 42, 45, 48-52, 55, 56, 58-60, 63, 65, 68, 69, 74, 76,
79-81, 83, 84, 87, 88, 90, 94-96, 98, 99, 102, 104]

Cross-validation 12 (16%) [32, 39, 44, 53, 57, 62, 66, 73, 78, 88, 99, 101]

External validation 9 (12%) [30, 32, 35, 42, 45, 46, 48, 72, 100]

Solely external validation 5 (6.5%) [30, 35, 46, 72, 100]

In addition to another type of validation 4 (5.2%) [32, 42, 45, 48]

Not performed or not listed 22 (29%) [33, 36, 38, 40, 43, 47, 61, 64, 67, 70, 71, 75, 77, 82, 85, 86, 89, 91-93, 97, 103]

Generalizability

Claimed 23 (30%) [30-32, 35, 38, 45, 49, 51, 58, 59, 65, 73, 74, 78-80, 83, 85, 87, 94, 96, 97, 100]

Externally validated 5 (6.5%) [30, 32, 35, 45, 100]

Comparison

Compared to other existing algorithms 24 (31%) [30, 35, 39, 45-47, 49, 58, 60, 63, 64, 72, 75, 80, 83, 87, 90, 94, 95, 98-101, 104]

or models

Tested difference in outcomes for statistical 4A (5.2%) [35, 39, 60, 63]

significance

 
Kersloot et al. Journal of Biomedical Semantics

(2020) 11:14

Table 7 Performance measures used in the included studies

Page 16 of 21

 

 

 

 

 

 

 

 

 

 

 

 

Description Formula n (%) References
Confusion Matrix Lists the True Positives (TP), True Negatives (TN), False 12 (16%) [34, 44, 47, 51, 56, 58, 60, 61, 84, 87, 91, 93]
Positives (FP), False Negatives (FN), and the Total (n)
amount in a 2 x 2 contingency Table.
TP: Text annotated with ontology concept when
ontology concept is present in reference standard
TN: Text not annotated with ontology concept when
ontology concept is absent in reference standard
FP: Text annotated with ontology concept when
ontology concept is absent in reference standard
FN: Text not annotated with ontology concept when
ontology concept is present in reference standard
Performance measures
Recall TE 68 (88%) [11, 12, 29-31, 33-53, 56-58, 60-64, 66-73, 75-88,
90-94, 96, 99-104]
Precision Pop 66 (86%) [11, 12, 29-31, 33-36, 38-51, 53, 56-58, 60-73, 75-88,
90, 91, 93, 94, 96, 99-104
]
F-score 2. plecsionRecat 57 (74%) [11, 12, 30, 31, 33-36, 39-41, 44, 46-50, 52, 53, 55,
57-63, 66-73, 75-80, 82-84, 86-88, 90, 91, 95, 96,
98-100, 102-104]
Accuracy Ty IN 11 (14%) [30, 32, 34, 41, 48, 52, 67, 74, 78, 92, 96]
Specificity Wo 6 (7.8%)  [29, 34, 85, 92, 93, 96]
AUC Not applicable 5 (6.5%) — [29, 39, 57, 95, 99]
Kappa Ps = =]-— a 3 (3.9%) [35, 89, 97}
Processing time Not applicable 3 (3.9%)  [32, 47, 83]
Negative Predictive Value aN 3 (3.9%)  [29, 85, 93]
False Positive Rate we 1 (1.3%) = [34]
False Negative Rate a 1 (1.3%) [34]
Information entropy —5>,P; log(Pi) 1(1.3%) [64]
. 0 ;
Mean Reciprocal Rank ae ane 1(1.3%) = [74]
Initial annotator agreement Not applicable 1 (1.3%) = [79]
Match/no match (%) Not applicable 1 (1.3%) [89]
Overgeneration po 1 (1.3%) = [93]
Undergeneration a 1 (1.3%) [68]
Error ae 1(1.3%) [68]
Fallout He 1 (1.3%) [68]
«2 0 r
Mean Standard Error Ly" (¥,-¥;) 1 (1.3%) [57]

 

processing. Our definitions of these NLP tasks and the as-
sociated categories are given in Table 1 and Table 2.

Table 3 lists the included publications with their first
author, year, title, and country. Table 4 lists the included
publications with their evaluation methodologies. The
non-induced data, including data regarding the sizes of
the datasets used in the studies, can be found as supple-
mentary material attached to this paper.

Table 5 summarizes the general characteristics of
the included studies and Table 6 summarizes the

evaluation methods used in these studies. In all 77
papers, we found twenty different performance mea-
sures (Table 7).

Discussion
In this systematic review, we reviewed the current state
of NLP algorithms that map clinical text fragments onto
ontology concepts with regard to their development and
evaluation, in order to propose recommendations for fu-
ture studies.
Kersloot et al. Journal of Biomedical Semantics (2020) 11:14

Main findings and recommendations

We identified 256 studies that reported on the devel-
opment of such algorithms, of which 68 did not
evaluate the performance of the system. We included 77
studies. Many publications did not report their findings in
a structured way, which made it challenging to extract all
the data in a reliable manner. We discuss our findings and
recommendations in the following five categories: Used
NLP systems and algorithms, Used data, Evaluation and
validation, Presentation of results, and Generalizability of
results. A checklist for determining if the recommenda-
tions are followed in the reporting of an NLP study is
added as supplementary material to this paper.

Used NLP systems and algorithms

A variety of NLP systems are used in the reviewed
studies. Researchers use existing systems (v= 29,
38%), develop new systems with existing components
(1=25, 33%), or develop a completely new system
(1 = 23, 30%). Most studies, however, do not publish
their (adapted) source code (1 =57, 74%), and a de-
scription of the algorithm in the final publication is
often not detailed enough to replicate it. To ensure
reproducibility, implementation details, including de-
tails on data processing, and preferably the source
code should be published, allowing other researchers
to compare their implementations or to reproduce
the results. Based on these findings, we formulated
three recommendations (Table 8).

Used data

Most authors evaluate their algorithms with manual annota-
tions (1 = 40, 52%) and use data present in their institutions
(1 =55, 71%). However, it is not clear what these datasets
consist of. Most studies describe the data as ‘reports’, ‘notes’,
or ‘summaries’, but do not list the contents or example rows
from the dataset. It is, therefore, not clear what types of pa-
tients and what specific types of data are included, making

Table 8 Recommendation regarding the use of systems and
algorithms

 

1. Describe the system or algorithm that is used or the system that is
developed for the specific NLP task.
1. When an existing NLP system or algorithm is used, describe how it
is set up, how it is implemented in practice, and if and how the
implementation differs from the original implementation.
2. When a new system is developed, describe the components and
features used in the system, and preferably include a flow chart that
explains how these elements work together.
2. Include the source code of the developed algorithm as
supplementary material to the publication or upload the source code to
a repository such as GitHub.
3. Specify which ontologies are used in the encoding task, including the
version of the ontology.
1. If a new ontology is developed for the encoding task, report on
the development and content of the ontology and rationale for the
development of a new ontology instead of the use of an existing
one. The MIRO guidelines could be used to structure the report [105].

 

Page 17 of 21

Table 9 Recommendation regarding the use of data

 

1. To ensure that new algorithms can be compared against your system,
aim to publish the used training, development, and validation data in a
data repository.
1. In case the data cannot be published, determine if the data can be
accessed on request or can be used in a federated learning approach
(i.e, a learning process in which the data owners collaboratively train
a model in which process any data owner does not expose the data
to others [107]).
2. In case a reference standard is used, include information about the
origin of the data (external dataset, subset of the dataset) and the
characteristics of the data in the dataset. If possible, reference the
dataset using a DOI or URL.
3. If an external dataset is used, give a short description of the data
present in the dataset and reference the source of the dataset.

 

 

the study hard to reproduce. Finally, we found a wide range
of dataset sizes and formats. The training datasets, for ex-
ample, ranged from 10 clinical notes to 636.439 discharge re-
ports. The use of small datasets can result in an overfitted
algorithm that either performs well on the dataset, but not
on an external dataset, or performs poorly, for the algorithm
was only trained on a specific type of data. More difficult rec-
ognition tasks require more data, and therefore sample size
planning is recommended [106]. To improve the description
and availability of datasets used in NLP studies, we formu-
lated three recommendations (Table 9).

Evaluation and validation

Evaluation of the algorithm determines its perform-
ance on the dataset, and validation determines if the
algorithm is not overfitted on that dataset and thus if
the algorithm might work on other datasets as well.
Over one-fourth of the studies (1=68, 27%) that we
identified did not evaluate their algorithms. In
addition, 22 included studies (29%) did not validate
the developed algorithm. A statement claiming that
an algorithm can be used in clinical practice can be
questioned if the algorithm has not been evaluated
and validated. Across all studies, 20 performance
measures were used. To harmonize evaluation and
validation efforts, we formulated three recommenda-
tions (Table 10).

Table 10 Recommendation regarding the evaluation and
validation of Natural Language Processing algorithms

 

1. Perform an evaluation using generic (i.e., precision, recall, and F-score)
performance measures and appropriate aspects of evaluation including
discrimination, calibration, and preferably accuracies of predictions (e.g.,
AUC, calibration graphs, and the Brier score).
1. Include a motivation for the choice of measures, with references to
existing literature where appropriate (e.g., Sokolova and Lapalme'’s
analysis of performance measures [108]).
2. Perform an error analysis and discuss the errors in the Discussion
section of the paper. Include possible changes to the algorithm that
could improve its performance for these specific errors.
3. When using a non-probabilistic NLP method: determine the cut-off
value (a priori) for a ‘good’ test result before evaluating the algorithm.
Elaborate why this cut-off value is chosen.

 

 
Kersloot et al. Journal of Biomedical Semantics (2020) 11:14

Presentation of results

Authors report the evaluation results in various formats.
Only twelve articles (16%) included a confusion matrix
which helps the reader understand the results and their
impact. Not including the true positives, true negatives,
false positives, and false negatives in the Results section of
the publication, could lead to misinterpretation of the re-
sults of the publication’s readers. For example, a high F-
score in an evaluation study does not directly mean that
the algorithm performs well. There is also a possibility
that out of 100 included cases in the study, there was only
one true positive case, and 99 true negative cases, indicat-
ing that the author should have used a different dataset.
Results should be clearly presented to the user, preferably
in a table, as results only described in the text do not pro-
vide a proper overview of the evaluation outcomes
(Table 11). This also helps the reader interpret results, as
opposed to having to scan a free text paragraph. Most
publications did not perform an error analysis, while this
will help to understand the limitations of the algorithm
and implies topics for future research.

Generalizability of results

88% of the studies did not perform external validation
(1 = 68). Of the studies that claimed that their algorithm
was generalizable, only 22% (m= 5) assessed this claim
through external validation. However, one cannot claim
generalizability without testing for it. Moreover, in 19%
(1 =3) of the cases where external datasets were used,
the datasets were not referenced and only listed in the
text of the article, making it harder to find the used data
and reproduce the results. Algorithm performance
should be compared to that of other state-of-the-art al-
gorithms, as this helps the reader decide whether the
new algorithm could be considered useful for clinical
practice. However, only 24 studies (31%) made this com-
parison, and four of those studies (17%) tested the per-
formance difference for statistical significance. We also
found that the authors’ descriptions of generalizability are
rather ambiguous and unclear. We formulated five recom-
mendations regarding the generalizability of results
(Table 12).

Table 11 Recommendation regarding the presentation of
results

 

1. Report the outcomes of the evaluation in a clear manner, preferably
in a table accompanied by a textual description of the outcomes.
1. Aim to include a confusion matrix in the reporting of the
outcomes.
2. Use figures if they contribute to the making the results more readable
and understandable for the reader. If a figure is used, make sure that
the data is also available in the text or in a table.

 

Page 18 of 21

Table 12 Recommendation regarding the generalizability of
results

 

1. Compare the results of the evaluated algorithm with other algorithms
by using the same dataset as reported in the publication of the other
algorithm or by processing the same dataset with another algorithm
available through the literature. Report the outcomes of both
experiments and test for statistical significance.

2. Describe in what setting the research is performed. Include if the
research is part of a challenge (e.g,., i2b2 challenge), or that the research
is carried out in a specific institute or department.

3. Before claiming generalizability, perform external validation by testing
the algorithm on a different, external dataset from other research
projects or other publicly available datasets. Aim to use a dataset with a
different case mix, different individuals, and different types of text.

4. Determine and describe if there are potential sources of bias in data
selection, data use by the NLP algorithm or system, and evaluation.

5. When claiming generalizability, clearly describe the conditions under
which the algorithm can be used in a different setting. Describe for
which population, domain, and type and language of data the
algorithm can be used.

 

 

 

Strengths

Our study has three main strengths: First, to our
knowledge, this is the first systematic review that fo-
cuses on the evaluation of NLP algorithms in medi-
cine. Second, we used a large number of databases
for our search, resulting in publications from many
different sources, such as medical journals and com-
puter science conferences. Third, we used existing
statements and guidelines and harmonized them to
induce our findings and used these findings to
propose a list of recommendations.

Limitations

Several limitations of our study should be noted as
well. First, we only focused on algorithms that evalu-
ated the outcomes of the developed algorithms. Sec-
ond, the majority of the studies found by our
literature search used NLP methods that are not con-
sidered to be state of the art. We found that only a
small part of the included studies was using state-of-
the-art NLP methods, such as word and graph em-
beddings. This indicates that these methods are not
broadly applied yet for algorithms that map clinical
text to ontology concepts in medicine and that future
research into these methods is needed. Lastly, we did
not focus on the outcomes of the evaluation, nor did
we exclude publications that were of low methodo-
logical quality. However, we feel that NLP publica-
tions are too heterogeneous to compare and _ that
including all types of evaluations, including those of
lesser quality, gives a good overview of the state of
the art.

Conclusion
In this study, we found many heterogeneous ap-
proaches to the development and evaluation of NLP
Kersloot et al. Journal of Biomedical Semantics (2020) 11:14

algorithms that map clinical text fragments to ontol-
ogy concepts and the reporting of the evaluation re-
sults. Over one-fourth of the publications that report
on the use of such NLP algorithms did not evaluate
the developed or implemented algorithm. In addition,
over one-fourth of the included studies did not per-
form a validation and nearly nine out of ten studies
did not perform external validation. Of the studies
that claimed that their algorithm was generalizable,
only one-fifth tested this by external validation. Based
on the assessment of the approaches and _ findings
from the literature, we developed a list of sixteen rec-
ommendations for future studies. We believe that our
recommendations, along with the use of a generic
reporting standard, such as TRIPOD, STROBE, REC-
ORD, or STARD, will increase the reproducibility and
reusability of future studies and algorithms.

Supplementary Information
Supplementary information accompanies this paper at https://doi.org/10.
1186/s13326-020-00231-2z.

Additional file 1.

Additional file 2.
Additional file 3.

 

Abbreviations

ACL: Association for Computational Linguistics; ACM: Association for
Computing Machinery; EHR: Electronic Health Record; FN: False Negatives;
FP: False Positives; HPO: Human Phenotype Ontology; NLP: Natural Language
Processing; PRISMA: Preferred Reporting Items for Systematic reviews and
Meta-Analyses; TN: True Negatives; TP: True Positives

Acknowledgements
Not applicable.

Authors’ contributions

Study conception and design: MK, RC, DA, and AA. Acquisition of data: FP
and MK. Analysis and interpretation of data: FP and MK. Drafting of
manuscript: MK. Critical revision: RC, DA, and AA. All authors read and
approved the final manuscript.

Funding
This work was supported by Castor EDC and the European Regional
Development Fund (ERDF).

Availability of data and materials
All data generated or analysed during the study are included in this
published article and its supplementary information files.

Ethics approval and consent to participate
Not applicable.

Consent for publication
Not applicable.

Competing interests
The authors declare that they have no competing interests.

Page 19 of 21

Received: 17 July 2020 Accepted: 3 November 2020
Published online: 16 November 2020

References

1. Ford E, Nicholson A, Koeling R, Tate AR, Carroll J, Axelrod L, et al. Optimising
the use of electronic health records to estimate the incidence of
rheumatoid arthritis in primary care: what information is hidden in free text?
BMC Med Res Methodol. 2013;13.

2. Rosenbloom ST, Denny JC, Xu H, Lorenzi N, Stead WW, Johnson kB. Data
from clinical notes: a perspective on the tension between structure and
flexible documentation. J Am Med Informatics Assoc. 2011;18:181-6.

3. Coorevits P, Sundgren M, Klein GO, Bahr A, Claerhout B, Daniel C, et al.

Electronic health records: new opportunities for clinical research. J Intern

Med. 2013;274:547-60.

4. Danciu |, Cowan JD, Basford M, Wang X, Saip A, Osgood S, et al.

Secondary use of clinical data: the Vanderbilt approach. J Biomed

nform. 2014;52:28-35.

5. Price SJ, Stapley SA, Shephard E, Barraclough K, Hamilton WT. Is omission of
free text records a possible source of data loss and bias in clinical practice
research Datalink studies? A case-control study. BMJ Open. 2016;6.

6. Gruber TR. A translation approach to portable ontology specifications.
Knowl Acquis. 1993;5:199-220.

7. SNOMED International. SNOMED CT http://www.snomed.org/snomed-ct/
five-step-briefing. Accessed 29 Jun 2020.

8. Kohler S, Carmody L, Vasilevsky N, Jacobsen JOB, Danis D, Gourdine JP, et al.
Expansion of the human phenotype ontology (HPO) knowledge base and
resources. Nucleic Acids Res. 2019;47:D1018-27.

9. Krasowski M, Schriever A, Mathur G, Blau J, Stauffer S, Ford B. Use of a data
warehouse at an academic medical center for clinical pathology quality
improvement, education, and research. J Pathol Inform. 2015;6:45.

10. Wu H, Toti G, Morley KI, Ibrahim ZM, Folarin A, Jackson R, et al. SemEHR: a
general-purpose semantic search system to surface semantic data from
clinical notes for tailored care, trial recruitment, and clinical research. J Am
Med Inf Assoc. 2018;25:530-7.

11. Shivade C, Malewadkar P, Fosler-Lussier E, Lai AM. Comparison of UMLS

terminologies to identify risk of heart disease using clinical notes. J Biomed

nform. 2015;58:S103-10.

12. Lingren T, Thaker V, Brady C, Namjou B, Kennebeck S, Bickel J, et al.

Developing an algorithm to detect early childhood obesity in two tertiary

pediatric medical centers. Appl Clin Inform. 2016;7(3):693-706.

13. Ni Y, Kennebeck S, Dexheimer JW, McAneney CM, Tang H, Lingren T, et al.
Automated clinical trial eligibility prescreening: increasing the efficiency of
patient identification for clinical trials in the emergency department. J Am
Med Informatics Assoc. 2015;22:166-78.

14. Sun H, Depraetere K, De Roo J, Mels G, De Vloed B, Twagirumukiza M, et al.
Semantic processing of EHR data for clinical research. J Biomed Inform.
2015;58:247-59.

15. Kreimeyer K, Foster M, Pandey A, Arya N, Halford G, Jones SF, et al. Natural
language processing systems for capturing and standardizing unstructured
clinical information: a systematic review. J Biomed Inf. 2017;73:14-29.

16. Gonzalez-Hernandez G, Sarker A, O'Connor K, Savova G. Capturing the
Patient's perspective: a review of advances in natural language processing
of health-related text. Yearb Med Inf. 2017;26:214-27.

17. Jovanovic J, Bagheri E, Jovanovié J, Bagheri E, Jovanovic J, Bagheri E, et al.
Semantic annotation in biomedicine: the current landscape. J Biomed
Semant. 2017;8:44.

18. UK EQUATOR Centre. The EQUATOR Network. https://www.equator-network.
org/. Accessed 29 Jun 2020.

19. Ford E, Carroll JA, Smith HE, Scott D, Cassell JA. Extracting information from
the text of electronic medical records to improve case detection: a
systematic review. J Am Med Informatics Assoc. 2016;23:1007-15.

20. Vuokko R, Makela-Bengs P, Hypponen H, Lindqvist M, Doupi P, Makela-
Bengs P, et al. Impacts of structuring the electronic health record: results of
a systematic literature review from the perspective of secondary use of
patient data. Int J Med Inform. 2017;97:293-303.

21. Collins GS, Reitsma JB, Altman DG, Moons KGM, TRIPOD Group. Transparent
reporting of a multivariable prediction model for individual prognosis or
diagnosis (TRIPOD): the TRIPOD statement. TRIPOD Group Circ. 2015;131:211-9.

22. von Elm E, Altman DG, Egger M, Pocock SJ, Gatzsche PC, Vandenbroucke
JP. The strengthening the reporting of observational studies in

 

 

 
Kersloot et al. Journal of Biomedical Semantics

23.

24.

25.

26.

2/7.

28.

29.

30.

32.

33.

34,

35,

36.

37.

38.

39.

40.

42.

43.

AA,

45.

46.

(2020) 11:14

epidemiology (STROBE) statement: guidelines for reporting observational
studies. J Clin Epidemiol. 2008;61:344-9.

Benchimol El, Smeeth L, Guttmann A, Harron K, Moher D, Peteresen | et al.
The REporting of studies Conducted using Observational Routinely-
collected health Data (RECORD) Statement. PLoS Med. 2015;12:1-22.
Bossuyt PM, Reitsma JB, Bruns DE, Gatsonis CA, Glasziou PP, Irwig L, et al.
STARD 2015: an updated list of essential items for reporting diagnostic
accuracy studies. BMJ. 2015;351:h5527,

Moher D, Liberati A, Tetzlaff J, Altman DG, Altman D, Antes G et al. Preferred
reporting items for systematic reviews and meta-analyses: The PRISMA
statement. PLoS Med. 2009;6:1-6.

The EndNote Team. EndNote. Philadelphia: Clarivate; 2013.

Ouzzani M, Hammady H, Fedorowicz Z, Elmagarmid A. Rayyan—a web and
mobile app for systematic reviews. Syst Rev. 2016;5:210.

Veritas Health Innovation. Covidence systematic review software.
Melbourne: Veritas Health Innovation; 2020.

Afshar M, Dligach D, Sharma B, Cai X, Boyda J, Birch S, et al. Development and
application of a high throughput natural language processing architecture to
convert all clinical documents in a clinical data warehouse into standardized
medical vocabularies. J Am Med Inform Assoc. 2019;26:1364-9.

Alnazzawi N, Thompson P, Ananiadou S. Mapping Phenotypic Information
in Heterogeneous Textual Sources to a Domain-Specific Terminological
Resource. PLoS One. 2016;11(9):e0162287.

Atutxa A, Perez A, Casillas A. Machine Learning Approaches on Diagnostic
Term Encoding with the ICD for Clinical Documentation. IEEE J Biomed Heal
Informatics. 2018;22(4):1323-9,

Barrett N, Weber-Jahnke JH, Thai V. Engineering natural language
processing solutions for structured information from clinical text: extracting
sentinel events from palliative care consult letters. Stud Health Technol
nform. 2013;192:594-8,

Becker M, Bockmann B. Extraction of UMLS(R) Concepts Using Apache cTAKES
for German Language. Stud Health Technol Inform. 2016;223:PG-71-6.

Becker M, Kasper S, Bockmann B, Jockel K-H, Virchow |. Natural language
processing of German clinical colorectal cancer notes for guideline-based
treatment evaluation. Int J Med Inform. 2019;127:141-6.

Bejan CA, Wei WQ, Denny JC. Assessing the role of a medication-indication
resource in the treatment relation extraction from clinical text. J Am Med
nformatics Assoc. 2015;22:e162-76.

Castro E, Iglesias A, Martinez P, Castaho L. Automatic Identification of
Biomedical Concepts in Spanish-language Unstructured Clinical Texts.
German Research Cent for Artificial, Intelligence - DFKI GmbH,
Kaiserslautern, Germany Seattle, WA, USA: ACM; 2010. p. 751-7.

Catling F, Spithourakis GP, Riedel S. Towards automated clinical coding. Int J
Med Inform. 2018;120:50-61.

Chapman WW, Fiszman M, Dowling JN, Chapman BE, Rindflesch TC.
Identifying respiratory findings in emergency department reports for
biosurveillance using MetaMap. Medinfo. 2004;11:487-91.

Chen J, Zheng J, Yu H. Finding Important Terms for Patients in Their
Electronic Health Records: A Learning-to-Rank Approach Using Expert
Annotations. JMIR Med informatics. 2016;4(4):e40.

Chiaramello E, Pinciroli F, Bonalumi A, Caroli A, Tognola G. Use of “off-the-shelf”
information extraction algorithms in clinical informatics: A feasibility study of
MetaMap annotation of Italian medical notes. J Biomed Inform. 2016;63:22-32.
Chodey KP, Hu G. Clinical text analysis using machine learning methods. In:
2016 IEEE/ACIS 15th International Conference on Computer and
Information Science (ICIS); 2016. p. 1-6.

Chung J, Murphy S. Concept-value pair extraction from semi-structured
clinical narrative: a case study using echocardiogram reports. AMIA Annu
Symp Proc. 2005:131-5.

Combi C, Zorzi M, Pozzani G, Moretti U, Arzenton E. From narrative
descriptions to MedDRA: automagically encoding adverse drug reactions. J
Biomed Inform. 2018;84:184-99.

de Bruijn B, Cherry C, Kiritchenko S, Martin J, Zhu X. Machine-learned
solutions for three stages of clinical information extraction: The state of the
art at i2b2 2010. J Am Med Informatics Assoc. 2011;18(5):557-62.

Deisseroth CA, Birgmeier J, Bodle EE, Kohler JN, Matalon DR, Nazarenko Y, et al.
ClinPhen extracts and prioritizes patient phenotypes directly from medical
records to expedite genetic disease diagnosis. Genet Med. 2019;21:1585-93.
Demner-Fushman D, Rogers WJ, Aronson AR. MetaMap Lite: An evaluation
of a new Java implementation of MetaMap. J Am Med Informatics Assoc.
201 7;24(4):841-4.

 

 

47.

48.

49.

50.

52.

53.

54,

55,

56.

57.

58.

59.

60.

62.

63.

64,

65,

66.

6/7.

68.

Page 20 of 21

Divita G, Zeng QT, Gundlapalli AV, Duvall S, Nebeker J, Samore MH. Sophia:
A Expedient UMLS Concept Extraction Annotator. AMIA Annu Symp Proc.
2014;2014:467-76.

Duarte F, Martins B, Pinto CS, Silva MJ. Deep neural models for ICD-10
coding of death certificates and autopsy reports in free-text. J Biomed
nform. 2018;80:64-77.

Falis M, Pajak M, Lisowska A, Schrempf P, Deckers L, Mikhael S, et al.
Ontological attention ensembles for capturing semantic concepts in ICD
code prediction from clinical text; 2019. p. 168-77.

Ferrao JC, Janela F, Oliveira MD, HMG M. Using Structured EHR Data and
SVM to Support ICD-9-CM Coding. In: 2013 IEEE International Conference on
Healthcare Informatics; 2013. p. 511-6.

Gerbier S, Yarovaya O, Gicquel Q, Millet A-L, Smaldore V, Pagliaroli V, et al.
Evaluation of natural language processing from emergency department
computerized medical records for intra-hospital syndromic surveillance.
BMC Med Inform Decis Mak. 2011;11:50.

Goicoechea Salazar JA, Nieto Garcia MA, Laguna Téllez A, Canto Casasola
VD, Rodriguez Herrera J, Murillo CF. Development of an automated coding
system to retrieve and analyze diagnostic information stored in hospital
emergency department records. Emergencias. 2013;25(6):430-6.

Hamid H, Fodeh SJ, Lizama AG, Czlapinski R, Pugh MJ, LaFrance WC Jr, et al.
Validating a natural language processing tool to exclude psychogenic
nonepileptic seizures in electronic medical record-based epilepsy research.
Epilepsy Behav. 2013;29:578-80.

Hassanzadeh H, Kholghi M, Nguyen A, Chu K. Clinical document
classification using labeled and unlabeled data across hospitals. AMIA .
Annu Symp proceedings AMIA Symp. 2018;2018:545-54.

Helwe C, Elbassuoni S, Geha M, Hitti E, Makhlouf OC. CCS Coding of
Discharge Diagnoses via Deep Neural Networks. German Research Cent for
Artificial, Intelligence - DFKI GmbH, Kaiserslautern, Germany Seattle, WA,
USA: ACM; 2017. p. 175-9.

Hersh W, Mailhot M, Arnott-Smith C, Lowe H. Selective automated indexing of
findings and diagnoses in radiology reports. J Biomed Inform. 2001;34(4):262-73.
Hoogendoorn M, Szolovits P, Moons LMG, Numans ME. Utilizing uncoded
consultation notes from electronic medical records for predictive modeling
of colorectal cancer. Artif Intell Med. 2015;69:53-61.

Jindal P, Roth D. Extraction of events and temporal expressions from clinical
narratives. J Biomed Inform. 2013;46:S13-9.

Kang BY, Kim DW, Kim HG. Two-phase chief complaint mapping to the
UMLS metathesaurus in Korean Electronic Medical Records. IEEE Trans Inf
Technol Biomed. 2009;13(1):78-86.

Kersloot MGMG, Lau F, Abu-Hanna A, Arts DLDL, Cornet R. Automated
SNOMED CT concept and attribute relationship detection through a web-
based implementation of cTAKES. J Biomed Semantics. 2019;10:14.
Konig M, Sander A, Demuth |, Diekmann D, Steinhagen-Thiessen E.
Knowledge-based best of breed approach for automated detection of
clinical events based on German free text digital hospital discharge letters.
PLoS One. 2019;14:e0224916.

Li Q, Spooner SA, Kaiser M, Lingren N, Robbins J, Lingren T, et al. An end-to-
end hybrid algorithm for automated medication discrepancy detection.
BMC Med Inform Decis Mak. 2015;15:37.

Li F, Jin Y, Liu W, Rawat BPS, Cai P, Yu H. Fine-tuning bidirectional encoder
representations from transformers (BERT)-based models on large-scale
electronic health record notes: an empirical study. JMIR Med informatics.
2019;7:e 14830.

Liu C, Ta CN, Rogers JR, Li Z, Lee J, Butler AM, et al. Ensembles of natural
anguage processing systems for portable phenotyping solutions. J Biomed
nform. 2019;100:103318.

Lowe HJ, Huang Y, Regula DP. Using a statistical natural language Parser
augmented with the UMLS specialist lexicon to assign SNOMED CT codes
to anatomic sites and pathologic diagnoses in full text pathology reports.
AMIA Annu Symp Proc. 2009;2009:386-90.

Luo Y, Sohani AR, Hochberg EP, Szolovits P. Automatic lymphoma
classification with sentence subgraph mining from pathology reports. J Am
Med Informatics Assoc. 2014;21(5):824-32.

Meystre S, Haug PJ. Natural language processing to extract medical
problems from electronic clinical documents: performance evaluation. J
Biomed Inform. 2006;39(6):589-99,

Meystre SM, Thibault J, Shen S, Hurdle JF, South BR. Automatically detecting
medications and the reason for their prescription in clinical narrative text
documents. Stud Health Technol Inform. 2010;160(Pt 2):944-8.

 

 

 

 

 
Kersloot et al. Journal of Biomedical Semantics

69.

70.

72.

73.

74,

75,

76.

77.

78.

79.

80.

82.

83.

84.

85.

86.

87.

88.

89.

90.

(2020) 11:14

Minard AL, Ligozat AL, Abacha AB, Bernhard D, Cartoni B, Deléger L, et al.
Hybrid methods for improving information access in clinical documents:
Concept, assertion, and relation identification. J Am Med Informatics Assoc.
2011;18(5):588-93.

Mishra R, Burke A, Gitman B, Verma P, Engelstad M, Haendel MA, et al. Data-
driven method to enhance craniofacial and oral phenotype vocabularies. J
Am Dent Assoc. 2019;150:933-9 e2.

Nguyen AN, Truran D, Kemp M, Koopman B, Conlan D, O'Dwyer J, et al.
Computer-assisted diagnostic coding: effectiveness of an NLP-based
approach using SNOMED CT to ICD-10 mappings. AMIA . Annu Symp
proceedings AMIA Symp. 2018;2018:807-16.

Oellrich A, Collier N, Smedley D, Groza T. Generation of silver standard
concept annotations from biomedical texts with special relevance to
phenotypes. PLoS One. 2015;10(1):e0116040.

Patrick JD, Nguyen DHM, Wang Y, Li M. A knowledge discovery and reuse
pipeline for information extraction in clinical notes. J Am Med Informatics
Assoc. 2011;18(5):574-9.

Pérez A, Atutxa A, Casillas A, Gojenola K, Sellart A. Inferred joint multigram
models for medical term normalization according to ICD. Int J Med Inform.
2018;110:111-7.

Reategui R, Ratté S. Comparison of MetaMap and cTAKES for entity
extraction in clinical notes. BMC Med Inform Decis Mak. 2018;18(Suppl 3):74.
Roberts K, Harabagiu SM. A flexible framework for deriving assertions from
electronic medical records. J Am Med Informatics Assoc. 2011;18(5):568-73.
Rousseau JF, lp IK, Raja AS, Valtchinov VI, Cochon L, Schuur JD, et al. Can
automated retrieval of data from emergency department physician notes
enhance the imaging order entry process? Appl Clin Inform. 2019;10:189-98.
Savova GK, Masanz JJ, Ogren PV, Zheng J, Sohn S, Kipper-Schuler KC, et al.
Mayo clinical text analysis and knowledge extraction system (cTAKES):
architecture, component evaluation and applications. J Am Med Informatics
Assoc. 2010;17:507-13.

Shoenbill K, Song Y, Gress L, Johnson H, Smith M, Mendonca EA. Natural
language processing of lifestyle modification documentation. Health
Informatics J. 2019:1460458218824742.

Sohn S, Clark C, Halgrim SR, Murphy SP, Chute CG, Liu H. MedXN: An open
source medication extraction and normalization tool for clinical text. J Am
Med Informatics Assoc. 2014;21(5):858-65.

Solti |, Aaronson B, Fletcher G, Solti M, Gennari JH, Cooper M, et al. Building
an automated problem list based on natural language processing: lessons
learned in the early phase of development. AMIA Annu Symp Proc. 2008;
2008:687-91.

Soriano IM, Pena JLC, Breis JTF, Roman IS, Barriuso AA, Baraza DG.
Snomed2Vec: Representation of SNOMED CT Terms with Word2Vec. In:
2019 IEEE 32nd International Symposium on Computer-Based Medical
Systems (CBMS); 2019. p. 678-83.

Soysal E, Wang J, Jiang M, Wu Y, Pakhomov S, Liu H, et al. CLAMP - a toolkit
for efficiently building customized clinical natural language processing
pipelines. J Am Med Informatics Assoc. 2018;25(3):331-6.

Spasi¢ |, Zhao B, Jones CB, Button K. KneeTex: An ontology-driven system
for information extraction from MRI reports. J Biomed Semantics. 2015;6:34.
Strauss JA, Chao CR, Kwan ML, Ahmed SA, Schottinger JE, Quinn VP.
Identifying primary and recurrent cancers using a SAS-based natural language
processing algorithm. J Am Med Informatics Assoc. 201 3;20(2):349-55.

Sung SF, Chen K, Wu DP, Hung LC, Su YH, Hu YH. Applying natural language
processing techniques to develop a task-specific EMR interface for timely
stroke thrombolysis: A feasibility study. Int J Med Inform. 2018;112:149-57.
Tchechmedjiev A, Abdaoui A, Emonet V, Zevio S, Jonquet C. SIFR annotator:
ontology-based semantic annotation of French biomedical text and clinical
notes. BMC Bioinformatics. 2018;19:405.

Ternois |, Escudie J-B, Benamouzig R, Duclos C. Development of an
automatic coding system for digestive endoscopies. Stud Health Technol
Inform. 2018;255:107-11.

Travers DA, Haas SW. Evaluation of Emergency Medical Text Processor, a
system for cleaning chief complaint text data. Acad Emerg Med. 2004;
11(11):1170-6.

Tulkens S, Suster S, Daelemans W. Unsupervised concept extraction from
clinical text through semantic composition. J Biomed Inform. 2019;91:103120.
Usui M, Aramaki E, lwao T, Wakamiya S, Sakamoto T, Mochizuki M.
Extraction and standardization of patient complaints from electronic
medication histories for Pharmacovigilance: natural language processing
analysis in Japanese. JMIR Med informatics. 2018;6:e11021.

92.

93.

94,

95,

96.

97,

98.

99.

Page 21 of 21

Valtchinov VI, Lacson R, Wang A, Khorasani R. Comparing Artificial Intelligence
Approaches to Retrieve Clinical Reports Documenting Implantable Devices
Posing MRI Safety Risks. J Am Coll Radiol. 2019;51546-1440(19):30862.

Wadia R, Akgun K, Brandt C, Fenton BT, Levin W, Marple AH, et al.
Comparison of natural language processing and manual coding for the
identification of cross-sectional imaging reports suspicious for lung Cancer.
JCO Clin cancer informatics. 2018;2:1-7.

Walker G, Soysal E, Xu H. Development of a natural language processing
tool to extract radiation treatment sites. Cureus. 2019;11:e6010.

Xie X, Xiong Y, Yu PS, Zhu Y. EHR Coding with Multi-scale Feature Attention
and Structured Knowledge Graph Propagation. ACM; 2019. p. 649-58.

Xu H, Fu Z, Shah A, Chen Y, Peterson NB, Chen Q, et al. Extracting and
integrating data from entire electronic health records for detecting
colorectal cancer cases. AMIA Annu Symp Proc. 2011;2011:1564-72.

Yadav K, Sarioglu E, Smith M, Choi HA. Automated outcome classification of
emergency department computed tomography imaging reports. Acad
Emerg Med. 2013:20(8PG):848-54.

Yao L, Mao C, Luo Y. Clinical text classification with rule-based features and
knowledge-guided convolutional neural networks. BMC Med Inform Decis
Mak. 2019;19(Suppl 3):71.

Zeng Z, Espino S, Roy A, Li X, Khan SA, Clare SE, et al. Using natural
language processing and machine learning to identify breast cancer local
recurrence. BMC Bioinformatics. 2018;19(Suppl 17):498.

. Zhang S, Elhadad N. Unsupervised biomedical named entity recognition:

Experiments with clinical and biological texts. J Biomed Inform. 2013;46(6
PG):1088-98.

. Zhou X, Han H, Chankai |, Prestrud A, Brooks A. Approaches to Text Mining for

Clinical Medical Records. In: German Research Cent for Artificial, Intelligence -
DFKI GmbH, Kaiserslautern, Germany Seattle, WA, USA: ACM; 2006. p. 235-9.

. Zhou L, Plasek JM, Mahoney LM, Karipineni N, Chang F, Yan xX, et al. Using

Medical Text Extraction, Reasoning and Mapping System (MTERMS) to
process medication information in outpatient clinical notes. AMIA Annu
Symp Proc. 2011;2011:1639-48.

. Zhou L, Lu Y, Vitale CJ, Mar PL, Chang F, Dhopeshwarkar N, et al.

Representation of information about family relatives as structured data in
electronic health records. Appl Clin Inform. 2014;5:349-67.

. Hassanzadeh H, Nguyen A, Koopman B. Evaluation of Medical Concept

Annotation Systems on Clinical Records; 2016. p. 15-24.

. Matentzoglu N, Malone J, Mungall C, Stevens R. MIRO: guidelines for

minimum information for the reporting of an ontology. J Biomed
Semantics. 2018;9:1-13.

. Beleites C, Neugebauer U, Bocklitz T, Krafft C, Popp J. Sample size planning

for classification models. Anal Chim Acta. 2013;760:25-33.

. Yang Q, Liu Y, Chen T, Tong Y. Federated machine learning: concept and

applications. ACM Trans Intell Syst Technol. 2019;10:1-19.

. Sokolova M, Lapalme G. A systematic analysis of performance measures for

classification tasks. Inf Process Manag. 2009;45:427-37.

Publisher’s Note
Springer Nature remains neutral with regard to jurisdictional claims in
published maps and institutional affiliations.

 

 

Ready to submit your research? Choose BMC and benefit from:

e fast, convenient online submission

e thorough peer review by experienced researchers in your field

e rapid publication on acceptance

e support for research data, including large and complex data types

e gold Open Access which fosters wider collaboration and increased citations

e maximum visibility for your research: over 100M website views per year

K BMC

At BMC, research is always in progress.

Learn more biomedcentral.com/submissions

 

 
