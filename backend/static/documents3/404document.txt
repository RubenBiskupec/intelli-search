Schmidt et al. FURASIP Journal on Audio, Speech, and Music
Processing (2020) 2020:11

https://doi.org/10.1186/s13636-020-00178-0

RESEARCH Open Access

Motor data-regularized nonnegative
matrix factorization for ego-noise

Suppression

EURASIP Journal on Audio,
Speech, and Music Processing

Check for
updates

 

Alexander Schmidt” ®, Andreas Brendel, Thomas Haubner, and Walter Kellermann

Abstract

Ego-noise, i.e., the noise a robot causes by its own motions, significantly corrupts the microphone signal and severely
impairs the robot's capability to interact seamlessly with its environment. Therefore, suitable ego-noise suppression
techniques are required. For this, it is intuitive to use also motor data collected by proprioceptors mounted to the
joints of the robot since it describes the physical state of the robot and provides additional information about the
ego-noise sources. In this paper, we use a dictionary-based approach for ego-noise suppression in a semi-supervised
manner: first, an ego-noise dictionary is learned and subsequently used to estimate the ego-noise components of a
mixture by computing a weighted sum of dictionary entries. The estimation of the weights is very sensitive against

other signals beside ego-noise contained in the mixture. For increased robustness, we therefore propose to
incorporate knowledge about the physical state of the robot to the estimation of the weights. This is achieved by
introducing a motor data-based regularization term to the estimation problem which promotes similar weights for
similar physical states. The regularization is derived by representing the motor data as a graph and imprints the
intrinsic structure of the motor data space onto the dictionary model. We analyze the proposed method and evaluate
its ego-noise suppression performance for a large variety of different movements and demonstrate the superiority of
the proposed method compared to an approach without using motor data.

Keywords: Ego-noise, Motor data, Robot audition, Humanoid robot

1 Introduction

Microphone-equipped robots are exposed to various
kinds of noise, specifically to self-created noise, which is
referred to as ego-noise in the following. It is caused by
the robot’s electrical and mechanical components such as
rotating motors and joints as well as the moving body
parts. Ego-noise is a crucial problem in robot audition
[1, 2] since it severely corrupts the recorded microphone
signals and impairs the robot's capability to react to unan-
ticipated acoustic events. For this reason, ego-noise sup-
pression is a crucial preprocessing step in robot audition.

 

*Correspondence: alexander.as.schmidt@fau.de

Multimedia Communications and Signal Processing,
Friedrich-Alexander-Universitat Erlangen-Nurnberg (FAU), Cauerstrasse 7,
91058 Erlangen, Germany

o) Springer Open

 

Ego-noise suppression is particularly challenging for
several reasons. First, ego-noise is usually louder than
other signals of interest, e.g., a desired speech signal (“tar-
get”), since the ego-noise sources are typically located
in immediate proximity of the microphones. For exam-
ple, for the humanoid robot NAO™, which we will use
as experimental platform in this paper, the microphones
are mounted to the head of the robot. Thereby, they are
only few centimeters away from the shoulder motors and
joints, cf. Fig. 1. Another challenging aspect of ego-noise
is that it cannot be modeled as a single static point inter-
ferer as the joints are located all over the body of the robot
and the resulting structure-borne sound is transduced
to air not just at isolated points. Furthermore, ego-noise
is highly non-stationary since typically different move-

© The Author(s). 2020 Open Access This article is licensed under a Creative Commons Attribution 4.0 International License, which
permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit
to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The

images or other third party material in this article are included in the article’s Creative Commons licence, unless indicated
otherwise in a credit line to the material. If material is not included in the article’s Creative Commons licence and your intended
use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the
copyright holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0/.
Schmidt et al. EURASIP Journal on Audio, Speech, and Music Processing

(2020) 2020:11 Page 2 of 15

 

 

 

 

Fig. 1 Illustration of a typical human-robot interaction scenario. The desired source ("target") is shown on the left. Two exemplary, spatially distributed
ego-noise sources are shown in blue. Besides, typical distances between the sources and the microphones are given. Obviously, the ego-noise
sources are located close to the microphones while the distance between target and microphones is typically larger. Image of robot taken from [12]

 

 

ments are performed successively with varying speeds and
accelerations.

One of the first approaches for ego-noise suppression
goes back to the SIG humanoid robot [1] which was
equipped with microphones mounted inside the robot's
housing near the motors in order to record ego-noise
reference signals. These signals were subsequently used
as reference for adaptive filtering-based ego-noise can-
celation. Interestingly, these reference signals were inter-
preted as additional auditory perception channels of the
robot. Internal microphones were also used in [3] for
speech enhancement for a human-robot dialog system. In
this approach, the recorded reference signals are incor-
porated into a frequency-domain semi-blind source sep-
aration algorithm with subsequent multichannel Wiener
filtering.

In many robot designs, it is not possible to mount
additional reference microphones inside the robot due to
space and hardware constraints. Furthermore, a poten-
tially large number of internal microphones are required
to obtain reference signals for each ego-noise source.
This drawback motivates approaches which operate on
the external microphone signals only. Here, it can be
exploited that ego-noise exhibits a characteristic struc-
ture in the Short-Time Fourier Transform (STFT) domain.
Due to the limited number of degrees of freedom for
the movements of the robot, those spectral patterns can-
not be arbitrarily diverse. These two properties motivate
the use of learning-based dictionary methods where the
ego-noise signals are approximated by prototype signals,
so-called atoms, which are collected in a dictionary. Then,
for each time frame, a linear combination of atoms has
to be found which optimally fits the current ego-noise

signal with respect to the chosen criterion. An example
for such a dictionary learning algorithm is K-SVD [4],
which has been applied for multichannel ego-noise sup-
pression in [5]. Another widely used approach to train a
dictionary is nonnegative matrix factorization (NMF) [6-
8]. For NMF, the dictionary is restricted to nonnegative
elements only which is well-suited to model power spec-
tral densities (PSDs) of acoustic sources. An according
approach for ego-noise suppression has been investigated,
e.g., in [9]. The concept of NMF has been extended for
multichannel recordings [10] by extending the (nonnega-
tive) source model by an additional spatial model. This has
been applied for ego-noise suppression in [11].

Besides methods using the audio modality only (referred
to as audio only-based methods in the following), other
ego-noise suppression approaches use knowledge about
motor information given by, e.g., motor commands or
motor data such as engine rotation frequency, joints’
angle, or angular velocities collected by proprioceptors.
The advantage of using motor data compared to motor
commands is that the emitted ego-noise is directly related
to the instantaneous internal state of the robot, measured
by motor data. Since a robot is not a fully deterministic
system, this measured state may be significantly different
from the target state defined by the motor command.

Typically, a sufficiently accurate analytical model of
the dependency between motor data and emitted ego-
noise can usually not be obtained since the mechani-
cal dependencies and interactions between structure and
airborne sounds are highly complex. Therefore, current
ego-noise suppression approaches model these dependen-
cies entirely or partly by learning-based strategies. For
example in [13], a neural network-based approach is used
Schmidt et al. EURASIP Journal on Audio, Speech, and Music Processing

to predict the PSDs of ego-noise caused by the Aibo!™™
robot. The feedforward neural network, consisting of two
hidden layers containing thirty nodes each, is fed with
angular position and velocity data of current and past
time frames. The PSD estimates are subsequently used
for spectral subtraction which was shown to result in
a significant improvement of speech recognition rates.
In [14], it is demonstrated that the harmonic structure
of ego-noise can be estimated using motor data. This
prior knowledge is included to a single-channel NMF-
based ego-noise modeling. It is proposed to approximate
the currently observed ego-noise spectrogram by com-
bining elements from a dictionary Dy which models the
harmonic structure and another dictionary Dr which cap-
tures the residual part of the ego-noise. The benefit of this
approach is that only Dp requires a prior learning step
while Dy is completely motor data-driven. It is shown that
the proposed approach significantly outperforms an audio
only-based method for the suppression of ego-noise that
is not well represented in the training data. Although this
approach is close to the proposed method from a method-
ical point of view, it aims at a different direction since it
explicitly addresses the suppression of ego-noise if train-
ing and test data are unbalanced. This is not the case in
the scenario considered in this paper.

Other popular methods for ego-noise suppression com-
bining audio and motor information are template-based
approaches. Here, the key idea is to save the characteris-
tic spectral shape of the ego-noise as PSD templates in a
data base. In [15], each template is associated with a motor
command which triggered the current movement. Based
on this, during application, matching templates are iden-
tified and temporally aligned to the recorded signal. An
alternative template-based approach was presented in [16,
17], where motor data instead of motor commands are
used to identify the templates in the data base. For a cur-
rent motor data sample, the nearest neighbor in the motor
data space is searched and the associated template used as
ego-noise estimate.

The concept to associate motor data with ego-noise
templates was adopted in [18]. However, there, motor
data samples are linked to a set of atoms from a learned
dictionary-based ego-noise model. Nonlinear classifiers in
the motor data space are used to associate a motor data
sample to a set of atoms, whose elements are subsequently
combined to approximate the current ego-noise record-
ing. Thereby, the classifiers replace the expensive iterative
search for atoms in the dictionary.

In this paper, the idea of choosing atoms depending
on motor data is adopted from [18] and we propose to
expand the conventional, audio only-based NMF model
by a motor data-dependent regularization term, which
promotes similar atom activations in those time frames
in which similar motor data is measured. The proposed

(2020) 2020:11 Page 3 of 15

regularization term is derived from a graph structure
which encodes the similarity between the motor data sam-
ples. While the main benefit of the method in [18] was
a reduction of computational complexity, the presented
approach in this paper results in a significant performance
improvement. The proposed method is inspired by graph-
regularized NMF [19, 20], which was proposed in the
context of clustering and classification of text documents.
There, the NMF model and the regularization are operat-
ing in the same data space. In this work, however, we learn
an NMF model on acoustic data while the regularization
encodes the geometry of the motor data space. Thus, we
combine an acoustic model with non-acoustic reference
information.

This paper is structured as follows. In Section 2.1, we
describe the used motor data. After succinctly introducing
NMF in Section 2.2, we present the novel motor data-
regularized NMF in Section 2.3 Thereby, we first describe
the construction of the motor data graph structure in Sub-
section 2.3.1 and derive the proposed regularization term
in Subsection. 2.3.2. Then, the modified NMF optimiza-
tion problem is formulated and according update rules are
presented in Subsection. 2.3.3. The resulting novel ego-
noise suppression algorithm is summarized in Section 2.4
and its efficacy is demonstrated in Section 3.

2 Motor data-regularized NMF for ego-noise
suppression

In the following, we consider the bin-wise squared mag-

nitude of a single-channel microphone signal in the STFT

domain, represented in spectrograms denoted as Y =

[y---¥,] € R‘,*”, where F is the number of frequency

bins and L is the number of considered time frames.

2.1 Motor data descriptions and definitions

The physical state of a robot can be described by motor
data, collected by proprioceptors providing angular posi-
tion information of the joints driven by the motors. In
the following, we consider a robot which is equipped with
m = 1,...,M proprioceptors each capturing one angle
of a joint. We denote the s-th observed angular posi-
tion in STFT frame ¢@ for proprioceptor m by ay Ee R.
Within frame £@, a total number of Sg motor data sam-
ples is observed, ie., s = 1,...,S,. In this paper, we
account for the fact that the motor data is not necessar-
ily synchronized with the audio data recording so that for
a fixed observation interval for the audio data, the num-
ber of motor data may vary, i.e., Se may change with @.
This is specifically the case for the NAO robot used for the
experiments in this paper.

Depending on the kind of ego-noise, only a subset of
proprioceptors is relevant for ego-noise suppression. For
example, if only ego-noise caused by arm movements is
present, only motor data of the arm joints are required.
Schmidt et al. EURASIP Journal on Audio, Speech, and Music Processing

(2020) 2020:11 Page 4 of 15

 

Ye
STFT

*
Audio signal:

  
 
 

Time
Proprioceptor signal: al) gi?) .
pe ee ee Be ein 1

: (1) (2) :
: A 23 Ap 93:

Frequency (kHz) —

 

and angular velocity) of this joint

 

Joint 23
Q
ap = ee
Joint Feature Oe,1
Selection Calculation
e.g., Joint 1 e.g., angular position,
>me=l1 angular velocity

Motor data >

 

Time (s) >

Fig. 2 Left: Illustration of data collection and processing. We consider a robot for which motor data of 23 joints and a single-channel microphone
signal are recorded. The €th STFT frame is processed. Note that the total number of motor data samples can be varying from frame to frame, cf,
Section 2.1. Right: Example spectrogram for right arm shoulder ego-noise and corresponding normalized motor data samples (angular position

 

 

In the following, we denote the index set of relevant
proprioceptors for these joints by M.

From proprioceptor data collected for proprioceptor m,
the instantaneous angular velocity can be estimated by

(s) (s—1)

a —a
on, = me M, (1)
AT\

where A T denotes the time difference between adjacent

observations a) and oS), Note that for s = 1, a Y is
chosen to be the last angular sample of previous the frame

++ (S)
e

€ — 1. Analogously, angular acceleration a; can be com-

. . . - (Ss)
puted from successive angular velocity estimates @;_,

- (s—1)
hom:
To associate each spectrogram frame Ye with a single

motor data sample, we propose first to compute the arith-
metic average of all Sy angular positions in STFT frame
e

and

Se
- 1 oo”
Oem = Se L Oe mm M1 € M. (2)

We proceed analogously for angular velocity and accel-
eration and obtain Oem, &em> respectively. We then con-
catenate the averaged angular data for all considered
proprioceptors in a feature vector

_ _ - 7 a a T
ae = [ae 229 U0 mA msAlms---+> ce | , (3)

which we will refer to as motor data vector for frame ¢ in
the following. The left part of Fig. 2 exemplarily illustrates
the described preprocessing of the data.

2.2 NMF for ego-noise suppression

In the following, we briefly summarize NMF. We intro-
duce succinctly how semi-supervised NMF can be used
for ego-noise suppression and explain the main drawback
of the known approach before we introduce the proposed
motor data-based regularization.

The objective of NMF is to approximate the nonnegative
matrix Y, ie., a matrix whose elements are all larger or
equal than zero, by a product of two nonnegative matrices
DandH

Y~Y=DH =[Dm,...,Dh,], (4)

where D € R‘,** is the so-called dictionary of size F x K

and H = [h,...,hz] € Ri is referred to as activa-
tion matrix [8, 21]. This approach can be interpreted as
approximating each column of Y by a weighted sum of
columns of D (the so-called atoms or bases), where the
weights are given by the corresponding column entries of
H. K is referred to as size of the dictionary and describes
the number of atoms in D. Typically, K « F,L holds, ice.,
NMF can be considered as a compact representation of
data.

The factorization is achieved by minimizing a cost func-
tion which penalizes the dissimilarity between Y and Y
defined by the model parameters D, H. Typically, the cost
function is applied element-wise on the elements of the
Schmidt et al. EURASIP Journal on Audio, Speech, and Music Processing

matrices Y and Y. In this paper, we consider the Euclidean
distance between Y and Y as cost function yielding the
optimization problem

min ||¥Y — DH ||?
ae (5)
st. D,H>0O,

where ||-||— denotes the Frobenius norm and D,H > 0
means that all elements of D,H are larger or equal to
zero, ensuring nonnegativity. The optimization problem
in Eq. 5 is typically solved using iterative updates alter-
nating between D,H such that the nonnegativity of D,H
is implicitly guaranteed if they are initialized with pos-
itive values. The update rules can be derived based on,
e.g., the Majorization-Minimization principle or heuristic
approaches [7, 8].

For ego-noise suppression, we apply a semi-supervised,
two-stage strategy [21], c.f. Section 2.4: first, we use audio
data containing ego-noise only and train an ego-noise dic-
tionary. Then, given a mixture of ego-noise and speech,
these dictionary elements remain constant and only its
activations are estimated. For this, again, the same itera-
tive update rules are used, which have shown to be sen-
sitive to the additional speech signal. As a consequence,
the atom activations are no longer estimated correctly. For
improved robustness, we therefore propose to extend this
audio only-based estimation of the activations by taking
also the physical state of the robot, measured in terms
of motor data, into account. Thus, the estimation of the
activations is additionally guided by reference information
which is completely unaffected by the speech signal.

2.3 Motor data-regularized NMF

The basic idea of our approach is that activations should
be similar if the physical state of the robot is similar. For
this, we measure the similarity between robot states in
frames £ and j by comparing motor data vectors a, and
a; and enforce similar activations hg and h; if a, and a;
are close. This will be achieved by imprinting the intrin-
sic geometry of the motor data space to the NMF cost
function. Results from spectral graph theory [22, 23] and
manifold learning theory [24] have shown that local geo-
metric structure of given data points can be modeled
using an undirected graph. Based on these results, we first
introduce a motor data-based graph structure and sum-
marize subsequently how a regularization term, enforcing
similar activations for similar motor data, can be derived.
We then reformulate the NMF optimization problem Eq. 5
and present according update rules for its minimization.

2.3.1 Motor data graph structure

In the following, we define a graph where the motor data
vectors @1,...,a@z, constitute the nodes. The edges con-
necting the nodes are assumed to be bidirectional, ie.,

(2020) 2020:11 Page 5 of 15

 

 

Fig. 3 Part of an undirected graph where motor data vectors ae,
L=1,..., L are the nodes of the graph. The weights of the edges are
given by Eq. 6: the more similar two motor data vectors are, the larger
the weight of the connecting edge is

 

 

 

we obtain an undirected graph. A part of an exemplary
graph is illustrated in Fig. 3. The edge which connects
nodes @&¢ and w; has weight W; = Wj¢ and should reflect
the affinity between the two motor data points. Depen-
dent on the considered scenario, numerous measures have
been proposed to quantify the affinity between a, and a;
[22], e.g., a nearest-neighbor or dot-product weighting. In
this paper, we determine the weight W¢; using a Gaussian
kernel

lle — oxi ll3
We = Wie = exp a E (0, 1], (6)

with scale parameter € € R,. The larger Wg, the higher
the affinity between two motor data samples is and we
obtain We; = 1 if ae = a;. Note that by adjusting ¢, the
connectivity of the graph can be controlled, e.g., for larger
€, the neighbors of a node are connected with a larger
weight. Therefore, € can be used to control the reach of
the local neighborhood of a node. Based on the affin-
ity weights, we define the affinity matrix W = W! ¢«
[0, 1]/*4, where the [ W] ej = We. Furthermore, we intro-
duce the diagonal matrix Z of size L x L with Zee =
» We = dL; Wie and zero else.

2.3.2 Motor data-based regularization term

The derivation of the regularization term is based on
results from [24, 25]. It is assumed that the considered
motor data lie on a Riemannian manifold A. We are look-
ing for a mapping f : A — R, which can be interpreted
as a mapping from the manifold to a line. f should pre-
serve the local geometry of the manifold, i.e., close points
on the manifold should be mapped to close points on the
Schmidt et al. EURASIP Journal on Audio, Speech, and Music Processing

line. This implies that f is allowed to vary only smoothly
for similar arguments. Appropriate mappings f can be
obtained by an optimization on the manifold which can
be discretely approximated on the motor data graph by
searching for an f which minimizes

LoL
- S> > (FG) —f£&))” We, (7)
é=1 j=1
where f is a function of the nodes of the graph [24, 25].
To exploit the geometric information of the motor data
manifold for the estimation of the activation vectors, we
manipulate Eq. 7 and replace the abstract mapping f by
the activation of atom k

LoL
1 2
R= 5 SOS (hee = hig) We (8)

(=1 j=l

where /i;¢ denotes the ¢-th element of hz, i.e., hye is the
scaling of atom ¢ in time frame k. The regularization term
Rx needs to be minimized jointly with Eq. 5 with respect
to the activations for every atom k, c.f. Section 2.3.3. Note
that the motor data-based regularization R, implicitly
influences also the structure of the dictionary elements
since the optimized activations directly affect the update
of D.

Note that in Eq. 8, affinities W:; can be interpreted as
weighting parameter: if two motor data vectors a, and
a; are similar, W¢; is close to one according to Eq. 6 and

(2020) 2020:11 Page 6 of 15

the minimization of Eq. 8 enforces similar hg and hy.
Using the parameters defined in Section 2.3.1, Eq. 8 can
be directly related to the so-called graph Laplacian L =
Z — W [22]

Ry = hy Zhy — hi Why

(9)
= hy Lhy.

Summing over all atoms results in the final regularization
term

R= R, = tr (H™LH) (10)

k=1

where tr(-) denotes the trace operator.

2.3.3 Motor data-regularized NMF

The derived regularization term Eq. 10 can be directly
included into Eq. 4. We obtain as modified optimization
problem

min ||Y — DH? + dtr (HTH)
D,H (11)
st. D,H>0O,

where A > O controls the influence of the motor data-
based regularization.

For minimization, we form the partial derivatives with
respect to D and H in Eq. 11 and obtain iterative update
rules [19, 20]

 

Learning of D (Training)

Input:
- Ego-noise recording Y = |[yj,...
- Motor data aj,...,Q@z7

YL

Learning algorithm:

- Initialize D, H randomly

- Construct W, Z from @1,...,Q@z
- Repeat until convergence:

 

[D] -, < [D] DH Vi Vif, k
k kk “ ’
D'TY +\A\,7HWw
tH), < [HT], -| CH ATHW ee pg
[DTY +ArHZ],,
Y — DH
Output: D

 

(right)

Ego-noise suppression (Evaluation)

Input:
- Mixture of ego-noise and speech Y = |[y,,...,y |
- Motor data a1,...,Q@z
- Ego-noise dictionary D from learning step
Suppression algorithm:
- Initialize Ds, Hs, H randomly
- Construct W, Z from @1,...,Q@z
- Repeat until convergence:
[YHs|
SIfk
[Ds] px — [Ds] pe ° Se Vf, k
LY Hs] ¢,
[DTY +n HW]
ke
A] ce — [A] ye: TY Vk, €
[D Y + ARHZ| ep
[Ds ¥]
[Hs] ,¢— [Hs] ,0° rT =e Wh, b
IDsY |.
Y=(D Ds]|7? = DH+DsH
S Hs S445S
- Compute [Ys] ¢, = [F] fe. [Y] fe using Eq. 14

Output: estimate of desired speech signal Ys

Fig. 4 Overview of the proposed semi-supervised, two-stage algorithm for ego-noise suppression: Learning of D (left) and ego-noise suppression

 

 
Schmidt et al. EURASIP Journal on Audio, Speech, and Music Processing

[YH" |,

[Dlx < (Da: ——: (12)
YH!
[rH],
D'Y+,HW

[H]ke <— (Ake - [pv AAW he (13)
[DTY 4 MHZ]

where [D] selects the fk-th element from D. Similar to
conventional NMF, the iterative update can be stopped,
e.g., after a fixed number of iterations. In this paper, in
each iteration we additionally compute the cost accord-
ing to Eq. 11 and terminate updating Eqs. 12,13 after
convergence.

Eqs. 12 and 13 reduce to the conventional update rules
for NMF if A = 0 [8]. Note that since the proposed method
aims at enforcing similar activations for close motor data
vectors, the regularization has an effect on the update rule
for H only, while the update for D is unaffected.

2.4 Proposed algorithm for ego-noise suppression

As mentioned in Section 2.2, we apply a semi-supervised,
two-stage strategy for ego-noise suppression [21]. We first
employ audio data containing ego-noise only and train D
imprinting the intrinsic geometry of the motor data space
onto the model using the proposed regularization. Given
a mixture of ego-noise and speech, we use D to model
and suppress the current ego-noise and to obtain a speech

(2020) 2020:11 Page 7 of 15

e Learning D: As input, spectrograms Y = [v1 Lee y1|
are given containing ego-noise only. Per spectrogram
frame y,, a motor data vector a, is computed.

ae,€ =1,...,L is used to construct the affinity and
degree matrix, W and Z, respectively. Subsequently,
the update rules Eqs. 12 and 13 are used to compute
dictionary D, where the introduced regularization
term is weighted by A7.

Ego-noise suppression: Another dictionary Ds of
size Ks and according activation Hs is initialized to
model the additional speech signal in the considered
mixture Y. Analogously to the learning step before,
W and Z are constructed from the new motor data
vectors possibly representing different movements.
Using the same update rules as before, Ds, H and Hs
are updated while D remains constant. The motor
data-based regularization term is weighted by Ag.
Note that for optimizing the activations of the speech
model Hs, we set Ag = 0 since the motor data-based
regularization should affect only the estimation of the
ego-noise activations. After identifying the optimum
model parameters captured by Ds, H and Hs, we use
a spectral enhancement filter to obtain an estimate for
the desired speech signal [Ys], = LF re LY] e¢ for
the f¢-th bin where the enhancement filter is given by

 

estimate. In the following, we describe the proposed algo- [DsHs | ee
rithm for ego-noise suppression in detail, c.f. Fig. 4 for an [F] ie Tp Deel.” (14)
overview. I; ¢+ [Ds slp
C) Phone connector A /D
: Internal CPU
USB
' |Synchronization|_
1 ; Ethernet

Motor data, Joint 1

 

XX

Fig. 5 Overview of recording setup. A detailed explanation is given in Section 3.1

.

Motor data, Joint 23

 
Schmidt et al. EURASIP Journal on Audio, Speech, and Music Processing

Note that typically Az 4 Ary holds, i.e, the regularization
terms in both steps have different weights. This is further
detailed in the following section.

3 Experimental evaluation

In the following, we evaluate the proposed method using
real microphone recordings. We first describe the hard-
ware setup, the synchronization of audio and motor data
and the recording scenarios, and introduce the evaluation
metrics. Then, we present suppression results for ego-
noise of different movements and discuss the influence of
crucial parameters.

3.1 Recording setup

For our experiments, we conducted experiments with
a commercially available NAO H25 robot [12]. For the
audio recordings, we used a self-constructed head [26]
with a microphone array of 12 sensors. For all follow-
ing experiments, we used the frontmost microphone.
Since the NAO platform does not provide an in-built
synchronization on audio sample level, we developed a
synchronization scheme which is illustrated in Fig. 5: the
microphone signals are fed into an external analog-to-
digital (A/D) converter using conventional phone con-
nectors (IEC 60603-11). The sampled data is forwarded
to the robot’s internal CPU via USB, where it is syn-
chronized with the motor data collected by the pro-
prioceptors of the robot. The resulting data stream,
containing audio and motor data, is finally transmit-
ted to an external PC via Ethernet, which is used for
recording.

3.2 Scenario description

The recordings were conducted in a room with moderate
reverberation (T¢é9 = 200 ms). We investigate ego-noise
of different right arm movements of the robot. Compared
to movement noise of other body parts, ego-noise of the
arms has the most severe effect on the microphone sig-
nals due to the immediate closeness of the active joints to
the microphones. In total, we recorded ego-noise of three
motion sequences:

e Sequence I consists of repeating right arm waving
movements, activating all six joints of the arm. The
robot lifts the arm using the right shoulder pitch
motor, while performing waving movements with the
remaining five motors of the right arm.

e Sequence II resembles Sequence I; however, the
lifting of the arm is performed with randomly varying
velocity and acceleration of the right shoulder pitch
motor. The number of employed joints is identical to
Sequence I.

e Sequence III is a mixture of left and right arm
movements where both left and right joints are

(2020) 2020:11 Page 8 of 15

controlled independently with varying speeds. Since
movements of the left and right arm are considered,
12 joints are used in total, ie., compared to Sequence
I/II the number of joints is doubled.

While Sequence I is a relatively simple scenario due to its
repetitive character, Sequence II and Sequence III are more
challenging for a description by a dictionary. For Sequence
II, the random accelerations of the right shoulder pitch
motor result in a large variety of spectral patterns which
must be captured by the dictionary. The same holds for
ego-noise of Sequence III, where the doubling of employed
joints causes more spectral diversity.

The recorded ego-noise was used for training the dic-
tionary and evaluation, where the data for evaluation was
not contained in the training data. In total, we recorded
60 s for each motion sequence and split the ego-noise data
such that approximately 30 s ego-noise for the learning of
D is available.

To evaluate the suppression performance, we consider a
scenario in which a target source is talking to the robot.
The robot is standing on the floor level while it performs
different waving movements of the right arm. The micro-
phones of the robot are at a height of 55 cm. For the speech
signal, utterances from male and female speakers of the
GRID corpus [27] were used. The loudspeaker was posi-
tioned at 1 m distance of the robot, at a height of 1 m.
The recorded reverberant utterances were added to the
ego-noise with varying signal-to-noise (SNR) ratios (see
Section 3.3).

The audio signals are sampled at fg = 16 kHz and trans-
formed to the STFT domain using a Hamming window of
length 64 ms with overlap of 50 %. The internal operating
system of the NAO robot saves motor data samples of all
joints into an internal cache which can be accessed by the
user. This cache is typically updated every 10 ms. Conse-
quently, the sampling frequency of the motor data is given
by fs ~ 100 Hz, i.e, typically Se = 6 motor data samples
are available per time frame.

We evaluated the overall performance of the ego-noise
suppression in terms of signal-to-distortion ratio (SDR
in dB) and signal-to-artifacts ratio (SAR in dB). For the

Table 1 Performance achieved by the proposed method and
audio only-based NMF for different Ay and Ag. Ego-noise is
caused by movements of Sequence | (K = 20, Ks = 20, SNR =
3dB,e =5- 107°)

 

 

Proposed
NMF At = 0.9 At = 0.0 At = 0.9
Ae = 0.0 he = 19.0 he = 19.0
SDR [dB] 7.37(40.11) 7.7 (£0.1) 9.5 (+£0.03) 9.77 (£0.03)
SAR [dB] 9.63 (40.18) 10.09(40.1) 12.1(40.01) 12.64 (+ 0.03)
PESO 1.35(4£0.02) 1.36(40.02) 142(4£0.01) 1.45 (+ 0.01)

 
Schmidt et al. FURASIP Journal on Audio, Speech, and Music Processing

computation of both, Matlab functions provided by [28]
are used. In practice, it must be expected that the ego-
noise and speech estimates, i.e., DH and DcsHs, contain
estimation errors resulting in imperfect enhancement fil-
ter F, cf. Eq. 14. As a consequence, the ego-noise can-
not be removed entirely from the mixture and/or the
desired speech is distorted. The severity of both effects
is reflected in the selected performance criteria SDR and
SAR, respectively. While SDR measures the amount of

(2020) 2020:11 Page 9 of 15

remaining ego-noise and speech distortion after process-
ing, SAR considers introduced speech distortion only. For
unprocessed data, the SDR corresponds to the SNR of the
input mixture while SAR is infinite. Beside SDR and SAR,
we also evaluate PESQ (perceptual evaluation of speech
quality [29]). To obtain representative results, we averaged
over 100 runs with random initialization of the matrices
in NMF. Standard deviations for all results are given in
brackets.

 

 

motor data-regularized NMF, At = 0.9, Ag = 19 were used

X

 

 

 

a) NMF
1 ¢
tT
= f mn
So |
a
S
2
o Q
Q
£05
oO A
NN 6
oS G) (\ 4
& ¢)
—
O n
= mn
O -- H ¥ vi_g f Q Q i <
o 10 15 20
k—-
b) motor data-regularized NMF
1 eS
tT
cq ©)
S I
a)
S ‘
2
om d
Q 4
£ 05 .
o Q
N » Y
PR @ ©)
& 4
$y 4
oO G) (\
o ‘ A os &
9 LL # 14 » I | I
D 10 15 20
k-
© activation vector hy = [he,... hep... hex]?
activation vector h; = [hyj1...hjp..-hjK]*

Fig. 6 Estimated ego-noise activations by a NMF and b motor data-regularized NMF for time frames € and j, where € and / were chosen such that
We; is large (here We * 0.9). The considered mixture of ego-noise (Sequence |) and speech has SNR = 3 dB, dictionary sizes K = 20 and Ks = 20. For

 
Schmidt et al. EURASIP Journal on Audio, Speech, and Music Processing

(2020) 2020:11 Page 10 of 15

 

Frequency /kHz >
Frequency/kHz >

 

Time/s >

 

 

1 2 1
Time/s >

Fig. 7 Spectrograms of an exemplary ego-noise extract from Sequence II (logarithm of magnitude). The left figure shows the original ego-noise. In
the center and right figures, ego-noise estimates using audio-only NMF and the proposed method are depicted, respectively. Without motor data
regularization, the ego-noise is in parts incorrectly estimated and adapts to the speech signal. Corresponding components are marked with red
ellipses (middle). Note that these undesired components are not or significantly less visible in the ego-noise estimate of the proposed method (right)

Frequency /kHz >
i m

ho

 

2 1 2
Time/s >

 

 

3.3 Evaluation and discussion of the results

For evaluating the proposed method for ego noise of
motion Sequence I, II, and II, the size of the ego-noise
dictionary and speech dictionary has been chosen to K =
Ks = 20 for Sequence I and K = 30, Ks = 20 for
Sequence II and III. These parameters have shown best
suppression performance in terms of SDR for audio only-
based NMF on the respective ego-noise recordings. We
first discuss the choice of Ay and Ag and illustrate the
effect of the regularization term 7. Subsequently, we
evaluate the suppression performance for different SNRs
and finally discuss alternative choices for the motor data
vector ay.

3.3.1. Impact and choice of Ay and XE

In Table 1, the suppression results for particular choices of
Ay and Ag are given. First, we incorporate the motor data
information only into the training (Ay = 0.9) and leave the
suppression step unchanged Az; = 0. Compared to audio
only-based NMF (denoted as “NMEF” in the following),
this already shows a slight improvement of the results. For
Ay = Oand AZ; = 19, we obtain significantly better results
than for NMF, which shows that enforcing similar acti-
vations for similar physical states of the robot helps even
if this constraint has not be learnt during the learning of
the dictionary. Best results are obtained if the regulariza-
tion term is included to both learning and suppression.
Note that Ay and Ag are of different orders of magni-
tude, what will be further investigated and interpreted in
Section 3.3.2.

The effect of the proposed regularization term is illus-
trated in Fig. 6. We consider two time frames ¢ and
j of a mixture of ego-noise (Sequence I) and speech.
Frames ¢ and j are chosen such that W2; is large, ie.,

@ ; and a; are close indicating that the robot has simi-
lar physical states. Hence, similar activations are desired.
Figure 6a shows elements of the activation vectors hy
and h; obtained if audio only-based NMF is used. It
is obvious that the activations differ significantly, which
can be explained by the additional speech signal present
in frames £ and j which affects the estimation of the

 

 

 

 

 

 

10
9
tT
a 8
<7
ec
A 7
6
3) AE >
100 200 300
> €>
0 5 10 15 20
1073
— NMF
Proposed, varying Am, Ap = 0, € = 5- 1073
Proposed, varying €, Ap = 0, Ag = 19
Fig. 8 Performance for varying Ag and e. For this experiment, K = 20,
Ks = 20, SNR = 3 dB is chosen and ego-noise caused by movements
of Sequence | is used

 
Schmidt et al. EURASIP Journal on Audio, Speech, and Music Processing

ego-noise activations. Figure 6 b illustrates the ele-
ments of hy and h; estimated by proposed motor data-
regularized NMF. Here, in contrast to audio only-based
NMF, the activations coincide even if additional speech is
present.

For further illustration, Fig. 7 shows spectrograms of an
ego-noise extract and its estimates using audio-only NMF
and the proposed method. Without motor data regular-
ization, the speech signal leads to additional, undesired
components in the ego-noise estimate. In contrast, this
effect is not or only weakly pronounced for the proposed
method.

The effect of varying Ag and € on the suppression result
is illustrated in Fig. 8. For Ag = 0, the regularization
is ineffective and the proposed method reduces to audio
only-based NMF (Ay; = 0 holds during the learning of D).
If A; is chosen too large, the effect of the motor data domi-
nates and the suppression performance degrades. Ap = 19
appears to result in the best result for the considered mix-
ture. However, note that the optimal choice of Ag depends
on the SNR of the mixture, as will be discussed in more

(2020) 2020:11 Page 11 of 15

detail in Section 3.3.2. We now consider the suppression
performance for varying scale parameter €, c.f. Eq. 6. For
€ — 0, we obtain according to Eq. 6

We > 0, Vé,jE1,...,2L,

i.e, all connections in the graph are set to zero. Accord-
ingly, the regularization term in Eq. 10 equals zero and
the results of the proposed method and audio only-based
NMF coincide. For increasing €, Eq. 6 gets less selective
and the number neighbors of a node with large affinity
increases. For the setup in Fig. 8, the maximum SDR is
obtained for € = 5- 10~, which turned out to result
in robust performance even for ego-noise of other move-
ments. For larger €, the suppression performance deteri-
orates since more and more connections between nodes
obtain large weights and the discriminative nature of the
graph is reduced.

3.3.2 Varying SNRs
So far, we only considered mixtures with constant SNR.
In a typical human-robot interaction, the SNR is however

Table 2 Suppression performance achieved by NMF and the proposed method for varying SNRs. For this experiment, ego-noise by
movements of Sequence | is used. Parameters used for proposed methods are given in the last rows. For all SNRs, dictionaries of size

K = 20, Ks = 20 are used

 

 

SNR SDR [dB] SAR [dB] Parameters

(PESQ) NMF Proposed NMF Proposed NMF Proposed

— 10dB — 3.95 (+021) —3.95 (+0.21) 453 (+ 0.26) 453 (£0.26) 1.09 (+ 0.00) 1.09 (+ 0.00) Ay =0, Ac =0
(1.08) €=5-107?
—5dB 2.76 (£0.43) 2.82 (+ 0.33) 6.01 (+ 0.04) 6.52 (+ 0.06) 1.19 (£0.01) 1.22 (+ 0.00) Ay = 0.1, Ac = 0.1
(1.11) €=5-107?
—2dB 5.82 (£0.03) 6.19 (+ 0.04) 7.86 (+ 0.03) 8.77 (£0.02) 1.27 (£0.01) 1.32 (+ 0.01) Aq = 1.1,Ac = 1.0
(1.12) €=5-107?
—1dB 6.24 (+ 0.02) 7.04 (+ 0.02) 8.31 (£0.06) 9.49 (+ 0.02) 1.28 (+ 0.02) 1.37 (+ 0.03) Ap = 1.1,Ac = 1.5
(— 1) €=5-107?

0 dB 6.60 (+ 0.03) 7.76 (£0.04) 8.70 (+ 0.08) 10.32 (£0.01) 1.28 (+ 0.01) 1.37 (+ 0.02) AT = 1.0, Ac = 4.0
(1.13) €=5-107?

1 dB 6.89 (+ 0.05) 8.41 (4 0.06) 9.05 (£0.12) 11.12 (£0.01) 1.3 (+0.01) 1.4 (+ 0.02) Ay = 1.0,Ac = 84
(1.14) €=5-107?

2 dB 7.15 (£0.08) 9.15 (£0.04) 9.36 (£0.14) 11.84 (+ 0.02) 1.31 (+ 0.03) 1.41 (+ 0.02) AT = 1.0,Ac = 11.0
(1.15) €=5-10-°

5 dB 7.58 (£0.09) 10.92 (+ 0.1) 9.96 (+ 0.2) 13.88 (+ 0.04) 1.35 (£0.02) 1.45 (+ 0.01) Ay = 1.1,Ac = 168
(1.21) €=5-107?

10 dB 8.17 (£0.24) 13.59 (+ 0.03) 10.66 (£041) 16.29 (+ 0.10) 1.41 (£0.00) 1.54 (+ 0.00) Ay = 1.1, Ac = 20.1
(1.37) €=5-107?

 
Schmidt et al. EURASIP Journal on Audio, Speech, and Music Processing

changing due to, e.g., varying distances between desired
source and robot or different power levels of the signal
of interest. Therefore, a robust ego-noise suppression at
different SNRs is of high importance.

In the following, we evaluate the proposed approach for
SNR € {+ 10,+ 5,+ 2,+ 1,0} dB of the input mixture.
For this, we added scaled versions of the speech signal to
the ego-noise. Note that for the considered NAO robot
SNR=10 dB is an unlikely scenario since it corresponds to
an human-robot distance of only a couple of centimeters
or a very loud human voice. We acknowledge, however,
that for robots which emit less loud ego-noise, such a high
SNR could be realistic.

Results for ego-noise Sequence I are given in Table 2.
In the right part of Table 2, parameters AT,Az, and €
used for the proposed method are summarized. Interest-
ingly, for SNR=— 10 dB, the proposed method shows best
result if the regularization is ineffective. Consequently, it
does not show any benefit compared to audio only-based
NMF. For larger SNRs, SDR and SAR increase both for
audio only-based NMF and the proposed method. Motor

(2020) 2020:11 Page 12 of 15

data-regularized NMF consistently shows superior per-
formance, while the relative improvement between the
proposed approach and NMF increases for growing SNR,
e.g., for SNR=+ 2 dB, a gain of + 2 dB in SDR and
2.5 dB in SAR is achieved. This effect can be explained
by the fact that for audio only-based NMF, the esti-
mation of the activations is more severely impaired by
the additional speech signal. This effect becomes more
pronounced for increasing SNR. Since motor data is a
non-acoustic reference signal, the regularization term is
not affected by the increasing power of the additional
speech component. This also explains why almost no ben-
efit could be observed for low SNR when the additional
speech signal does not have an impact on the ego-noise
estimation.

While € is constant for all SNRs, especially A¢ has to
be increased continuously for larger SNRs. By this, the
influence of the motor data-dependent regularization gets
more aggressive compensating the increasingly negative
impact of the speech on the estimation of the ego-noise
activations.

Table 3 Suppression performance achieved by NMF and the proposed method for varying SNRs. For this experiment, ego-noise by
movements of Sequence Il is used. Parameters used for proposed methods are given in the last rows. For all SNRs, dictionaries of size

K = 30, Ks = 20 are used

 

 

SNR SDR [dB] SAR [dB] PESO Parameters

(PESQ) NMF Proposed NMF Proposed NMF Proposed

— 10dB — 2.59 (+ 0.09) — 2.59 (+ 0.09) 3.48 (+ 0.05) 3.48 (+ 0.05) 1.16 (+ 0.02) 1.16 (+ 0.02) AT = 0,Ac =0
(1.14) €=5-107?
—5dB 2.33 (£0.04) 2.45 (£0.05) 5.40 (£0.01) 5.41 (£0.02) 1.19 (+ 0.00) 1.19 (+0 .00) Aq = 0.1, Ac = 0.5
(1.15) €=5-107-°
—2dB 4.82 (+ 0.02) 5.36 (£0.03) 6.77 (£0.01) 7.64 (+ 0.04) 1.22 (+ 0.01) 1.23 (+ 0.01) Ap =1,Ac=1
(1.15) €=5-107?
—1dB 5.27 (£0.02) 6.16 (+ 0.03) 7.15 (£0.02) 8.25 (+ 0.04) 1.25 (+ 0.04) 1.28 (+ 0.02) Ay = 1.5, Ac = 1.5
(1.15) €=5-107?

0 dB 5.60 (+ 0.03) 6.82 (+ 0.04) 7.52 (£0.08) 8.75 (£0.07) 1.26 (+ 0.01) 1.31 (+ 0.01) Ar = 0.9, Ac = 2.0
(1.16) €=5-107?

1 dB 5.82 (£0.01) 7.45 (£0.03) 7.8 (£0.01) 9.48 (+ 0.08) 1.26 (+ 0.03) 1.37 (+ 0.02) AT = 1.0, Ac = 4.0
(1.16) €=5-107?

2 dB 5.89 (£0.01) 8.05 (+ 0.01) 6.12 (+ 0.02) 10.38 (+ 0.06) 1.27 (£0.01) 1.37 (+ 0.01) AT = 3.0,Ac = 9.1
(1.18) €=5-107-°

5 dB 6.37 (+ 0.03) 10.00 (+ 0.04) 8.6 (+ 0.03) 12.26 (£0.18) 1.30 (+ 0.02) 1.39 (+ 0.00) Ay = 2.1,Ac = 14.9
(1.24) €=5-107?

10 dB 6.69 (+ 0.03) 12.20 (£0.15) 9.06 (+ 0.04) 14.09 (+ 0.21) 1.40 (+ 0.03) 1.48 (+ 0.00) Ay = 25,Ac = 19.5

(1.35)

€=5-10°°

 
Schmidt et al. EURASIP Journal on Audio, Speech, and Music Processing

(2020) 2020:11

Page 13 of 15

Table 4 Suppression performance achieved by NMF and the proposed method for varying SNRs. For this experiment, ego-noise by
movements of Sequence Ill is used. Parameters used for proposed methods are given in the last rows. For all SNRs, dictionaries of size

K = 30, Ks = 20 are used

 

 

SNR SDR [dB] SAR [dB] PESO Parameters

(PESQ) NMF Proposed NMF Proposed NMF Proposed

— 10dB — 234 (+075) — 234 (+075) 3.46 (+ 0.09) 3.46 (+ 0.09) 1.07 (+ 0.00) 1.07 (+ 0.00) Ay =0, Ac =0
(1.05) €=5-107?
—5dB 3.7 (£0.29) 3.91 (£0.17) 6.00 (+ 0.05) 6.14 (£0.1) 1.11 (£0.05) 1.13 (+ 0.01) Ay = 0.9, Ac = 0.9
(1.05) €=5-107?
—2dB 5.53 (£0.02) 5.81 (£0.02) 746 (£0.04) 8.06 (+ 0.03) 1.2 (+ 0.01) 1.25 (+ 0.01) AT = 0.6, Ac = 2.5
(1.06) €=5-107?
—1dB 5.88 (+ 0.03) 6.40 (+ 0.02) 7.88 (+ 0.04) 8.65 (+ 0.05) 1.25 (£0.01) 1.3 (+0.01) Ay = 0.3,Ac =44
(1.06) €=5-107?

0 dB 6.08 (+ 0.02) 6.97 (+ 0.04) 8.14 (+ 0.03) 9.26 (£0.09) 1.26 (+ 0.01) 1.32 (+ 0.01) AT = 04,Ac = 6.9
(1.07) €=5-107?

1 dB 6.34 (+ 0.03) 7.46 (+£0.01) 8.48 (+ 0.03) 9.78 (£0.03) 1.29 (+ 0.04) 1.38 (+ 0.02) Ar = 0.5, Ac = 8.0
(1.08) €=5-10-°

2 dB 6.55 (£0.05) 7.98 (£0.01) 8.76 (+ 0.04) 10.38 (+ 0.04) 1.31 (£0.03) 1.39 (+ 0.01) Ay = 0.5, Ac = 125
(1.09) €=5-107?

5 dB 6.99 (0.06) 9.10 (£0.02) 9.38 (£0.05) 11.59 (£0.05) 1.35 (£0.01) 1.41 (+ 0.01) Ay = 0.5, Ac = 225
(1.12) €=5-107?

10 dB 7.73 (£0.1) 10.5 (+ 0.05) 9.95 (£0.04) 13.2 (+ 0.06) 1.42 (+ 0.0) 1.51 (+ 0.02) Ay = 04, Ac = 29.5
(1.23) €=5-107?

 

Table 5 Performance degradation of proposed method for suboptimal parameter settings. We chose Ay = 0.5 = const. and

Ag = 8.0 = const. which are optimal for SNR= 1 dB and evaluated SNRs — 1 dB,..., 3 dB. For each performance value of the proposed
method, the degradation relative to optimum parameter settings for Ae and Az is given in parentheses. For this experiment, ego-noise
by movements of Sequence Ill is used

 

 

SNR=— 1 cB SNR=0 dB SNR=+ 1 dB SNR=+ 2 dB SNR=+ 3 dB
PESQ=1.06 PESQ=1.07 PESQ=1.08 PESQ=1.09 PESQ=1.1
SDR [dB] 5.88 6.08 6.34 6.55 672
NMF SAR [dB] 7.88 8.14 8.48 8.76 9.00
PESO 1.25 1.26 1.29 1.31 133
SDR [dB] 6.25 (— 0.15) 6.87 (— 0.1) 7.46 (+ 0.0) 7.87 (— 0.11) 8.19 (— 0.22)
Proposed sar [dB] 8.41 (— 0.24) 9.36 (— 0.1) 9,78 (+ 0.0) 10.19 (— 0.19) 10.51 (— 0.38)
PESO 1.26 (— 0.04) 1.30 (— 0.02) 1.38 (+ 0.0) 1.37 (— 0.02) 1.39 (— 0.02)

 
Schmidt et al. EURASIP Journal on Audio, Speech, and Music Processing

(2020) 2020:11

Page 14 0f 15

Table 6 Performance for different designs of ae: if no derivatives are considered, ae is composed of angular positions only. If one
derivative is considered, a¢ contains angular positions and their first order temporal derivatives. For this experiment, ego-noise caused
by movements of Sequence Il is used, SNR=0 dB, K = 30, Ks = 20,e = 5-1077,Ap = 0.9,and Ac = 2

 

 

NMF Proposed
# of derivatives of ae 0 1 2 3 4
SDR [dB] 5.60 (+ 0.03) 3.87 (+ 0.08) 6.63 (+ 0.06) 6.82 (+ 0.04) 6.68 (+ 0.04) 6.35 (+ 0.05)
SAR [cB] 7.52 (+ 0.08) 5.46 (+ 0.07) 8.3 (+ 0.02) 8.75 (+ 0.07) 8.60 (+ 0.06) 8.26 (+ 0.06)
PESO 1.23 (£0.01) 1.18 (£0.02) 1.29 (+ 0.03) 1.31 (£0.01) 1.3 (£0.02) 1.29 (+ 0.01)

 

We conducted the same experiments for ego-noise
caused by motions of Sequence II and Sequence III. The
results are summarized in Tables 3 and 4. In principle, the
results obtained for Sequence I can be confirmed: the pro-
posed method outperforms audio only-based NMF con-
sistently, especially for high SNRs, and Ag shows a signif-
icant dependence on the SNR. Interestingly for Sequence
II, the absolute values for A; have to be chosen slightly
smaller for optimum performance than for Sequence I.
Overall, the suppression results are ~ 1 dB (Sequence II)
and ~ 0.5 dB (Sequence III) worse than for Sequence I,
which can be explained by the more complex movements,
c.f, movement description in Section 3.2.

Note that for an optimal choice of Az knowledge of the
SNR is required for which a single-channel or multichan-
nel SNR estimator can be employed. However, it must be
expected that the SNR estimation is imperfect leading to
a suboptimal choice of A¢. The resulting effect on the sup-
pression performance is shown in Table 5. We chose Ap =
8.0 and Ay = 0.5, i.e, optimal parameters for SNR= 1 dB,
and evaluated the proposed method for SNRs —1 dB,...,
3 dB, simulating imperfect SNR estimates. Overall, a sub-
optimal parameter choice leads to a degradation of the
suppression performance. However, the proposed method
still shows superior results compared to audio only-based
NMF.

3.3.3 Alternative choices for a

In the previous experiments, the motor data vector a,
was composed of the angular position and its first- and
second-order temporal derivatives, i.e., angular velocity
and acceleration. By complementing angular position by
its first and second order derivatives, we implicitly added
temporal information to our model since not only current,
but also past motor data samples are taken into account
for the construction of a, c.f. Eq. 1.

In the following, we evaluate how the performance of
the proposed method depends on the amount of temporal
context included into ay.

Results are given in Table 6. First, we consider a motor
data vector a, which contains only angular positions, i.e.,
no derivatives are used. The suppression result lags sig-
nificantly behind audio only-based NMF. This drop in

performance is not surprising since by considering angu-
lar position alone it cannot be distinguished whether, e.g.,
the robot raises or drops its arm if up- and downwards
movements have the same trajectory. Consequently, the
ego-noise caused by these two movements is assessed as
similar. The results improve drastically if angular veloc-
ity is added to motor data vector ae. If also angular
acceleration is included, the results further improve; how-
ever, the additional gain is clearly smaller compared to
that of adding the first derivative. Adding higher order
derivatives to a¢ does not offer further benefit as results
get slightly worse with increasing number of derivatives
incorporated to a.

4 Summary and outlook

In this paper, we proposed motor data-regularized NMF
and used it in a semi-supervised manner for ego-noise
suppression.

The basic idea of the presented method is to improve
the approximation of the ego-noise by taking motor data
describing the physical state of the robot into account. We
propose to construct a motor data graph which encodes
the similarities between motor data samples. Based on
this, a regularization term can be derived and added to
the conventional, audio only-based NMF cost function. It
enforces the activation of similar dictionary entries when
the robot is in similar physical states. We evaluated the
proposed method for mixtures of desired speech signals
and ego-noise of different movements and considered
various SNRs of the mixture. The presented approach
showed superior performance in all scenarios, especially
for high SNR when the power of the additional speech
signal is large and the estimation of the ego-noise acti-
vations based on audio data-only is challenging. Con-
sequently, the weighting of the motor data-dependent
regularization term has to be increased for larger SNR.

For future work, we plan to evaluate the proposed
method for other NMF cost functions, such as Itakuro-
Saito and Kullback divergence. Furthermore, we plan to
evaluate the presented concept for multichannel NMF,
where dictionary-activation-modeling of single-channel
NM is extended by a spatial covariance matrix for each
atom and frequency bin.
Schmidt et al. FURASIP Journal on Audio, Speech, and Music Processing

Authors’ contributions

AS has conducted the research on this paper. AB, TH, and WK contributed
valuable feedback on the conceptual idea and assisted the work intensively.
All authors read and approved the final manuscript.

Funding
This work was partially supported by the DFG under contract no
<Ke890/10-2> within the Research Unit FOR2457 “Acoustic Sensor Networks”.

Competing interests
The authors declare that they have no competing interests.

Received: 8 January 2020 Accepted: 10 June 2020
Published online: 31 July 2020

References

1. K. Nakadai, T. Lourens, H. G. Okuno, H. Kitano, in Proc. 17th Nat. Conf.
Artificial Intell. (AAAI). Active audition for humanoid (AAAI, Austin, TX,
2000), pp. 832-839

2. H.G. Okuno, K. Nakadai, in Proc. IEEE Int. Conf. Acoust., Speech and Signal
Process. (ICASSP). Robot audition: its rise and perspectives (IEEE, South
Brisbane, QL, Australia, 2015), pp. 5610-5614

3. J. Even, H. Saruwatari, K. Shikano, T. Takatani, in Proc. IEEE/RSJ Int. Cont.
Intelligent Robots and Systems (IROS). Semi-blind suppression of internal
noise for hands-free robot spoken dialog system (IEEE, St. Louis, MO,
2009), pp. 658-663

4. M. Aharon, M. Elad, A. Bruckstein, K-SVD: an algorithm for designing
overcomplete dictionaries for sparse representation. IEEE Trans. Signal
Process. 54(11), 4311-4322 (2006)

5. A.Deleforge, W. Kellermann, in Proc. IEEE Int. Conf. Acoust., Speech, and
Signal Process. (ICASSP). Phase-optimized K-SVD for signal extraction from
underdetermined multichannel sparse mixtures (IEEE, South Brisbane, QL,
Australia, 2015), pp. 355-359

6. D.D.Lee,H.S. Seung, Learning the parts of objects by non-negative
matrix factorization. Nature. 401(6755), 788-791 (1999)

7. D.D.Lee, H.S. Seung, in Proc. 13th Int. Conf. Neural Inform. Process. Syst.
(NIPS). Algorithms for non-negative matrix factorization (NeurlPS, Denver,
CO, 2000), pp. 535-541

8. C.Févotte, J. ldier, Algorithms for non-negative matrix factorization with
the B-divergence. Neural Comput. 23(9), 2421-2456 (2011)

9. 7. Tezuka, T. Yoshida, K. Nakadai, in Proc. IEEE Int, Conf. Robotics and
Automation (ICRA). Ego-motion noise suppression for robots based on
semi-blind infinite non-negative matrix factorization (IEEE, Florence, Italy,
2014), pp. 6293-6298

10. H. Sawada, H. Kameoka, S. Araki, N. Ueda, Multichannel extensions of
non-negative matrix factorization with complex-valued data. IEEE/ACM

Trans. Audio, Speech, Language Process. 21(5), 971-982 (2013)

11. T. Haubner, A. Schmidt, W. Kellermann, in Proc. [TG Fachtagung
Sprachkommunikation. Multichannel nonnegative matrix factorization for
ego-noise suppression (VDE-Verlag, Oldenburg, Germany, 2018),
pp. 136-140

12. Clean PNG, NAO, der humanoide Roboter. https://de.cleanpng.com/png-
m5r7ur/ Accessed 20 May 2020

13. A. Ito, T. Kanayama, M. Suzuki, S. Makino, in Proc. European Conf. Speech
Communication and Technology (INTERSPEECH - Eurospeech). Internal noise
suppression for speech recognition by small robots (ISCA, Lisbon,
Portugal, 2005), pp. 2685-2688

14. A. Schmidt, W. Kellermann, in Proc. IEEE Int. Conf. Acoust., Speech, and
Signal Process. (ICASSP). Informed ego-noise suppression using motor
data-driven dictionaries (IEEE, Brighton, UK, 2019), pp. 116-120

15. Y. Nishimura, M. Ishizuka, K. Nakadai, M. Nakano, H. Tsujino, in Proc. IEEE/
RAS Int, Conf Humanoid Robots (Humanoids). Speech recognition for a
humanoid with motor noise utilizing missing feature theory (IEEE,
Cancun, Mexico, 2006), pp. 26-33

16. G. Ince, K. Nakadai, T. Rodemann, Y. Hasegawa, H. Tsujino, J. Imura, in Proc.
IEEE/RSJ Int. Conf. Intelligent Robots and Systems (IROS). Ego-noise
suppression of a robot using template subtraction (IEEE, St. Louis, MO,
2009), pp. 199-204

17. G. Ince, K. Nakadai, T. Rodemann, Y. Hasegawa, H. Tsujino, in Proc. /EEE Int,
Conf. Robotics and Automation (ICRA). |mura: A hybrid framework for ego
noise cancellation of a robot (IEEE, Anchorage, AK, 2010), pp. 3623-3628

 

(2020) 2020:11 Page 15 of 15

18. A. Schmidt, A. Deleforge, W. Kellermann, in Proc. IEEE/RSJ Int. Cont.
Intelligent Robots and Systems (IROS). Ego-noise reduction using a motor
data-guided multichannel dictionary (IEEE, Daejon, South Korea, 2016),
pp. 1281-1286

19. D. Cai, X. He, X. Wu, J. Han, in Proc. 8th IEEE Int, Conf. on Data Mining.
Non-negative matrix factorization on manifold (IEEE, Pisa, Italy, 2008),
pp. 63-72

20. D. Cai, X. He, J. Han, T. S. Huang, Graph regularized nonnegative matrix
factorization for data representation. IEEE Trans. Pattern Anal. and Mach.
Intell. 33(8), 1548-1560 (2011)

21. M.N. Schmidt, J. Larsen, F.-T. Hsiao, in Proc. IEEE Workshop Mach. Learning
Signal Process. Wind noise reduction using non-negative sparse coding
(IEEE, Thessaloniki, Greece, 2007), pp. 431-436

22. U.von Luxburg, A tutorial on spectral clustering. Statistics and
Computing. 17(4), 395-416 (2007)

23. F.R.K. Chung, Spectral graph theory, 1st edn, vol. 1. (American
Mathematical Soc., Providence, RI, 1997)

24. M. Belkin, P. Niyogi, V. Sindhwani, Manifold regularization: a geometric
framework for learning from labeled and uUnlabeled examples. J. Mach.
Learn. Research. 7, 2399-2434 (2006)

25. M. Belkin, Problems of learning on manifolds. PhD Thesis. (The University of
Chicago, Chicago, 2003)

26. Seventh Framework Programme, ‘Embodied Audition for RobotS’ (EARS).
https://robot-ears.eu/. Accessed 25 Sept 2018

27. M.Cooke, J. Barker, An audio-visual corpus for speech perception and
automatic speech recognition. J. Acoustical Society of America. 120(5),
2421-2424 (2006)

28. C. Févotte, R. Griboval, E. Vincent, in Technical Report 1706. BSS EVAL
toolbox user guide (IRISA, Rennes, France, 2005). Software available at
http://www. irisa.fr/metiss/bsseval/

29. ITU-T Recommendation P.862.2: Wideband extension to
recommendation P.862 for the assessment of wideband telephone
networks and speech codecs. Recommendation, ITU (November 2007)

Publisher’s Note
Springer Nature remains neutral with regard to jurisdictional claims in
published maps and institutional affiliations.

 

Submit your manuscript to a SpringerOpen”®
journal and benefit from:

> Convenient online submission

> Rigorous peer review

> Open access: articles freely available online
> High visibility within the field

> Retaining the copyright to your article

 

Submit your next manuscript at > springeropen.com

 

 

 
