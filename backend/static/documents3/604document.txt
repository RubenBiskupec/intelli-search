© sciendo

Int. J. Appl. Math. Comput. Sci., 2019, Vol. 29, No. 4, 783-796

DOI: 10.2478/amcs-2019-0058 @ amMecs

 

REVISITING THE OPTIMAL PROBABILITY ESTIMATOR FROM SMALL
SAMPLES FOR DATA MINING

BOJAN CESTNIK #2?

“Department of Knowledge Technologies
Jozef Stefan Institute, Jamova 39, 1000 Ljubljana, Slovenia

’Temida d.o.0., Dunajska cesta 51, 1000 Ljubljana, Slovenia

e-mail: bojan.cestnik@temida.si

Estimation of probabilities from empirical data samples has drawn close attention in the scientific community and has been
identified as a crucial phase in many machine learning and knowledge discovery research projects and applications. In
addition to trivial and straightforward estimation with relative frequency, more elaborated probability estimation methods
from small samples were proposed and applied in practice (e.g., Laplace’s rule, the m-estimate). Piegat and Landowski
(2012) proposed a novel probability estimation method from small samples Fp, 5 that is optimal according to the mean
absolute error of the estimation result. In this paper we show that, even though the articulation of Piegat’s formula seems
different, it is in fact a special case of the m-estimate, where p, = 1/2 and m = V2. In the context of an experimental
framework, we present an in-depth analysis of several probability estimation methods with respect to their mean absolute
errors and demonstrate their potential advantages and disadvantages. We extend the analysis from single instance samples
to samples with a moderate number of instances. We define small samples for the purpose of estimating probabilities as
samples containing either less than four successes or less than four failures and justify the definition by analysing probability
estimation errors on various sample sizes.

Keywords: probability estimation, small samples, minimal error, m-estimate.

1. Introduction particular event (Rudas, 2008). It can be estimated
from a data sample as a single value by the maximum
When dealing with uncertainty in various situations, likelihood estimate. On the other hand, a community of
probabilities often come into play (Starbird, 2006). Bayesians share the view that probabilities themselves can
Probabilities are used to assign meaningful numerical be random variables distributed according to probability
values (from the interval between 0 and 1) to express density functions and can, therefore, be used to express
the likelihoods that certain random events will occur. also more or less uncertain degrees of (subjective) beliefs
Probabilities are the pillars of many scientific and business that some events will occur (Berger, 1985).
disciplines, including statistics (DeGroot and Schervish, 7 a
2012), game theory (Webb, 2007), quantum physics In essence, the problem of probability estimation

(Gudder, 1988), strategic and financial decision-making from data samples can be formulated as follows (Good,

(Grover, 2012), as well as knowledge discovery and data 1965). Suppose that we have conducted (observed)
mining (DasGupta, 2011; Flach, 2012). and recorded a sample of n independent experiments

(instances), out of which there are s successes and f
failures (s + f = n). How do we estimate the probability
p of success in the domain under observation? Or,
analogously, based on the collected experiments, how do
we estimate the probability p that the next experiment will
be a success?

Conceptually, there seems to be a controversial
dispute in the scientific community about the existence
and interpretation of various kinds of probabilities
(Good, 1966). In particular, there is a substantial
conceptual difference between the so-called frequentists
and Bayesians. For frequentists, on the one hand,
probability represents a frequency of occurrence of a In this paper we deal with probability estimation
amcs Ep

B. Cestnik

 

methods from small samples, which is a difficult and
intricate task (Good, 1965; 1966; Chandra and Gupta,
2011; Chan and Kroese, 2011). The subject is not
to be confused with the problem of detecting small
samples and determining the optimal sample size for
statistical analyses (Good and Hardin, 2012), which
is beyond the scope of this paper. To define the
concept of “small sample” for the purpose of estimating
probabilities, we start with the definition of its opposite:
“sufficiently large sample.” Probability theory states that
if sample size n is large enough, differences between
diverse probability estimation methods are negligible
(Good, 1965). Therefore, we are more interested in
determining which sample size reduces the differences
between various probability estimation methods than in
determining which sample size reduces the estimation
errors close to zero. For the study reported in this paper
we presume, as asserted by Good (1965) in his book, the
following.

Definition 1. (Sufficiently large sample) For the purpose
of estimating probabilities, a sample is large enough if
both s and f are greater than 3.

As explained and demonstrated in Section [6] on
such large samples we can, for all practical purposes,
more or less safely use any mathematically sound method
for probability estimation, since the differences between
average mean absolute errors of different estimation
methods tend to drop below the threshold of 0.01.

In addition to Definition[1] we define the concept of
small sample.

Definition 2. (Small sample) For the purpose of
estimating probabilities, a sample is small if either s or
f is less than 4.

Note that Definition |2| does not imply that samples
containing more than 8 instances are not small samples.
In fact, the expected size of a sufficiently large sample
depends on the actual probability of success in the
sample. The results of our analysis concerning the
shortest sufficiently large sample size show that if we are
sampling from a population where the actual probability
of success is 0.5, the average expected shortest sufficiently
large sample size is 10.2 with a median of 10 and a
standard deviation of 2.3. If the actual probability of
success is 0.2 (or its antonym 0.8), the average expected
shortest sufficiently sample size is 20.1 with a median
of 19 and a standard deviation of 8.8. More detailed
results concerning the analysis of small sample sizes are
presented in Section [6] Note, however that, according to
Definitions [I]and[2] every sample containing less than or
equal to 7 instances is a small sample, regardless of the
actual probability of success in the sample.

2. Historical background and related work

According to the classical definition, the probability
of obtaining a success in the next experiment can be
estimated with relative frequency (Feller, 1968)

S S
Delf = —— = 1
Drelt af (1)

n

Probability estimation with relative frequency fits
nicely into the frequentist paradigm and is perfect in
the limit case, when the sample size n approaches
infinity (or, is acceptable, if the sample is at least large
enough). However, when the sample size is small, there
are three major shortcomings concerning such probability
estimations. First, the estimates may have extreme values
of O and | which might be intricate in further numerical
calculations. Second, the estimation errors might be
considerably high. And third, the estimates with relative
frequency do not stabilize fast enough with increasing the
sample size (Piegat and Landowski, 2013).

To curtail the apparent shortcomings of relative
frequency, Laplace (1814) proposed the formula

stl —s+l
st+tf+2 n+4+2’

 

PLaplace — (2)
which is also called Laplace’s rule of succession (e.g.,
Feller, 1968; Good, 1965). Laplace’s formula fits
into the Bayesian probability estimation paradigm since it
assumes a uniform prior probability distribution by adding
one fictitious success and one fictitious failure to the data
sample used for the estimation.

Note that solves the first problem of relative
frequency (1), since PLaplace Can never be equal to 0 or 1. In
addition, Laplace’s rule of succession typically alleviates
the second and third problems of relative frequency by
reducing the average errors of the estimations (Feller,
1968; Good, 1965).

Inspired by the work of Good (1965), Cestnik (1990)
proposed a more general Bayesian method for probability
estimation called the m-estimate:

S+ Dam s+ pam
Pcestnik (Pa; m) — seer = — (3)

The m-estimate has two parameters: pg and ™; pq 1S
a prior probability and ™m is a weight assigned to the prior
probability. The m-estimate was first used in the context
of machine learning and empowered several learning
algorithms to significantly improve the classification
accuracy of generated models (Cestnik, 1990; Cestnik and
Bratko, 1991; DZeroski et al., 1993).

A typical data set used for classification tasks in
machine learning (Breiman ef al., 1984; Flach, 2012)
consists of several learning instances, described with
attributes and their values. Each learning instance belongs
to a designated class. The task of machine learning
Revisiting the optimal probability estimator from small samples for data mining

 

is to construct a model for predicting the value of the
class given the values of the attributes. The m-estimate
was intentionally designed for estimating conditional
probabilities of a class given the values of selected
attributes (Cestnik, 1990). The unconditional probability
of the class, estimated from the whole sample, is taken
as a prior pq. Since the whole data set is usually
large enough for reliable probability estimation with
any probability estimation method, such unconditional
estimates are typically considered sufficiently accurate.
When estimating the conditional probability of a class
given the values of the selected attributes in a rule or
a decision tree, the corresponding data set is filtered
according to the attributes’ values. Such filtered data
sets often qualify as small samples, containing just a
small subset of the original set of learning instances.
In this context, the m-estimate regularly demonstrated
its superiority over relative frequency and Laplace’s rule
of succession (Cestnik, 1990; Cestnik and Bratko, 1991;
Mitchell, 1997; Domingos and Pazzani, 1997; Furnkranz
and Flach, 2005; Sulzmann and Furnkranz, 2009).

In their paper, Piegat and Landowski (2012)
proposed a novel formula for the probability estimation:
1 s—f 1 s—f

5° den f ra 2 Wata) (4)

PPiegat(@) — (s + f + a) 2 2(n + a)

Formula is in their paper denoted by Eppa
and has one parameter a. The theoretical optimization
of the mean absolute error (MAE) with the proposed
formula (4) yielded the optimal value of a = \/2 (Piegat
and Landowski, 2012). After the replacement with the
optimized value of a, the following formula, denoted by
Ep, V2 in their paper, was obtained:

. 1 s—f
Driegat (V2) at5 nV (5)

Piegat and Landowski (2012) demonstrated, both
theoretically and experimentally, that on small samples
(sample size < 25) the accuracy achieved with their
formula was considerably better than the accuracy
of relative frequency and closely comparable to the
accuracy of Laplace’s rule (2) and the m-estimate (8) used
with parameters pg = 1/2 and m = 2.

The probability estimation methods studied in this
paper are the following: relative frequency (1), Laplace’s
rule of succession (2), Piegat’s formula Ep, J3 (5), and
Cestnik’s m-estimate (3). In calculations and graphical
presentations, as well as for shorter annotations in text,
the methods are denoted by shorter names “rvelfr”,
“Laplace”, “Piegat”, and “Cestnik”, respectively. For
denoting the actual probability of a sample we use the
symbol p, while the estimated probability is denoted as
p. The prior probability used in the m-estimate is denoted
aS Pa-

As an error measure of a probability estimation
method we use the mean absolute error (abbreviated
as MAE in the paper) for easier comparison with the
findings reported in Piegat and Landowski (2012). Also,
the preliminary experiments with another measure of
error, root mean squared error (RMSE), revealed that
the general observations and conclusions remain the same
regardless of the error measure used. However, in their
subsequent papers, Piegat and Landowski (2013; 2014)
showed that after using RMSE to optimize errors of
their probability estimation formula (4) they obtained the
optimal value a = 2, which made their formula equivalent
to Laplace’s rule.

Piegat and Landowski (2012) argue that having no
knowledge about prior probabilities is often the case.
However, in several situations it is possible to acquire
background (prior) knowledge that can be effectively
used in calculating posterior probability estimates after
observing a series of experiments. In such situations, the
more elaborated m-estimate reveals its advantages. We
can specify both parameters: p, as a prior probability, and
m as the strength of our confidence in prior. Even if our
knowledge about the prior probability is partially limited
(e.g., interval, distribution), it can still help reducing the
estimation errors.

Piegat and Landowski (2012) made a comparison
of the results achieved using their formula with the
m-estimate; they set the parameters of the m-estimate
such that pg = 1/2 and m = 2, which effectively
transformed the m-estimate into Laplace’s rule. They
argue that the comparison with such an uninformed
version of the m-estimate is fair, since the relative
frequency, Laplace’s rule and Piegat’s formula do not use
any additional information about the priors.

In this paper we compare four probability estimation
methods labelled as “relfr’, “Laplace”, “Piegat’” and
“Cestnik”, with respect to their mean absolute errors in the
context of a carefully designed experimental framework
for conducting experiments and comparisons. The aim
is to study the impact of availability/absence of prior
information on the final estimation errors, as well as the
effect of various levels of noise in the training samples
on the estimation errors of the four probability estimation
methods. Our prediction is that, especially when dealing
with the estimations from small samples, information
about prior probabilities can help reducing the estimation
errors.

The paper is organized as follows. In the next section
we provide additional theoretical background for the four
observed probability estimation methods and demonstrate
that Piegat’s formula is in fact a special case of Cestnik’s
m-estimate. In Section |4| we describe the design and
implementation of the experimental framework used in
our study and clarify some additional methodological
issues. We demonstrate the utility of the experimental

CF acs
amcs Up

B. Cestnik

 

framework in Section[5]by presenting experimental results
of the four studied probability estimation methods. In
Section [6] we present the analysis of the sample size
(small sample, sufficiently large sample) impact on the
estimation errors of the studied probability estimation
methods. In conclusions we summarize the most
important contributions of this research.

3. Theoretical background

In this section we revisit the probability estimation
methods (relative frequency, Laplace’s rule of
succession, Piegat’s formula, and the m-estimate)
and further elaborate their representations to deepen
the understanding. We present methods’ parameters (if
required by the method) and discuss their role in the
estimation. Finally, we demonstrate that Piegat’s formula
is a Special case of the m-estimate.

3.1. Methods for probability estimation. As stated
in Section [1] the relative frequency is a standard
method for probability estimation. It works well if the
sample is large enough. As can be observed throughout
this subsection, all other probability estimation methods
incorporate the ratio s/n, either explicitly or implicitly, in
their calculation.

Laplace’s formula (2) can be rewritten as a weighted
average of relative frequency s/n and 1/2,

n 1 2

- x =x ——.
n+2'2° n+2

 

PLaplace — (6)

Technically, (2) assumes ignorance of the prior
probability by adding two fictitious experiment outcomes
to the collected sample: one success and one failure.
In the Bayesian sense, it introduces a uniform prior
distribution with the expected value of j, = 1/2 (Good,
1965).

Piegat’s formula can also be rewritten as a
weighted average of relative frequency s/n and 1/2,

S n 1 /2
— xX ——+ —- x ——..
n n+V2 2 n+v2

At first sight, the equivalence of formulas and
(7) is not obvious. A more detailed explanation of the
derivation is given in Section[B.2] At this point, however,
observe that we can simplify both and to the
following expression:

PPiegat ( V2) — (7)

Sr

sia

PPiegat (2) =

 

(8)

=
+
S

In consequence, the only difference between Piegat’s
formula (7) and Laplace’s rule (6) is the number of added
fictitious instances to the sample. While in Laplace’s rule

there are two fictitious instances added (one success and
one failure), Piegat’s formula adds /2 instances (/2 /2
successes and \/2/2 failures).

For the purpose of explaining the role of parameters
Dq and m, we can transform Cestnik’s formula to the
form of a weighted average of relative frequency s/n and
Da (Cestnik and Bratko, 1991):

 

 

 

s n
DCestni a =— xX a X* . 9
Pcestnik (Pa, ™) 7 Xam 1P**% pam (9)
In (9) we introduce
m
— 10
oom (10)

To express the factor n/(n +m) in (9) in terms of a,
observe that
n n+m—-—m

= ———_ = 1- a. (11)

n+m n+m
Since both m and n are supposedly non-negative
numbers, a can take values from the interval |0, 1]. Using

a, we can rewrite (9) as
. s
Pcestnik (Pa, 7) — ” x (1 _ a) + Pa X Q. (12)

Formulas (9) and show that the estimate jcestnik
is a linear combination of relative frequency s/n and prior
probability p,. In the extreme case, when qa is equal to 0
(m = QO), the result of formula is equal to relative
frequency s/n. On the other hand, if @ is equal to 1 (n =
0: or, if m > 0: m — ov), then the result of formula
converges to prior probability pg.

Formula can be rearranged as a sum of relative
frequency and a residual,

A S S
Dcestnik (Pa; 7) =—-t+ (po —_ ~ ) x a. (13)
nr nr

The role of the residual is to push the estimation away
from relative frequency s/n towards prior probability pa.
The strength of the push is proportional to the value of a.

The process of Bayesian probability estimation is
sometimes called smoothing or flattening (Flach, 2012;
Fienberg and Holland, 1972; Bouguila, 2013). The main
role of smoothing is to push the estimated probability
away from the extreme value obtained with relative
frequency (1) towards some sort of average value (1/2 for
Laplace’s and Piegat’s formulae, p, for the m-estimate).
Contrary to formula (13), formula can be represented
as the sum of prior probability and the residual:

A §
Pcestnik(Pa; m) = Pa + (- —_ Pa) x (1 —_ a). (14)

In the role of the residual is to push the estimate
from prior probability p, towards relative frequency s/n.
The strength of the push is proportional to the value of
(1 — a). The expressions of the m-estimate used in
and are suitable to better understand the role of
parameter q@ in error analyses reported in the subsequent
sections.
Revisiting the optimal probability estimator from small samples for data mining

 

3.2. Piegat’s formula is a special case of the ™-
estimate.

Theorem 1. Piegat’s formula (5) is equivalent to Ces-
tnik’s m-estimate with parameters m = 2 and

Pa = 1/2.

Proof. We start with Piegat’s formula (Piegat and
Landowski, 2012) for estimating probabilities from small
samples (note that in his original formula Piegat used nap
for the number of confirmations of hypothesis h and nz,
for the number of confirmations of anti-hypothesis h):

1 s—f

2 * 2(n + V2). >)

At first sight, the m-estimate

PPiegat (/2) =

S+ Dam

a (16)

PCestnik (Da; m) —
looks very different from Piegat’s formula (15). In
we substitute n with s + f and rearrange it as a single
fraction:

. s+ft+vVv2+s-—f
Briegat(W2) = —=—————.. (17)
eu(V2) 2(s+ f + v2)
After simplifying the numerator, we obtain
. 25+ V2
Driegat (V2) Fe (18)

7 s+ f+vV/2)

Next, we divide both the numerator and denominator by 2
and replace s + f with n:

. stiVv2  s+5vV2
Driegat (V2) a (19)
s+f+vV2  n+v2
The comparison of and demonstrates that
Piegat’s formula is a special case of Cestnik’s m-estimate;
if in we set parameters m = J/2 and p, = 1 /2, we
obtain (19), which is equivalent to (15). Z
Note that the m-estimate is more general than
the other three estimation methods, since it subsumes all
the others. We can obtain all the other estimation methods
by setting the m-estimate parameters m and p,. The
appropriate parameter setting of m and p, for obtaining
the other probability estimation methods is shown in
Table[1]

4. Methodology and the experimental
framework

In this section we describe the implementation of the
experimental framework that was used for the evaluation
of the presented methods with respect to their mean
absolute errors (MAE). The framework is conceptually

Table 1. Setting the parameters of the m-estimate for obtaining
the other probability estimation methods.

method / parameters of the m-estimate | pg m

relative frequency
Laplace’s rule of succession

 

Piegat’s E'p, 5

similar to the framework used by Piegat and Landowski
(2012) for their practical experiments; additionally,
it introduces several new features and improvements.
The most important requirements and decisions for the
experimental framework were as follows:

e Generate samples with large numbers of instances
distributed according to the binomial distribution
with the probability of success p. From each
generated sample we would like to be able to extract
a substantial number of sub-samples for probability
estimation tests, so that the statistical validity of
the estimation errors is achieved. The decision was
to perform 100000 experiments. Therefore we set
the generated sample size to 100500. Note that
Piegat and Landowski (2012) used the sample size
of 10000.

e Probabilities of successes in the sample should
be evenly represented and the interval (0, 1)
should be reasonably well covered. We decided to
use 21 different probabilities with the interval
of 0.05 between two adjacent probabilities
(0.01, 0.05, 0.10,...,0.95, 0.99); the lowest and the
highest probability were set deliberately to avoid
0.0 and 1.0. Note that Piegat and Landowski (2012)
used 11 selected probabilities in their experiments.

e Probability estimation methods’ should be
implemented in a unified and comparable way.
Access to data samples should be unified.
The framework should provide an_ additional
functionality to introduce noise to the artificial
training samples to mimic more realistic practical
situations.

e The experimental framework implemented in R (R
Core Team, 2018) should be publicly available for
download and experimentation. It is available on
GitHub (Cestnik, 2018) under the MIT license.

4.1. Sample generation in the experimental frame-
work. The instances that comprise artificial samples
are drawn from the binomial distribution. Artificial
samples (Larose, 2010) are often generated to mimic the
samples obtained from the real world, which are generally
more costly and sometimes also more difficult to obtain.

CB arcs
ro

B. Cestnik

 

However, there is one major difference between the two
kinds of samples. In samples collected from real world
we often do not know the actual probability p; so, we
have to estimate p from the sampled data. Since the actual
p is unknown, the absolute error |p — p|. One of the
benefits of artificial samples is that, due to the known p,
we can reliably calculate the absolute error |p — p| of the
probability estimation.

Let us first generate a random sample S, of n binary
instances, where each instance can be either a success with
probability p or failure with probability 1 — p. A success
is encoded as 1 and a failure as 0. From sample S,, we
select a sequence of / consecutive instances, starting with

 

instance 7; the selected sub-sample is denoted as sl MT

We can use sub-sample gi "| to estimate the probability
with a given method:

Pmethoa (St!) (20)

and compare the estimate with the known probability p
that was used to generate the sample S,,. We can calculate
the absolute error (AE) of the estimation method:

AE method (S12!) — |Pmethoa (S47""!) ~~ pl. (21)

The mean absolute error (MAE) of the probability
estimate with a given method on 100000 sub-samples of
size / is the following:

x prvae AE method (9)
MAE meinoa( St") = =acT/ | (22)

In index j runs from 1 to 100000, so that each
sub-sample git is obtained from sample S, as a
sequence of / instances starting at instance 7.

To obtain the average of MAEs (AMAB) for all 21
samples Sp,,j7 € {1,...,21} we used the following
formula:

a 1 MAE method (set )

AMAEnmethod (1) = 1

(23)

AMAE method (1) calculates the average error of MAEs
of the method on sub-samples of size / from all
the samples generated with the preselected probabilities
within the experimental framework. AMAE can be used
as a single value estimate of the absolute error of the
method. Note that even though AMAE is calculated as an
average of averages (MAEs), it yields an accurate average
error estimate from all AEs, since each MAE 1s calculated
as an average error from the same number of sub-samples.

To measure how different probability estimation
methods mm, and m2 are, we can compare the AMAEs
(23) of the two methods. However, since the AMAE is the
average of MAEs, it can be similar even if the two MAE
arrays are quite different in various probability intervals.

For this reason, a more precise measure of the similarity
of two methods ADIFFyn1, m2(/) was used:

i |DFmnt, m2(J, 1))|

ADIFF yn), m2(L) = 7

(24)

where

DF m1, m2(j, 2) = MAEmi (S$) — MAEmo (Sf). (25)
4.2. Data structures, functions and procedures in the
experimental framework. The proposed experimental
framework consists of the generated instance samples,
the functions for probability estimation and calculation
of estimation errors, and a procedure that implements
various testing scenarios.

The samples S;, are generated for all the preselected
probabilities p; (¢ € [1,...,21). Each sample consists of
100500 instances. 100000 sub-samples of various sizes
(from 1 to 500) starting at consecutive positions can be
generated from each sample S,,.

The probability estimation functions are defined for
each of the studied methods: relative frequency (1),
Laplace’s rule (2), Piegat’s formula (5), and the
m-estimate (3). The framework also includes a function
that calculates MAEs of the selected probability
estimation method.

Algorithm [I] defines the basic evaluation procedure
of a probability estimation method. Two main parameters
of the algorithm are the method for the estimation of
probabilities and the number of instances (sample size)
from which the probability is estimated. In addition,
we have to provide probability estimation parameters if
required by the method. Such parameters include prior
probability for the estimation and the value of m for
the m-estimate. To simulate more realistic settings for
conducting experiments, we also included distortion of
prior probability for the m-estimate, and distortion of the
index of the training sample that can be used to introduce
noise in the sample.

5. Evaluation of probability estimation
methods in the experimental framework

The mathematical probability theory (Feller, 1968) states
that, in an idealized situation when the sample size
approaches infinity, the probability of success p is equal
to the relative frequency:

p= lm r (26)

noo nN
In reality, however, obtaining samples of an infinite size
nm is not physically feasible. Therefore, we have to take
into account the fact that probability estimation errors are
bound to occur. Among several factors that influence
Revisiting the optimal probability estimator from small samples for data mining

 

Algorithm 1.
method.

Step 1. Select a method for probability estimation and
set the parameters required by the method.

Evaluation of a probability estimation

Step 2. Select the level of noise in the sample: distortion
pq Of pq for the m-estimate and distortion d, of the index
of the training sample.

Step 3. Select estimation sample size / (e.g., 1, 2, 3,...).

Step 4. Use formula on each of the 21 samples
Sp,(¢ € 1,...,21) to calculate the MAEs of the selected
method and store the results in an array, where each
element of the array represents the MAE of one sample.

Step 5. Use the array of stored results for displaying
graphs and computing the AMAE with formula of
the method.

the validity of statistical analyses as well as probability
estimation errors (Good and Hardin, 2012), in our study
we focused on the following two: small samples and
biased prior assumptions. Small samples, even if obtained
without any other bias, are themselves the cause of
probability estimation errors (Good, 1965). And second,
biased prior assumptions, if incorporated in probability
estimation methods, also affect the probability estimation
errors.

In this section we present the results of our
experimental work. There were three tasks that we wanted
to accomplish with our experiments. The first task (1)
was to compare all four probability estimation methods
on sub-samples of the same size and to examine the
impact of sub-sample sizes 1 to 7 (small samples) on
the performance of each probability estimation method.
In the second experiment (2) we evaluated the impact of
a random distortion of prior probability p, (biased prior
assumptions) used in the m-estimate and compared such
a distorted m-estimate with the other estimation methods.
The third task (3) was to compare the performances of
all the estimation methods with the metrics proposed in
Dem$Sar (2006) for comparing the performances of data
mining algorithms.

Three probability estimation methods (relative
frequency (1), Laplace’s rule (2) and Piegat’s formula
have no additional parameters except n and s. However,
the ™-estimate requires two parameters: pa and m.
If not explicitly stated otherwise, in the experiments with
the m-estimate the actual probability p of sample S,, was
taken as parameter p, and, the parameter ™ was set to
2, which was a sort of standard value in many studies
that used the m-estimate (e.g., Cestnik, 1990; Flach,
2012). Note that taking the probability p of S, as the
parameter p,, which means that the actual probability of
the sample was taken as a prior in probability estimation,
is idealized and seems to offer an unfair advantage to

 

 

 

 

 

 

wo
Oo '|--0-  relfr ee OO Og
-a- laplace a “OL
56 + |?  piegat we OL
= © |-4- cestnik oO ‘o,
oO « 8 . o ‘© a
5 ST . Bs ‘ a 2
Oo POL BL ig Qt &
g “OTL my LO”
N | LOOK --- of.
a) é se a hears > ‘9
Cc / +.B. RIAA BA AL _a ‘
oO ‘ Lg 8 B AOR \
o- ‘ a 8 ay ,
E oT S A A 9g
a AL \
(bs . . ALS
So | &xtra-low low medium high extra—high
°
0.0 0.2 0.4 0.6 0.8 1.0
p

Fig. 1. Mean absolute errors of the relative frequency, Laplace’s
rule, Piegat’s formula and Cestnik’s m-estimate when
the estimation is performed on samples of size 1. Ver-
tical lines indicate boundaries between loosely defined
probability intervals named extra-low, low, medium,
high and extra-high.

the m-estimate; therefore, the obtained results have to
be considered as the minimal possible absolute errors
achieved with the m-estimate. To compensate for such an
ideal setting and to obtain a more realistic comparison of
the studied probability estimation methods, we introduced
pq distortions of pg in the experiments described in later
subsections.

5.1. Comparison of probability estimation methods
on sub-samples of the same size. The first task was to
compare the four estimation methods according to their
mean absolute errors (MAEs) on small sub-samples of
the same size. We started with sub-samples of size 1
(single instance samples). The comparison of MAEs of
the four estimation methods is shown in Fig. The
relative frequency produced the highest MAEs and the
m-estimate the lowest MAEs. The behaviour of the MAEs
of “Piegat” is quite similar to the MAEs of “Laplace”;
the only difference between the two methods is in their
smoothing constant: while “Laplace” uses the value 2,
“Piegat” uses smaller \/2 and, therefore, enforces a sightly
weaker push of the probability estimate towards prior
probability 1/2. Note that the value of a (as in (12)) ona
single instance sample is 2/3 ~ 0.6667 for “Laplace” and
V2/(1 + V2) & 0.5858 for “Piegat”.

The obtained average mean absolute errors (AMAEs)
are shown in Table[2] The relative frequency produced the
highest AMAE (0.3185) and the m-estimate the lowest
(0.1062). Laplace’s rule and Piegat’s formula resulted
in mutually comparable AMAEs (0.2037 and 0.1993)
that lied between the former two. Relative frequency
estimation is the most different from all the other
estimation methods, while Laplace’s rule and Piegat’s
formula are the most similar.
amcs Sp

 

 

 

 

 

 

 

B. Cestnik
Table 2. AMAEs of the four methods on sample sizes | to 7.
lo
Sample a
size “relfr’ “Laplace” “Piegat”  “Cestnik” 3: laplace
— st - -
S S '|-a- cestnik
®o
GO
=) oS | oe TOeL ao? aon
Oo 2 tq" ° Qa.
” Be. . eo
6 84 ofa? Sa 8
c oo ga. oO” z. 2 o & 3 Bee a. Le
oo a. _ <7 Al It ~.w6- A J “a,
SO J ogg ROR R B08 .
Es Sa ya 8,
ee SAS,
2 4 &tra-low low medium high extra—hig®
I I I I I I
0.0 0.2 0.4 0.6 0.8 1.0

 

To interpret the behaviour of MAEs of the four
probability estimation methods in Fig. [1] we grouped
the probabilities p on the x axis into loosely defined

intervals. In particular, in Fig. we observed two
compelling interval boundary values: the intersection
point between MAE of “relfr’” and MAE of “Laplace”
(or MAE of “Piegat’’), and the intersection point between
MAE of “Cestnik” and MAE of “Laplace” (or MAE of
“Piegat’). Note that the MAEs of “Laplace” and “Piegat”
are noticeably similar, so we decided to use MAEs of
“Laplace” in calculations of the interval boundary values.
Since we were not interested in the exact determination
of the interval boundary values, they were determined
experimentally within the experimental framework. The
decision was to use 0.01 tolerance: if two values differed
less than the tolerance 0.01, they were considered equal
to each other. The first interval boundary was set at 0.14,
which was the lowest probability where MAE of “relfr”
rose equal to MAE of “Laplace” (0.01 tolerance). The
second boundary value was determined accordingly and
was set to 0.29.

The loosely defined probability intervals in Fig.
were named as extra-low, low, medium, high, and extra-
high. The interval boundaries were named accordingly:
boundary extra between the extra-low and low intervals,
and boundary medium between the low and medium
intervals. Boundaries extra and medium were conversely
used as (1 — boundary) for determining the antonym
boundaries between medium and high and high and
extra-high intervals. Accordingly, in Fig. [1] there are
five loosely defined intervals of actual probabilities p:
extra-low (0.00, 0.14], low (0.14, 0.29), medium [0.29,
0.71], high (0.71, 0.86), and extra-high [0.86, 1.00).

On the samples with actual probabilities of success
from extra-low and extra-high relative frequency “relfr”
performed much better than “Laplace” and “Piegat”. On
the other three intervals (low, medium, high) “Laplace”
and “Piegat” performed considerably better than “relfr’.
The m-estimate evidently performed better than all other
methods on all the intervals except on the medium
interval, when the performances of “Cestnik’’, “Laplace”
and “Piegat’” were roughly comparable. Note, however,

Fig. 2. Mean absolute errors of the relative frequency, Laplace’s
rule, Piegat’s formula and Cestnik’s m-estimate when
the estimation is performed on samples of size 2. Ver-
tical lines indicate boundaries between loosely defined
probability intervals that are named extra-low, low,
medium, high and extra-high.

that the results for “Cestnik” might be too optimistic to
generalize, since the actual p was taken as hypothetical
Da, Mm = 2.

The comparison of the errors of the four methods
on sub-samples of size 2 is shown in Table [2] and in
Fig. The interval boundaries were recomputed using
the same procedure as for single instance samples. Note
that boundary extra decreased to 0.12 and boundary
medium decreased to 0.22. Average mean absolute
errors (AMAEs) are shown in Table The relative
frequency still produced the highest AMAE (0.2192) and
the m-estimate the lowest (0.1069). Laplace’s rule and
Piegat’s formula resulted in comparable AMAEs (0.1709
and 0.1670) that lie between the former two.

By adding an additional instance to a single
instance sample AMAE decreased substantially for
“relfr’, decreased moderately for “Laplace” and “Piegat’,
while for “Cestnik’”’, contrary to our expectations, AMAE
slightly increased. A more detailed analysis of such
unexpected behaviour revealed that for probabilities 0.35
to 0.65 MAE cestnik slightly decreased on samples of size
2 with respect to single instance samples; however, for
probabilities up to 0.30 and over 0.70 MAE cestnik slightly
increased by adding an additional instance to a single
instance sample. The increase was especially notable
for probabilities between 0.1 and 0.2, as well as 0.8 and
0.9. Those probabilities were for the m-estimate harder to
estimate correctly from two instance samples than from
single instance samples. The main reason for such a
slight increase in the m-estimate’s AMAE was found by
observing parameter a in formula (12): a = 2/3 for
single instance samples, while a = 1/2 for two instance
samples, which corresponded to smaller weight attached
to prior probability p, in the latter case. Since the actual
Revisiting the optimal probability estimator from small samples for data mining

 

prior of the sample was taken as pq, the higher a enlarged
the impact of p, to the final probability estimation and,
therefore, induced the lower estimation error.

The comparison of the errors of the four probability
estimation methods on sub-samples of size 3 is shown in
Fig.|3} Note that boundary extra further dropped to 0.11
and boundary medium dropped to 0.18. Average mean
absolute errors (AMAEs) are shown in Table[2]} AMAEs
of all four methods were reduced with the introduction of
a new instance to the sample; however, the order of the
estimation methods from the highest to the lowest AMAE
was preserved.

Figures [4] and [5] show the calculated MAEs on
samples with 10 and 100 instances, respectively. Note
that the values on the y axis in both figures are rescaled
to show the differences between the methods in more
detail. The AMAEs of the four probability estimation
methods on the samples of 10 and 100 instances are shown
in Table 2] While Fig. [4] still exhibits subtle differences
between the MAEs of distinctive methods, the differences
between the methods in Figure[5]are practically negligible.
Note that both boundaries extra and medium in Fig.
further dropped to 0.06 and 0.08, respectively. Since the
differences between the methods in Fig. [5]on samples of
size 100 were almost negligible, the boundaries extra and
medium became irrelevant.

In summary, AMAEs of the four probability
estimation methods on sample sizes 1 to 7 are shown in
Table The interval boundaries changed substantially
with increasing the number of instances in the samples,
as shown in Table The size of the medium interval
increased with increasing the sample size and slowly
prevailed on account of diminishing the other four
intervals. For further analyses and interpretations we
generalized the boundaries of loosely defined intervals
from Table 3] by computing the average of the first five
sample sizes (from 1 to 5). Generalized boundary extra
was set to 0.10 and generalized boundary medium to 0.20.

Table 3. Interval boundaries extra and medium depending on the
sample size.

Boundary
Sample size | extra medium

 

 

 

 

 

 

 

©
Oo |--0- relfr
--G- laplace
5 ot lo piegat
= © |-4- cestnik
®
DB oo
=o]
D eg
o NJ, @--O--9--90 ---9---G---9 a
c o eB oe 2 2 Q _-are
O-.g BS. 22: LLB IIZ>-g.- &. 1B LL}
8 _ OS Oe ge g 8 SRS A : g ae
Eo] gy A “A *Q
ia AN
e 4 efra-low low medium high extra—fyh
! ! ! ! ! !
0.0 0.2 0.4 0.6 0.8 1.0

p

Fig. 3. Mean absolute errors of relative frequency, Laplace’s
rule, Piegat’s formula and Cestnik’s m-estimate when
the estimation is performed on samples of size 3. Ver-
tical lines indicate boundaries between loosely defined
probability intervals that are named extra-low, low,
medium, high and extra-high.

 

 

 

 

 

 

lo
o |-o- relfr
--@- laplace 6 o
oO “o- piegat (Prnrg Og
- -A- cestnik O---0" -- Borg B--g. s@---0,
o fc | a eB ~S- Bg -
Qs 2 BB a BBB o
= fa tek
9 Be Bee Beg daly"
2 ae By
TS io og Xx ‘AL B- ©
c Co ils” A,
© oO My
rab) A ‘
E
| l'  ®
co | extra-0 medium Qyextra—
So - low w h, high
° T T T T T
0.0 0.2 0.4 0.6 0.8 1.0

p

Fig. 4. Mean absolute errors of relative frequency, Laplace’s
rule, Piegat’s formula and Cestnik’s m-estimate when
the estimations are performed on samples of size 10.
Vertical lines indicate boundaries between loosely de-
fined probability intervals that are named extra-low, low,
medium, high and extra-high.

 

 

 

 

 

 

--0-- relfr
--B-- laplace
x |-<- piegat
= oH ABO, ae - - Be
Qo |-4- cestnik we “ae Bg
o frre Beg
2 3] a a,
2o x ‘a.
O ie
R
gal A
S ee
c g
o P
= ad i
oO _} ‘
& 8
oO a a
oO
o 4
©
0.0 0.2 0.4 0.6 0.8 1.0

p

Fig. 5. Mean absolute errors of relative frequency, Laplace’s
rule, Piegat’s formula and Cestnik’s m-estimate when
the estimation is performed on samples of size 100.

5.2. Introducing biased prior assumptions as distor-
tions pq of pg to obtain hypothetical p, in the m-
estimate. In the experiments described in the previous
subsection we used the actual p of the samples as a prior
amcs Gp

 

probability p, in the m-estimate. Such a serendipity
could rarely happen in a real-world situation; normally,
we are bound to start the estimation with an approximate
prior probability p,. Therefore, to make the estimation
set-up more realistic and to compensate for such an
“overly informed” m-estimate, we introduced deliberate
distortions to prior probabilities; given the maximal
distortion pg, we, in each estimation, randomly selected
hypothetical p, from the interval [pa — pa, Pa + Dal.

The AMAEs of the m-estimate increased with the
growing distortion in pg, which can be observed from
Table |4| The increase was moderate for distortion pg =
0.3, substantial for distortion pg = 0.5, and extensive
for distortion pg = 1.0. By comparing the results from
Tables [4] and 22] we observed that while the AMAEs of
the m-estimate with pg = 0.3 were still well below the
corresponding AMAEs of “Laplace” and “Piegat’”. The
difference between the AMAEs of the m-estimate with
Da = 0.5 and those of “Laplace” and “Piegat’” were only
slightly in favour of the m-estimate. With distortion pg =
1.0 the m-estimate’s AMAEs rose close to the AMAEs
of relative frequency and was thus far above AMAEs
of “Laplace” and “Piegat’”. Increasing the number of
instances in samples decreased AMAEs of the m-estimate
in all cases.

Comparisons of the m-estimate using pg distortions
(0.3, 0.5 and 1.0) of pg with other probability estimation
methods on single instance samples are shown in Figs. [6]
and With increasing distortions to pg, the MAEs
and AMAEs of the m-estimate increased. While the
m-estimate with pg = 0.3 distortion of pg on the
average still performed better than Laplace’s rule and
Piegat’s formula (Fig. [6), the distortion of 0.5 increased
the MAEs of the m-estimate slightly over the MAEs of
“Laplace” and “Piegat” in the medium interval (Fig. [7),
even though the overall AMAE of the m-estimate with
Da = 0.5 (0.1773) was still slightly smaller than
AMAEs of “Laplace” (0.2037) and “Piegat’” (0.1993) on
single instance samples. The slight superiority of the
m-estimate’s AMAEs with pg = 0.5 over AMAEs of
“Laplace” and “Piegat” can be observed from Tables

Table 4. AMAEs of the m-estimate with m = 2 on sample sizes
1 to 7 and distinctive distortions pq of pa.

Sample pq distortion in pq
Size 0.0 0.3 0.5 1.0

 

 

 

 

 

 

 

B. Cestnik
wo
4 o- .
Oo |--o-- relfr oe ee
5S Ss --B-- laplace o hg
© 6 7-~<- piegat o ©
® -&-- cestnik /
®o . ao
ro : 9 ® -
B stot “ 7 6
2 e238 Be
2 N | ooe, o--O--O o oe
c e Olan ark BOB: Bg A ae a
ow ” ae Ege a 3 eas en \
os foe oe aS ALL
€ oT A--g-- A A B-A
ro) © °o
2 4
T T T T T T
0.0 0.2 0.4 0.6 0.8 1.0

Fig. 6. Comparison of MAEs of the four estimation methods,
pa distortion of p, for the m-estimate = 0.3.

 

 

 

 

 

 

--©-- relfr o re

5 < pe laplace oO mS
© o 1: piegat ° Se
® --A-- cestnik ‘
®o o

© : 2 ° -
5B Ss ot v . =m)
fe TOE 9’ ‘og TS
g a OLB, NO

_ POs --& nN
BG oO 3 oR _B--B8- Oo OBA wg oN
c A--p.-n---A-- Bs: 2 _--G--a ae DOB --A AAA

Ore a a Sle ‘

& Q “&e. wag - OO .
Oo = 4 @ ‘a
E oO /

oO o o

2 4

0.0 0.2 0.4 0.6 0.8 1.0
p

Fig. 7. Comparison of MAEs of the four estimation methods,
pa distortion of pq for the m-estimate = 0.5.

 

 

 

 

 

 

wo
am © --9.
Oo |--o-- relfr om an
--B-- laplace a .
oO + | P o 8
© 6 7<- piegat ° Ne,
o -&- cestnik} ».
Lo | +s 2 vB a
D> o ©. “<A. “ ‘ ao" 2
9° ee AB Le
8 a oa A AL Any pee eB 8
ws SS B--~A__ a -A-- oo Ae

CS of o OE. veo nara toad ‘e
c / Be Og BBB OLB ‘
S _ STB ee ~ og ET .
Ee So || g Q

oO oe °o

2 4

0.0 0.2 0.4 0.6 0.8 1.0
p

Fig. 8. Comparison of MAEs of the four estimation methods,
pa distortion of pq for the m-estimate = 1.0.

and [2] With the distortion of pq = 1.0 the m-estimate
performed worse than “Laplace” and “Piegat” on all 21
single size samples from the experimental framework
(Fig.[8). Therefore, when #, is for the m-estimate selected
randomly (e.g., distortion pg = 1.0), the AMAEs of
the m-estimate from Table |4] show the inferiority of the
m-estimate to “Laplace” and “Piegat” from TableJon all
small sample sizes | to 7.
Revisiting the optimal probability estimator from small samples for data mining

 

cestnik piegat

 

cestnik_pd0.3 relfr
laplace cestnik_pd1.0
cestnik_pd0.5

 

Fig. 9. Ranking the probability estimation methods in a critical
difference plot. Calculated MAEs on sub-samples from
1 to 7 instances were used for comparison and ranking.
CD is the critical difference obtained with a = 0.01.

5.3. Ranking the probability estimation methods.
For comparing and ranking the results obtained by the
four studied probability estimation methods (relative
frequency, Laplace’s rule, Piegat’s formula, and the
m-estimate) we applied the approach proposed by DemSar
(2006) and refined by Garcia and Herrera (2008) as well
as Garcia et al. (2010) for statistically comparing the
performance of different machine learning algorithms.
For the m-estimate we included also three additional
variations of biased prior assumptions by introducing
distortions pq of pg: 0.3, 0.5 and 1.0. MAEs for each of
the seven probability estimation methods on sub-samples
of sizes 1 to 7 were calculated on 100000 sub-samples
extracted from 21 samples in the experimental framework.
As aresult, 147 distinct MAE calculations were obtained
for each probability estimation method and used for
pairwise performance comparison.

The process of analysing the results was
implemented in R_ using package scmamp (Calvo
and Santafé, 2016). The obtained critical difference plot
is shown in Fig. [9] The critical difference calculated
with Nemenyi test with parameter a = 0.01 was 0.8724.
When the difference between two probability estimation
methods in the critical difference plot was greater than the
critical difference, the performances of the two methods
can be regarded as significantly different from each
other. In Fig.[9|the probability estimation methods whose
performance was not significantly different are connected
with a horizontal line.

Not surprisingly, the m-estimate with no distortions
in pq (labeled as “Cestnik” in Fig. [9) was ranked the
first. The second method was the m-estimate with
distortion pg = 0.3 (labelled as “Cestnik_pd0.3”);
when distortions pg were small enough, the m-estimate
still performed significantly better than all the other
probability estimation methods. Next came a group
of methods including Laplace’s rule (“Laplace”), the
m-estimate with distortion pg = 0.5 (“Cestnik_pd0.5”)
and Piegat’s formula (‘‘Piegat’); the performances of
these three methods were not significantly different.

The lowest ranked methods were relative frequency
(“relfr’) and the m-estimate with distortion pg = 1.0
(“Cestnik_pd1.0”), whose mutual performance differences
were also statistically insignificant. The effect of
distortions pg of prior probability p, in the m-estimate
can be summarized as follows: when distortions pg were
relatively small (e.g., smaller than 0.3), the m-estimate
performed significantly better than the other probability
estimation methods; with distortions pg around 0.5
the m-estimate performed similarly to Laplace’s rule
and Piegat’s formula, while distortions pg close to 1.0
degraded the performance of the m-estimate to become
even slightly worse than the performance of relative
frequency.

6. Experiments for finding the shortest
large enough sample

Besides defining the sample size directly by its length,
we can specify it indirectly by defining a certain criterion
that the sample must satisfy. For example, Definition [1]
states that a sample is large enough if it contains more
than three successes and more than three failures. Samples
containing at least s successes and at least f failures can
be of variable length, with their average length depending
heavily on the authentic probability of success in the
sample. In this subsection we present both theoretical and
experimental findings concerning the determination of the
shortest large enough sample according to Definition[]]
When sampling from binomial distribution B(n, p),
the probability of obtaining exactly s successes in n
experiments (number of failures is f = n — s) is

ae —p)*. (27)

Pr(s,n) =
We used to calculate the exact probability that,
according to B(n,p), at least sjjm successes and at least
fiim failures are obtained in n experiments:

i=n— flim

PLs> sims f > flim (n) — Ss” Pr(i, n). (28)

t=Slim

In all the probabilities Pr(i,n) are summed over
the index 7 from sj;m to n — flim. The lower limit of
index 2 guarantees that the number of successes is equal
to or greater than s);,,, while the upper limit guarantees
that the number of failures is equal to or greater than
fiim by limiting the number of success to less than or
equal to n — flim. For shorter notation in the subsequent
formulas we denote A the condition s > sjim, f > flim. To
estimate the average sample size that contains at least sjim
successes and at least fiim failures, we first transformed
the cumulative probability distribution Pr,(m) to the

CF arcs
amcs Ep

B. Cestnik

 

Table 5. Statistical moments of sizes of the shortest large
enough samples (Definition [I) distributions for all 21
probabilities used in the experimental framework.

probab.
ind of success | mean median mode sd

0.01, 0.99 300 =—199.0
0.05, 0.95 60 39.0
0.10, 0.90 30.—: 19.0
0.15, 0.85 20 12.3
0.20, 0.80 1 8.8
0.25, 0.75 6.7
0.30, 0.70 5.2
0.35, 0.65 4.1
0.40, 0.60 3.2
0.45, 0.55 2.6

0.50 2.3

—
’
—

NbN
i)

Oo

GN

6,

x”

FP a
== SR Lr CON LO

WRN On4 © WO

—
oe
—
tO

probability density for each n:

J Pry(n) ifn = 1,
pra(n) = ma —Pr(n—1) ifn>1. 0)

Then, we calculated the expected average of pr) (mn) for all
sample sizes from | to oo:

[by = Ss” nm X pry(n). (30)
n=1

The standard deviation of pr)\(n) was calculated
accordingly:

 

oO, = So (n= py)? x pry (7). (31)
n=l

In numerical calculations of formulas and that
are presented in Table[5]we used the upper limit of 1500
instead of oo, since the values of pr, (n) tend to drop to
O for n larger than 1500. The so calculated statistical
moments of samples’ length distributions are presented
in Table The decreasing order of the sample size
mean, median and mode indicates that the probability
distributions of sample sizes are highly positively skewed
with a long right tail. In fact, the calculated skewness
(DeGroot and Schervish, 2012) was greater than | for all
sample size probability distributions shown in Table[5]

In this subsection we present experimental results
that additionally justify Definitions[1]and[2]by measuring
and comparing AMAEs of the four probability estimation
methods on sub-samples described by such indirect
sample-size criteria. We compared the methods’ errors
on the shortest samples containing at least three, four, and
five successes and failures.

The results of the four probability estimation
methods obtained on such sub-samples from the

 

 

experimental framework obtained as the average of
100000 experiments in the experimental framework
are shown in Table [6] AMAEs of the four
probability estimation methods decreased with increasing
the descriptive sample sizes. However, note that in
these experiments we were not interested that much in
minimizing the values of AMAEs; our goal was to observe
and minimize the differences between the estimation
methods in terms of ADIFFs. On the samples described
with 4s and 4f all ADIFFs dropped below 0.01 (or very
close to 0.01 for ADIFF between “relfr’ and “Cestnik’’).
Note that, for example, on the 3s and 3f samples all
ADIFFs between “Cestnik” and the other estimation
methods were quite higher than 0.01.

The MAEs obtained by the four probability
estimation methods on the shortest large enough sample
(as in Definition [1) are shown graphically in Fig.
The differences between the used estimation methods
are small; in fact, on the average they are smaller than
0.01, as can be observed from Table [6] part 4s and
4f. Since the differences between AMAEs and ADIFFs
of parts 4s and 4f, and 3s and 3/f are really small,
one might conditionally accept also the samples with 3s
and 3f as large enough, sacrificing a small additional
estimation error for the sake of simplicity in selecting
relative frequency as the estimation method. However,
the decision of choosing the samples of 4s and 4f as
the shortest sufficiently large samples is supported also
by the assertion of Good (1966), as already mentioned
in the context of Definition[1] Therefore, in spite of the
relatively small differences between ADIFFs of 4s and
4f, and 3s and 3f, the proposed threshold of 0.01 seems

Table 6. AMAEs and ADIFFs of the four probability estimation
methods on indirectly described sample sizes.

amar | ret

3s and 3f

ADIFF
“Laplace” “Piegat”
“relfr’
“Laplace”

“Piegat” | 0.0839 | 0.0070 0.0027
“Cestnik” 0.0150 0.0140 0.0137

4s and 4f

“relfr’”’
“Laplace”
“Piegat”
“Cestnik”

0.0097

0.0739 | 0.0070
0.0736 | 0.0050
0.0103

5s and 5f

0.0020

0.0098 0.0095

“relfr’”’
“Laplace”

“Piegat”
“Cestnik”

0.0055
0.0666 | 0.0039
0.0076

0.0016

0.0071 0.0070
Revisiting the optimal probability estimator from small samples for data mining

 

 

 

 

 

 

 

 

 

 

LO
o --0-- relfr
L - laplace
© -&- piegat
bo _-O. -A-- cestnik
2 sl ge B- & & ° Ng Db Ae
= & A LA AA Bog BA “Aow A Bu
9 Boh AaB.
oO io Or,
© 8 B “ A a et
ae OR Rh
® g”" “Sg
E a a
8 | ® B
o T T T T T T
0.0 0.2 0.4 0.6 0.8 1.0
p

Fig. 10. Comparison of MAEs of “relfr’, “Laplace”, “Piegat”
and ““Cestnik” on the shortest sub-samples that contain
four or more successes and four or more failures.

to additionally support and justify Definition[I]

7. Conclusions

In this paper we tested and compared four probability
estimation methods in the context of small samples:
relative frequency, Laplace’s rule of succession, Piegat’s
formula and the m-estimate. The main contributions of
the paper can be summarized as follows. We defined
the concepts of a sufficiently large sample and a small
sample for probability estimation in Definitions [1] and 22]
We proved that Piegat’s estimate is a special case of the
m-estimate. We described an experimental framework in
R that was used to conduct our study. The framework
is available for download from GitHub (Cestnik, 2018)
under the MIT license and provides a playground for
future studies to assess the performance characteristics of
various probability estimation methods. In an in-depth
analysis and comparison of several probability estimation
methods we identified their strengths and weaknesses on
small samples. We ranked several probability estimation
methods on a critical distance plot according to the
approach of Dem§Sar (2006).

For Definition [2] of small samples for probability
estimates we offered a justification in terms of error
analysis. The definition is meaningful (small sample
contains either less than four successes or less than
four failures) in the sense that each individual sample
can be effectively classified as small or large enough.
Consequently, appropriate probability estimation methods
can be applied. For example, if a sample is classified
as large enough, relative frequency can be used without
hesitation. However, on a small sample it might be
beneficial to invest additional effort in selecting a more
appropriate probability estimation method to reduce the
estimation error to an acceptable level. On the other
hand, we can strive to enlarge the sample to become
large enough. However, there are situations in which

such enlargements are not viable. In such cases, the only
sensible decision is to take what we have and do the best
with it.

For further work we plan to investigate the impact
of biased samples to the estimation errors of various
probability methods. In addition, we would like to
develop procedures to determine an optimal m for the
m-estimate with respect to a given distortion pg of the
prior probability. Within the experimental framework we
plan to develop new estimation methods that combine the
high precision of the m-estimate and the simplicity of
Laplace’s rule or Piegat’s formula.

Acknowledgment

The author wishes to thank Marko Bohanec from the
Department of Knowledge Technologies at Jozef Stefan
Institute for his comments and suggestions on earlier
drafts of this paper.

References

Berger, J.O. (1985). Statistical Decision Theory and Bayesian
Analysis, Springer, New York, NY.

Bouguila, N. (2013). On the smoothing of multinomial estimates
using Liouville mixture models and applications, Pattern
Analysis and Applications 16(3): 349-363.

Breiman, L., Friedman, J.H., Olshen, R.A. and Stone, C.J.
(1984). Classification and Regression Trees, Wadsworth,
Belmont.

Calvo, B. and Santafé, G. (2016). SCMAMP: Statistical
comparison of multiple algorithms in multiple problems,
The R Journal 8(1): 248-256.

Cestnik, B. (1990). | Estimating probabilities: A crucial
task in machine learning, Proceedings of the 9th Euro-
pean Conference on Artificial Intelligence, London, UK,
pp. 147-149.

Cestnik, B. (2018). Experimental framework in R_ for
experimenting with probability estimations from small

samples, https://github.com/BojanCestnik/

Cestnik, B. and Bratko, I. (1991). On estimating probabilities
in tree pruning, Proceedings of the European Working Ses-
sion on Learning, Porto, Portugal, pp. 138-150.

Chan, J.C.C. and Kroese, D.P. (2011). Rare-event probability

estimation with conditional Monte Carlo, Annals of Oper-
ations Research 189(1): 43-61.

Chandra, B. and Gupta, M. (2011). Robust approach
for estimating probabilities in naive-Bayes classifier for
gene expression data, Expert Systems with Applications
38(3): 1293-1298.

DasGupta, A. (2011). Probability for Statistics and Machine
Learning: Fundamentals and Advanced Topics, Springer,
New York, NY.

DeGroot, M. and Schervish, M. (2012). Probability and Statis-
tics, Addison-Wesley, Boston, MA.

OF arcs
B. Cestnik

 

amcs ip

Demé&ar, J. (2006). Statistical comparisons of classifiers over
multiple data sets, Journal of Machine Learning Research
7(1): 1-30.

Domingos, P. and Pazzani, M. (1997). On the optimality of the
simple Bayesian classifier under zero-one loss, Machine
Learning 29(2): 103-130.

Dzeroski, S., Cestnik, B. and Petrovski, I. (1993). Using the
m-estimate in rule induction, Journal of Computing and
Information Technology 1(1): 37-46.

Feller, W. (1968). An Introduction to Probability Theory and Its
Applications, Willey, Hoboken, NJ.

Fienberg, S.E. and Holland, P.W. (1972). On the choice
of flattening constants for estimating multinomial
probabilities, Journal of Multivariate Analysis
2(1): 127-134.

Flach, P. (2012). Machine Learning: The Art and Science of Al-
gorithms that Make Sense of Data, Cambridge University
Press, New York, NY.

Furnkranz, J. and Flach, P.A. (2005). ROC ‘n’ tule
learning—towards a better understanding of covering
algorithms, Machine Learning 58(1): 39-77.

Garcia, S., Fernandez, A., Luengo, J. and Herrera, F. (2010).
Advanced nonparametric tests for multiple comparisons in
the design of experiments in computational intelligence
and data mining: Experimental analysis of power, /nfor-
mation Sciences 180(10): 2044-2064.

Garcia, S. and Herrera, F. (2008). An extension on statistical
comparisons of classifiers over multiple data sets for all
pairwise comparisons, Journal of Machine Learning Re-
search 9(12): 2677-2694.

Good, I.J. (1965). The Estimation of Probabilities: An Essay on
Modern Bayesian Methods, MIT Press, Cambridge, MA.

Good, I.J. (1966). How to estimate probabilities, IMA Journal
of Applied Mathematics 2(4): 364-383.

Good, P. and Hardin, J. (2012). Common Errors in Statistics
(and How to Avoid Them), Wiley, Hoboken, NJ.

Grover, J. (2012). Strategic Economic Decision-Making: Us-
ing Bayesian Belief Networks to Solve Complex Problems,
Springer New York, NY.

Gudder, S. (1988). Quantum Probability, Academic Press,
Boston, MA.

 

Laplace, P.-S. (1814). Essai philosophique sur les probabilités,
Courcier, Paris.

Larose, D. (2010). Discovering Statistics, W.H. Freeman, New
York, NY.

Mitchell, T.M. (1997). Machine Learning, McGrawHill,
Maidenhead.

Piegat, A. and Landowski, M. (2012). Optimal estimator
of hypothesis probability for data mining problems with
small samples, International Journal of Applied Math-
ematics and Computer Science 22(3): 629-645, DOI:
10.2478/v 10006-012-0048-z.

Piegat, A. and Landowski, M. (2013). Mean square error optimal
completeness estimator eph2 of probability, Journal of
Theoretical and Applied Computer Science 7(3): 3-20.

Piegat, A. and Landowski, M. (2014). Specialized,
MSE-optimal m-estimators of the rule probability
especially suitable for machine learning, Control and
Cybernetics 43(1): 133-160.

R Core Team (2018). R: A Language and Environment for Statis-
tical Computing, R Foundation for Statistical Computing,
Vienna,|https: //www.R-project.org/

Rudas, T. (2008). Handbook of Probability: Theory and Appli-
cations, SAGE Publications, Thousand Oaks, CA.

Starbird, M. (2006). What Are the Chances? Probability Made
Clear, Chantilly, VA.

Sulzmann, J.N. and Furnkranz, J. (2009). An empirical
comparison of probability estimation techniques for
probabilistic rules, in J. Gama et al. (Eds), Discovery Sci-
ence, Springer, Heidelberg, pp. 317-331.

Webb, J. (2007). Game Theory: Decisions, Interaction and Evo-
lution, Springer, London.

Bojan Cestnik received his PhD in computer sci-
ence from the University of Ljubljana, Faculty
of Computer and Information Science, in 1991.
Presently, he is the managing director at the com-
pany of Temida, a researcher at the Department
_ of Knowledge Technologies at Jozef Stefan Insti-
§ tute, and a professor of computer science at the
University of Nova Gorica. His professional and
/ research interest include knowledge based infor-
mation systems and machine learning.

Received: 15 December 2018
Revised: 24 March 2019
Accepted: 23 April 2019
