Information Systems 94 (2020) 101561

 

   

vo

ELSEVIER

Contents lists available at ScienceDirect

Information Systems

 

 

journal homepage: www.elsevier.com/locate/is
Scalable alignment of process models and event logs: An approach ®
based on automata and S-components “nee

 

Daniel ReifSner**, Abel Armas-Cervantes °, Raffaele Conforti?, Marlon Dumas °,
Dirk Fahland ‘, Marcello La Rosa*

* University of Melbourne, Australia
> University of Tartu, Estonia
“Eindhoven University of Technology, Netherlands

ARTICLE INFO

 

Article history:

Received 27 August 2019

Received in revised form 4 May 2020
Accepted 19 May 2020

Available online 22 May 2020
Recommended by Manfred Reichert

Keywords:

Process mining
Conformance checking
Automata

Petri nets
S-components

* Corresponding author.

E-mail addresses: dreissner@student.unimelb.edu.au (D. Reifgner),

abel.armas@unimelb.edu.au (A. Armas-Cervantes),

ABSTRACT

Given a model of the expected behavior of a business process and given an event log recording its
observed behavior, the problem of business process conformance checking is that of identifying and
describing the differences between the process model and the event log. A desirable feature of a
conformance checking technique is that it should identify a minimal yet complete set of differences.
Existing conformance checking techniques that fulfill this property exhibit limited scalability when
confronted to large and complex process models and event logs. One reason for this limitation is that
existing techniques compare each execution trace in the log against the process model separately,
without reusing computations made for one trace when processing subsequent traces. Yet, the
execution traces of a business process typically share common fragments (e.g. prefixes and suffixes).
A second reason is that these techniques do not integrate mechanisms to tackle the combinatorial
state explosion inherent to process models with high levels of concurrency. This paper presents two
techniques that address these sources of inefficiency. The first technique starts by transforming the
process model and the event log into two automata. These automata are then compared based on a
synchronized product, which is computed using an A* heuristic with an admissible heuristic function,
thus guaranteeing that the resulting synchronized product captures all differences and is minimal in
size. The synchronized product is then used to extract optimal (minimal-length) alignments between
each trace of the log and the closest corresponding trace of the model. By representing the event log
as a single automaton, this technique allows computations for shared prefixes and suffixes to be made
only once. The second technique decomposes the process model into a set of automata, known as S-
components, such that the product of these automata is equal to the automaton of the whole process
model. A product automaton is computed for each S-component separately. The resulting product
automata are then recomposed into a single product automaton capturing all the differences between
the process model and the event log, but without minimality guarantees. An empirical evaluation using
AO real-life event logs shows that, used in tandem, the proposed techniques outperform state-of-the-
art baselines in terms of execution times in a vast majority of cases, with improvements ranging from
several-fold to one order of magnitude. Moreover, the decomposition-based technique leads to optimal
trace alignments for the vast majority of datasets and close to optimal alignments for the remaining

ones.
© 2020 The Authors. Published by Elsevier Ltd. This is an open access article under the CC BY license
(http://creativecommons.org/licenses/by/4.0/).

1. Introduction

Modern information systems maintain detailed business pro-
cess execution trails. For example, an enterprise resource plan-
ning system keeps records of key events related to a company’s
order-to-cash process, such as the receipt and confirmation of
purchase orders, the delivery of products, and the creation and
payment of invoices. Such records can be grouped into an event

raffaele.conforti@unimelb.edu.au (R. Conforti), marlon.dumas@ut.ee (M. Dumas), log consisting of sequences of events (called traces), each consist-
d.fahland@tue.nl (D. Fahland), marcello.larosa@unimelb.edu.au (M. La Rosa). ing of all event records pertaining to one case of a process.

https://doi.org/10.1016/j.is.2020.101561

0306-4379/© 2020 The Authors. Published by Elsevier Ltd. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).
2 D. Reifsner, A. Armas-Cervantes, R. Conforti et al. / Information Systems 94 (2020) 101561

Process mining techniques |1] allow us to exploit such event
logs in order to gain insights into the performance and confor-
mance of business processes. One widely used family of process
mining techniques is conformance checking [2]. A conformance
checking technique takes as input a process model capturing the
expected behavior of a business process and an event log cap-
turing its observed behavior. The goal of conformance checking
is to identify and describe the differences between the process
model and the event log. Acommon approach to achieve this is by
computing alignments between traces in the event log and traces
that may be generated by the process model. In this context, a
trace alignment is a data structure that describes the differences
between a trace of the log and a possible trace of the model.
These differences are captured as a sequence of moves, including
synchronous moves (moving forward both in the trace of the log
and in the trace of the model) and asynchronous moves (moving
forward either only in the trace of the log or only in the trace
of the model). A desirable feature of a conformance checking
technique is that it should identify a minimal (yet complete)
set of behavioral differences. In the context of trace alignments,
this means that the computed alignments should have a minimal
length (or more generally a minimal cost).

Existing techniques that fulfill these properties [3,4] exhibit
scalability limitations when confronted with large and complex
event logs. For example, in a collection of 40 real-life event
logs presented later in this paper, the execution times of these
techniques are over 30 s in a quarter of cases and over 10 s in
about half of the cases. This hampers the use of these techniques
in interactive settings where it is necessary to apply conformance
checking repeatedly. For example, in the context of automated
process discovery [5], a large number of candidate models may
need to be compared by computing their conformance with re-
spect to a given log. In fact, an analyst may run this operation
hundreds of times against the same log, when considering dif-
ferent abstraction or filtering settings. In this context, waiting
10 s for each individual computation is unacceptable as it would
hamper user experience.

The scalability limitations of existing conformance checking
techniques stem, at least in part, from two sources of inefficiency:

1. These techniques compute an alignment for each trace of
the log separately. They do not reuse partial computations
made for one trace when processing other traces. Yet,
traces in an event log typically share common prefixes
and suffixes. We hypothesize that computing alignments
for common prefixes or suffixes only once may improve
performance in this context.

2. They do not integrate mechanisms to tackle the combina-
torial state explosion inherent to process models with high
levels of concurrency. Note that the number of possible
interleavings of the parallel activities increases rapidly,
for example four tasks in parallel can be executed in 24
different ways while eight tasks can already be executed in
40,320 different ways. This combinatorial explosion has an
impact on the space of possible alignments between traces
in an event log and the process model.

This paper presents two complementary techniques to address
these issues. The first technique starts by transforming the pro-
cess model and the event log into two automata. Specifically,
the process model is transformed into a minimal Deterministic
Acyclic Finite State Automaton (DAFSA), while the process model
is transformed into another automaton, namely its reachability
graph. These automata are then compared using a synchronized

product! computed via an A* heuristic with an admissible heuris-
tic function. The latter property guarantees that the resulting
synchronized product captures all differences with a minimal
number of non-synchronized transitions, which correspond to
differences between the log and the model. The synchronized
product is then used to extract optimal (minimal-size) alignments
between each trace of the log and the closest corresponding trace
of the model.

To tackle the second of the above issues, the paper also pro-
poses a technique wherein the process model is first decomposed
into a set of automata, known as S-components, such that the
product of these automata is equal to the automaton of the whole
process model. A synchronized product automaton is computed
for each S-component separately. For example, given a model
with four activities in a parallel block, this model is decomposed
into four models — each containing one of the four parallel tasks.
These concurrency-free models are then handled separately, thus
avoiding the computation of all possible interleavings and re-
ducing the search space for computing a minimal synchronized
product. Once we have computed a product automaton for each
S-component, these product automata are then recomposed into
a single product automaton capturing all the differences between
the process model and the event log. The article puts forward
conditions under which this recomposition leads to a correct
output. The article shows that the resulting recomposed product
automaton is not necessarily minimal.

This article is an extended and revised version of a previ-
ous conference paper [6]. This latter paper introduced the first
technique mentioned above (automata-based alignment). With
respect to the conference version, the additional contributions
are the idea of using S-components decomposition in conjunction
with automata-based alignment and the associated recomposi-
tion criteria and algorithms. These contributions are supported
by correctness proofs both for the automata-based and for the
decomposition-based technique as well as an empirical evalua-
tion based on 40 real-life datasets and three baselines, including
two baselines not covered in the conference version.

The next section discusses existing conformance checking
techniques. Section 3 introduces definitions and notations related
to finite state machines, Petri nets and event logs. Next, Sec-
tion 4 introduces the automata-based technique, while Section 5
presents the technique based on S-component decomposition. Fi-
nally, Section 6 presents the empirical evaluation while Section 7
summarizes the contributions and discusses avenues for future
work.

2. Related work

The aim of conformance checking is to characterize the dif-
ferences between the behavior observed in an event log and
the behavior captured by a process model. In this article, we
specifically aim to identify behavior observed in the log that is
disallowed by the model (a.k.a. unfitting behavior). Below, we re-
view existing techniques for this task. We first discuss techniques
based on token replay, which do not aim to achieve optimality.
We then review techniques based on (exact) trace alignment,
which aim to minimize a cost function, such as the length of
the computed alignments. Finally, we review two families of
techniques to tackle the complexity of computing optimal trace
alignments: approximate trace alignment and divide-and-conquer
techniques.

1a synchronized product of two automata is an automaton capturing the
combined behavior of the two automata executed in parallel, with synchro-
nization occurring when transitions with the same symbol are taken in both
automata (i.e. when both automata make the same move).
D. Reifsner, A. Armas-Cervantes, R. Conforti et al. / Information Systems 94 (2020) 101561 3

Token replay. A simple technique to detect and measure unfitting
behavior is token-based replay |7]. The idea is to replay each trace
against the process model. In the token-based replay technique
presented in [7], the process model is represented as a Workflow
net - a type of Petri net with a single source place, a single
sink place and such that every transition is on a path from the
source to the sink. The token replay technique fires transitions
in the Petri net, starting from an initial marking where there is
one token in the source place, following the order of the events
in the trace being replayed. Whenever the current marking is
such that the transition corresponding to the next event in the
trace is not enabled, the replay technique adds tokens to the
current marking so as to enable this transition. Once the sink
state of the Petri net is reached, the technique counts the number
of remaining tokens, i.e. tokens that were left behind in places
other than the sink place of the Workflow net. The unfitting
behavior is quantified in terms of the number of added tokens and
remaining tokens. An extended version of this technique, namely
continuous semantics fitness [8], achieves higher efficiency at the
expense of incompleteness. Another extension of token replay [9]
decomposes the model into single-entry single-exit fragments,
such that each fragment can be replayed independently. Other
extensions based on model decomposition are discussed in [10].

Intuitively, replay techniques count the number of “passing
errors” that occur when parsing each trace against the process
model. Replay fitness methods fail to identify a minimum num-
ber of parsing errors required to explain the unfitting behavior,
thus overestimating the magnitude of differences. To tackle this
limitation, several authors have proposed to rely on optimal trace
alignment instead of replay [3].

Trace alignment. Trace alignment techniques extend replay tech-
niques with the idea of computing an optimal alignment between
each trace in the log and the closest corresponding trace of the
process model (specifically the trace with the smallest Leven-
shtein distance) . In this context, an alignment of two traces is
a sequence of moves (or edit operations) that describe how two
cursors can move from the start of the two traces to their end.
In a nutshell, there are two types of edit operations. A match
operation indicates that the next event is the same in both traces.
Hence, both cursors can move forward synchronously by one
position along both traces. Meanwhile, a hide operation (deletion
of an element in one of the traces) indicates that the next events
are different in each of the two traces. Alternatively, one of the
cursors has reached the end of its trace while the other has not
reached its end yet. Hence, one cursor advances along its traces by
one position while the other cursor does not move. An alignment
is optimal if it contains a minimal number of hide operations. This
means that the alignment has a minimal length.

Conformance checking techniques that produce trace align-
ments can be subdivided into all-optimal and one-optimal. A
conformance checking technique is called all-optimal if it com-
putes every possible minimal-distance alignment between each
log trace and the model. Meanwhile, a conformance checking
technique is called one-optimal, if it computes only one minimal-
distance alignment for each log trace.

The idea of computing alignments between a process model
(captured as a Petri net) and an event log was developed in Adri-
ansyah et al. [3,11]. This proposal maps each trace in the log into
a (perfectly sequential) Petri net. It then constructs a synchronous
Petri nets as a product out of the model and the perfectly se-
quential net corresponding to the trace. Finally, it applies an
A* algorithm to find the shortest path through the synchronous
net which represents an optimal alignment. Van Dongen [4] ex-
tends Adriansyah et al.’s technique [3,11] by strengthening the
underlying heuristic function. This latter technique was shown to

outperform [3,11] on an artificial dataset and a handful of real-
life event log-model pairs. In the evaluation reported later in this
article, we use both [3,11] and [4] as baselines.

De Leoni et al. [12] translate the trace alignment problem
into an automated planing problem. Their argument is that a
standard automated planner provides a more standardized im-
plementation and more configuration possibilities from the route
planning domain. Depending on the planner implementation, this
technique can either provide optimal or approximate solutions.
In their evaluation, De Leoni et al. show that their technique
can outperform [3] only on very large process models. Subse-
quently, [4] empirically showed that trace alignment techniques
based on the A®* heuristics outperform the technique of De Leoni
et al. Accordingly, in this article we do not retain the technique
by De Leoni et al. as a baseline.

In the above techniques, each trace is aligned to the process
model separately. An alternative technique, explored in [13], is
to align the entire log against the process model, rather than
aligning each trace separately. Concretely, the technique pre-
sented in [13] transforms both the event log and the process
model into event structures [14]. It then computes a synchronized
product of these two event structures. Based on this product, a
set of statements are derived, which characterize all behavioral
relations between tasks captured in the model but not observed
in the log and vice-versa. The emphasis of behavioral alignment is
on the completeness and interpretability of the set of difference
statements that it produces. As shown in [13], the technique is
less scalable than that of [3,11], in part due to the complexity of
the algorithms used to derive an event structure from a process
model. Since the emphasis of the present article is on scalability,
we do not retain [13] as a baseline. On the other hand, the
technique proposed in this article computes as output the same
data structure as | 13] - a so-called Partially Synchronized Product
(PSP). Hence, the output of the techniques proposed in this arti-
cle can be used to derive the same natural-language difference
statements produced by the technique in [13].

Approximate trace alignment. In order to cope with the inherent
complexity of the problem of computing optimal alignments, sev-
eral authors have proposed algorithms to compute approximate
alignments. Sequential alignments [15] is one such approximate
technique. This technique implements an incremental approach
to calculate alignments. The technique uses an ILP program to
find the cheapest edit operations for a fixed number of steps
(e.g. three events) taking into account an estimate of the cost of
the remaining alignment. The technique then recursively extends
the found solution with another fixed number of steps until a
full alignment is computed. We do not use this technique as a
baseline in our empirical evaluation since the core idea of this
technique was used in the extended marking equation alignment
technique presented in [4], which derives optimal alignments and
exhibits better performance than Sequential Alignments. In other
words, [4] subsumes [15].

Another approximate alignment technique, namely Alignments
of Large Instances or ALI [16], finds an initial candidate alignment
using a replay technique and improves it using a local search algo-
rithm until no further improvements can be found. The technique
has shown promising results in terms scalability when compared
to the exact trace alignment techniques presented in [3,4,11].
Accordingly, we use this technique as a baseline in our evaluation.

An approximate model-log alignment technique for detecting
all possible alignments for a trace is the evolutionary approximate
alignments [17]. It encodes the computation of alignments as a
genetic algorithm. Tailored crossover and mutation operators are
applied to an initial population of model mismatches to derive
a set of alignments for each trace. In this article, we focus on
computing one alignment per trace (not all possible alignments)
4 D. Reifsner, A. Armas-Cervantes, R. Conforti et al. / Information Systems 94 (2020) 101561

and thus we do not consider these techniques as baselines in
our empirical evaluation. Techniques that compute all-optimal
alignments are slower than those that compute a single optimal
alignment per trace, and hence the comparison is unfair.

Bauer et al. [18] propose to use trace sampling to approxi-
mately measure the amount of unfitting behavior between an
event log and a process model. The authors use a measure of
trace similarity in order to identify subsets of traces that may
be left out without substantially affecting the resulting mea-
sure of unfitting behavior. This technique does not address the
problem of computing trace alignments, but rather the problem
of (approximately) measuring the level of fitness between an
event log and a process model. In this respect, trace sampling
is orthogonal to the contribution of this article. Trace sampling
can be applied as a pre-processing step prior to any other trace
alignment technique, including the techniques presented in this
article.

Last, Burattin et al. [19] propose an approximate technique
to find alignments in an online setting. In this technique, the
input is an event stream instead of an event log. Since traces are
not complete in such an online setting, the technique computes
alignments of trace prefixes and estimates the remaining cost of
a possible suffix. The emphasis of this technique is on the quality
of the alignments made for trace prefixes, and as such, it is not
directly comparable to trace alignment techniques that take full
traces as input.

Divide-and-conquer techniques. In divide-and-conquer  tech-
niques, the process model is split into smaller parts to speed
up the computation of alignments by reducing the size of the
search space. Van der aalst et al. [20] propose a set of criteria
for a valid decomposition of a process model in the context of
conformance checking. One decomposition technique that fulfills
these criteria is the single-entry-single-exit (SESE) process model
decomposition technique. Munoz-Gama et al. [10] present a trace
alignment technique based on SESE decomposition. The idea is to
compute an alignment between each SESE fragment of a process
model and the event log projected onto this model fragment. An
advantage of this technique is that it can pinpoint mismatches
to specific fragments of the process model. However, it does not
compute alignments at the level of the full traces of the log — it
only produces partial alignments between a given trace and each
SESE fragment. A similar technique is presented in [21].

Verbeek et al. [22] presents an extension of the technique
in [10], which merges the partial trace alignments produced for
each SESE fragment in order to obtain a full alignment of a
trace. This latter technique sometimes computes optimal align-
ments, but other times it produces so-called pseudo-alignments
— i.e., alignments that correspond to a trace in the log but not
necessarily to a trace in the process model. In this article, the
goal is to produce actual alignments (not pseudo-alignments).
Therefore, we do not retain [22] as a baseline.

Song et al. [23] present another technique for recomposing
partial alignments, which does not produce pseudo-alignments.
Specifically, if the merging algorithm in [22] cannot recompose
two partial alignments into an optimal combined alignment, the
algorithm merges the corresponding model fragments and re-
computes a partial alignment for the merged fragment. This pro-
cedure is repeated until the re-composition yields an optimal
alignment. In the worst case, this may require computing an
alignment between the trace and the entire process model. A lim-
itation of [23] is that it requires a manual model decomposition
of the process model as input. The goal of the present article
is to compute alignments between a log and a process model
automatically, and hence we do not retain [23] as a baseline.

3. Preliminaries

This section defines the formal concepts and notations used
throughout the paper: finite state machines, Petri nets and event
logs. The various concepts presented herein use labeling functions
to assign labels to elements. For the sake of uniformity, ’ denotes
a finite set of labels and t € » is a special “silent” label . We
use Z-notation [24] operators over sequences. Given a sequence
C = (X1,X2,...,Xn), |c| denotes the size, and head and tail
retrieve the first and last element of a sequence, respectively,
Le., |c| = n, head(c) = x, and tail(c) = x,. The element at index
iin the sequence c is retrieved as c[i] = x;. The operators for
and after retrieve the elements before and after i in a sequence,
respectively. For example, for(c, i) = (x;,...,x;) and after(c, i) =
(Xi.1,-..-Xn). Finally, MultiSet denotes the multiset representation
of a sequence.

3.1. Finite state machines

A pervasive concept in our techniques is that of finite state
machine (FSM), which is defined as follows.

Definition 3.1 (Finite State Machine (FSM)). Given the set of labels
»/, a finite state machine is a directed graph FSM = (N,A, 5, R),
where N is a finite non-empty set of states, A C N x x x N is
a set of arcs, s € N is an initial state, and R C N is a set of final
states.

An arc in a FSM is a triplet a = (n,,1,n;), where n, is the
source state, n; is the target state and | is the label associated to
the arc. We define functions src(a) = n, to retrieve the source
state, A(a) = | to retrieve the label and tgt(a) = n; to retrieve the
target state of a. Furthermore, given a node n € N and arc a =
(n;,1,n:) € A, letn » ad =n; ifn = ns, and n » a = n otherwise.
The set of incoming and outgoing arcs of a state n is defined as
pn = {fa € A|n = tgt(a)} and n>» = {a € A|n = src(a)},
respectively. Finally, a sequence of (contiguous) arcs in a FSM is
called a path.

3.2. Process models and Petri nets

Process models are normative descriptions of business pro-
cesses and define the expected behavior of the process. For ex-
ample, we consider the loan application process model displayed
in Fig. 1 using the BPMN notation. Once this process starts, the
credit history, the income sources, personal identification and
other financial information are checked. Once the application is
assessed, either a credit offer is made, the application is rejected
or additional information is requested (the latter leading to a re-
assessment). The process model in Fig. 1 will be used as a running
example in this article. For the sake of brevity, we will refer to the
activities by the letters attached to the them, e.g., “Check credit
history” will be referred to as “A” etc.

In the context of this work, business processes are represented
as a particular family of Petri nets, namely labeled free-choice
sound workflow nets. This formalism uses transitions to represent
activities, and places to represent resource containers. The formal
definition of labeled Petri nets is given next.

Definition 3.2 (Labeled Petri Net). A (labeled) Petri net is the tuple
PN = (P,T,F,2), where P and T are disjoint sets of places and
transitions, respectively (together called nodes); F C (P x T)U
(T x P) is the flow relation, and 7: T —> » is a labeling function
mapping transitions to the set of task labels » containing the
special label rt.
D. Reifsner, A. Armas-Cervantes, R. Conforti et al. / Information Systems 94 (2020) 101561 5

 
 
 

A

 

Check
credit
history

 
  

 
 
 
 

Check
income
sources

 
 
  

Check
personal
identification

 
  
  

Check
other financial
information

Assess
application

Receive
additional
information

 
  
 
 
 
    
 
   
 
 
 
 

  
 

Make
credit
offer

 
 

 
  
 
  
 
 
 
 
   
 
   
   
   

  
 
 
 

Notify
rejection

outright
rejection

  
  

 
  
 

Request
additional
information

Fig. 1. Example loan application process model.
Source: Adapted from [13].

Transitions labeled with t describe invisible actions that are
not recorded in the event log when executed. A node x is in
the preset of a node y if there is a transition from x to y and,
conversely, a node z is in the postset of y if there is a transition
from y to z. Then, the preset of a node y is the set ey = {x €
P UT\(x,y) € F} and the postset of y is the set ye = {z €
PUT|(y, Z) € F}.

Workflow nets [25] are Petri nets with two special places, an
initial and a final place.

Definition 3.3 (Labeled Workflow Net). A (labeled) workflow net
is a triplet WN = (PN, i, 0), where PN = (P,T,F, i) is a labeled
Petri net, i € P is the initial and o € P is the final place, and the
following properties hold:

e The initial place i has an empty present and the final place
has an empty postset, i.e., ei = 0e = &.

e If a transition t* were added from o toi, such that ei = oe =
{t*}, then the resulting Petri net is strongly connected.

The execution semantics of a Petri net can be represented by
means of markings. A marking m : P — No is a function that
associates places to natural numbers representing the amount of
tokens in each place at a given execution state. As we will later
work with the so-called incidence matrix of a Petri net, we define
the semantics already in terms of vectors over places. Fixing an
order {pi,..., Dx} = P over all places, we write a marking m
as a column vector m = (m(p;),...,™(pn))'. We slightly abuse
notation and write m for both the function and the column vector;
further we represent m as the multiset of marked places in our
examples. In vector notation, the pre-set et of any transition t
defines a column-vector N-(t) = (xj,...,X,)' with xj = 1
if pj € et, and x; = O otherwise. Correspondingly, we define
N*(t) = (z,...,Z,)"’ with z = 1 if pj € te, and z = O
otherwise, for the post-set of t. We lift + , —, and < to vectors
by element-wise application.

A transition t is enabled at a marking m if each pre-place of
t contains a token in p, i.e, N-(t) < m. An enabled transition t
can fire and yield a new marking m’ = m — N~(t) + N*(t) by
consuming from all its pre-places (N~(t)) and producing on all
its post-places (N*(t)). A marking m is reachable from another
marking m’, if there exists a sequence of firing transitions 0 =
(tj,...t,) such that V1 < i < ni: m = m_, — N (tj) +
N*(t;) A N-(t)) < m1, where m = m’ andm, = mA
marking k-bounded if every place at a marking m has up to k
tokens, i.e., m(p) < k for any p € P. A Petri net equipped with
an initial marking and a final marking is called a (Petri) system
net. The following definition for a system net refers specifically
to workflow nets.

Definition 3.4 (System Net). A System net SN is a triplet SN =
(WN, mo, my), where WN is a labeled workflow net, mp denotes
the initial marking and m, denotes the final marking.

A system net is k-bounded if every reachable marking in
the workflow net is k-bounded. This work considers 1-bounded
system nets that are sound [26], i.e., where from any marking m
reachable from mp we can always reach some my € my, there is
no reachable marking m > my € m; that contains a final marking,
and each transition is enabled in some reachable marking. Fig. 2
shows the system net representation for our running example.

The reachability graph [27] of a system net SN contains all
possible markings of SN - denoted as M. Intuitively, a reachability
graph is a non-deterministic FSM where states denote markings,
and arcs denote the firing of a transition from one marking
to another. The reachability graph for the running example is
depicted in Fig. 3 showing markings as multi-sets of places. In
this figure, every node contains the places with a token at each
of the reachable markings. The complexity for constructing a
reachability graph of a safe Petri net is O(2!?Y"!) [28]. The formal
definition of a reachability graph is presented next.

Definition 3.5 (Reachability Graph). The reachability graph of a
System net SN = (WN, mo, mf) is a non-deterministic finite state
machine RG = (M, Arc, Mo, m,), where M is the set of reachable
markings and Agg is the set of arcs {(m,, A(t), m2) € Mx yx M |
Mz = m,—et +te}.

3.3. Event logs

Event logs, or simply logs, record the execution of activities
in a business process. These logs represent the executions of
process instances as traces - sequences of activity occurrences
(a.k.a. events). A trace can be represented as a sequence of labels,
such that each label signifies an event. Although an event log is
a multiset of traces containing several occurrences of the same
trace, we are only interested in the distinct traces in the log
and, therefore, we define a log as a set of traces. Fig. 4 depicts
an example of a log containing activities of the loan application
process in Fig. 1 We define the concept of a trace and an event
log as follows:

Definition 3.6 (Trace and Event Log). Given a finite set of labels »’,
a trace is a finite sequence of labels (l,,...,1,) € 2’*, such that
|; ¢ X’ for any 1 <i<n. An event log L is a set of traces.
6 D. Reifsner, A. Armas-Cervantes, R. Conforti et al. / Information Systems 94 (2020) 101561

 

Fig. 3. Reachability graph of the running example.

B,D,A,E,F,G)
C,A,B,E,E,G)

C,A,B,E,H,1,E,F,G)

 

Fig. 4. Example log for our loan application process.

4. Automata-based conformance checking

The objective of conformance checking is to identify a minimal
set of differences between the behavior of a given process model
and a given log. As illustrated in Fig. 5, the first technique pro-
posed in this paper computes this minimal set of differences by
constructing an error-correcting product, between the reachabil-
ity graph of the model and an automaton-based representation of
the log (called DAFSA). An error-correcting product is an automa-
ton that synchronizes the states and transitions of two automata.
These synchronizations can represent both common and deviant
behavior. (4.1) First, the input process model is expanded into a
reachability graph. (4.2) In parallel, the event log is compressed
into a minimal, acyclic and deterministic FSM, a.k.a. DAFSA. The
resulting reachability graph and DAFSA are then compared (4.3)
to derive an error-correcting synchronized product automaton —
herein called a PSP. Each state in the PSP is a pair consisting of a
state in the reachability graph and a state in the DAFSA. A PSP rep-
resents a set of trace alignments that can be used for diagnosing
behavioral difference statements via further analysis. The trace
alignments contained in the PSP are optimal, i.e. minimal and
deterministic (4.4). The rest of this section starts by introducing

some necessary concepts and is followed by a description of each
of the steps including proofs of minimality and determinism of
alignments.

4.1. Expanding a Petri net to its t-less reachability graph

Petri nets can contains t-transitions representing invisible
steps that are not recorded in an event log and they are captured
in the reachability graph of a Petri net. Our technique aims at
matching events from the event log to activities in the pro-
cess model, and thus t transitions can never be matched. Other
techniques like [3,4] handle these t-transitions as automatically
matched events. We argue however that a pre-emptive removal
of t transitions from the reachability graph can speed up the
presented technique since less steps need to be considered. In
principle, we assume that a Petri net has a minimal number
of t-transitions, for instance, by applying structural reduction
rules that preserve all visible behavior [29]. However not all t-
transitions can be removed by structural reduction of the Petri
net. We therefore remove the remaining t-transitions through
behavior preserving reduction rules on the reachability graph by
the breadth-first search algorithm given in Alg. 1. Intuitively, for
every marking m reached by a t-transition aq; = (m,,T,m) €
Arg and any outgoing transition a7 = (m,l,mz) © Ar, the
algorithm replaces a, with aj2 = (mj, 1, m2) (lines 6-8 and lines
19-21). This replacement is repeated until all arcs representing
t-transitions are removed. In case all incoming arcs of a state get
replaced we also remove m and its outgoing arcs (Lines 12-16).
Function replaceTau also handles the case of another outgoing t-
labeled transition az = (m, tT, m 2) by a depth-first search along
t-transitions in Ap (lines 22-24). The algorithm then removes
each remaining t transition a = (m1, t, my) targeting the final
D. Reifsner, A. Armas-Cervantes, R. Conforti et al. / Information Systems 94 (2020) 101561 7

Algorithm 1: Remove Tau Transitions

input: Reachability Graph RG

o < (mo); // List of markings to check
2 < {mo}; // Markings checked

while o + () do

mh WwW NHN =

a w

10

11
12

13

14
15
16

17
18

19
20

21
22

23
24
25

26
27
28

29

31

32
33

34

 

m < head o;// Remove marking m from the head
the list
o <-tailo;
Ww <{a=(m,l,m)erm|l=tAm¢
m,};// Outgoing t arcs atm
fora <¢ W do
| replaceTau(a, m, {m});// Replace t arcs

Arc < Arc \ ¥;// Remove outgoing tT arcs
for (m, 1, m2) € mp | m2 ¢ 2 do
// Insert the target marking of each
outgoing arc into the auxiliary lists
0 <o Om;
Q <—2U{m};

ES <—{meM|(em=SAm¢m)V(m=aAm¢

my )};// Non-initial markings with no incoming
arcs, and non-final markings with no outgoing
arcs. These markings result from the deletion
of t arcs

while © 4 2 do

 

form eé & do
A <A\(»mUmp)// Remove arcs from every
L marking in &
M <M \ &;// Remove all disconnected markings
F<—-{meM|(~onm=SAmMFzAM)V(m=SAmME
my )};// Determine if any more markings
became disconnected

for a = (m,,1,m;) ¢ »m; || =T do

replaceTauBackwards(a);// Replace t arcs that
target final markings with a backwards
replacement

return RG;
Function replaceTau((m,,t,m) € A, m € M, 0 € 2™)

 

// Inputs are an arc, amarking and a closed
list

for (m;, 1, m2) € m:> do
if! At Vm, € m, then
// Replace outgoing arcs of the input
marking that is not tT and its target is
not final
Arc < Arc U {(m4, I, m2 )};
Ise if m, ¢ © then
O <— OU{m};// Add m, to 2 list if it
has not been investigated yet.
replaceTau((m,,T,™M), M2, ©);// Try to
replace the input t arc from the new
target marking m2

@

 

 

Function replaceTauBackwards((m,1, t, mp) € Arc)

// Function for replacing a given Tt arc
backwards

// Replace incoming arcs of m, with arcs from
the predecessors of m, to my,
for (m2, 1,m,) € »m, | 1 AT do
| Arc = Arc U {(m2, 1, mp};
Arc = Arc \ {(111, T, mp)}; 7/7 Remove the t arc from
the reachability graph

marking while introducing new replacement arcs a’ = (mz, I, mp)
for each incoming arc of mj, such that (m2,1,m,) € Apc (Line
17 and function replaceTauBackwards). The reachability graph
returned by Alg. 1 is now free of t transitions. Fig. 6 shows the
t-less reachability graph of the loan application process. Observe
that the node [p1, p2, p3, p4] is removed and its outgoing arcs are
connected to the node [start], and, similarly, node [p5, p6, p7, p8]
is removed and its incoming arcs now target the node [p9] in-
stead. In addition, the arc ([p11], t, [end]) is replaced with the
newly introduced arc ([p10], G, [end]).

4.2. Compressing an event log to its DAFSA representation

Event logs can be represented as Deterministic Acyclic Finite
State Automata (DAFSA), which are acyclic and deterministic
FSMs. A DAFSA can represent words, in our case traces, in a
compact manner by exploiting prefix and suffix compression.

Definition 4.1 (DAFSA). Given a finite set of labels &, a DAFSA
is an acyclic and deterministic finite state machine DAFSA =
(Nparsas Aparsa, Spars» Rparsa), Where Nparsa is a finite non-empty
set of states, Aparsa GC Nparsa X L X Nopagsa 1S a Set of arcs, Sparsa €
Nparsa is the initial state, Rparsa CG Nparsa iS a Set of final states.

Daciuk et al. [30] present an efficient algorithm for construct-
ing a DAFSA from a set of words. In the constructed algorithm
every word is a path from the initial to a final state and, vice versa,
every path from an initial to a final state is one of the given words.
We reuse this algorithm to construct a DAFSA from an event log,
where the words are the set of traces. The complexity of building
the DAFSA is O(|’| - logn), where » is the set of distinct event
labels, and n is the number of states in the DAFSA.

A prefix of a state n € Nparsa iS a Sequence of labels associated
to the arcs on a path from the initial state to n and, analogously,
a suffix of n is a sequence of labels associated to the arcs on a
path from n to a final state. The prefix of the initial state and the
suffix of a final state is {()}. A state n can have several prefixes,
which are denoted by pref(n) = ns tinpjewn 1% @®1| x € pref(n;)},
where @ denotes the concatenation operator. Similarly, the set of
suffixes of n is represented by suff(n) = ns tinpjene { PBx|xeE
suff (n;)}. Prefixes and suffixes are said to be common iff they are
shared by more than one trace.

Definition 4.2 (Common Prefixes and Suffixes). Let DAFSA =
(Nparsa>s Aparsa> SDAFSAs RpAgsA ) be a DAFSA. The set of common
prefixes of DAFSA is the set Pref = {pref(n) | n € Npagsa A |n>| >
1}. The set of common suffixes of DAFSA is the set Suff = {suff(n) |
n € Npagsa A |>n| > 1}.

Fig. 7 depicts the DAFSA representation and its corresponding
common prefixes and suffixes for the example event log in Fig. 4.
In total, it summarizes 26 events with 16 arcs. All traces in the
event log are paths from s to one of the two final nodes f; or fo.
For instance, the trace (B,D, C, E, G) is represented by the path
((s, B, ny), (n1, D, n2), (n2, C, n3), (n3, E, n4), (n4, G, f,)). In this ex-
ample, the two common prefixes in nodes nz and nj1, as well as
the common suffixes from nodes nq and ns, are shared by two
traces in the event log.

4.3. Comparing a reachability graph with a DAFSA to derive a PSP

The computation of similar and deviant behavior between an
event log and a process model is based on an error-correcting
synchronized product (PSP) [31]. This subsection presents the
construction of the PSP that captures only the minimal num-
ber of behavioral mismatches between the event log and the
process model (i.e. optimal alignments). Intuitively, the traces
8 D. Reifsner, A. Armas-Cervantes, R. Conforti et al. / Information Systems 94 (2020) 101561

(4.1)

eee?

Petri Net

Reachability
Graph

     

( p5,p6,p3,p4 ) C
( p5,p2,p7,p4 )

   
   
      

(4.4)

eeeeeeeeees Oo pti mal
(i.e. Minimal and
are Deterministic)

 

Difference
Statements

Fig. 6. Tau-less reachability graph of the running example.

(B,D ),(C,A,B,E ) (G),(E,F,G)

(B,D,C,E,G )
(B,D,A,E,F,G)

 

(C,A,B,E,E,G )
(C,A,B,E,H,1,E, F,G)

 

Fig. 7. DAFSA representation of the running example log.

represented in the DAFSA are “aligned” with the executions of
the model by means of three operations: (1) synchronized move
(match), the process model and the event log can execute the
same task/event with respect to their label; (2) log operation
(Ihide), an event observed in the log cannot occur in the model;
and (3) model operation (rhide), a task in the model can occur,
but the corresponding event is missing in the log. Both a trace
in a log and an execution represented in a reachability graph are
totally ordered sets of events (sequences). An alignment aims at
matching events from both sequences that represent the tasks
with the same labels, such that the order between the matched
events is preserved. An event that is not matched has to be hidden
using the operation [hide if it belongs to the log, or rhide if it
belongs to an execution in the model. For example, given a trace
(B,D, C, E, G) and an execution in a model (B, D, C, A, E, G), the
first three activities B,D and C can be matched. Next, activity A
in the model cannot be matched, since it is not contained in the
trace, and needs to be hidden with an rhide operation (so that

the index in the model execution moves by one position). Last,
the remaining activities E and G can be matched again and the
matching for this example is complete.

In our context, the alignments are computed over a pair of
FSMs, a DAFSA and a reachability graph, therefore the three
operations: match, lhide and rhide, are applied over the arcs of
both FSMs. A match is applied over a pair of arcs (one in the
DAFSA and one in the reachability graph) whereas [hide and rhide
are applied only over one arc. We record the type of operation
and the involved arcs in a triplet called synchronization where _L
denotes the absence of an arc in case of Ihide and rhide.

Definition 4.3 (Synchronization). Let DAFSA = (Nparsa, Aparsa;
Sparsa» Rparsa) and RG = (M, Arc, Mo, ms ) be a DAFSA and a
reachability graph, respectively. Then, the set of all possible syn-
chronizations is defined as B(DAFSA, RG) = {(Ihide, dparsa, L) |
Aparsa © Aparsa} U {(rhide, L, drc) | drc € Arc} U {(match, dparsa,
Arc) | Aparsa € Aparsa \ Grc € Arc A A(dparsa) = A(arc)}.
D. Reifsner, A. Armas-Cervantes, R. Conforti et al. / Information Systems 94 (2020) 101561 9

Given a synchronization 6 = (Op, Gparsa, Arc), We define an
auxiliary function Bf = A(dparsa) that returns the label of the arc
of the DAFSA if it is not empty, i.e. dparsa #~-L, and otherwise
returns the label of the arc of the reachability graph, ie. BY =
A( dro) if dag #-L. This notation is well-defined as the labels of the
arc of the DAFSA is equal to the label of the reachability graph
in case of a match operation, i.e. A(dparsa) = A(drc) whenever
Aparsa #LHA# Arc. We further define functions for accessing the
operation and the arcs of a synchronization more easily, i.e. let
B°P = op, BAA = Aparsa, aNd BORG = Apc.

All possible alignments between the traces represented in a
DAFSA and the executions represented in a reachability graph
can be inductively computed as follows. The construction starts
by pairing the initial states of both FSMs and then applying the
three defined operations over the arcs that can be taken in the
DAFSA and in the reachability graph — each application of the
operations (synchronization) yield a new pairing of states. Note
that the alignments between (partial) traces and executions are
implicitly computed as sequences of synchronizations.

Given a sequence of synchronizations ¢ = (fj,..., 6m) with
Bi = (OD;, Giparsa, dizc), 1 < 1 < m, we define two projection
operations €[ pars, and €[pc¢ that retrieve the sequence of arcs for
the DAFSA and the reachability graph, respectively. The projection
onto DAFSA is the sequence €|parsq = (41,DAEsA; « - - + Im,DAFSA) |Aparsa
of the DAFSA-entries in € projected onto the arcs in DAFSA (i.e., re-
moving all 1). Correspondingly, é[pg = (G1,Rc,--++4m,RC) Ape:
Thus, €[parsa (€fp¢) contains the arcs of all match and lhide (rhide)
triplets. On top of that notation, we are interested in the se-
quence of labels represented by a sequence of arcs, shorthanded

as AE; parsa) = (A(1), ..., A(dn)).

Definition 4.4 ((Proper) Alignment). Given a log automaton DAFSA,
a reachability graph RG and a trace c € L, an alignment is defined
as a sequence of synchronizations ¢, = (61, B2,... hm), where
Bi € B(DAFSA, RG) A 1 <i < |c| < m.A proper alignment for the
trace c fulfills two properties:

1. The sequence of synchronizations with [hide or match op-
erations reflects the trace c, i.e. A(E¢ | parsa) = C.

2. The arcs of the reachability graph in the sequence of syn-
chronizations with rhide or match operations forms a path
in the reachability graph from the initial to the final mark-
ing, ie. let n = = |€c[pcl, then src(éclpo[1]) = mo A
tgt(€ctrc{n]) = mp AV <i <n: tgt(ecteclil) = src(éclrglit
1]).

The set of all proper alignments for a given trace c is denoted
as C(c, RG). We write &c¢jop = {B = (ODP, Aparsa, Arc) € €c} for the
synchronizations of a particular operation op in a given alignment
Ec.

Fig. 8 illustrates the alignment for the matching example be-
tween the trace (B, D, C, E, G) and the model execution (B, D, C,
A, E, G). Please note that this alignment is proper since all trace
labels are present and the arcs of the reachability graph form a
path in the automata displayed in Fig. 6 to the final marking [end].

A cost can be associated to a proper alignment for a given
trace. If an asynchronous lhide or rhide move is associated to
a non-t label then the cost increases. Assuming that the cost
of hiding a non-t transition is 1, the cost function is given as
follows:

Definition 4.5 (Alignment Cost Function). Given an alignment ¢ €
C(c, RG), the cost function cost : C(c, RG) — N for e is defined as
cost(e) = |{B ee | BY At A B® # match}|.

All alignments can be collected in a finite state machine called
PSP [31]. Every state in the PSP is a triplet (n,m, €), where n is a
state in the log automaton DAFSA, m is a state in the reachability
graph RG and ¢ is the sequences of arcs taken in the DAFSA and in
RG to reach n and m; every arc of the PSP is a synchronization of
DAFSA and RG; the pairing of the initial states is the initial state
of the PSP; and the final states are those with no outgoing arcs.
Next, we present the formal definition of a PSP:

Definition 4.6 (PSP). Given a log automaton DAFSA and a reach-
ability graph RG, their PSP is a finite state machine PSP =
(Nesp, Apsp, Spsp; Resp), Where Npsp © Noparsa X M x C is the set
of nodes, Apsp © Npsp x B(DAFSA, RG) x Npsp is the set of arcs,
Spsp = (SDAFSA> Mo, ()) € Npsp is the initial node, and Rpsp = {f €
Npsp | fe = @} is the set of final nodes.

A PSP can contain all possible alignments, however, it is
computationally expensive, and oftentimes unfeasible, to do so.
Therefore, we compute exclusively the alignments that are proper
and have a minimal cost; these alignments are called optimal.
Thus, in order to reduce the search space and prune not promising
alignments, we use an A* algorithm [32] to explore the most
promising paths in the PSP first, i.e., those minimizing the number
of hides.

The goal of our A*-search is the same as other “traditional”
techniques, such as [3,4], ie. to find alignments for each log
trace while minimizing the number of mismatches. However, the
difference between the traditional techniques and the technique
presented in this paper relies in the data structures used. Specifi-
cally, while the traditional techniques resemble the search for the
shortest path through a synchronous net, our A* search resembles
an error-correcting bi-simulation over two automata structures.
By applying the bi-simulation idea, we only need to compute the
reachability graph of the workflow net once and do not need to
compute a synchronous net for every unique trace in the event
log. We define the cost function for the A* as follows.

Definition 4.7 (A*-cost Function). Let L and PSP be a given event
log and PSP, then for every trace c € L and every node x =
(n,m, é) € PSP we define a cost function p(x,c) = g(x,c) +
h(x, c) that relies on the current cost function g and a heuristic
function h for estimating future hides for a given trace. We define
functions g and h as follows:

g(x,c) = {area if CX) IDarsa = for(c, |e(X)!parsal)
OO, otherwise

(1)

h(x, c) = min{|Frog(x, €) \ futoder|
+ |futoael \ Frog (X, c)| | fodel € Fyoael(X)}

Function g returns the current cost for a given node x in
the PSP and a given trace c to align. If the trace labels of the
partial alignment of x, i.e. €(X)[ parca, fully represent a prefix of
c then the cost of e(x) is that of the cost function defined in
Definition 4.5. Otherwise, node x is not relevant to trace c and
the cost is set to oo to avoid considering this node in the search.
Function h relies on two functions Figg and Fyodel. Fiog(X,C) =
MultiSet(c) \ €{parsq denotes the multiset of future trace labels
and Frode is the set of multisets of future model labels. The set of
future model labels Fyodei(X) is computed in a backwards breadth-
first traversal over the strongly connected components of the
reachability graph from each of its final markings. The multisets
of task labels are collected during the traversal and stored in
each node of the graph. All labels from cyclic arcs inside strongly
connected components are gathered during the traversal with a
special symbol w representing that the label can be repeated any
10 D. Reifsner, A. Armas-Cervantes, R. Conforti et al. / Information Systems 94 (2020) 101561

 

Operation match match

match rhide match match

 

Arc DAFSA (s, B ,n,) (n,,D ,n2)

(np, C, N3) L

(n3, E,n,4) (n,,G, f,)

 

Arc RG ([start],B, [p1,P¢6,P3-P4l)| (Pr Po Ps, Pa), D, [Pr Ps Ps Pal) | ([ Pi Po Ps Psl,C,[P1,P6P7Psl) | ([P1, Pe P7- Pel, A, [Po]) | ([Po],E, [Pr0]) | (Pol, G, [end])

 

Fig. 8. Proper alignment for the matching example.

number of times. For the comparison of these labels to achieve
an underestimating function, we set these labels to infinity for
the term |Frog \ fivodei| and to O for the term |fivodel \ Flog], ie. we
assume that repeated task labels match all corresponding labels
in the trace. Observe that h assumes that all events with the
same label in Frog and fivoder are matched, this is clearly an op-
timistic approximation, since some of the those matches might
not be possible; then the optimistic approximation computed by
h guarantees the optimality of the alignments; h is admissible.

Algorithm 2: Construct the PSP
input: Event Log L, Log automaton DAFSA, Reachability

 

 

 

Graph RG,
1 forc ~€ L do
2 | o < {(Spsp, P(Spsp, C))};
3 Pmax < |c| + minModelSkips;
4 while o 4 @ do
5 choose a tuple (Ngct = (Nparsa, M, €), EP) € oO, Such
that A(npp, p') ET: p> p's

6 a <o \ {(Nact, P)};
7 if Nparsa € Rparsa \m € My A El parsa = C then
8 if 0(Nact, C) < Pmax then
9 Pmax <— P(Nact, C);
10 Opt < @;
11 o < {(n, p(n,c)) €o | p(n, c) < Pmax}
12 Opt <— Opt U {Nac};
13 else
14 Nnew < 3
15 for oparsa = (Nparsa; [parsa, Mr) € Nparsa> | [parsa =

C(|€lparsal + 1) do
16 Nnew <— Nnew U {(1r, m, € & (Ihide, aparsa, -L))};
17 for Arg = (m, Irc, mt ) Ee mp | Xe = IDAFsA do
18 , Nnew <—

Nnew U {(Mt, Mt, € B (match, oparsa, Orc ))}

19 for arc = (Mm, lrg, Mm) € mM» do

Nnew <— Nnew U {Mparsa, Mt, € ® (rhide, 1, arc))} ;
20 o <—F U {(Mpext, P(Mnext, C)) | Mnexe €

| Nnew A P(Nnext, C) < Pmax};

21 for f < Opt do InsertIntoPSP(f,c, PSP) ;

2 return PSP;

N

Algorithm 2 shows the procedure to build the PSP, where an
A* search is applied to find all optimal alignments for each trace
in a log. The algorithm chooses a node with minimal cost p, such
that if it pairs two final states (one in the DAFSA and one in the
reachability graph) - representing the alignment of a complete
trace - then it is marked as an optimal alignment. Otherwise, the
search continues by applying lhide, rhide and match. As shown
in [13], the complexity for constructing the PSP is in the order of
O(3!NparsalIM!) where Npagsa is the set of states in the DAFSA and
M is the set of reachable markings of the Petri net.

In order to optimize the computation of the PSP, two memo-
ization tables are used: prefix and suffix. Both tables store partial
trace alignments for common prefixes and suffixes that have
been aligned previously. The integration of these tables requires
the modification of Alg. 2, as shown in Alg. 3. For each trace
c, the algorithm starts by checking if there is a common prefix
for c in the prefix memoization table. If this is the case, the A*

starts from the nodes stored in the memoization table for the
partial trace alignments that have been previously observed. In
the case of common suffix memoization, the algorithm checks at
each iteration whether the current pair of nodes and the current
suffix is stored in the suffix memoization table. If this is the case,
the algorithm appends nodes to the A* search for each pair of
memoized final nodes and appends all partial suffix alignments
to the current alignment instead of continuing the regular search
procedure. Please note that the command continue in line 1
of Alg. 3 refers to the while loop of lines 9-21 in Alg. 2. This
command skips lines 14-20 where we would usually offer new
nodes to the open queue, and it is not necessary anymore because
we had already inserted a node for the optimal suffix after the
current node. By reusing the information stored in these tables,
the search space for the A* is reduced.

The technique illustrated so far produces a PSP containing all
optimal alignments. Nevertheless, if only one optimal alignment
is required, then the algorithm can be easily modified to stop as
soon as the first alignment is found. Overall, the complexity of the
proposed technique is exponential in the worst case, i.e. O(|>'| -
logn + QIPUT] 4 3!Nparsal:IM1)_

Fig. 9 shows an abbreviated PSP obtained by synchronizing
the DAFSA of the loan application process in Fig. 7 and the t-
less reachability graph of Fig. 6. The PSP shows the one-optimal
alignments and abbreviates states in the PSP with only states in
the DAFSA for readability purposes, and the name of the opera-
tions are shorthanded with the initial letter and the label of the
activity, i.e., (match, X) = m(X). To understand its construction
let us consider the sample trace (B, D, C, E, G). Starting from the
source node of the PSP Spsp, the A* search explores the outgoing
arc with label B of the initial state of the DAFSA and all outgoing
arcs of the initial marking of the reachability graph, i.e. arcs with
the activity labels A,B,C and D. Thus, it will compute the cost
of performing the following possible synchronizations: (lhide, B),
(rhide, A), (rhide, B), (rhide, C), (rhide, D) and also (match, B), be-
cause both, the DAFSA and the reachability graph, can execute
B at their current state. Out of these six possibilities it will only
explore (match, B)* and (rhide, A) which have a cost of one. Other
synchronizations like (rhide, B)’ will never be explored since they
have a cost of three and there exist nodes with a lower cost. The
A* search will continue exploring the possible synchronizations
until all optimal alignments are discovered.

4.4, Alignments are minimal and deterministic

This section shows that the computed alignments are deter-
ministic and minimal. In particular, we introduce rules to break
ties between alignments with the same cost. While determinism
is not a necessary property of alignments, it is a desired property
for end-users that rely on the output of conformance check-
ing techniques to, for instance, improve their process models.
Newer studies, such as the [33], deem deterministic results of
conformance measures as desirable in process mining.

2 In case of (match, B) we have a current cost of zero since it is a match (i.e.
g(n) = 0), and a future cost of one (i.e. h(n, c) = |{C, D, E, G} \ {A, C, D, E, G}| +
|{A, C, D, E, G} \ {C, D, E, G}| = 1).

3 In case of (rhide,B) we have a current cost of one since it is
a hide (ie. g(n) = 1), and a future cost of three (ie. A(n,c) =
|{B, C, D, E, G} \ {A, C, D, E, G}| + |{A, C, D, E, G} \ {B, C, D, E, G}| = 2).
D. Reifsner, A. Armas-Cervantes, R. Conforti et al. / Information Systems 94 (2020) 101561 11

Algorithm 3: Construct the PSP with Prefix- and Suffix Memoization

> replace line 2 in Alg. 2 with the following block:

 

> Reuse common prefix alignments
fori=1— |c| do o —o U {(Mnext, E(Mnext, C)) | Mnexe € PrefixTable(c for i)} ;
ifo = 2 then o <a U {(Spsp, o(Spsp, C)} ;

 

> replace line 14 in Alg. 2 with the following block:

 

> Reuse common suffix alignments
suff ace <— € after |{B = (Op, Aparsa, rc) € € | op F rhide}|
> Nnew <— {Oparsas fro, € ®B Ssugp) | Ubarsa. fro. Ssug¢) € SuffixTable(nparsa, m, Suff act )};

o <—oU {(Mnext, P(Mnext, C)) | Mnext € Nnew};
if New # 2 then continue ;

 

  
   

De ee ee ee
"Ed

Fig. 9. The PSP for our loan application process example.

(a) m0) mic)
Cs] Cg HEED, HO

Fig. 10. Deterministic one-optimal alignment for trace (B, D, C, E, G).

Alignments are deterministic. A trace can have several opti-
mal alignments, however, in order to have a deterministic com-
putation of a single optimal alignment, we define an order on the
construction of the PSP. This order is imposed on the operations,
with the following precedence order: match > rhide > lhide,
and on the lexicographic order of the activity labels. We apply
this precedence order at each iteration of the A*-search on the
set of candidate nodes of the queue that all have the lowest cost
values w.r.t. o. In that way the A* search will still always explore
the cheapest nodes first and guarantees to find an alignment
with optimal cost. The precedence order merely provides a tool
to deterministically select an optimal alignment from the set
of optimal alignments with a specific order of operations and
activity labels already during the exploration of the search space.

We choose to prioritize rhide over lhide synchronizations in
the preference order to increase the number of match synchro-
nizations in the returned optimal alignment. We would like
to remind the reader that an increase in match synchroniza-
tions does not change the cost function for an alignment as
per Definition 4.7. An alignment with more match synchroniza-
tions, however, can link the observed trace more closely to the
process model. The following lemma shows that for optimal
alignments, more rhide synchronizations lead to more match
synchronizations. Fig. 10 demonstrates all 4 possible optimal
alignments with the same cost for trace (B,D,C,E,G) of the
loan application example with one mismatch (missing activity

A in the parallel block). Out of these four, we select alignment
(m(B), m(D), m(C), r(A), m(E), m(G)) according to the precedence
order.

Lemma 4.1. Let €, be an optimal alignment for a trace c. For any
other optimal alignment e. for c, such that €Q,nige < €c\rhide, then

f
Eclmatch < &c|match-

Proof. Given two optimal alignments ¢¢, 7, it holds that these
two alignments have the same cost according to Definition 4.5,
i.e. cost(€-) = cost(e,), and these two alignments are proper
according to Definition 4.4. Further, we assume that e, has more
rhide synchronizations than ¢7, i.e. Ecirhide < €&c\rhide- AS a first step,
we assume that ¢, has exactly one more rhide synchronization
than €(, 1€. Ecjrhide = €ciphide + 1. The cost of an alignment
is the number of rhide and lhide synchronizations disregarding
all synchronizations involving t. Since we remove all t-labeled
transitions in Alg. 1, the cost of an alignment equals exactly to
the number of rhide and lhide synchronizations. By the assump-
tions, €- has one more rhide synchronization than, and the same
cost as, e. and so it follows that ¢/ has exactly one more lhide
synchronization for a trace label @ than ¢, ie. (Ihide, 2) € e. A
(lhide, £2) ¢ €- A £ € c. Since both alignments properly represent
the trace, the sum of their [hide and match synchronizations is
equal to the size of the trace |c|. Therefore, ¢, needs to have one
more match synchronizations than ¢/, in particular (match, €) €
Ec A (match, 0) ¢ &, A € € c. The general case of multiple rhide
synchronizations follows from inductive reasoning. If an optimal
alignment ¢, has x more rhide than another optimal alignment
e/, then e/ must have x more lhide than ¢, because they have the
same cost. Similarly, €- must have x more match synchronizations
than e7 since the number of [hide and match synchronizations
needs to equal to the size of the trace |c|. Hence, it holds for
two optimal alignments ¢,, ¢, with Ecirhide < €&c\rhide that €

/
. c\match <
Ec\match and thus the proof is complete.

 

 

 

 
12 D. Reifsner, A. Armas-Cervantes, R. Conforti et al. / Information Systems 94 (2020) 101561

Revising the construction of the PSP for one optimal align-
ments. Algorithm 4 shows the modified procedure to construct a
PSP containing one deterministic optimal alignment for a given
trace c which differs from Alg. 2 by using the deterministic
selection criteria explained above (line 10), and terminating when
the entire trace has been read and the final state in RG has been
reached (line 13).

Algorithm 4: Revised for one-optimal: Construct the PSP

input: Event Log L, Log automaton DAFSA, Reachability
Graph RG
1 forc € L do
2 f < align(c, DAFSA, RG);
3 L InsertIntoPSP(f , c, PSP);

4 return PSP;

5 Function align(c, DAFSA, RG)

6 | o < {(Spsp, P(Spsp, C))};

7 Pmax <-| C | + minModelSkips;

8 while o 4 @ do

9 Opt <— {((Nparsa, M, €), 0) € o, Such that
ANpsp. pyEec:p> p'};

10 choose a tuple ngct = ((Nparsa, M, €), E.) € Opt with
the following priorities :

op(e(\e|)) : match > rhide > lhide and choosing
A(eé(\é|)) in lexicographical order;

 

11 a <o \ {(Nact, P)};
12 if Mparsa € Rparsa \ M € Rec A El pars, = C then
13 return MNgct = (Tparsa, Tra; €c);
14 else
15 Nnew < 3
16 for aparsa = (Nparsa; Iparsa, Mt) € Nparsa® | Iparsa =

C(|€lparsal + 1) do
17 Nnew < Nnew U {(n, m, € @ (lhide, aparsa, L))};
18 for Arg = (m, Irc, mt ) Ee mp | Xe = IDAFsA do
19 ; Nnew <

Nnew U {(Mt, Mt, € B (match, oparsa, Orc ))}

20 for arc = (mM, lr¢, M:) € mM» do

Nnew <— Nnew U {Mparsa, Mt, € ® (rhide, 1, arc))} ;
21 o <0 U{(Mnext, P(Mnext, C)) | Mnext €

Nnew ax P(Mnext ; C) < Pmax};

 

 

Alignments are proper and minimal. Note that the “final”
node (rpaesa, rrc, €c) returned in line 13 defines a sequence «é, of
synchronizations. Next, we show that «, is indeed a proper and
optimal alignment of c to RG. Let #(c, PSP) = é, be a function
that “extracts” ¢, out of the constructed PSP PSP returned by Alg.
A.

Lemma 4.2. Let L, DAFSA and RG be an event log, a DAFSA
and a reachability graph, respectively. For each trace c € L and
PSP = Alg4(L, DAFSA, RG), it holds that e- = (c, PSP) is a proper
alignment of c to RG, i.e. €. € C(c, RG).

Proof of Sketch. In order to prove that ¢, is a proper align-
ment, we proceed to show that it fulfills the two properties in
Definition 4.4.

(1) The projection on the DAFSA reflects the trace A(&¢|parsa) =
c. Recall that the projection of any proper alignment onto DAFSA
contains only match or lhide operations. Alg. 4 starts at the initial
state of the DAFSA for every given trace, iterates over the trace
(9-21) and adds lhide-operations (line 17) and match-operations
(line 19) for outgoing arcs with the next label of the trace. Every
alignment é¢, returned by Alg. 4 then fulfills this property by

construction as it needs to fulfill the condition €[pars, = c in line
12 for determining if a given alignment is final.

(2) Eclr¢ is a path form mp to a final marking my € My. Recall
that the projection of any proper alignment onto RG contains
only match or rhide operations. The algorithm always starts to
add arcs from the initial marking of the reachability graph. At
every iteration of the main loop (9-21) it either adds arcs with
match operations in line 19 or with rhide operations in line 20
from the set of outgoing arcs of the current marking in the
reachability graph. The algorithm then adds a new node to the
queue that contains the target of the added arc. By lines 18 and
20, subsequent arcs are only added if they are outgoing arcs of
the node m reached in RG, and thus will always form a path in
RG. This path will always start from the initial marking and end
in a final marking as per the condition in line 12 and thus it is a
path through the reachability graph.

 

 

 

 

Lemma 4.3. Let L, DAFSA and RG be an Event log, a DAFSA and a
Reachability Graph, respectively. Then it holds for each trace c € L
and PSP = Alg4(L, DAFSA, RG) that the alignment é, = d(c, PSP) is
minimal w.r.t the cost function g(¢,), ie. fe’ € C(c, RG) : g(e’) <
&(Ec).

Proof of Sketch. Algorithm 4 finds alignment é, inside the while
loop in function align (5-21). Potential alignments are inserted
into a queue in lines 19, 17 and 20. In line 10, a candidate
alignment is chosen from the queue with a minimal cost function
value with respect to p. In each iteration of the while loop,
the active candidate alignment is checked for being final in line
12. Once a candidate alignment e, is found final, it is returned
by the function. Since all candidate alignments ¢ in the queue
are selected and then removed according to their cost function
value p(€) in increasing order, the first alignment that is a proper
alignment for trace c will have a minimal value for p(é,). If
h(x) = 0 would hold, then the candidate alignment would always
be picked according to the cost function g and trivially the first
final alignment would also be optimal, since all alignments with
smaller costs had been investigated.

 

 

 

 

Observe that for all final states f © Rpsp, h(f) = O, since
every final state in the PSP represents a proper alignment and
a proper alignment fully represents the trace, ie. Fig = Y,
and its projection on the reachability graph represents a path,
Le. Fyode = . It follows that e, is optimal w.r.t. 0, when
function h underestimates the cost to the optimal cost for any
investigated node, which is in line with the optimality criterion
of the A*-search algorithm [32].

We show that our definition of function h fulfills this criterion
by analyzing how it estimates future hides for any given node.
Let node x be a candidate node, function h compares the multiset
of future log labels, determined by trace c set minus the already
aligned trace labels €(X)[pars,, with every possible multiset of
future model labels to all possible final markings. The multisets
of future task labels represent possible paths in the reachability
graph to a final marking and a path to a final node in the DAFSA
representing the suffix of trace c. By comparing multisets to find
deviations, the context of task labels is dropped and h allows for
a lower cost than g. Repeated task labels are also assumed to be
matched in these multisets and thus are not taken into account
in the comparison. Finally, function h minimizes the difference of
all multiset comparisons such that it always finds the closest final
marking in terms of distance. Given that the multisets represent
possible paths, the value of h can only be as high as the true cost
of a path and will underestimate the cost in case the abstractions
obscure differences due to context or cyclic structures. Thus, h
underestimates the true cost to the closest final marking and thus
the alignment ¢€, is minimal with respect to p.
D. Reifsner, A. Armas-Cervantes, R. Conforti et al. / Information Systems 94 (2020) 101561 13

5. Taming concurrency with S-components

Process models with significant amounts of parallelism can
lead to exponentially large reachability graphs, given that they
need to represent all different interleavings. Large reachability
graphs can negatively affect the performance of the automata-
based technique presented in the previous section. More gener-
ally, the combinatorial state explosion inherent to models with
parallelism has a direct impact on the size of the space of possible
trace alignments. To prevent this combinatorial explosion, this
section presents a novel (approximate) divide-and-conquer tech-
nique based on the decomposition of the model into concurrency-
free sub-models, known as S-Components. This technique im-
proves the execution time for models with concurrency, at the
expense of allowing for over-approximations compared to an
optimal alignment, which as we will show later, are infrequent
and minimal in practical scenarios. The divide-and-conquer tech-
nique of this section is an alternative to the exact PSP-based
technique presented in Section 4. Fig. 11 outlines the proposed
divide-and-conquer technique consisting of the following steps:
(1) divide the process model into S-Components, (2) expand each
S-Component to its reachability graph, (3) project the alphabet
of each S-Component on the event log to derive sub logs, (4)
compress each sub-log into a DAFSA, (5) compare the reachability
graphs (see Step 2) and the corresponding DAFSAs to derive sub-
PSPs, and (6) recompose the related results into alignments that
are (7) proper and (8) approximate, but empirically in most cases
optimal.

Several steps of this technique have been already introduced
in the previous section, such as the expansion of a process model
to its reachability graph, the compression of a log into its DAFSA
and the comparison of a reachability graph to a DAFSA to derive
a PSP. In the following, we will introduce the remaining steps:
namely, decomposing a process model into S-Components (Sec-
tion 5.1), projection of logs onto S-Components and recomposing
the results of conformance checking for each S-component into
an alignment (Section 5.2). In Section 5.3, we discuss when the
alignments are approximate, and prove in Section 5.4 that they
are proper.

5.1. Dividing a process model into S-Components

The decomposition technique considers uniquely-labeled
sound free-choice workflow nets, a subclass of workflow nets [25,
34]. A workflow net is uniquely labeled if every non-silent label
is assigned to at most one transition. Soundness was defined in
Section 3.2. A net is free-choice iff whenever two transitions t; and
t2 share a common pre-place s, then s is their only pre-place; in
a free-choice net concurrency and choices are clearly separated.
The formal definitions are given below.

Definition 5.1 (Uniquely-labeled Sound Free-choice Workflow Net).
A labeled workflow net WN = ((P,T,F,A),i, 0) is free-choice
iff for any two transitions t},f2 € T: s € et; M et) implies
et; = ef, = {s}. A workflow net is uniquely-labeled, iff for any
(1,0 € Tpy, A(t) = A(t2) x T => t} = tf. A system
net is uniquely-labeled, sound, and free-choice if the underlying
workflow net is.

An S-Component [25,34] of a workflow net is a substructure,
where every transition has one incoming and one outgoing arc (it
does not contain parallelism). A sound free-choice workflow net
is covered by S-Components and every place, arc and transition of
the workflow net is contained in at least one S-Component, which
is also a workflow net. Fig. 12 shows 4 different S-components of
the running example of Fig. 2. Each S-Component contains one of
the four tasks A, B, C or D that can be executed in parallel. Note

that S-components can overlap on non-concurrent parts of the
workflow net as indicated by nodes with solid borders.

Before we explain the decomposition of a workflow net into
S-Components, we need to introduce the concept of the incidence
matrix of a Petri-net. Recall from Section 3.2 that a marking
m = (m(p;),..., M(p,))™ is a column vector over the places P =
{p1,..-, Dk}; and vectors N~(t) and N*(t) describe the tokens
consumed and produced by t on each p € P. The resulting effect
of t on P is N(t) = N~(t) + N*(t). The incidence matrix of a
Petri net N is the matrix N = (N(t,)...N(t,-)) of the effects of
all transitions T = {t,,..., ¢,}. Given a firing sequence o in WN
Starting in mo, let the row vector y = (y1,...,y,) specify how
often each t;,i= 1,...,r occurred in o. For any such row vector,
the marking equation m = mj) + N -y yields the marking reached
by firing o. Fig. 13 shows how the marking equation of the Petri
net of our sample loan application process in Fig. 2 gives a new
marking from the initial marking.

The decomposition of a sound free-choice Petri net into S-
Components is based on its place invariants. A place invariant
is an integer vector indicating the number of tokens that are
constant over all reachable markings. It can be determined as an
integer solution J to the marking equation J-N = 0, i.e., J -mp =
J-m for all reachable markings m of N, because J-N-y = 0 [34]. The
equation J -N = 0 has an infinite number of solutions. Place in-
variants can be non-trivial, in the following denoted as PI, they are
different from 0 and are minimal (not linear combinations of other
place invariants of N). We are only interested in the unique set
of non-trivial place invariants PI, which can be obtained through
standard linear-algebra techniques. Each minimal place invariant
J possibly defines an S-Component as a subnet of the workflow
net consisting of the support (J) of J [34]. The workflow net can be
decomposed into n S-Component subnets, where n is the number
of minimal place invariants of the workflow net, i.e. |PI|. We next
define a S-Component net and the decomposition of a workflow
net.

Definition 5.2 (S-Component, S-Component Decomposition). Let
WN = ((Py, Ty, Fy, An), 1,0) be a sound, free-choice workflow
net. Let J be a minimal place invariant of WN. An S-Component
WN, is a non-empty, strongly connected labeled workflow net
WN, = ((P), Ty, Fy, Aj), i, 0) with the following properties:

eP={pePy|peVJ)Aep CT ApeCTy}

eT, = {t €Ty | jet UP)| =1= |t eU P|}

e F ={(p,t)e Fy |pePAt eT }U(t,p) < Fy |t eT) Ape
Py}

e Ay = {((t, 1) e An | t € Ty}

For the set of all minimal place invariants PI of WN, the S-
Component decomposition @ is a non-empty set of S-Component
workflow nets that cover WN, i.e. C = {WN, | J € PI}.

S-Components are concurrency-free, as the requirement
Jet UP;| = 1 = |t e U P| allows only one input/output place per
transition. Applying the decomposition to our running example,
four minimal place invariants are computed: (1100010001
1111)(10100010011111),(10010001011111)
and (1000100011111 1). Fig. 12 shows the derived four
S-Component workflow nets; each S-Component contains one of
the four tasks A, B, C or D that can be executed in parallel.

5.2. Conformance checking with S-component decomposition
This subsection introduces a novel divide-and-conquer tech-

nique to speed up the conformance checking between a system
net and an event log. The division of the problem relies on the
14

  

Reachability
Graph n

  

Petri Net |

S-Component n

  

_>

mo t A BC D tE F GH I
start / 1 -100 00 000 00 0
p, | 0 1-100 000 00 0 0
p, | 0 1 0-100 0000 0 0
p; | 0 1 00-1000 0 0 0 0
p, | 0 1 00 0-10 0 00 0 0
ps | 0 0 100 0-10 00 0 0
P, | 0 0010 0-10 00 0 0
p |o!l*]0 00 1 0-10 0 0 0 0
pe | 0 000 0 1-10 0 0 0 0
po | 0 0000 01-1000 1
Pio | 0 000 00 0 1-1-10 0
pi, | 0 000 0 00 0 0 1-10
Pro | 0 00000000 0 1 =-1
end \ 0 0000000 1 0 0 0

 
    
    
  

D. Reifsner, A. Armas-Cervantes, R. Conforti et al. / Information Systems 94 (2020) 101561

(5.3)
Approximate
and proper

(5.4)

m
Q\ start
0 |} p,
Oe
0 P3
0 | Py
tc ABCDTtTEFGHIt 0 Ps
2 _ 6
* (QP rrrr2 or rroy ay oye
Ue
0 | Po
| Pio
O} Pr
0} Pio
O/ end

Fig. 13. Marking equation to reach marking (p10) for our loan application example.

decomposition of the workflow net into S-Component workflow
nets as introduced in Section 5.1.

The following definition introduces trace projection, an oper-
ation that filters out the events with labels not contained in the
alphabet of a particular S-Component.

Definition 5.3 (Trace Projection). A trace projection, denoted as },,
is an operation over a trace c = (lj, lb,...,1,) that filters out all
the labels not contained in A, i.e. Chih} = (li, ]j,..., 1) such
thatO <i<j<,...,<k<n.

The novel divide-and-conquer technique decomposes the
workflow nets into concurrency-free sub-workflow nets - S-
Components -, computing partial alignments between projected
traces and S-components, and recomposing the partial align-
ments to create alignments for each trace in the log. Note that
the alignments are partial because the projected traces are only
parts of a complete trace. In the following, we explain the full
procedure, illustrated in Fig. 14 and defined in Alg. 5, as we obtain
and re-compose partial alignments for the trace (B, D, A, E, F, G)
in our running example and the S-Component workflow nets

(Fig. 12). Observe that in our running example there are four S-
Component workflow nets, each representing the execution of
one of the parallel activities A, B, C and D.

Algorithmic idea.

Algorithm 5 is given the S-Components SN,,...,SN, of SN
and the log automaton DAFSA of the complete log L which has
an alphabet ». Each S-component SN; has alphabet »;. We first
compute for each S-component SN; its reachability graph and the
DAFSAs DAFSA; of the projected log with alphabet »; (see Lines
2-5). From that point on, Alg. 5 computes and recomposes along
the k S-components and stores all information in vectors of length
k, ie, 2) = (24,..., X') (see Line 6).

We continue by taking each trace c in the log projecting it
onto the alphabet of each S-component c/s,. For our example
trace (B,D, A, E, F, G) four partial traces are created: (B, E, F, G),
(D, E, F, G), (E, F, G) and (A, E, F, G). The traces share the subse-
quence (E,F,G) as the corresponding transitions are in the se-
quential part of the workflow net and hence in all S-components
in Fig. 12.

Then, we compute the deterministic optimal alignment ¢; of
each projected trace c/s, to its S-component SN; (by calling Alg.
D. Reifsner, A. Armas-Cervantes, R. Conforti et al. / Information Systems 94 (2020) 101561 15

Algorithm 5: Construct PSP by Recomposing S-Component Alignments

input: Event Log L, Log automaton DAFSA, System net SN = (WN, mo, My) with its S-Component decomposition
C = {WN,,..., WNx};
// compute decomposed reachability graph and DAFSA for each S-component
1 &, < labels occurring in L;
2 »; < labels occurring in WN; for eachi=1,...,k;
3 RG; < reachability graph of SN; = (WNi, Mo, My) for eachi=1,...,k;
4 DAFSA; < construct DAFSA({c|», | c € L}) for eachi=1,...,k;
5X < (2}4,..., Xk);
6 for Trace c € Ldo
// compute alignments locally for each S-component
7 € <— (€1,..., €k) with e; <— align(c{y,, DAFSA;, RG;) with Alg. 4 for eachi = 1,...,k;
// recompose local alignments ¢ into global alignment
8 | & < ();

9 n <— (Mparsa(E1(0)), ..., Nparsa(ex(O)));
10 m <— (mMpc(é1(0)), ..., Mrc(ex(O)));
11 pos < (pos;,..., pos.) with pos; < O for eachi=1,...,k;

12 for pos, <1: |c|+1 do
// next log event, try to recompose one synchronization with ¢

13 £ <— c[pos;];
// but first local components may need to do model steps to reach ¢, try to recompose model steps

14 (couldRecompose, pos, mM, €<) <— recomposeModelStepsUntil(¢, €,, €, pos, m, X’, »’) with Alg. 8;
15 if couldRecompose = false then

// Recomposition conflict: S-components locally aligned models steps ina different order,

cannot recompose

16 jump to line 23;
17 if (Vi=1...k| 2 e€ +; = op(ej(pos;)) = lhide) \ € AL then

// S-components having ¢ agree on log step, recompose their synchronizations
18 (€-, pos, n) <— recomposeLogStep(£, €-, €, pos, n, X’') with Alg. 6;
19 else if (Vi=1...k|@¢€ 2; = > op(ej(pos;)) = match) A € 41 then

// S-components having ¢ agree on log and model step, recompose their synchronizations
20 (€¢, pos, n, m) <— recomposeMatchStep(£, €-, €, pos, n,m, X’) with Alg. 7;
21 else if € 41 then

// Operation conflict: S-components locally disagree on operation, cannot recompose
22 jump to line 23;

 

 

23 if. Any conflict occurred then ¢, < align(c, DAFSA, RG) with Algorithm 4;
24 | InsertIntoPSP(€,., c, PSP);

25 return PSP;

 

4 in line 7 of Alg. 5); we call each ¢; a projected alignment. Fig. 14
shows the four optimal projected alignments ¢)-€4 retrieved by
Alg. 4 for our running example. Note that because each SN; is
sequential, the reachability graph of each SN; has the same size
as SN; itself. Thus the k projected alignment problems are expo-
nentially smaller than the alignment problem on the reachability
graph of the original SN.

Once the projected alignments have been computed, we iter-
ate over the original trace c and compose the projected alignments
€ = (&,...,&) (between the DAFSA; and RG; of SN;) into a
global alignment ¢, between DAFSA and RG of SN. We explain
the idea of this recomposition by recomposing the projected
alignments €,-€4 of our example of Fig. 14. The recomposition
technically “replays” all alignments (€1, €2, €3, €4) along trace c =
(B, D, A, E, F, G) in parallel. For each next event @ of the log, Alg.
5 determines which alignments together can replay @ (and make
a joint step in their DAFSAs and in their reachability graphs).
Initially, the 4 S-components of Fig. 12 are locally in their initial Fig. 14. Example for applying Alg. 5 to trace (B,D,A,E,F,G) to our running
markings m = ([start], [start], [start], [start]) (see Alg. 5, line 10). example.

We iterate over trace c = (B, D, A, E, F, G) as shown in Fig. 14.

 

(1) For the first event B, all S-components involving B (which
is the single S-component 2 in this case) have as their for B. We add a match step m(B) for the composed align-
next synchronization ¢€;(pos;) a match synchronization m(B) ment ¢, and S-component 2 reaches m2 = [p6], while
16 D. Reifsner, A. Armas-Cervantes, R. Conforti et al. / Information Systems 94 (2020) 101561

S-components 1,3, and 4 remain in [start], respectively.
Recall that t-transitions were removed from the reacha-
bility graph, allowing this single step. In Alg. 5, the condi-
tion in line 19 and recomposeMatchStep line 20 define this
composition step explained below.

(2-3) Similarly, for the next events D and A of c, m(D) and
m(A) synchronizations from ¢€, and €2 are added to é, by
recomposeMatchStep, which corresponds to reaching [p8]
and [p5] in S-components 1 and 4.

(4.1) The fourth event E occurs in all S-components, but ¢3 has
at its current position pos; = O an rhide synchronization
for C which is only later followed by an E-synchronization.
In Fig. 12, this corresponds to S-component 3 still be-
ing in marking [start] and transition E not being enabled
yet. In order to reach E and to “catch up” with all other
S-components, S-component 3 can locally replay rhide syn-
chronizations of any label that is not the current label
E. In Alg. 5, recomposeModelStepsUntil line 14 define this
composition step explained below. In our example, r(C) is
added to €, and S-component 3 reaches marking [p7].

(4.2) Now all S-components agree on m(E) synchronizations,
thus m(E) is added to €, and all S-components reach mark-
ing [p10]. Note that all S-components having the m(E)
make a joint step, expressed in lines 19-20 of Alg. 5 by
an update on several components of the vector m.

(5) The algorithm proceeds similarly in step 5 by adding a
match synchronization for label F.

(6) For label G, all S-components agree on an [hide synchro-
nization which is added to é€, as [(G). This is the third case
in the loop of Alg. 5 by the condition in line and the
composition due to recomposeLogSteps in line 18 explained
below.

The resulting sequence ¢, of synchronizations is a proper align-
ment according to Definition 4.4 and is added to the PSP (line
24). Algorithm 5 may fail to recompose the S-components in
case the projected alignments locally disagree on the next syn-
chronization to compose, i.e., lines 16 and 22. In this case, we
revert back to computing a global alignment without decom-
position (line 23). In the remaining of this subsection, we ex-
plain the technical details of this recomposition. First, we ex-
plain how several S-Components can be synchronized with trace
c with a vector notation. Then, we introduce and formalize
the two recomposition cases, which involve operations from
the three algorithms recomposeModelStepsUntil, recomposeLogStep
and recomposeMatchStep.

Composing partial alignments by synchronizing k FSMs.

Recall that an alignment is a sequence of synchronizations.
Each synchronization §; = (op;, b;, a;) of a projected alignment ¢;
refers to an arc bj = (nj, €, n,;) of DAFSA DAFSA; and/or an arc a; =
(m;, €,m;) of the reachability graph RG; of SN;; DAFSA; and RG;
are FSMs. Each arc has a source and target state of the projected
DAFSA/reachability graph. The task of Alg. 5 is to compose from
the nodes and arcs of the projected DAFSA; and RG; along trace c
a sequence €,- of synchronizations of nodes and arcs of the global
log automaton DAFSA and RG. This sequence é, has to form a
path through DAFSA (i.e., describe the trace c) and a path through
RG (i.e., describe a run). Then ¢, is an alignment of c to SN by
Definition 4.4.

Technically, we construct the nodes and arcs of DAFSA and
RG as vectors of the nodes and arcs of the projected DAFSA; and
RG;. We represent the composed DAFSA node in €, as a vector
n = (m,...,Mk),ni € Noparsa, and the composed state of the
reachability graph as a vector m = (mj,...,Mx),m; € Nrc;.
Both vectors are initialized in lines 9 and 10 from the projected

initial states, respectively. We represent the arcs of the composed
DAFSA as a partial vector b = (by,..., by), where a component
b; =-L may be undefined; a partial vector a = (dj,..., da)
denotes an arc of the recomposed reachability graph. For instance,
let dz = (M2, £2, M,), d4 = (Ma, £4, m),) be arcs of the reachability
graph of S-components 2 and 4. The vector b = (LL, bz, 1, by)
describes that S-components 2 and 4 synchronize in b while S-
components 1 and 3 do not participate. We may only synchronize
arcs of different S-components if they agree on the label, e.g., if
£(b2) = £(b4). The synchronized arc b = (_L, bz, 1, b4) then has
the label @(b) = €(b2) = €(b4) and takes S-component 2 from m2
to m, and S-component 4 from mz, to m;,.

As we iterate over the trace c in Alg. 5, our composition has
to include in the partial vector b all arcs that agree on the current
label @. First, we give some technical notation for constructing the
partial vectors from the available DAFSA; and RG; arcs, and then
we explain the loop for the composition.

Suppose we are at the composed marking m = (m),..., Mx)
of all the RG;; the next arcs we can follow in the RG; are aj, ..., dx,
a; = (mj, ¢;,m,). We may follow only those arcs together that

share the same label. The partial composition of these arcs for
some label ¢ is the vector a = (@1,..., Gx) with a; = aq; if 2(a;) = £
and a; = otherwise. For any component i where a; #_L, the state
changes from mj; to m; and all other components remain in their
state. Technically, we write m; » (m;, €, m;) = m; and m; » L= m;
which we lift tom » a = (m,; » dj,...,mM, » dy). Thus, a
traverses all those arcs with label £ and m p» a is the composed
successor marking reached by this partial synchronization. These
definitions equally apply for composing arcs of the DAFSAj.

We now can explain how we compose the projected align-
ments ¢; into ¢, by composing the arcs of the DAFSA; and RG; in
the order in which they occur in the ¢;,i = 1,..., k. We “replay”
trace c starting from an empty composed alignment, all projected
alignments are at pos; = 0, and at the initial composed nodes n
and m for the DAFSA; and RG; (lines 8-11 in Alg. 5).

The next event to replay is € = c(pos,) (line 13 of Alg. 5). The
next projected synchronizations are 6; = e;(pos;),i = 1,...,k
with 6; = (op;, aj, bj). Two cases may arise.

Case 1: For all S-components i that have @ e€ J; in their
alphabet, their next synchronization f; involves arcs labeled with
£ = £(f;); lines (17-20 in Alg. 5). In this case, all S-components
“agree” and we can synchronize the DAFSA; arcs and the RG; arcs
in the 6; of those S-components into a synchronization for @ in
€-. Again, three cases may arise.

1. All synchronizations 6; labeled with @ agree on the opera-
tion lhide (line 17 in Alg. 5). We obtain the next synchro-
nization for ¢, by composing the DAFSA; arcs with @ and
updated the node n for the composed DAFSA as defined
by recomposeLogStep in Alg. 6. The partially composed arc
a’ =(n, €,n » a) of the DAFSA; in the new synchronization
(lhide, a’, |.) describes that all S-components make a lhide
step together (i.e, no S-component fires a transition for
event £). The new synchronization is appended to ¢, and
we advance the position pos; for all S-components involved
in this composition.

2. All synchronizations 6; labeled with @ agree on the oper-
ation match (line 19 in Alg. 5). We append to ¢, a new
match synchronization with partially composed DAFSA; arcs
and RG; arcs, describing that all involved S-components
make a match step together, and update nodes n and m
of the DAFSA and the reachability graph; see function
recomposeMatchStep in Alg. 7.

3. The partial alignments of some S-components disagree on
the operation, i.e, we have conflicting partial solutions
(lines 21-22). In this case we fall back to computing a
global alignment without decomposition (line 23).
D. Reifsner, A. Armas-Cervantes, R. Conforti et al. / Information Systems 94 (2020) 101561 17

Algorithm 6: recomposeLogStep, recompose log steps for
current event ¢
input: Next log label 2, current partial recomposed
alignment ¢€,, local alignments ¢, positions in local
alignments pos, local DAFSA states n, labels in each
component >

. .\a | .
1b <— ei(pos; "fl xi , for eachi=1,...,k;
L otherwise
2 && <— & @ (hide, (n, 0, n » (by, ..., bx)), L);

3 n<np (by,..., Dx);
4 pos; <— pos; + 1 foreachi=1,...,k where @ € 4%);
5 return (é,, pos, 1);

Algorithm 7: recomposeMatchStep, recompose matching
steps for current event ¢

input: Next log label 2, current partial recomposed
alignment €;, local alignments ¢, positions in local
alignments pos, local DAFSA states n, local model
states m, labels in each component Y

. . \ADAFSA | .
1b < €i(Posi) yl Xi , for eachi=1,...,k;
L otherwise
. . \ARG | .
24a) <— €;(Pos;) ple & , for eachi=1,...,k;
L otherwise
3 E& <— €& @ (match, (n, £,n » (bi,..., by)), (m, 2, m >

(d1,..., Qk)));
4n<np(bj,..., dx);
5 Mm <—~mMp (dy,..., A);
6 pos; < pos; + 1 for eachi=1,...,k where @ € 437;
7 return (¢€,, pos, n,m);

Case 2: There are S-components i that have @ € J; in their
alphabet, but the next synchronization f; is not labeled with ¢ +
£(B;). The set Cy, defined in line 1 of function
recomposeModelStepsUntil in Alg. 8 contains all these
S-components. These S-components have to “catch up” with rhide
synchronizations to reach a state where they can participate in a
[hide or match synchronization over ¢ (lines 2-13 of Alg. 8). How-
ever, such S-components may only catch up together: Suppose
there is an S-component i having as next synchronization an rhide
over £(6;) = x # £, then all S-components with x in their alphabet
(set lab, in line 4) must also have an rhide synchronization on x
as their next synchronization (set sync, in line 3). If we find such
a set sync, (line 5), then we can compose a rhide synchronization
from the RG; arcs in sync, and append it to ¢, (lines 6-9). This step
may have to be repeated if there is another S-component that
still has to catch up. If the projected alignments disagree on the
next rhide, we have conflicting partial solutions and fall back to
computing a global alignment without decomposition (lines 11-
12). Note that recomposeModelStepsUntil is called in Alg. 5 (line
14) for each new trace label @ and lets all S-components catch up
before attempting to synchronize on £.

In this way, we consecutively construct two paths: one through
the composition of the DAFSA; (by the a’ = (n,é,n p» a)
arcs) and one through the composition of the RG;. In Section 5.4
we formally state that these paths correspond to paths through
DAFSA and RG and thus ¢, is an alignment; the proof is given
in Appendix C,

5.3. Optimality is not guaranteed under recomposition

The recomposition of partial alignments in Alg. 5 is not nec-
essarily optimal. Fig. 15 shows a pair of S-Components, each

Algorithm 8: recomposeModelStepsUntil, recompose model
steps until enabling next log event @

input: Next log label 2, current partial recomposed
alignment ¢€,, local alignments ¢, positions in local
alignments pos, local model states m, labels in each
component »’, labels in the full log »7
1 Ce < {(i, €;) |i =1...k A pos; < je|AC(e €
di A €(e;(posi)) F €) Vv (€ =L))}:
while C; 4 2 do
sync, <— {(1, €) | €(ei(pos;)) = x A op(e;(pos;)) = rhide}
for each label x € 27;
lab, < {(i, €;) | x € 2%} for each label x € 27;
if Sx € XY : sync, = lab, then
Ei(pos;)"> if (i, e;) € sync,
a otherwise

 

WwW N

6 adj < , for each

i=1,...,k;

Ec < €c ® (rhide, L,(m,x,m pm (aj, ..

m <— mp (d1,..., dx);

pos; <— pos; + 1 for each (i, ¢;) € sync,;

10 Ce < {(i,e;) |i =1...k A pos; < |e|AC((E €

| 2 A E(ei(pos;)) # £) V (€ =L))};

Ise

// S-components locally aligned models

steps inadifferent order, cannot
recompose

12 return (false, pos, m, &-)

oe ax. )));

eo oe NI

11

@

 

 

13 return (true, pos, m, €,);

representing a parallel activity A or B followed by a merging
activity C and a trace (C,A,B), where the merging activity is
miss-allocated before the parallel activities. The two optimal pro-
jected alignments according to the sorting from Section 4.4 then
each include a rhide synchronization for the parallel activity, a
match synchronization for the merging activity C and a lhide
synchronization for the parallel activity. Note that both projected
alignments are optimal in cost. Once the projected alignments
are recomposed, the cost of the recomposed alignment is 4:
(r(A), r(B), m(C), I(A), I(B)). However, there exists another proper
alignment with a lower cost of 2: (I(C), m(A), m(B), r(C)). The rea-
son why the recomposed alignment is not optimal, while the pro-
jected alignments are optimal, is that the projected alignments
choose one optimal alignments out of multiple possible opti-
mal alignments with the same cost without considering which
choices would globally minimize the cost when recomposing
the projected alignments. In this example, the projected align-
ments with another kind of sorting could also be (I(C), m(A), r(C))
and (I(C), m(B), r(C)), which would recompose to the optimal
alignment.

With the current sorting introduced in Section 4.4, we in-
troduce an additional cost of one over the optimal cost per
S-Component workflow net for a task miss-allocation of a merg-
ing activity possibly multiple times, when the parallel block is
enclosed in a cyclic structure. Hence, the worst-case cost over-
approximation of the proposed recomposition algorithm for a
given trace c is k « #i, where k is the size of the S-Component
decomposition and #i is the number of maximal repetitions of
a label in c that is also contained in a parallel block in the
process model. Transforming the recomposition procedure into
a minimization problem of selecting the best projected align-
ments for recomposition would however increase the calculation
overhead exponentially since every trace can have exponentially
many optimal alignments for each S-Component workflow net.
18 D. Reifsner, A. Armas-Cervantes, R. Conforti et al. / Information Systems 94 (2020) 101561

Trace: (C, A,B)

LZ start

start ¢

p2 B p6

start

O_POrp

Trace 1: (C,A ) —— Alignment 1: ( r(A), m(C), L(A) )
Ee Recomposed Alignment:
@{ bot bo bO (r(A),r(B),m(C), L(A), (B))
. pl A p5 C end

Cost :4
wane eee eee eee eee eee a But(!)

end * Trace 2: ( C,B )) —— Alignment 2: (r(B),m(C), l(B) ) |

: p2 3 p6 C end

Optimal Alignment:
(1(C), m(A),m(B),r(C))
Cost : 2

Fig. 15. Counter-example to optimality of a recomposed alignment.

Thus, selecting the best optimal projected alignments can be com-
putationally more expensive than calculating only one-optimal
alignments for the initial workflow net and event log. How-
ever, calculating the reachability graphs of workflow nets without
parallel constructs is polynomial in size, speeding up the calcula-
tion of one optimal-projected alignments, and thus the proposed
technique can provide significant speed-ups over the original
technique on process models with parallelism.

Even though the presented technique computes non-optimal
results, the evaluation shows that both the fraction of affected
traces as well as the degree of over-approximation is rather low.
The results obtained for the evaluation of this novel technique is
oftentimes close to optimal.

5.4. Proper alignments by addressing invisible label conflicts

The recomposition of synchronizations from the partial align-
ments of the S-components in Alg. 5 relies on the unique la-
beling. In this way, arcs in the reachability graphs of different
S-components can safely be related to each other. However, if a
uniquely labeled process model contains a t-labeled transition,
Alg. 1 reduces these t-labeled transitions by contraction with
subsequent visible edges. This may lead to two arcs in the reach-
ability graph carrying the same label D but describing different
effects, a hidden form of label duplication. Applying Alg. 5 on such
a model may lead to two partial alignments where the composed
synchronization agree on label D, but the underlying arcs in the
reachability graphs disagree, leading to a “hidden” recomposition
conflict not detected by Alg. 5. The resulting ¢, would no longer
form a path through the process model.

In the following, we illustrate the problem by an example
and discuss a simple change to Alg. 1 that ensures a unique
labeling over all reachability graphs (global and projected). For
such reachability graphs, Alg. 5 always returns an alignment,
which we prove formally. Fig. 16 shows an example with trace
(A, B,D) and a process model, where the parallel tasks B and C
can be skipped. The process model is decomposed into two S-
Component nets, one for each of the two parallel activities. When
the trace is projected onto the S-Component with activity C, the
obtained alignment matches both trace activities and skips activ-
ity C with the t transition. The sub-trace (A, B, D) can be fully
matched on the other S-Component. The recomposed alignment
is (m(A), m(B), m(D)). However, A, B, D is not a path through the
reachability graph of this process model.

Note that reducing the reachability graph of the model in
Fig. 16 by Alg. 1 leads to two D-labeled arcs: ([p1], D, [end]) (by
the skipping t-transition) and ([p3, p5], D, [end]) (by the joining
t-transition). The alignment for the first S-component uses the
former whereas the alignment for the second S-component uses
the latter, leading to the conflict described above.

Fig. 17 illustrates how to relabel arcs in the reachability graph
to avoid “hidden” label duplication. First, add to each t-transition
a unique index at the start of Alg. 1 so that all t-transitions
are uniquely labeled. Second, we alter Alg. 1 to maintain the
identity of the removed Tt transitions in the next visible transition.

In particular, when replacing an arc (nj, €,n2) for an arc with
label t;, we create an extended label (7;, 2) for the replacement
arc. Let Alg. 1* be this modification of Alg. 1 and let Alg. 5*
which invokes Alg. 1* instead of Alg. 1. Alg. 1* and the extended
labels are not used for the PSP construction Algs. 2 and 4. We
omit the technical details. The changes in Fig. 17 lead to the
following differences: The transition t; can now be distinguished
from transition t3. During the recomposition, there will be a label
conflict between the extended labels (t;,D) and (173, D). Since
the recomposition can no longer find a viable path through the
process model for these conflicting cases, these traces need to
be aligned on the reachability graph of the input process model
with Alg. 4 in Section 4. This ensures that alignments of traces
with conflicts found during the recomposition also form a path
through the process model according to Lemma 4.2. While the
quality of the results is maintained for these conflicting cases, this
implies that calculation speed is lost since the sub-alignments are
calculated for each S-Component and these results are invalid.
Thus, this divide-and-conquer technique is specially faster when
the number of conflicting cases during the recomposition is low.
Please note, however, that only cases with conflicts need to go
though this procedure. Recomposed alignments without conflict
do not need to be re-computed with Alg. 4.

Next, we will investigate whether recomposed alignments
without conflicts are proper, i.e. all trace labels are contained
and forms a path through the reachability graph of the input
process model. The following lemma states that the recomposed
alignment is a proper alignment.

Lemma 5.1. Let L be an event log and SN = (WN, mo, m;) be
a system net, where WN is a uniquely labeled, sound, free-choice
workflow net. Let PSP’ = Alg5*(L, DAFSA, SN). For every trace c € L,
Ec = €(PSP’, c) is a proper alignment. Specifically, the following two
properties hold:

1. The sequence of synchronizations with lhide or match opera-
tions reflects the trace Cc, 1.e. (Ec parsa) = C.

2. The arcs of the reachability graph in the sequence of syn-
chronizations with rhide or match operations forms a path in
the reachability graph from the initial to the final marking,
Le. let n = |E€c[pg|, then src(€cfrgl1]) = Mo A tgt(eclrg(n)) =
mp A Vi, di+1 € Elpg | 1 <1 <n: tgt(a;) = src(aj+1).

The formal proof by induction on the length of c is given in Ap-
pendix C. The core argument is to show that the markings and
the transition firings of SN can be reconstructed from the vector
m of markings of each S-component nets. Further, the arcs in the
reachability graphs of the S-components nets are isomorphic to
the transitions. As a result, the transition effect of the original
transition in SN can be recomposed from the effects in the S-
component nets. The latter argument requires the uniqueness of
arcs in the reachability graphs provided by Alg. 1*.
D. Reifsner, A. Armas-Cervantes, R. Conforti et al. / Information Systems 94 (2020) 101561 19

   

Trace: { A, B,D)

Trace 1: ( A, D )——> Alignment 1: ( m(A), m(D) )

“—~»_Recomposed Alignment:
{m(A),m(B),m(D))
Cost : 0

But(!)

|

Alignment does not form
a path on the process
model, i.e. Activity B can
only be executed if also
activity C is executed.

Fig. 16. Recomposed alignment that cannot be replayed on the process model.

Trace 1: {( A, D ) ——> Alignment 1: { m(A),m(t;, D) )

   

Trace: { A, B,D)

 

 

 

 

c A B dD

e | m(A) m(t1, D)
ez | m(A) | m(t2,B) m(r3,D)
Ec m(A) m(B) Conflict

 

Fig. 17. Detecting the invisible label conflict.

6. Evaluation

We implemented our techniques in a standalone open-source
tool* as part of the Apromore software environment. Given an
event log in XES format and a process model in BPMN or PNML
(the latter is the serialization format of Petri nets), the tool
returns several conformance statistics such as fitness and raw fit-
ness cost. Optionally, the tool can also return a list of one-optimal
alignments for each unique trace as well as their individual align-
ment statistics. The tool implements both the Automata-based
technique described in Section 4 as well as the extended tech-
nique with the S-Components improvement described in Sec-
tion 5.

Using this tool, we conducted a series of experiments to mea-
sure the time performance and the quality of the results obtained
by both our techniques against two exact techniques for comput-
ing alignments, which are state-of-the-art, and one approximate
technique: (1) the newest version of the one-optimal alignment
with the ILP marking equation, first presented in [35] and imple-
mented in ProM in the PNetReplayer package (ILP Alignments);
(2) the one-optimal alignment technique using the extended
marking equation presented in [4] and implemented in ProM in
the Alignment package (MEQ Alignments); and (3) the approx-
imate alignment technique for large instances (ALI) [16] using
local search.? ALI is implemented in Python and we used it
in conjunction with the commercial LP solver Gurobi to con-
duct the experiments. We implemented multi-threading for each

4 Tool available at https://apromore.org/platform/tools. Source code available
at https://github.com/apromore/DAFSABasedConformance.

2 Tool available at https://www.cs.upc.edu/~taymouri/tool.html.

unique trace, and in the S-Components variant, also for each
S-Component.

The two baseline implementations for optimal alignments
computation use optimized data structures and efficient hash-
codes [36]. Accordingly, we optimized our software implemen-
tation using similar techniques, so as to achieve results that are
as comparable as possible. Specifically, we optimized the queue-
ing mechanism by improving the selection of suitable solutions,
merging overlapping solutions and prioritizing longer solutions
with the same cost to find an optimal solution more efficiently.
While the approximate technique ALI is only implemented as a
Python prototype, the authors previously compared it with the
two baselines for optimal alignments computation, and showed
to outperform these on a synthetic dataset [16].

6.1. Setup

Using our tool and the reference tools for the three baselines,
we conducted a series of experiments to measure the execution
time of all five techniques, in milliseconds. Each experiment,
i.e. applying a technique to one model-log pair, was run five
times and we report the average results of runs #2 to #4 to
avoid influence of the Java class loader and reduce variance.
Given that the complexity of the alignment problem is worst-time
exponential, we decided to apply a reasonable time bound of ten
minutes to each experiment. We note that previous experiments
reported that in certain cases the computation of an alignment
may take over a dozen hours [10].

Measuring time performance was the primary focus of our
experiments. Besides time performance, we measured the quality
of alignment. We did so in terms of alignment cost (Definition 4.7)
per trace. In particular, we aggregate the alignment cost per
20 D. Reifsner, A. Armas-Cervantes, R. Conforti et al. / Information Systems 94 (2020) 101561

unique cost to their weighted average taking into account their
trace counts to stay consistent with the results of baseline tech-
niques. The alignment cost is a secondary factor of comparison
to measure the degree of optimality of the results. We chose
to report the alignment cost over other conformance measures
such as fitness as it allows one to more precisely pinpoint the
over-approximation of the results, if any. The experiments were
run multi-threaded with a fixed amount of 16 threads for each
technique to achieve a comparable computation setup. The exper-
iments were conducted on a 22-core Intel Xeon CPU E5-2699 v4
with 2.30 GHz, with 128 GB of RAM running JVM 8. This machine
can execute up to 44 threads per socket.

Given that a different number of threads can lead to differ-
ent time performance, we repeated our tests in a single-thread
setting. The results of this latter experiment are reported in
Appendix B and are consistent with those obtained in the multi-
thread setting reported in this section.

6.2. Datasets

We used two datasets of log-model pairs from a recent bench-
mark on automated process discovery [37] The first dataset con-
sists of twelve public event logs. These logs in turn originate from
the 4TU Centre for Research Data.° They include the logs of the
Business Process Intelligence Challenge (BPIC) series, BPIC12 [38],
BPIC13.p [39], BPIC13ine [40], BPIC14 [41], BPIC15 [42], BPIC17
[43], the Road Traffic Fines Management process log (RTFMP) [44]
and the SEPSIS Cases log (SEPSIS) [45]. These logs record process
executions from different domains such as finance, healthcare,
government and IT service management. The BPIC logs from years
2011 and 2016 (BPIC11 and BPIC16) were excluded since they do
not represent real business processes. The second dataset is com-
posed of eight proprietary logs sourced from several organiza-
tions around the world, including healthcare, banking, insurance
and software vendors. In the benchmark, some of the public logs
(marked with “s”) were filtered in order to remove infrequent
behavior, using the technique in [46]. The reason for this filtering
was that the majority of automated discovery techniques used in
the benchmark could not discover a model from the unfiltered log
with the allotted memory (i.e. they ran into a state-space explo-
sion). In order to guarantee compatibility with the benchmark,
we decided to keep these logs as is, i.e. we did not remove the
filter.

Each of the two datasets (public and private) comes with four
process models per log, that have been discovered using four
state-of-the-art automated discovery methods in the benchmark
in [37], namely: Inductive Miner [47], Split Miner [48], Structured
Heuristics Miner [49] and Fodina [50]. We discarded the process
models discovered by the latter two methods for our experiments
since they may lead to process models with transitions with du-
plicate labels (and in some cases also to unsound models), which
our S-Components extension does not handle. This resulted in a
total of 40 log-model pairs for our evaluation. Table 1 reports
the log characteristics. There are logs of different sizes in terms
of total traces (681-787,667) or total number of events (6660-
1,808,706). The difficulty of the conformance checking problem,
however, is more related to the percentage of distinct traces
(0.01%-97.5%), the number of distinct events (7-82) and the trace
length (avg. 1-32). These logs thus feature a wide range of charac-
teristics, and include both simple and complex logs. For reference,
we made the public logs and the corresponding models, together
with all the results of our experiments, available online [51].

Table 2 reports the statistics of the process models obtained
with Inductive (IM) and Split Miner (SM), for each log in our

6 https://data.4tu.nl/repository/collection:event_logs_real.

Table 1
Descriptive statistics of the event logs in the public and private datasets.

Log Total Distinct Total Distinct Trace length
name traces traces (%) events events

min avg max
BPIC12 13,087 33.4 262,200 36 3 20 175
BPIC13,p 1487 12.3 6660 7 1 4 35
BPIC13ine 47554 20.0 65,533 13 1 9 123
BPIC14; 41,353 36.1 369,485 9 3 9 167
BPIC151¢ 902 32.7 21,656 70 5 24 50
BPIC152¢ 681 61.7 24,678 82 4 36—s«63
BPIC153¢ 1369 60.3 43,786 62 4 32 54
BPIC154, 860 52.4 29,403 65 5 34 54
BPIC15s¢ 975 45.7 30,030 74 4 31 61
BPIC17; 21,861 40.1 714,198 41 11 33 113
RTFMP 150,370 0.2 561,470 11 2 4 20
SEPSIS 1050 80.6 15,214 16 3 14 185
PRT1 12,720 8.1 75,353 9 2 5 64
PRT2 1182 97.5 46,282 9 12 39 = =276
PRT3 1600 19.9 13,720 15 6 8 9
PRT4 20,000 29.7 166,282 11 6 8 36
PRT6 744 22.4 6011 9 7 8 21
PRT7 2000 6.4 16,353 13 8 8 11
PRTO 787,657 0.01 1,808,706 8 1 2 58
PRT10 43,514 0.01 78,864 19 1 1 15

evaluation. Specifically, this table reports size (number of places,
transitions and arcs), number of transitions, number gateways
(XOR-splits, AND-splits) and size of the resulting reachability
graph from the Petri net (in case of a BPMN model, it is the
Petri net obtained from this model). In addition, if a Petri net
has at least one AND-split, we also report on the number of
S-Components and for each of them the following statistics:
their average Petri net size, average number of transitions, av-
erage number of XOR-splits and average size of the resulting
reachability graph.

Inductive Miner is designed to discover highly-fitting models.
As a result, the models often exhibit a large reachability graph
as the models need to cater for a large variety of executions
present in the logs. Split Miner provides a trade-off between
fitness and precision by filtering the directly-follows graph of the
log before discovering the model. That leads to process models
with a smaller state space, but with a possibly higher number of
fitness mismatches. Altogether, these models present two differ-
ent scenarios for conformance checking: the models discovered
by Inductive Miner require a large state space to be traversed
with a low to medium number of mismatches per trace, while the
models of Split Miner have a smaller state space with a medium
to high number of mismatches per trace.

The S-Component decomposition can drastically reduce the
size of the state space of the model. This becomes apparent
when comparing the size of the reachability graph with that of
the S-Component reachability graphs, e.g. BPIC12 (IM) reduces
from 1997 nodes and arcs to a total of 583 nodes and arcs and
BPIC14; from 4383 to a total of 261 nodes and arcs. This reduction
depends on the internal structure of the model, i.e. the number
of S-components and the nesting of XOR-splits and AND-splits.
Sometimes, this reduction will not lead to a smaller state space,
e.g. for BPIC1535 (IM) the size reduces from 875 to 191.5 per S-
Component, which leads to a total state space of 1532 nodes and
arcs for all S-Components, which is larger than the size of the
original model.

6.3. Results

Table 3 reports the running times in milliseconds for each
technique against each of the 40 log-model pairs, using a fixed
D. Reifsner, A. Armas-Cervantes, R. Conforti et al. / Information Systems 94 (2020) 101561 21

Table 2
Descriptive statistics of the process models obtained by IM and SM from the datasets in Table 1.

Miner Domain Dataset Size Trns XOR AND

BPIC12 177 45 16 2

BPIC13¢p 31 8 2 0

BPIC13 inc 56 13 3 1

BPIC14, 124 29 8 2

BPIC15 45 449 127 48 0

. BPIC15>¢ 537 150 55 1

Public BPIC153, 464 128 47 3

BPIC15 a5 469 131 51 1

BPIC155¢ 381 111 31 0

IM BPIC17; 121 33 8 0

RTFMP 111 26 9 2

SEPSIS 145 37 13 3

PRT1 70 16 4 1

PRT2 175 43 16 1

PRT3 111 27 8 2

Private PRT4 91 21 5 2

PRT6 86 20 4 2

PRT7 99 23 5 2

PRT 96 21 7 2

PRT10 124 35 8 1

BPIC12 315 85 29 1

BPIC13¢p 49 13 4 0

BPIC13 inc 56 15 5 0

BPIC14, 88 24 9 0

BPIC15 45 368 98 25 0

. BPIC15>¢ 444 117 25 0

Public BPIC153, 296 78 17 0

BPIC15 a5 323 85 18 0

BPIC155¢ 359 94 18 0

SM BPIC17; 149 40 12 0

RTFMP 102 28 11 0

SEPSIS 162 44 15 0

PRT1 104 28 9 0

PRT2 166 45 15 0

PRT3 96 25 8 1

Private PRT4 126 33 10 1

PRT6 46 11 2 1

PRT7 86 19 3 5

PRT 107 29 10 0

PRT10 327 90 34 0

number of 16 threads per technique. The best execution time for
each experiment is highlighted in bold.

Analyzing the overall performance. Our S-Components tech-
nique outperforms the other techniques in eight out of 40 log-
model pairs; our Automata-based technique performs best in 28
out of 40 cases, and the extended MEQ Alignments technique
outperforms in three out of 40 cases. The total time spent for
all 40 datasets, excluding any timeouts, is comparable between
the Automata-based technique and the S-Component technique
(circa 230 s with the S-Components technique gaining 17 s). Both
our techniques improve on ILP Alignments by 500 s (68% of its
computation time) and on the extended MEQ Alignments and ALI
by over 1000 s (85% of their computation time).

Investigating timeout cases. In total, the S-Components tech-
nique times out (‘‘t/out” in the table) in two cases, the Automata-
based technique in three, ILP Alignments in one case and the
extended MEQ alignments technique times out in six cases. ALI
is the only technique that never times out in the datasets used
in our experiments, though, as discussed later in the section, this
technique always over-approximates. While all other techniques
timed out on PRT2 (IM), which has a huge state space of 5,515,357
nodes and arcs in the reachability graph, ALI managed to com-
pute approximate alignments for this dataset. The S-Components
technique actually manages to compute alignments quickly for
this log-model pair since the S-Component reachability graphs
are very small, but times out when some traces conflict with
each other in the recomposition algorithm and need to be aligned

RG size #SComp @ size @ Trns @ XOR @ RG size
1997 10 130.9 36.3 12.3 58.3
9 1 - - - -
121 3 28 7 1 14
4383 10 53.9 13.9 2.7 26.1
719 1 - - - -
1019 2 530 149 55 232
875 8 438.5 123.5 45.5 191.5
1019 2 462 130 51 202
429 1 - - - -
59 1 - - - -
2394 6 52.7 13.8 3.7 25
2274 8 99 27.5 9 44
195 4 39.3 10 1.8 19.3
5,515,357 7 49 13 4 23
167 8 71 19 4 33
154 8 54 14 2 26
65 6 59 15 2 29
158 8 62 16 2 30
9121 7 27.9 7 1.1 13.9
184 2 115.5 33.5 7.5 48.5
95 2 308 84 29 140
13 1 - - - -
17 1 - - - -
24 1 - - - -
156 1 - - - -
186 1 - - - -
136 1 - - - -
141 1 - - - -
159 1 - - - -
54 1 - - - -
37 1 - - - -
41 1 - - - -
28 1 - - - -
37 1 - - - -
34 2 89 24 8 41
34 2 119 32 10 55
20 2 39 10 2 19
39 6 57 14.7 2.7 27.7
32 1 - - - -
92 1 - - - -

on the original reachability graph, which is much larger. The S-
Components technique manages to compute alignments for the
BPIC14- (IM), which was not possible for the Automata-based
technique within the 10-minute bound of the timeout.

Improvements of our techniques. The Automata-based tech-
nique performs better than both state-of-the-art techniques ILP
and MEQ Alignments by one-two orders of magnitude. For ex-
ample, for the BPIC17; (IM) it takes 680 ms against 20.7 s of ILP
Alignments or for BPIC12 (SM) it takes 4578 ms vs. 188,489 ms
of ILP Alignments. When the state space reduction of the S-
Components is effective, it shows the potential to improve over
other techniques by at least one order of magnitude, e.g. for
BPIC12 (IM) it improves from 121,845 ms (Automata-based) to
44,301 ms and for BPIC14; (IM) from 84,102 ms (ILP) to 7789 ms.
In total the Automata-based technique improves over all base-
line techniques by one order of magnitude in ten datasets and
the S-Component technique in three datasets. The S-Component
extension improves over the automata-based technique by one
order of magnitude in five cases.

Problematic cases of the S-Component technique. The pro-
cess models discovered by Split Miner do not feature parallel
constructs except the model discovered from the BPIC12 log.
Thus, in these logs, the performance of the S-Component exten-
sion is the same as that of the automata-based technique. In
the BPIC12 (SM) case, the Automata-based technique outperforms
the S-Component technique because it exploits the parallel con-
structs in the model. This is due to the combined state-space
22
Table 3
Time performance in milliseconds.
Miner Domain Dataset Baselines
ILP Extended MEQ.
alignments alignments
BPIC12 129,268 464,849
BPIC13¢p 97 1,362
BPIC1 3 inc 1,514 17,857
BPIC14¢ 84,102 143,006
BPIC15 45 3,323 1,312
Public BPIC15>¢ 19,663 4,300
BPIC153¢ 30,690 15,644
BPIC15 5 11,696 6,574
BPIC155¢ 6,830 2,859
IM BPIC17¢ 20,745 63,335
RTFMP 1,846 108,818
SEPSIS 6,592 4,347
PRT1 868 8,860
PRT2 t/out t/out
PRT3 203 1,176
Private PRT4 4,041 14,396
PRT6 131 582
PRT7 106 1,456
PRT 30,772 t/out
PRT10 562 33,813
BPIC12 188,489 487,878
BPIC13¢p 128 1,934
BPIC1 3 inc 1,120 23,497
BPIC14¢ 37,987 t/out
BPIC15 45 2,972 847
. BPIC15>¢ 9,128 1,352
Public BPIC153¢ 7,282 2,911
BPIC15 45 7,258 1,804
BPIC155¢ 8,805 1,423
SM BPIC17¢ 27,011 22,572
RTFMP 1,836 112,328
SEPSIS 4,912 t/out
PRT1 1,954 21,642
PRT2 37,556 t/out
PRT3 181 1,524
Private PRT4 7,433 49,980
PRT6 75 603
PRT7 96 1,439
PRT 30,835 t/out
PRT10 828 36,458
Total time spent (ms): 728,934 1,662,737
# Best cases: 0 3
# Second best cases: 5 3
# Timeouts: 1 6

D. Reifsner, A. Armas-Cervantes, R. Conforti et al. / Information Systems 94 (2020) 101561

Our approaches

ALI Automata-based S-Component Hybrid
approach approach approach
49,018 121,845 44,301 44,301
3,836 45 52 45
27,850 4,733 155 155
100,351 t/out 7,789 7,789
19,651 t/out t/out t/out
43,863 2,423 9,541 9,541
47,525 2,042 22,191 2,228
33,958 1,023 4,915 4,915
23,239 30,648 17,577 30,648
60,621 680 3,530 680
5,884 334 507 507
23,842 31,113 1,575 1,575
10,812 774 170 170
17,296 t/out t/out t/out
6,500 60 106 92
32,811 1,021 1,329 1,053
6,223 32 72 50
5,898 34 70 59
10,738 12,686 4,505 4,505
8,677 63 166 166
118,053 4,578 68,246 4,641
4,351 28 42 28
18,906 140 290 140
157,733 3,185 7,792 3,185
12,986 1,528 1,397 1,528
26,114 1,036 1,026 1,036
25,067 609 934 609
19,893 585 655 585
24,608 765 660 765
265,169 727 3,669 727
7,020 110 345 110
18,821 276 343 276
10,788 135 379 135
91,186 3,830 3,836 3,830
6,439 55 89 65
47,776 475 1,794 489
5,997 33 52 41
5,887 26 103 45
18,165 1,336 1,776 1,336
9,374 78 92 78
1,432,927 229,090 212,069 128,128
1 28 8 20
2 3 26 15
0 3 2 2

of the S-Component reachability graphs being larger than the
original size of the reachability graph of the process model. This
can already happen for process models with a small amount of
parallel behavior in comparison to models with a large amount
of other behavior, i.e. the model from the BPIC12 log has one
parallel block with two parallel transitions against a total of 85
transitions. The log-model pair BPIC153- of IM exhibits similar
problems.

Hybrid approach: definition and performance. Since the
advantages of the S-Components decomposition are limited to a
specific type of process models (those with large state spaces due
to a high degree of parallelism), we derived an empirical decision
rule to derive when to use the S-Components improvement on
top of our Automata-based technique. In particular, we apply
this improvement if the sum of the reachability graph sizes of
all S-Components is smaller than that of the original reachability
graph of the process model. This decision rule selects the fastest
technique in 32 out of 40 cases in our evaluation. In detail, it
selects the Automata-based technique correctly in 25 cases and
the S-Components technique in 7 cases. The remaining 8 cases
where the Hybrid approach chooses the slowest technique split
equally to 4 cases each for the Automata and S-Components

techniques (F-Score of 88.9%). The problematic cases where the
rule selects the S-Components technique wrongly, revolve around
process models with small state spaces where the computation
of S-Components is still an overhead over the Automata-based
technique (so this is more of a limitation of our S-Components
technique). In the remaining 4 cases where we mistakenly select
the Automata-based technique, the S-Components technique falls
back to the Automata-based one and outperforms it due to vari-
ance in computation times. We added the execution times for this
hybrid technique to Table 3.

In total, the hybrid technique gains 100 s over the Automata-
based (44%) and the S-Components technique (39%) and improves
the results by ALI and the extended MEQ Alignments by one
order of magnitude. In detail, the Hybrid approach manages to
outperform all other techniques in 20 out of 40 cases and per-
forms second-best in 15 more cases. The reported execution
time of the includes the time required to decide if to apply the
S-Components improvement. In 30 out of 40 experiments, the
decision rule does not impact the execution time noticeably (<
1 ms). First, if we end up selecting the S-Components, we do
not actually need additional time, since the reachability graphs
for the S-Component nets are computed anyways as part of the
D. Reifsner, A. Armas-Cervantes, R. Conforti et al. / Information Systems 94 (2020) 101561 23
Table 4
Cost comparison and order of approximation for those log-model pairs where S-Components over-approximate.
Miner Domain Dataset Cost Over-Apprx. *Apprx traces Avg over Apprx.
ILP eMEQ ALI Aut. S-Comp ALI S-Comp ALI S-Comp ALI S-Comp
Align. Align. Appr. Appr. Appr. Appr. Appr.
Public BPIC152¢ 2.02 2.02 26.73 2.02 2.07 24.71 0.05 100.0% 5.2% 24.71 1
IM SEPSIS 0.12 0.12 12.83 0.12 0.12 12.69 0.00 100.0% 0.2% 12.69 1
Private PRT6 0.09 0.09 2.31 0.09 0.12 2.22 0.03 69.9% 2.7% 3.17 1.05
PRTO 0.38 t/out 2.14 0.38 0.39 1.79 0.01 98.9% 0.9% 1.80 1.50
SM Public BPIC12 1.29 1.29 17.87 1.29 1.30 16.58 0.02 73.6% 0.8% 22.55 2
Private PRT7 1.40 1.40 2.22 1.40 1.41 0.83 0.01 37.0% 1.2% 2.23 1

decomposition technique. Second, if we select the base technique
for a process model without parallelism, we can detect this case
by checking all transitions of the Petri net, which is a linear
operation, so the time is again negligible. In the remaining 10
out of 40 experiments the decision rule takes on average 40 ms
for process models with concurrency. For these experiments, we
need to calculate the reachability graphs for every S-Component
net to decide the rule. In practice, this time was always negligible
in our experiments, but there can be very large process models
for which this operation may be expensive. However, in these
cases, it is likely that we would select the S-Component technique
anyway. This shows that the Hybrid approach strikes a trade-off
between computing additional information to choose the fastest
approach and reducing the overall computation time by choosing
the best-suited approach.

Analyzing cost over-approximations. Table 4 shows the op-
timal costs for a subset of datasets. In these log-model pairs, the
S-Components technique over-approximates the optimal cost of
the alignments, i.e. in 6 out of 40 cases. For completeness the
full table with optimal costs for all datasets can be found in
Appendix A. The difference between the S-Component technique
and all other techniques with optimal costs ranges from 0.002 to
0.052 per trace. We further broke down the over-approximation
into two columns: the fraction of traces in the log that were
affected by an over-approximation, which ranges from 0.2 to
5.2%, and the average fitness-cost that was over-approximated
in the affected traces, which ranges from 1 to 2 mismatches
more than the optimal number. We observe that the technique
never under-approximates and always returns proper alignments.
In comparison, ALI over-approximates in all datasets and the
degree of over-approximation is much larger. It ranges from 0.83
up to 26.22. The fraction of approximated traces is also much
larger, ranging from 9.3 to 100% of aligned traces. By design, the
Automata-based technique always has the same cost as the ILP or
the MEQ Alignments and thus is always optimal.

Investigating causes of over-approximations. One example
of over-approximation can be observed in the SEPSIS dataset
(IM) for the trace (CRP, Leucocytes, LacticAcid, ER Registration,
ER Triage, ER Sepsis Triage, IV Antibiotics, IV Liquid). The opti-
mal alignment for this trace, retrieved with ILP-Alignments, is
((rhide,ER Registration), (match,CRP), (match,Leucocytes), (match,
Lactic-Acid), (Ihide,ER Registration), (match,ER Triage), (match,ER
Sepsis Triage), (match,IV Antibiotics), (match,IV Liquid)) with a
cost of 2, because task ER Registration is misplaced after the par-
allel block. The S-Components technique finds instead the follow-
ing alignment: ((lhide,CRP), (Ihide,Leucocytes), (Ihide,LacticAcid),
(match,ER Registration), (match,ER Triage), (match,ER Sepsis
Triage), (match,IV Antibiotics), (match,IV Liquid)) with a cost of
3. As shown in Fig. 18, in the process model, task ER Registration
appears before the parallel block, while in the trace this occurs af-
ter the activities in a parallel block. As a result, the S-Component
technique will hide all the activities in the parallel block, Le.
CRP, Leucocytes and LacticAcid, and then match the activity

ER Registration. When recomposing the projected alignments,
however, the added alignment cost will be 3 instead of 2. Note
that the alignment of the S-Components technique is still a proper
alignment, i.e. it represents the trace and forms a path through
the process model.

6.4. Threats to validity

A potential threat to validity is the selection of datasets. We
decided to use two datasets of real-life log-model pairs from a
recent discovery benchmark [37]. These datasets exhibit a wide
range of structural characteristics and originate from different
industry domains, so they provide a good representation of re-
ality. However, the models discovered by Split Miner did not
contain a lot of parallel structures and were thus not highlight-
ing the strengths of the S-Components decomposition. This calls
for further experiments with models with a higher degree of
parallelism, and more in general, with very large real-life log-
model pairs. Such datasets are not publicly available at the time
of writing. An alternative, is to use artificial datasets as in [52].

The selection of benchmark techniques is another threat to va-
lidity. The techniques presented in this article are only applicable
to a subclass of Petri nets, namely 1-safe sound workflow nets,
while the two exact techniques are applicable to a wider class
of Petri nets, namely easy sound Petri nets, and the approximate
technique is applicable to sound Petri nets. To the best of our
knowledge, however, there are no conformance checking tech-
niques available that target this specific subclass of Petri nets for
a better comparison. In addition, this specific class of Petri nets
has relevance to the field of Process Mining since BPMN models
can be translated to this class and several mining algorithms such
as Split Miner [48], Inductive Miner [47] or Fodina [50] produce
Petri nets of this class.

A final threat to validity is posed by the number of methods
used for automated process discovery (two). Potentially we could
have chosen a larger number of methods. The choice of Split
Miner and Inductive Miner was determined by both pragmatic
reasons (other methods such as Structured Heuristics Miner re-
turn models with duplicate labels which we cannot handle, or
led to models for which fitness could not be computed) as well
as by the need to test two extreme cases: models with large state
Spaces versus models with large degrees of parallelism. More-
over, they are the best performing automated discovery methods
according to the benchmark in [37]. So, all considered, they
constitute a sufficiently representative set of discovery methods.

7. Conclusion

This article presented two contributions to the field of confor-
mance checking of event logs against process models. First, the
article showed that the problem of conformance checking can
be mapped to that of computing a minimal partially synchro-
nized product between an automaton representing the event log
(its minimal DAFSA) and an automaton representing the process
24

D. Reifsner, A. Armas-Cervantes, R. Conforti et al. / Information Systems 94 (2020) 101561

 

 

 

 

  
 

IV
Antibiotics

 

 

 

 

 

ic PS

 

 

  

tT

   

start

 

ER
Registration

 

 

 

 

 

 

 

 

 

 

 

 

Sop

 

P29 LacticAcid P10

 

 

 

 

 

p21)—>»

 

 

ay

 

 

 

 

 

 

 

 

 

 

 

P3  ERSepsis 4 r - - t
Triage

   
 

Triage

 

P11\ Leucocytes /P22

 

 

 

 

 

 

 

 

 

 

    

 

p19

end
Release A Release C Return ER

 

 

 

Admission °18 Release D

NC

 

 

 

Release E

Fig. 18. Sepsis Inductive Miner process model.

model (its reachability graph). The resulting product automaton
can be used to extract optimal alignments between each trace in
the log and the closest corresponding trace of the model.

The use of a DAFSA to represent the event log allows us to
reuse the optimal alignment computations for prefixes or suffixes
that are shared by multiple traces. This is a distinctive feature of
the proposal with respect to existing trace alignment techniques,
which compute an optimal alignment for each trace in the log
separately, without any reuse across traces. The empirical evalua-
tion shows that this technique outperforms state-of-the-art trace
alignment techniques in a clear majority of cases.

However, like other techniques for computing optimal trace
alignments, the proposed automata-based technique suffers from
degraded performance when the process model has a high degree
of concurrency. This issue stems from the combinatorial state
explosion inherent to such process models. This state explosion,
in turn, leads to larger search spaces of possible alignments.
To address this shortcoming, the article presented a divide-and-
conquer technique, wherein the process model is decomposed
into a collection of concurrency-free components, namely S-
components. Each of these S-components (which corresponds
to an automaton) is then aligned separately against a projected
version of the log, leading to one product automaton per S-
component. The article spells out criteria under which the result-
ing product automata can be recomposed into a correct (although
not necessarily optimal) product automata of the original event
log and process model. When two or more S-components can-
not be re-composed due to a conflict, these S-components are
merged and a product automaton is computed for the merged
S-component. The evaluation showed that this decomposition-
based technique achieves lower execution times than the mono-
lithic automata-based technique when the number of
S-components is high, in part thanks to the fact that the
decomposition-based technique lends itself to parallel computa-
tion. The evaluation also showed that the decomposition-based
technique computes optimal alignments in the majority of cases.
In those model-log pairs where it does not find the optimal
(minimal) alignments, the over-approximation is small (one or
a handful of moves) and it only occurs for a small percentage of
traces (5% or less).

To benefit from the advantages of both techniques (basic
automata-based and decomposition-based technique), the article
also presented a hybrid technique where either the automata-
based technique (without decomposition) or the S-components-
decomposition technique is used depending on the size of the
reachability graph versus the total size of the S-components. The
empirical evaluation showed that this hybrid technique outper-
forms all other techniques in a clear majority of cases (first in 30
out of 40 logs and second in 5 of the remaining 10 cases).

The proposed technique still fails to perform satisfactorily
on a handful of the event logs used in the evaluation. Further

improvements may be achieved by designing tighter heuristic
functions to guide the A* algorithm, particularly to handle process
models with nested loops.

In this article, we combined the S-components decomposition
with an automata-based conformance checking technique. This
combination is natural since each S-component corresponds to a
concurrency-free slice of the process model, which can be seen
as an automaton. However, the idea of using an S-component
decomposition for conformance checking has broader applicabil-
ity. We foresee that the S-components decomposition technique
could also be used in conjunction with other trace alignment
techniques. In particular, adapting the S-components technique
to work with techniques that align one trace at a time, such as
those of Adriansyah et al. [3] or Van Dongen [4], is a possible
avenue for future work.

This article addressed the problem of identifying unfitting log
behavior. However, the ideas investigated in this paper could also
be applied to the related problem of identifying additional model
behavior, that is, behavior captured in the process model but not
observed in the event log [13]. This latter problem is related to
that of measuring the precision of a process model relative to
an event log, which is an open problem in the field of process
mining [53]. Another direction for future work is to investigate
the application of the S-components decomposition technique
to the problem of identifying and measuring additional model
behavior.

Declaration of competing interest

The authors declare that they have no known competing finan-
cial interests or personal relationships that could have appeared
to influence the work reported in this paper.

Acknowledgments

This research was funded by the Australian Research Coun-
cil (grant DP180102839), the Estonian Research Council (grant
IUT20-55), and the European Research Council (PIX project).

Appendix A. Complete cost comparison

See Table A.5.

Appendix B. Time performance — single threaded

See Table B.6.
D. Reifsner, A. Armas-Cervantes, R. Conforti et al. / Information Systems 94 (2020) 101561 25
Table A.5
Cost comparison and order of approximation for those log-model pairs where S-Components over-approximate.
Miner Domain Dataset Cost Over-Apprx. *Apprx traces Avg over Apprx.
ILP eMEQ ALI Aut. S-Comp ALI S-Comp ALI S-Comp ALI S-Comp
Align. Align. Appr. Appr. Appr. Appr. Appr.
BPIC12 0.87 0.87 3.38 0.87 0.87 3.05 0.00 100.0% 3.05
BPIC13¢p 1.46 1.46 2.36 1.46 1.46 0.89 0.00 81.0% 1.10
BPIC1 3 inc 0.84 0.84 4.14 0.84 0.84 3.31 0.00 98.6% 3.35
BPIC14; 1.94 1.94 3.58 t/out 1.94 3.24 0.00 100.0% 3.24
BPIC15 4 0.50 0.50 15.01 t/out t/out 14.51 t/out 100.0% 14.51
Public BPIC152¢ 2.02 2.02 26.73 2.02 2.07 24.71 0.05 100.0% 5.2% 24.71 1
BPIC153¢ 1.70 1.70 25.67 1.70 1.70 23.97 0.00 100.0% 23.97
BPIC15 1.14 1.14 22.84 1.14 1.14 21.69 0.00 100.0% 21.69
BPIC155¢ 1.20 1.20 24.90 1.20 1.20 23.70 0.00 100.0% 23.70
IM BPIC17; 0.83 0.83 11.53 0.83 0.83 10.93 0.00 100.0% 10.93
RTFMP 0.06 0.06 1.77 0.06 0.06 1.71 0.00 100.0% 1.71
SEPSIS 0.12 0.12 12.83 0.12 0.12 12.69 0.00 100.0% 0.2% 12.69 1
PRT1 1.43 1.43 4.57 1.43 1.43 3.15 0.00 98.7% 3.19
PRT2 t/out t/out 38.32 t/out t/out 0.00 0.00 0.0% 0.00
PRT3 0.23 0.23 3.84 0.23 0.23 3.61 0.00 100.0% 3.61
Private PRT4 1.22 1.22 4.79 1.22 1.22 3.56 0.00 98.5% 3.61
PRT6 0.09 0.09 2.31 0.09 0.12 2.22 0.03 69.9% 2.7% 3.17 1.05
PRT7 0.00 0.00 2.10 0.00 0.00 2.10 0.00 99.5% 2.11
PRTO 0.38 t/out 2.14 0.38 0.39 1.79 0.01 98.9% 0.9% 1.80 1.50
PRT10 0.06 0.06 2.81 0.06 0.06 2.75 0.00 99.9% 2.76
BPIC12 1.29 1.29 17.87 1.29 1.30 16.58 0.02 73.6% 0.8% 22.55 2
BPIC13¢p 0.09 0.09 2.19 0.09 0.09 2.10 0.00 97.8% 2.15
BPIC1 3 inc 0.24 0.24 3.77 0.24 0.24 3.54 0.00 99.7% 3.55
BPIC14¢ 2.91 t/out 5.83 2.91 2.91 2.92 0.00 67.3% 4.34
BPIC15 4 3.20 3.20 19.38 3.20 3.20 16.18 0.00 93.2% 17.36
Public BPIC152¢ 10.22 10.22 27.44 10.22 10.22 17.21 0.00 80.8% 21.31
BPIC153¢ 9.70 9.70 13.75 9.70 9.70 4.06 0.00 99.3% 4.08
BPIC15 ¢ 10.42 10.42 22.23 10.42 10.42 11.81 0.00 76.9% 15.37
BPIC155¢ 8.10 8.10 17.04 8.10 8.10 8.94 0.00 71.5% 12.51
SM BPIC17¢ 1.47 1.47 18.94 1.47 1.47 17.47 0.00 100.0% 17.47
RTFMP 0.03 0.03 2.36 0.03 0.03 2.32 0.00 86.3% 2.69
SEPSIS 4.72 t/out 12.23 4.72 4.72 7.51 0.00 93.5% 8.03
PRT1 0.29 0.29 3.95 0.29 0.29 3.66 0.00 99.4% 3.68
PRT2 8.32 t/out 34.53 8.32 8.32 26.22 0.00 100.0% 26.22
PRT3 2.54 2.54 6.50 2.54 2.54 3.96 0.00 99.4% 3.98
Private PRT4 1.91 1.91 3.59 1.91 1.91 1.68 0.00 64.3% 2.61
PRT6 1.08 1.08 1.26 1.08 1.08 0.19 0.00 9.3% 2.00
PRT7 1.40 1.40 2.22 1.40 1.41 0.83 0.01 37.0% 1.2% 2.23 1
PRTO 0.35 t/out 1.43 0.35 0.35 1.08 0.00 28.7% 3.77
PRT10 0.10 0.10 2.76 0.10 0.10 2.65 0.00 97.2% 2.73

Appendix C. Recomposing partial alignments is correct

Lemma 5.1 states that the sequence e, returned by Alg. 5* (L,
DAFSA, SN), the modification of Alg. 5 constructing reachability
graphs as described in Section 5.4, is an alignment of DAFSA to
a sound, uniquely-labeled, free-choice workflow net SN. In other
words, the projection ¢, onto the left-hand component is trace
c, and the projection on the right-hand component is a path
through the reachability graph of WN. We prove both properties
individually.

Proof of Lemma 5.1.1. We show A(é¢[parsq,) = C by induction on
the prefixes c’ of c in the for-loop in lines 10-39. For the empty
prefix c’ before the for-loop, ¢- = (). In each iteration of the for-
loop with pos, < |c|, the prefix c’ is extended with € = c(pos,) €
L, and the current prefix of €, is extended with a synchronization
(lhide, (n, €,n’), ) (line 27) or (match, (n, €, n’),(m, 2, m’)) (line
33). Thus, the proposition holds for both prefixes. The only other
extension of the current prefix of €, in Alg. 5 is with synchro-
nizations (lhide, |,(m, 2, m’)) in line 18 which do not occur in

Mc para)

Proving Lemma 5.1.2 requires some further notation, defini-
tions, and observations on Petri nets.

For a WN, let C = {WN,,WN>,...,WN;,} be the set of
S-Components of WN. By the abuse of notation, let C(t) be

 

 

 

 

the set of S-components in which t is contained as WN; =
(Pi, Tj, Fi, Ai), i;,0;) € C(t) iff t e Tj, for each t € Ty; sets
C(p), p € P;, are defined accordingly.

In a sound free-choice net WN, the pre- and post-sets of
a transition t (together) cover the same S-component, which
follows from WN being covered by S-components [54] and the
free-choice structure:

J ety) = e(t) = LJ ev).

peet pcte

(C.1)

In any free-choice net WN with S-components {WN 1,WNo,...,
WN} and reachability graphs RG(WNj;) = (M!, A’, m,M;),j =
1,...,k holds:

each reachable marking m € M! has the formm = [p], p € P; (C2)

eacharc a € A’ has the forma = ([p], A(t), [p']), p. p’ € Pj, t € T;
(C.3)

Without loss of generality, in a sound, free-choice workflow net
WN = (P,T,F,A, mo, mf) holds mo = [po], Po € P, epo = Y and
ms = {[Pr]}, Pp € P, ppe = Y.

Proof of Lemma 5.1.2. We have to show that &€,|p¢ corresponds
to a path through the RG of WN. Let &€clp¢ = (a4, ..., ds).
D. Reifsner, A. Armas-Cervantes, R. Conforti et al. / Information Systems 94 (2020) 101561

Our approaches

ALI Automata-based S-Component Hybrid
approach approach approach
539,214 428,166 160,070 160,070
4469 330 317 330
29,657 24,917 504 504
130,455 t/out 9844 9844
20,203 t/out t/out t/out
44,657 8061 16,418 16,418
49,142 12,218 69,432 12,218
35,125 3837 8064 8064
24,688 32,413 18,582 32,413
283,112 7127 8996 7127
6891 1779 1024 1024
29,281 58,571 2984 2984
10,891 2527 693 693
17,203 t/out t/out t/out
6438 392 404 392
32,359 6069 1954 6069
6125 315 330 315
5844 301 323 301
10,843 68,047 1937 1937
8750 350 724 724
118,053 32,035 111,256 32,035
4351 258 232 258
18,906 766 918 766
157,733 26,605 31,743 26,605
12,986 2266 2048 2266
26,114 3568 3678 3568
25,067 2531 2660 2531
19,893 2345 2388 2345
24,608 2710 2815 2710
265,169 6357 8206 6357
7020 354 593 354
18,821 1179 1219 1179
10,750 664 809 664
95,173 18,218 18,531 18,218
6422 332 437 332
48,438 3151 6831 3151
6015 249 300 249
5906 258 422 258
18,453 1472 2183 1472
9672 328 362 328
2,194,897 761,068 500,228 367,072
1 23 9 26
1 6 23 9
0 3 2 2

of t is marked, et = {p_, | j € e(t)} C mi_y, and t is enabled in

26
Table B.6
Time performance in milliseconds.
Miner Domain Dataset Baselines
ILP Extended MEQ.
alignments alignments
BPIC12 125,948 t/out
BPIC13¢p 295 2137
BPIC13inc 2040 79,597
BPIC14; 98,667 592,238
BPIC15 45 3691 6015
Public BPIC15 5 19,805 25,185
BPIC153¢ 31,075 91,996
BPIC15 a 12,093 38,816
BPIC155¢ 8174 15,553
IM BPIC17; 22,805 257,705
RTFMP 3924 147,135
SEPSIS 6964 17,785
PRT1 1379 12,454
PRT2 t/out t/out
PRT3 425 2175
Private PRT4 3945 22,515
PRT6 335 1168
PRT7 300 2560
PRT 29,538 t/out
PRT10 970 49,160
BPIC12 189,423 t/out
BPIC13¢p 350 3481
BPIC13inc 1764 96,106
BPIC14¢ 40,161 t/out
BPIC15 45 3239 2941
. BPIC15 > 9534 7025
Public BPIC153¢ 7541 12,926
BPIC15 45 7516 8220
BPIC155¢ 9111 6303
SM BPIC17; 28,474 91,585
RTFMP 3477 146,871
SEPSIS 5355 t/out
Private PRT1 2391 66,135
PRT2 36,539 t/out
PRT3 365 2627
PRT4 7319 160,196
PRT6 230 1005
PRT7 256 2256
PRT 27,542 t/out
PRT10 1263 96,503
Total time spent (ms): 754,223 2,068,372
Total outperforming: 7 0
Total second: 7 2
#Timeouts: 1 8
By Eq. (C.2), each mj = ({p}], ..., [p¥) and for the k S-
components of WN. For such a vector m = ([p'],..., [p*]) let,

m = {p',..., p*} be the set of marked places.

We show the proposition by showing that (a) mo = mj", (b)
each mi € Mrqwn),t = 1,...,5’ isa marking of WN, (c) each
(mj, £1, m;) € Arcwn) is a step in WN, and (d) m!, € MPN.

Regarding (a), the initial marking of each S-component j =
1,...,k is m) = [pol as mg’ = [po]. Thus, the proposition holds
by Mo = ([po], ..-. [Po]) in line 9.

We show (b) and (c) by induction on the length i of the pre-
fixes of €,.. For i = 0, (b) holds for mo due to (a), and (c) holds triv-
ially. For i > O, if €¢{p¢{i] = then there is nothing to show. Oth-
erwise, €cfrcli] = (Op, ap, (mMj-1, £1, m;)) and mj_1 € Arcwny by
inductive assumption. We have to show: for ([pj_4], Lees [pi j=
m;—; and ([p/],..., [p¥]) = mi, (Miz, i, Mi) € Arqwn)-.

If 2; # &€ = c(pos,) in line 11, then CG; # Q, and then
(my_1, €;,m;) due to line 18, mj = mj, » (a,..., a,x), and
lab, = sync, = C(t) for some transition t € T,A(t) = 0; = x
(by lines 15,16). If there was no such f¢, then e, is due to line 40
and the proposition holds by Lemma 4.2.

Because WN is uniquely labeled, t is unique. By line 14,
([p\_4]. €:, (pi) € Ape for each j € C(t). Due to (C.1), the preset

mj_1. Firing t yields the successor marking m* = (mj_;\et)Ute =
(mi \ {pi_, | J € C(t)}) U {pj |i € C(t)} by (C.1). By construction
of (a1,...,dx) in line 17 from sync, = C(t), we can rewrite
m* = (m_4 \ {pi_, | a; AL}) U {p} | a AL} as Alg. 1* ensures
transition effects are uniquely identified by their extended labels
(see Section 5.4). By line 18, and the definition of », m* = mj.
Thus, (™mj;_; \ et) Ute = m; and propositions (b) and (c) hold.

If €; = € = c(pos,) then (mj_1, €;, m;) due to line 33 and a sim-
ilar reasoning as above holds as there exists a unique transition
t with A(t) = @; and ([p)_,], 4, pil) € Ape with pi_, € mi for
each j € C(t).

To prove (d), we know m;"Y = {[pr]}, by N having a unique

final place p,. Thus, for m/, = ([p)], ..., [p%]), pt, = pr has to hold
for allj = 1,...,k. Suppose that for the recomposed alignment,
there exists j € {1,...,k} where in m’,, [p,] A [pr]. Each ¢
calculated in line 5 of Alg. 5* is an alignment. Thus, the path

E86 1, = (a\,.--,@,) through RG(WN;) ends in the final place

a = (mi, £,, [pr ]), and thus RG(WN;) has further arcs from [p] to
[p,] that should have been considered by Alg. 5*. Case distinction:

(i) For allj =1,...,k, [p!,] # [pr] with two possible cases:
D. Reifsner, A. Armas-Cervantes, R. Conforti et al. / Information Systems 94 (2020) 101561 27

(i-a) There exists some t € T of WN with m!, > et and
A(t) = x. Then either sync, = lab, in line 16 of Alg. 5*
and a synchronization with arc (m/,, x, m”) would have been
added to ¢, by the arguments for (c) given above. Or x =
€ = C(pos,), pos, < |c| and a corresponding synchronization
would have been added in line 33 of Alg. 5. Both cases
contradict the algorithm. _

(i-b) There exists no t <¢ T with m, > ef. But then m; is a
deadlock contradicting WN being sound.

(ii) There_exist j,r, [py] A [pr] and [p)] = [p,]. By (b) and

(c), m, © {pr, pi} is a reachable marking of WN which
contradicts WN being sound. O

References

[1]
[2]
[3]

[4]

[5]

[6]

[7]

[8]
[9]

[10]
[11]

[12]

[13]

[14]

[15]

[16]

[17]

[18]

[19]

[20]

[21]

[22]

W. van der Aalst, Process Mining - Data Science in Action, Second Edition,
Springer, 2016.

J. Carmona, B. van Dongen, A. Solti, M. Weidlich, Conformance Checking -
Relating Processes and Models, Springer, 2018.

A. Adriansyah, B. van Dongen, W. van der Aalst, Conformance checking
using cost-based fitness analysis, in: Proc. of EDOC, IEEE, 2011, pp. 55-64.
B. van Dongen, Efficiently computing alignments: using the extended
marking equation, in: M. Montali, I. Weber, M. Weske, J. vom Brocke (Eds.),
Business Process Management - 16th International Conference, BPM 2018,
Proceedings, in: Lecture Notes in Computer Science (including subseries
Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),
Springer, Germany, 2018, pp. 197-214.

A. Augusto, R. Conforti, M. Dumas, M. La Rosa, F. Maggi, A. Marrella,
M. Mecella, A. Soo, Automated discovery of process models from event
logs: Review and benchmark, IEEE Trans. Knowl. Data Eng. 31 (4) (2019)
686-705.

D. ReifSner, R. Conforti, M. Dumas, M. La Rosa, A. Armas-Cervantes, Scalable
conformance checking of business processes, in: H. Panetto, C. Debruyne,
W. Gaaloul, M. Papazoglou, A. Paschke, C. Ardagna, R. Meersman (Eds.), On
the Move to Meaningful Internet Systems. OTM 2017 Conferences, Springer
International Publishing, Cham, 2017, pp. 607-627.

A. Rozinat, W. van der Aalst, Conformance checking of processes based on
monitoring real behavior, Inf. Syst. 33 (1) (2008) 64-95.

A. Alves de Medeiros, Genetic Process Mining (Ph.D. thesis), TU/e, 2006.
S. vanden Broucke, J. Mufioz-Gama, J. Carmona, B. Baesens, J. Vanthienen,
Event-based real-time decomposed conformance analysis, in: Proc. of OTM,
Springer, 2014, pp. 345-363.

J. Mufioz-Gama, J. Carmona, W. van der Aalst, Single-entry single-exit
decomposed conformance checking, Inf. Syst. 46 (2014) 102-122.

A. Adriansyah, Aligning Observed and Modeled Behavior (Ph.D. thesis),
TU/e, 2014.

M. de Leoni, A. Marrella, Aligning real process executions and prescriptive
process models through automated planning, Expert Syst. Appl. 82 (2017)
162-183.

L. Garcia-Bafiuelos, N. van Beest, M. Dumas, M. La Rosa, W. Mertens,
Complete and interpretable conformance checking of business processes,
IEEE Trans. Softw. Eng. 44 (3) (2018) 262-290.

M. Nielsen, G. Plotkin, G. Winskel, Petri nets, event structures and domains,
part I, Theoret. Comput. Sci. (ISSN: 0304-3975) 13 (1) (1981).

B. van Dongen, J. Carmona, T. Chatain, F. Taymouri, Aligning modeled and
observed behavior: a compromise between complexity and quality, in:
Proc. of CAiSE, Springer, 2017.

F. Taymouri, Light Methods for Conformance Checking of Business
Processes, Universitat Politécnica de Catalunya, 2018.

F. Taymouri, J. Carmona, An evolutionary technique to approximate multi-
ple optimal alignments, in: M. Weske, M. Montali, I. Weber, J. vom Brocke
(Eds.), Business Process Management, Springer International Publishing,
Cham, 2018, pp. 215-232.

M. Bauer, H. van der Aa, M. Weidlich, Estimating process conformance by
trace sampling and result approximation, in: T. Hildebrandt, B. van Dongen,
M. Roglinger, J. Mendling (Eds.), Business Process Management, Springer
International Publishing, Cham, 2019, pp. 179-197.

A. Burattin, S. van Zelst, A. Armas-Cervantes, B. van Dongen, J. Carmona,
Online conformance checking using behavioural patterns, in: M. Weske,
M. Montali, I. Weber, J. vom Brocke (Eds.), Business Process Management,
Springer, Cham, 2018, pp. 250-267.

W. van der Aalst, Decomposing petri nets for process mining: A generic
approach, Distrib. Parallel Databases 31 (4) (2013) 471-507.

L. Wang, Y. Du, W. Liu, Aligning observed and modelled behaviour based
on workflow decomposition, Enterp. Inf. Syst. 11 (8) (2017) 1207-1227.
H. Verbeek, W. van der Aalst, Merging alignments for decomposed replay,
in: International Conference on Application and Theory of Petri Nets and
Concurrency, Springer, 2016, pp. 219-239.

[23]

[24]
[25]
[26]
[27]

[28]

[29]

[30]

[31]

[32]

[33]

[34]

[35]

[36]

[37]

[38]

[39]

[40]

[41]

[42]

[43]

[44]

[45]

[46]

[47]

W. Song, X. Xia, H. Jacobsen, P. Zhang, H. Hu, Efficient alignment between
event logs and process models, IEEE Trans. Serv. Comput. 10 (1) (2017)
136-149.

A. Diller, Z: An Introduction to Formal Methods, John Wiley & Sons, Inc.,
1990.

W. van der Aalst, The application of petri nets to workflow management,
J. Circuits Syst. Comput. 08 (01) (1998) 21-66.

H. Verbeek, T. Basten, W. van der Aalst, Diagnosing workflow processes
using woflan, Comput. J. 44 (4) (2001) 246-279.

E. Mayr, An algorithm for the general petri net reachability problem, SIAM
J. Comput. 13 (3) (1984) 441-460.

R. Lipton, The Reachability Problem Requires Exponential Space, Research
Report 62, Department of Computer Science, Yale University, New Haven,
Connecticut, 1976.

T. Murata, Petri nets: Properties, analysis and applications, Proc. IEEE 77
(4) (1989) 541-580.

J. Daciuk, S. Mihov, B. Watson, R. Watson, Incremental construction of
minimal acyclic finite-state automata, Comput. Linguist. 26 (1) (2000)
3-16.

A. Armas-Cervantes, P. Baldan, M. Dumas, L. Garcia-Bafiuelos, Diagnosing
behavioral differences between business process models: An approach
based on event structures, Inf. Syst. 56 (2016).

P. Hart, N. Nilsson, B. Raphael, A formal basis for the heuristic
determination of minimum cost paths, IEEE TSSC 4 (2) (1968) 100-107.
A. Syring, N. Tax, W. van der Aalst, Evaluating conformance measures in
process mining using conformance propositions, in: M. Koutny, L. Pomello,
L. Kristensen (Eds.), Transactions on Petri Nets and Other Models of
Concurrency XIV, Springer Berlin Heidelberg, Berlin, Heidelberg, 2019, pp.
192-221.

J. Desel, J. Esparza, Free Choice Petri Nets, Vol. 40, Cambridge university
press, 2005.

A. Adriansyah, B. van Dongen, W. van der Aalst, Conformance checking us-
ing cost-based fitness analysis, in: 2011 IEEE 15th International Enterprise
Distributed Object Computing Conference, 2011, pp. 55-64.

B. van Dongen, Efficiently computing alignments, in: F. Daniel, Q. Sheng,
H. Motahari (Eds.), Business Process Management Workshops, Springer
International Publishing, Cham, 2019, pp. 44-55.

A. Augusto, R. Conforti, M. Dumas, M. La Rosa, F. Maggi, A. Marrella,
M. Mecella, S. A., Automated discovery of process models from event
logs: Review and benchmark, IEEE Trans. Knowl. Data Eng. 31 (4) (2019)
686-705.

B. van Dongen, BPI Challenge 2012, Eindhoven University of Technology,
2012, http://dx.doi.org/10.412 1/UUID:3926DB30-F7 12-4394-AEBC-
75976070E91F, URL https://data.4tu.nl/repository/uuid:3926db30-f7 12-
4394-aebc-75976070e9 If.

W. Steeman, BPI Challenge 2013, Closed Problems, Ghent Univer-
sity, 2013, http://dx.doi.org/10.412 1/UUID:C2C3B154-AB26-4B3 1-AOE8-
8F2350DDAC11, URL https://data.4tu.nl/repository/uuid:c2c3b154-ab26-
4b31-a0e8-8f2350ddac11.

W. Steeman, BPI Challenge 2013, Incidents, Ghent University, 2013, http:
//dx.doi.org/10.412 1/UUID:500573E6-ACCC-4B0C-9576-AA5468B 10CEE,
URL https://data.4tu.nl/repository/uuid:500573e6-accc- 4b0c-9576-
aa5468b 10cee.

B. van Dongen, BPI Challenge 2014, Rabobank Nederland, 2014, http:
//dx.doi.org/10.412 1/UUID:C3E5D 162-0CFD-4BB0-BD82-AF52688 19C35,
URL https://data.4tu.nl/repository/uuid:c3e5d162-O0cfd-4bb0-bd82-
af5268819c35.

B. van Dongen, BPI Challenge 2015, Eindhoven University of Technol-
ogy, 2015, http://dx.doi.org/10.412 1/UUID:31A308EF-C844-48DA-948C-
305D167A0EC1, URL https://data.4tu.nl/repository/uuid:31a308ef-c844-
48da-948c-305d167a0ec1.

B. van Dongen, BPI Challenge 2017, Eindhoven University of Technology,
2017, http://dx.doi.org/10.412 1/UUID:5F3067DF-F10B-45DA- B98B-
86AE4C7A310B, URL _https://data.4tu.nl/repository/uuid:5f3067df-f10b-
45da-b98b-86ae4c7a310b.

M. de Leoni, F. Mannhardt, Road Traffic Fine Management Process,
Eindhoven University of Technology, 2015, http://dx.doi.org/10.4121/
UUID:270FD440- 1057-4FB9-89A9-B699B47990F5, URL https://data.4tu.nl/
repository/uuid:270fd440- 1057-4fb9-89a9-b699b47990f5.

F. Mannhardt, Sepsis Cases - Event Log, Eindhoven University of
Technology, 2016, http://dx.doi.org/10.4121/UUID:915D2BFB-7E84-49AD-
A286-DC35F063A460, URL https://data.4tu.nl/repository/uuid:915d2bfb-
7e84-49ad-a286-dc35f063a460.

R. Conforti, M. La Rosa, A. Ter Hofstede, Filtering out infrequent behavior
from business process event logs, IEEE Trans. Knowl. Data Eng. 29 (2)
(2016) 300-314.

S. Leemans, D. Fahland, W. van der Aalst, Discovering block-structured
process models from event logs-a constructive approach, in: International
Conference on Applications and Theory of Petri Nets and Concurrency,
Springer, 2013, pp. 311-329.
28

[48]

[49]

[50]
[51]

D. Reifsner, A. Armas-Cervantes, R. Conforti et al. / Information Systems 94 (2020) 101561

A. Augusto, R. Conforti, M. Dumas, M. La Rosa, Split miner: Discovering
accurate and simple business process models from event logs, in: 2017
IEEE International Conference on Data Mining (ICDM), IEEE, 2017, pp. 1-10.
A. Augusto, R. Conforti, M. Dumas, M.L. Rosa, G. Bruno, Auto-
mated discovery of structured process models from event logs: The
discover-and-structure approach, Data Knowl. Eng. 117 (2018) 373-392.
S. vanden Broucke, J. De Weerdt, DSS.

D. Reissner, Public Benchmark Data-Set for Conformance Checking in
Process Mining, University of Melbourne, 2019, http://dx.doi.org/10.
26188/5cd91d0d3adaa, URL __sihttps://melbourne.figshare.com/articles/
Public_benchmark_data-set_for_Conformance_Checking_in_Process_
Mining/808 1426.

[52] J. Mufioz-Gama, Conformance Checking in the Large (Dataset), Universitat

[53]

Politecnica de Catalunya, 2013, http://dx.doi.org/10.412 1/UUID:44C32783-
15D0-4DBD- AF8A-78B97BE3DE49, URL https://data.4tu.nl/repository/uuid:
44c32783- 15d0-4dbd-af8a-78b97be3de49.

N. Tax, X. Lu, N. Sidorova, D. Fahland, W.M.P. van der Aalst, The impreci-
sions of precision measures in process mining, Inf. Process. Lett. 135 (2018)
1-8, http://dx.doi.org/10.1016/j.ipl.2018.01.013.

[54] J. Esparza, Synthesis rules for petri nets, and how they lead to new results,

in: CONCUR ’90, in: Lecture notes in Computer Science, vol. 458, Springer,
1990, pp. 182-198.
