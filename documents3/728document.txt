Sabir et al. EURASIP Journal on Image and Video
Processing (2020) 2020:6

https://doi.org/10.1186/s13640-020-0493-9

RESEARCH Open Access

Segmentation-based image defogging
using modified dark channel prior

Aneela Sabir, Knhawar Khurshid’ ® and Ahmad Salman

Abstract

EURASIP Journal on Image
and Video Processing

Check for
updates

 

Image acquisition under bad weather conditions is prone to yield image with low contrast, faded color, and overall
poor visibility. Different computer vision applications including surveillance, object classification, tracking, and
recognition get effected due to degraded hazy images. Dehazing can significantly improve contrast, balance
luminance, correct distortion, remove unwanted visual effects/ and therefore enhance the image quality. As a result,
image defogging is imperative pre-processing step in computer vision applications. Previously, dark channel
prior-based algorithms have proven promising results over the available techniques. In this paper, we have proposed
a modified dark channel prior that uses fog density and guided image-filtering technique to estimate and refine
transmission map, respectively. Guided image filter soeeds up the refinement of transmission map, hence reduces the
overall computational complexity of algorithm. We have also incorporated segmentation of the foggy image into sky
and non-sky regions, after which, the modified dark channel prior and atmospheric light is computed for each
segment. Then, the average value of atmospheric light for each segment is used to estimate transmission map. We
have performed quantitative and subjective comparison for effective evaluation of our proposed algorithm against
the current state-of-the-art algorithms on natural and synthetic images. Different quality metrics, such as saturation,
mean square error, fog density, peak signal to noise ratio, structural similarity index metric, dehazing algorithm index
(DHQ)), full-reference image quality assessmen (FR-IOA), and naturalness of dehazed images have shown the

proposed algorithm to be better than existing techniques.

Keywords: Defogging, Dark channel, Guided image filter, Segmentation, Image enhancement

1 Introduction

Outdoor images are degraded due to hazy weather con-
ditions such as mist, rain, clouds, and fog. Image acqui-
sition, during such weather conditions, reduces contrast
of the image, fades colors, degrades quality, and makes
object features difficult to perceive by humans and con-
ventional computer vision systems. Therefore, it is imper-
ative to perform image dehazing as it is required for
different computer vision application such as surveil-
lance, image classification, detection, tracking, recogni-
tion, and obtaining satellite imagery. An effective dehaz-
ing approach should be able to significantly improve
contrast, balance luminance, correct distortion, remove
unwanted visual effects, and enhance the overall image
quality. Figure 1 shows two examples of the foggy and
the corresponding fog-free images taken from the RESIDE
dataset [1].

 

*Correspondence: khawar.khurshid@seecs.edu.pk
National University of Sciences and Technology, Islamabad, Pakistan

g) Springer Open

 

In the literature, image dehazing or defogging is
achieved through image enhancement, image restoration,
fusion-based approaches, and machine learning [2]. Image
enhancement algorithms are used to modify color and
contrast of the image without improving their quality,
whereas image restoration-based techniques defog the
image depending upon fog density [2].

Wang et al. have used wavelet transform and single scale
retinex algorithm to correct the foggy images and improve
brightness [3]. The depth map was computed by using
Bayesian theory and Markov regularization to reduce halo
artifacts in the images.

He et al. have used morphological operations to cal-
culate fog density [4] in which, foggy image bright-
ness is increased before estimating atmospheric light.
In [5], adaptive histogram equalization is used for con-
trast enhancement. Similarly, Xu et al. proposed defog-
ging algorithm based on contrast limited adaptive his-
togram equalization to improve contrast while removing

© The Author(s). 2020 Open Access This article is distributed under the terms of the Creative Commons Attribution 4.0
International License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and
reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to the

Creative Commons license, and indicate if changes were made.
Sabir et al. FURASIP Journal on Image and Video Processing

(2020) 2020:6

Page 2 of 14

 

 

 

Fig. 1 Sample images taken from the RESIDE dataset [1]. a Foggy Images where the fog is generated synthetically. b Fog-free images

 

 

fog and unwanted noise particles [6]. Various defogging
algorithms based on polarization are proposed in [7, 8].
Schechner et al. have proposed defogging using inver-
sion process of atmospheric scattering where two images
are taken from a polarizer at different orientations [7]. In
[8], Miyazaki et al. have proposed a polarization-based
technique to remove the fog particles from the image.
Their proposed algorithm takes two input images as a
prior knowledge to compute parameters used for image
defogging.

Tan et al. have proposed defogging algorithm consid-
ering dark channel of foggy images [9]. Dark channel
contains the low contrast pixel values and it acts as a prior
knowledge for foggy image restoration [10]. In [11], He
at al. have proposed a novel dark channel prior (DCP)
algorithm by assuming air light constraint for transmis-
sion map estimation. Another DCP-based algorithm is
proposed in [12] that uses bilateral filtering technique to
refine transmission map. Chen et al. have obtained clear
dark channel and preserved edge information by using
bilateral filter and the adaptive median filter [13]. The
process of DCP-based algorithm consists of estimation of
atmospheric light, estimation and refinement of transmis-
sion map, and consequently fog-free image reconstruc-
tion. In this method, foggy image brightness is increased
prior to estimating atmospheric light. Binary tree-based
atmospheric light estimation is proposed by Tang et al.
in [14]. Image defogging using RGB, LAB, and HSV color
spaces is proposed by Nair et al [15]. In this approach,
transmission map is refined using surround filter and
the surround constant is chosen arbitrarily. Li et al. have

proposed an improved bilateral filtering technique for
transmission map refinement [16]. In [17], Zhang and
Hou have proposed K-means clustering for atmospheric
light estimation. Zhu et al. have recently proposed new
technique to compute transmission map using energy
minimization and refinement of transmission map is done
using piece-wise smoothing filter [18]. The benefit of this
algorithm is to generate artifacts free defogged image. In
[19], globally guided image filter-based algorithm is pro-
posed which helps to improve color contrast of defogged
image. Ju et al. have proposed improved atmospheric scat-
tering model and the resultant image contains halo arti-
facts, in addition to fog factor and discoloration [20]. Lee
et al. proposed a novel approach by combining defogging
algorithm with de-mosaicking algorithm simultaneously
[21]. The combined algorithm has benefits of removing
noise in distant scenes. In [22], an algorithm based on
weighted least square and high dynamic range is pro-
posed which is used to preserve edge information in RGB
images. In [23], Majeed et al. have used hybrid median fil-
ter and accelerated local laplacian filter for image Dehaz-
ing. Visual enhancement and color restoration is done
using lo based gradient image decomposition. Tufail et
al. have proposed an improved DCP based on RGB and
YCbCr color spaces where transmission map refinement
is done using Laplacian and mean filters [24]. As a result of
refined DCP, better structural detail and enhanced color
range is achieved. Makarau et al. have proposed DCP
and bright channel prior (BCP) based on local search and
image segmentation to effectively remove fog [25]. Maka-
rau et al. have extended their work in [26] to improve
Sabir et al. EURASIP Journal on Image and Video Processing

dehazing technique by finding haze thickness using visible
and cirrus bands.

In [27], image segmentation algorithm is proposed by
Liu et al. in which RGB image is converted to YUV color
space followed by image segmentation using region grow-
ing technique by selecting seed points. Seed points are
selected on the basis of different fog density regions and
atmospheric light is estimated using quad-tree hierarchi-
cal search algorithm. Similarly, in [28], Hong and Cai
have proposed segmentation-based defogging algorithm
in which they have divided image into sky and non-sky
segments using Otsu segmentation technique. Dark chan-
nel prior is computed using adaptive parameter and image
fusion is applied to combine defogged sky and non-sky
segments. However, resultant images contain color distor-
tion and seem unnatural. In another work, Cai et al. have
proposed segmentation-based defogging algorithm using
adaptive factor [29]. In this algorithm, segmentation is
done using binary thresholding to compute sky and non-
sky regions. After defogging, fusion is applied to combine
sky and non-sky regions. The color scheme is distorted
at the edges of resultant image. In [30], reliability map
of DCP-based algorithm is proposed. In this technique,
they have found out the reliable regions which contain
sufficient prior knowledge to compute DCP. Transmis-
sion map is estimated using the reliable pixels only. Linear
fitting curve is then used to find the transmission map
for unreliable pixel values. Qing et al. have proposed K-
means clustering for depth maps calculation to defog
input image [31]. K-means is used to segment image into
multiple parts having different depth range; then, trans-
mission map is computed for each region. the edges of
resultant image are not smooth, and the fog factor is also
available at the edges.

The conditional Generative Adversarial Network is pro-
posed in [32] which directly removes haze from an image,
without estimating transmission map. Image defogging
is performed by an end-to-end trainable neural network.
Some other machine learning-based algorithms are also
proposed in [33-40]. Choi et al. have proposed fog-aware
density evaluator (FADE) and density-based reference-
less perceptual defogger (DEFADE) in [33]. In [34], Li
et al. have proposed residual-based deep CNN dehaz-
ing algorithm. Work consist of transmission map esti-
mation network and dehazing using residual network.
The advantage of residual-based network is its reduced
computational complexity as it does not require atmo-
spheric light estimation. Existing state-of-the-art algo-
rithms fail to completely remove fog from foggy image
and the results are either over saturated or low con-
trast. So, to avoid the over saturation and better remove
the fog particles , a modified DCP-based algorithm is
proposed. The major contributions of this work are as
follows:

(2020) 2020:6

Page 3 of 14

Modified dark channel prior is computed.
Transmission map based on fog density is estimated.
Segmentation-based defogging algorithm is proposed
We tested our algorithm using RESIDE images
dataset which includes both natural and synthetic
images. The results have proven that our algorithm
achieves the state-of-the-art performance on the
proposed defogging algorithm.

PWN PP

2 Proposed methodology

We have proposed two approaches for image defogging
task. The first one utilizes the modified dark channel prior
for image defogging, and the second one incorporates
segmentation of the input image for localized parameter
estimation before applying defogging algorithm.

2.1 Image defogging using modified dark channel prior
In this work, a modified dark channel is computed for
transmission map estimation. Later, transmission map is
refined using guided image filter (GIF). GIF is more effi-
cient than the other refinement filters as it reduces the
overall computation time for the transmission map refine-
ment, hence optimizing the defogging algorithm. The
work flow of our proposed technique is shown in Fig. 2,
which illustrates that the proposed model is applied to
foggy image to compute dark channel and atmospheric
light. Atmospheric light is used to estimate transmission
map which is refined in order to preserve the gradient
information. The refined transmission map is then used to
generate fog-free image.

2.1.1 Dark channel and atmospheric light estimation
First, a dark channel is computed to estimate atmospheric
light using Eq. (1), that is obtained from [11]. A minimum
filter of window size w is applied to compute dark channel
where is kept as 31 x 31. Foggy images along with the
corresponding dark channels are shown in Fig. 3.

Ipcp = min ( min_ /(y)) (1)

xew(k) yE{R,G,B}

After successfully computing dark channel, atmospheric
light Ajight is estimated which is a 3 x 1 vector contain-
ing highest intensity values that are computed from 0.1%
brightest pixels of dark channel. Algorithm 1 illustrates
the pseudo code to compute atmospheric light where, I is
input foggy image, Jpcp is dark channel prior, N is 0.1%
brightest pixel values In the dark channel and m is tempo-
rary variable. xxy is the size of dark channel prior. Asa first
step, Ipcp is compared with max value of N. If both values
are equivalent; then. input image pixels corresponding to
N pixel locations are considered as the atmospheric light.

2.1.2. Transmission map estimation and refinement
Atmospheric light is used to compute transmission map.
A transmission map as given in (2) is computed for each
Sabir et al. FURASIP Journal on Image and Video Processing

(2020) 2020:6

Page 4 of 14

 

Dark Channel
Computation

    

Hazy Image

 

Haze Free Image

 

Fig. 2 DCP-based algorithm for image defogging

   

—_—_ i

0.1% Brightest

pixels in Dark
Channel

  

Atmospheric
Light Estimation

Se - 2 Zn
aoe a

Transmission

ar Map Estimation

 

— oe

Transmission
Map Refinement

 

 

RGB color channel by dividing input image with its corre-
sponding color channel atmospheric light.

I
Te) 1-01 SY

Algorithm 1 Atmospheric Light Estimation
Input: I , I pcp

Output: Alignt

1: Compute x and y

2: Initialize m = 0

LOOP Process

3: fori = 1 tox andj = 1 toy do

4: if Ipcp = max(N) & (m < I(i, j)) then
5:m < I(i,j)

6: Alight — 1(i,/)

7: end if

8: end for

9: return A jignt

Here, value of ¢ depends upon fog density of the hazy
input image. Fog density (FD) is computed using FADE
[14]. where, fep; and fgp2 are fixed throughout the algo-
rithm and the values are chosen to avoid oversaturation
and to completely remove fog from input image. ffp; and
fep2 are set to 2.5 and 1, respectively. These values are
achieved after performing cross validation on RESIDE
dataset to estimate the accuracy of the performance of a
proposed model.

Algorithm 2 illustrates the pseudo code for estima-
tion and refinement of transmission map. After comput-
ing transmission map, refinement of transmission map
is required to preserve gradient information. In our pro-
posed methodology, guided image filter (GIF) is used for
the refinement process where input image itself is used
as guidance image as edge preserving and smoothing fil-
ter. GIF is faster than other refinement filters as it reduces

the overall computational complexity of the defogging
algorithm [41]. Therefore,

(3)

where, Trefined is a linear transform of T in a window of

size W. a and b are linear coefficients that are constant

in W;. Transmission map and refined transmission maps

are shown in Figs. 4 and 5, respectively. After refining the

transmission map, defogged image is reconstructed using:
I(x) —A

R(x) = ————_ + A
Trefined + €

Trefined(*) = aT + bgp Vk © Wy

(4)

Where, € is a constant with negligibly small value to avoid
division with zero. At the end of defogging algorithm,
gamma correction is also used to improve the overall
brightness of reconstructed image.

Algorithm 2 Transmission map estimation and

refinement

Input: Input Image (I), Atmospheric Light Ajignt

Output: Refined Transmission map T

1: Compute Fog Density FD

2: if (FD > f pp,) then

3:¢ — 0.8

4: else if frp < FD <f pp,) then

5:€ <— 0.7

6: else

7:6 <— 0.6

8: end if

Compute Transmission Map TM

9: TM —1-(¢T1)

10: Refine Transmission Map using Eq.(3).

11: return T

 

 

2.2 Segmentation-based image defogging using
modified dark channel prior

In this work, we have proposed defogging algorithm

using image segmentation technique. Image segmenta-

tion is done using graph-based segmentation technique.
Sabir et al. EURASIP Journal on Image and Video Processing (2020) 2020:6 Page 5 of 14

 

SAALAEEL LAA

HUE

Hi

or
ol
Cony
al
epee
oo
nl
i
od

 

(a)

Fig. 3 Dark channel computation. a Foggy images b Corresponding dark channels

 

 

The segments are based on sky and non-sky regions. _ that is, based on guided image filter. Segmentation-based
Dark channel and atmospheric light is computed foreach algorithm is efficient in terms of removing fog parti-
segment. Transmission map is estimated on the basis cles, yield high SSIM and PSNR, and lower value of
of average value of atmospheric light. The refinement MSE. Segmentation-based proposed algorithm is shown
process is same as discussed in previous methodology, _ in Fig. 6.

HLTH
” | PEPER
ig

i
a

tS Ey

Sire A ee
—

2a

 

(a)

Fig. 4 Transmission map estimation. a Foggy images b Transmission maps

 
Sabir et al. FURASIP Journal on Image and Video Processing

(2020) 2020:6

Page 6 of 14

 

Tee,

:
wt

fo
laeeeall
od
a
Ld

(a)

 

 

Fig. 5 Transmission map refinement. a Foggy images. b Refined transmission maps

 

 

In this approach, a semi-automatic segmentation is
used to convert foggy image into sky and non-sky seg-
ments. Foreground and background pixels are selected
manually to convert image into two segments. Scrib-
bles are drawn onto the image, which divides the
image into background and foreground pixels and
then graph theory is applied for fast segmentation.

Resultant segmented images are shown in Fig. 7. After
converting foggy image into sky and non-sky segments,
dark channel is computed for each segment using Eq. (5).
A minimum filter of window size w is applied to compute
dark channel, where w is kept at 31 x 31 for optimized
results. Foggy images along with dark channel are shown
in Fig. 8.

 

RGB to LAB
Conversion

Atmospheric
Light Estimation
Computation of (A1)
Average value

of A1 and A2 Atmospheric

Light Estimation
(A2)

Transmission map
estimation

 

 

Transmission map
refinement

 

Fig. 6 Segmentation-based image defogging using modified dark channel prior

Foreground and
background Pixels
selection

Graph based
Segmentation

Dark Channel
Computation

Dark Channel
Computation

Sky and non-
sky regions

Haze free image
reconstruction

Output Image

 
Sabir et al. EURASIP Journal on Image and Video Processing (2020) 2020:6 Page 7 of 14

 

 

(b)

Fig. 7 Image segmentation using graph cut theory. a Foggy image. b Sky regions. ¢ Non-sky regions

 

 

 

 

(b)

Fig. 8 Dark channels for segmented images. a Sky and non-sky regions of foggy image. b Corresponding dark channels for each segment

 

 

 

  

(a) (b)

Fig. 9 Transmission maps using image segmentation a Foggy image. b Transmission map. ¢ Refined transmission map

 

 

 

 

 
Sabir et al. FURASIP Journal on Image and Video Processing

Table 1 Overview of RESIDE data source and content

 

Type of images Number of images

 

 

Synthetic indoor hazy images 110,500

Synthetic outdoor hazy images 313,950

Natural unannotated hazy images 4807

Natural annotated hazy images 4322
Ipcp(seg;) = min min Iseg (Y) i=1,2 (5)

xew(k) yE{R,G,B}

After successfully computing dark channels, atmo-
spheric light is estimated using each dark channel. Final
atmospheric light is computed using the average values of
each atmospheric light. Transmission map estimation and
refinement is done using the same procedure as discussed
in first proposed methodology. The resultant transmis-
sion map along with refined transmission map computed
using the average value of atmospheric light are shown
in Fig. 9. After refining the transmission map, defogged
image is reconstructed. Fog-free image is reconstructed
using Eq. (4).

3 Results and discussion

Experiments are performed using realistic single-image
dehazing (RESIDE) [1] dataset which contains outdoor
hazy images including natural, as well as, synthetically
generated foggy images. Dataset is divided into four sub-
categories that are shown in Table 1.

(2020) 2020:6

Page 8 of 14

The experimental results are compared with He [11],
Zahid [24], DEFADE [33], and Tarel [42]. Image qual-
ity, visibility enhancement, edge and texture information,
color, and structure of image are important factors
to evaluate defogging algorithm [43]. For evaluation
of proposed algorithm results, full reference met-
ric such as structural similarity index metric (SSIM)
[44], peak signal to noise ratio (PSNR), full-reference
image quality assessment (FR-IQA) [45], and mean
square error (MSE) are compared with current state
of the art algorithms. Other than these metrics, some
non-reference metrics including naturalness image qual-
ity evaluator (NIQE) [46], fog density, blind/referenceless
image spatial quality evaluator (BRISQUE) [47], and
dehazing algorithms index (DHQI) [48] are also calcu-
lated.

PSNR is fully reference based metric that requires
ground truth image. PSNR is computed by:

MAX?

Where MAX represents highest possible pixel value in an
input image. MSE is mean square error, given by:

j-1 k-1

1 a . . 72
MSE = jk S S [Zinput (ir, ic) — Toutput i, ic) | (7)
iy=0 i-=0

where, Jinput and Joutput are input and fog-free recon-
structed output image, respectively, and jxk is size of
the image. If the PSNR is larger, image distortion will

 

(a) (b)

 

Defogged images using segmentation-based algorithm

 

Fig. 10 Proposed methodology results. a Input images. b Ground truth images. ¢ Defogged images using modified DCP-based algorithm. d

(c) (d)

 

 
Sabir et al. FURASIP Journal on Image and Video Processing

(2020) 2020:6

Page 9 of 14

 

(a) (b) (c) (d)

 

X

be smaller. So, for better performance of dehazing algo-
rithm, PSNR must be higher. SSIM also requires reference
image and it compares similarity of resultant image with
ground truth image depending upon brightness, contrast,
and structure. On the other hand, range of SSIM score
is 0 to 1 and value closer to 1 is more appealing to the
researchers. SSIM is defined as:

(tin Myout + ky) (20 xinyout + ka)

SSIM = —,_ _-, a
(u2,, + W3. +k1) (02, +02, +)

(8)

 

(e) (f) (g) (h)

Fig. 11 Comparison of different defogging algorithms using synthetically generated hazy dataset. a Input images. b Ground truth images. ¢ Tarel
[42]. d He [11]. e DEFADE [33]. f Zahid [24]. g Modified DCP-based proposed algorithm. h Segmentation-based proposed algorithm

 

where Xin and yout are two windows of common size,
[xin aNd fy, are mean of windows, oO; and Oy, a are
their variances and k; and ko are constants. Results gen-
erated using modified DCP-based algorithm and image
segmentation-based algorithms are shown in Fig. 10.
Figures 11 and 12 present a comparison of proposed algo-
rithm with different popular algorithms using syntheti-
cally generated foggy dataset and natural foggy dataset,
respectively. Figure 11 illustrates poor color contrast and

darker effects in He et al. [11] results. Also the DEFADE

 

(a) (b) (c) (d)

 

X

 

Fig. 12 Comparison of different defogging algorithms using real hazy dataset. a Input images. b Ground truth images. ¢€ Tarel [42]. d He [11].
e DEFADE [33]. f Zahid [24]. g Modified DCP-based proposed algorithm. h Segmentation-based proposed algorithm

(e) (f) (g) (h)

 
Sabir et al. FURASIP Journal on Image and Video Processing

Table 2 Quantitative comparison of proposed algorithm with existing state-of-the-art algorithms

(2020) 2020:6

Page 10 of 14

 

 

Quality metrics Tarel [42] He [11] DEFADE [33] Zahid [24] Proposed | Proposed ||
Image 1
SSIM 0.8193 0.8152 0.9124 0.7759 0.9589 0.9584
PSNR 16.7002 14.5748 19.7479 15.6148 25.2252 24.5213
MSE 0.0214 0.0349 0.0106 0.0274 0.0030 0.0064
NIQE 3.58125 4.5049 2.5549 3.2650 2.7789 2./722
BRISQUE 13.3862 8.1528 10.6486 30.0856 17.1191 15.01
DFD 2.24277 2.3037 1.05968 2.4419 0.8968 0.5426
DHQI 46.0615 41.7444 40.4703 36.0482 43.5329 46.2837
FR-IQA 0.8380 0.8434 0.6843 0.8917 0.8724 0.9113
Image 2
SSIM 0.8623 0.8642 0.8541 0.8087 0.9033 0.9231
PSNR 15.8230 17.2279 13.6398 17.4642 22.1352 21.9253
MSE 0.0262 0.0189 0.0433 0.0179 0.0061 0.0060
NIQE 4.0089 3.9558 2.6941 3.3273 2.6661 2./847
BRISQUE 23.8366 13.865 6.4767 18.9499 6.1645 9.766
DFD 2.0359 1.5937 0.5847 0.5438 0.4363 0.9021
DHQI 42.4847 35.4505 41.537] 32.4699 39.2611 45.7648
FR-IQA 0.5447 0.9005 0.7801 0.5604 0.6990 0.6605
Image 3
SSIM 0.8367 0.8130 0.7289 0.7271 0.8949 0.927
PSNR 16.8504 16.2668 15.6559 14.9335 21.7254 22.5421
MSE 0.0209 0.0236 0.0272 0.0321 0.0067 0.0056
NIQE 2.1909 5.6549 2.4606 3.1842 2.7001 2.6414
BIQE 21.9000 24.3922 21.4539 23.1685 9.7108 16.4404
DFD 2.0164 1.5703 0.5171 0.4619 0.8122 0.3352
DHQI 44.5484 35.4256 33.6742 34.0620 41.5119 44.8758
FR-IQA 0.5267 0.6322 0.6275 0.8024 0.8052 0.8347
Image 4
SSIM 0.7605 0.8033 0.8095 0.7509 0.9294 0.9294
PSNR 17.8995 15.2632 20.0107 15.1208 23.2599 23.2599
MSE 0.0162 0.0298 0.0100 0.0308 0.0047 0.0047
NIQE 1.6790 4.0895 2.0401 2.4170 2.0671 2.0671
BIQE 26.2341 18.9832 17.7013 24.2683 2.3296 2.3296
DFD 2.2579 2.5654 0.5714 0.5379 0.7176 0.3417
DHQI 44.9974 38.0236 41.2921 32.5804 46.1039 46.0652
FR-IQA 0.6674 0.6360 0.7039 0.8628 0.8640 0.8568
Average of 100 Images
SSIM 0.7712 0.8229 0.8244 0.7412 0.8607 0.8823
PSNR 15.0747 18.2877 18.3466 16.9376 21.2019 21.2011
MSE 0.03352 0.01926 0.02411 0.02254 0.00964 0.00865
NIQE 3.3659 4.5758 2.5645 3.4870 2.2303 2.6650
BIQE 26.7820 20.5096 19.7003 20.4987 17.7489 15.5156
DFD 0.8196 0.05351 0.1982 0.4754 0.06632 0.0250
DHQI 48.0391 49.3807 57.2062 52.6244 60.2057 57.8661
FR-IQA 0.5644 0.6902 0.7701 0.7471 0.8450 0.8596

 
Sabir et al. EURASIP Journal on Image and Video Processing

(2020) 2020:6

Page 11 of 14

 

Blind/Referenceless Image Spatial Quality Evaluator (BRISQUE)

DEFADE Zahid Proposed-II

(a)

Structural Similarity Index Metric

Tarel He

Proposed-I

DEFADE Zahid

(c)

Mean Square Error

Tarel He Proposed-I

Proposed-II

DEFADE

(c)

DHQI

Tarel He Zahid Proposed-I Proposed-II

DEFADE

(g)

Tarel He Zahid Proposed-| §Proposed-ll

 

Peak to Signal Noise Ratio

DEFADE

Tarel He Zahid Proposed-I Proposed-II
Fog Density
2 }
15
1
0.5
oF ll i - = —— in =
Tarel He DEFADE Zahid Proposed-I Proposed-II
Naturalness Image Quality Evaluator
10
9
8 1
7
6
5
4 _
3
2
Tarel He DEFADE Zahid Proposed-I Pr oposed-Il
FR-QA
0.9 ——
0.8
0.7
0.6
0.5
Tarel He DEFADE Zahid Proposed-|_ Proposed-ll

Fig. 13 Box plot for average quantitative comparison of 100 images for different state-of-the-art defogging algorithms. a No-reference quality
metric BRISQUE, b PSNR, ¢ SSIM, d fog density, e MSE and f NIOE, g DHOI, and h FR-IOA

 

[33] results show higher fog factor as shown. Proposed
algorithms results, comparatively, seem better as com-
pared to the other algorithms.

Quantitative comparison is presented in Table 2. The
proposed algorithm generates result with highest SSIM,
DHQI, FR-IQA and PSNR and lowest Fog density and
MSE. The experiments are performed on hundred dif-
ferent images. Figure 13 depicts the complete compari-
son of proposed algorithm with existing state of the art
algorithms through box plot. In each box, median is indi-
cated by central red mark, the top and bottom edges
of box indicate first and third quartile, respectively. The

whiskers above and below the box show the maximum and
minimum values, respectively. “+” symbol indicates out-
liers. Figure 13 shows that the image quality of defogged
image generated using proposed algorithm is better than
other algorithms. It further shows that PSNR is high-
est for proposed algorithm and lowest for Tarel [42].
The standard deviation of PSNR is highest for DEFADE
[33]. Comparison of SSIM, non-reference DHQI and full-
reference IQA is also presented in Fig. 13 which shows
the better performance of proposed algorithm. It also
presents fog density and MSE comparison for five differ-
ent state of the art algorithms. Our results contain lower

 
Sabir et al. EURASIP Journal on Image and Video Processing (2020) 2020:6 Page 12 of 14

 

HU

Mecieiiitii

H
ALLEL

tire

ALTE
Mii

Hi
ye

'
ait

Pe

meee

‘Ti iit f

| ‘ =E4

a is

PPLE

“LEEPER

a a

ture

 

Fig. 14 Comparison of proposed algorithm with current state of the art machine learning-based defogging algorithms. a Input image. b Ground
truth image. ¢ Dehaze-Net [37]. d MSCNN [36]. e Modified DCP-based proposed algorithm. f Segmentation-based proposed algorithm

 

 

Table 3 Quantitative comparison of proposed algorithm with existing state-of-the-art machine learning-based image defogging

 

 

Quality Metrics Dehaze-Net [37] MSCNN [36] AoD-Net [38] Proposed | Proposed ||
Image 1
SSIM 0.7362 0.8040 0.8245 0.86233 0.8916
PSNR 19.0583 17.401 20.9252 19.4014 20.9254
NIQE 2.6246 2.454 2.2992 3.1089 3.0930
BRISQUE 20.2741 274012 18.9295 18.4556 18.5600
Image 2
SSIM 0.863 0.8645 0.9432 0.93417 0.9032
PSNR 19.5769 19.7853 21.7582 22.477 20.5093
NIQE 3.9958 4.0555 20.6351 4.0373 4.3324
BRISQUE 22.391 24.9614 18.5274 17.7474 31.0225
Image 3
SSIM 0.8859 0.8635 0.8623 0.91604 0.9184
PSNR 24.4493 22.1310 25.5093 22.9655 25.0210
NIQE 3.5345 3.2623 4.1446 3.2526 4.3324

BRISQUE 17.4855 28.6885 18.2809 16.8705 22.5321

 
Sabir et al. EURASIP Journal on Image and Video Processing

value of MSE and NIQE which have proven promising
results.

The experimental results are compared with current
state-of-the-art machine learning algorithms including
MSCNN [36], Dehaze-Net [37], and AoD-Net [38]. Figure
wise comparison is presented in Fig. 14. It shows that the
results generated using MSCNN [36] are oversaturated
and contain low similarity index with ground truth image.
It further shows that results generated using Dehaze-Net
[37] still contains fog particles. Table 3 shows quantita-
tive comparison of these algorithms which has proven that
proposed algorithms either exceeds or comparable to the
machine learning-based algorithms which require large
amount of data for training and are generally computa-
tionally expensive.

4 Conclusion

In this paper, we have proposed two different techniques
for image defogging. The first one consists of a modified
DCP with guided image filter to estimate and refine the
transmission map in order to preserve edge informa-
tion. We also proposed a segmentation-based defogging in
which the foggy image is divided into two segments based
on sky and non-sky regions. The dark channel for each
segment is computed using the modified DCP algorithm.
Proposed algorithms could be selected depending upon
application. For indoor and less sky-region-based outdoor
applications, modified DCP-based algorithm is prefer-
able. Segmentation-based algorithm generates significant
results on outdoor images having sky and non-sky regions.
The proposed algorithms are tested against multiple state-
of-the-art approaches using the RESIDE dataset [1]. The
quantitative and qualitative comparisons are performed
for effective evaluation and validation. The results gen-
erated using the proposed algorithm show higher values
of SSIM and PSNR. The comparative analysis proved that
the results generated using the proposed algorithm are
better than existing algorithms with balanced luminance
and saturation with a lower mean square error and fog
density factor.

Abbreviations

BCP: Bright channel prior; BRISQUE: Blind/reference-less image spatial quality
evaluator; CNN: Convolutional neural network; DCP: Dark channel prior;
DEFADE: Density based reference less perceptual defogger; FADE: Fog-aware
density evaluator; GIF: Guided image filter; MSE: Mean square error; NIQE:
Naturalness image quality evaluator; PSNR: Peak signal to noise ratio; RESIDE:
Realistic single-image dehazing; SSIM: Structural similarity index

Acknowledgements
Not Applicable

Authors’ contributions

All authors contributed in preparation of this manuscript. AS is the main
author and carried out experimentation and generated results. KK was
involved in designing experiments and finalizing algorithms and was also
involved in writing the “Introduction” and “Results and discussion” sections of
the manuscript. AS was involved in writing the “Proposed methodology”

(2020) 2020:6

Page 13 of 14

section and provided some section of algorithm. All authors read and
approved the final manuscript.

Authors’ information

Aneela Sabir is a graduate student of School of Electrical Engineering and
Computer Science (SEECS) at National University of Sciences and Technology
(NUST). Her areas of insterest are image processing and machine learning.

Dr. Knawar Khurshid obtained his doctorate degree from Michigan State
University in Biomedical Imaging Systems and currently he is the director of the
center of excellence in FPGA and ASIC research (CEFAR) at National University
of Sciences and Technology (NUST), Pakistan. Dr. Khurshid specializes in signal
and image processing, embedded systems, pattern recognition, and computer
vision, with research interests in the areas of image segmentation, registration,
multimedia encoding, 3D display systems, and wearable bio-sensor modules.
Dr. Ahmad Salman is associated with School of Electrical Engineering and
Computer Science, National University of Sciences and Technology,
Islamabad, Pakistan. He did his PhD from University of Manchester, UK, in
computer science and specializes in machine learning and speech information
processing.

Funding
This work is funded by National University of Sciences and Technology (NUST),
Islamabad, Pakistan.

Availability of data and materials
Nota applicable

Competing interests
Not applicable.

Received: 23 August 2019 Accepted: 28 January 2020
Published online: 17 February 2020

References

1. B.Li, W. Ren, D. Fu, D. Tao, D. Feng, W. Zeng, Z. Wang, Benchmarking
single-image dehazing and beyond. IEEE Trans Image Process. 28(1),
492-505 (2019)

2. Y. Xu, J. Wen, L. Fei, Z. Zhang, in [EFF Access. Review of video and image
defogging algorithms and related studies on image restoration and
enhancement, vol. 4, (2016), pp. 165-188

3. M.Wang, 5S. D. Zhou. The study of color image defogging based on
wavelet transform and single scale retinex International Symposium on
Photoelectronic Detection and Imaging. vol. 8194 (SPIE, 2011). https://
doi.org/10.1117/12.897331

4. X.He, J. Mao, Z. Liu, J. Zhou, Y. Hua, in Chinese Conference on Pattern
Recognition. A fast algorithm for image defogging (Springer, Berlin, 2014),
pp. 149-158

5. 1. K. Kim, J. K. Paik, B.S. Kang, Contrast enhancement system using

spatially adaptive histogram equalization with temporal filtering. IEEE

Trans. Consum. Electron. 44(1), 82-87 (1997)

6.  Z. Xu, X. Liu, X. Chen, in 2009 International Conference on Computational
Intelligence and Software Engineering. Fog removal from video sequences
using contrast limited adaptive histogram equalization (IEEE, 2009).
https://doi.org/10.1109/cise.2009.5366207

7. Y.Y.Schechner, S. G. Narasimhan, S. K. Nayar. Instant dehazing of images
using polarization (IEEE Comput. Soc, 2001). https://doi.org/10.1109/cvpr.
2001.990493

8. D. Miyazaki, D. Akiyama, M. Baba, R. Furukawa, S. Hiura, N. Asada, in 2073
IEEE International Conference on Computer Vision Workshops.
Polarization-based dehazing using two reference objects (IEEE, 2013).
https://doi.org/10.1109/iccvw.2013.117

9. R.T. Tan, in 2008 IEEE Conference on Computer Vision and Pattern
Recognition (CVPR). Visibility in bad weather from a single image (IEEE,
2008). https://doi.org/10.1109/cvpr.2008.4587643

10. Z. Chen, J. Shen, P. Roth, Single image defogging algorithm based on
dark channel priority. J. Multimed. 8(4), 432-438 (2013)

11. K. He, J. Sun, X. Tang, Single image haze removal using dark channel prior.
IEEE Trans. Pattern Anal. Mach. Intell. 33(12), 2341-2353 (2011)

12. H. Xu, J. Guo, Q. Liu, L. Ye, in 2012 IEEE International Conference on
Information Science and Technology. Fast image dehazing using improved
dark channel prior (IEEE, 2012). https://doi.org/10.1109/icist.2012.6221729

 
Sabir et al. FURASIP Journal on Image and Video Processing

13.

14.

15,

16.

17.
18.
19,
20.
21.
22.

23.

24.

25,

26.

2/.

28.

29,

30.

31.

32.

33.

34.

35.

X. Chen, W. Sun, in Proceedings of the 2015 International Conference on
Mechatronics, Electronic, Industrial and Control Engineering. A fast
algorithm for single image dehazing based on estimating illumination
veil (Atlantis Press, 2015). https://doi.org/10.2991/meic-15.2015.225

J. Tang, Z. Chen, B. Su, J. Zheng, in Chinese Conference on Image and
Graphics Technologies. Single image defogging based on step estimation
of transmissivity (Springer, Singapore, 2017), pp. 74-84

D. Nair, P. Sankaran, Color image dehazing using surround filter and dark
channel prior. J. Vis. Commun. Image Represent. 50, 9-15 (2018)

A. Li, X. Li, in 2017 10th International Symposium on Computational
Intelligence and Design (ISCID). A novel image defogging algorithm based
on improved bilateral filtering (IEEE, 2017). https://doi.org/10.1109/iscid.
2017.126

W. Zhang, X. Hou, Light source point cluster selection-based atmospheric
light estimation. Multimed. Tools. Appl. 77(3), 2947-2958 (2018)

M. Zhu, B. He, Q. Wu, Single image dehazing based on dark channel prior
and energy minimization. IEEE Sig. Process Lett. 25(2), 174-178 (2018)
Z.Li, J. Zheng, Single image de-hazing using globally guided image
filtering. IEEE Trans. Image Process. 27(1), 442-450 (2018)

M. Ju, D. Zhang, X. Wang, Single image dehazing via an improved
atmospheric scattering model. Vis. Comput. 33(1 2), 1613-1625 (2017)

Y. Lee, K. Hirakawa, T. Q. Nguyen, Joint defogging and demosaicking. IEEE
Trans. Image Process. 26(6), 3051-3063 (2017)

M. 1. Anwar, A. Khosla, Vision enhancement through single image fog
removal. Eng. Sci. Technol. Int. J. 20(3), 1075-1083 (2017)

A.M. Chaudhry, M. M. Riaz, A. Ghafoor, A framework for outdoor RGB
image enhancement and dehazing. IEEE Geosci. Remote Sens. Lett. 15(6),
932-936 (2018)

Z. Tufail, K. Khurshid, A. Salman, |. F. Fareed Nizami, Khurshid K., B. Jeon,
Improved dark channel prior for image defogging using RGB and YCbCr
color space. IEEE Access. 6, 32576-32587 (2018)

A. Makarau, R. Richter, R. Maijller, P. Reinartz, Haze detection and removal
in remotely sensed multispectral imagery. IEEE Trans Geosci. Remote
Sens. 52(9), 5895-5905 (2014)

A. Makarau, R. Richter, D. Schladpfer, P. Reinartz, Combined haze and
cirrus removal for multispectral imagery. IEEE Geosci. Remote Sens. Lett.
13(3), 379-383 (2016)

Y. Liu, H. Li, M. Wang, Single image dehazing via large sky region
segmentation and multiscale opening dark channel model. IEEE Access.
5, 8890-8903 (2017)

Y. Hong, C. Cai, in 2076 IEEE 20th International Conference on Computer
Supported Cooperative Work in Design (CSCWD). An adaptive factor-based
method for improving dark channel prior dehazing (IEEE, 2016). https://
doi.org/10.1109/access.2018.2843261

C. Cai, Z. Qiuyu, L. Yanhua, in 2075 IEEE International Conference on
Mechatronics and Automation (ICMA). Improved dark channel prior
dehazing approach using adaptive factor (IEEE, 2015. https://doi.org/10.
1109/icma.2015.7237742

T.H. Kil, S. H. Lee, N. |. Cho, in 2073 IEEE International Conference on Image
Processing. Single image dehazing based on reliability map of dark
channel prior IEEE, 2013). https://doi.org/10.1109/icip.2013.6738182

C. Qing, Y. Hu, X. Xu, W. Huang, in 2077 IEEE International Conference on
Internet of Things (iThings) and IEEE Green Computing and Communications
(GreenCom) and IEEE Cyber, Physical and Social Computing (CPSCom) and
IEEE Smart Data (SmartData). |mage haze removal using depth-based
cluster and self-adaptive parameters (IEEE, 2017). https://doi.org/10.1109/
ithings-greencom-cpscom-smartdata.2017.163

R. Li, J. Pan, Z. Li, J. Tang, in 2078 IEEE/CVF Conference on Computer Vision
and Pattern Recognition. Single image dehazing via conditional generative
adversarial network (IEEE, 2018). https://doi.org/10.1 109/cvpr.2018.00856
L. K. Choi, J. You, A. C. Bovik, Referenceless prediction of perceptual fog
density and perceptual image defogging. IEEE Trans. Image Process.
24(11), 3888-3901 (2015)

J. Li, G. Li, H. Fan, Image dehazing using residual-based deep CNN. IEEE
Access. 6, 26831-26842 (2018)

K. Tang, J. Yang, J. Wang, in 2014 IEEE Conference on Computer Vision and
Pattern Recognition. Investigating haze-relevant features in a learning
framework for image dehazing (IEEE, 2014). https://doi.org/10.1109/cvpr.
2014.383

(2020) 2020:6

36.

37.

38.

39.

 

 

45.

 

Page 14 of 14

W. Ren, S. Liu, H. Zhang, J. Pan, X. Cao, M. H. Yang, in European Conference
on Computer Vision. Single image dehazing via multi-scale convolutional
neural networks (Springer, Cham, 2016), pp. 154-169

B. Cai, X. Xu, K. Jia, C. Qing, D. Tao, Dehazenet: An end-to-end system for
single image haze removal. IEEE Trans. Image Process. 25(11), 5187-5198
(2016)

B. Li, X. Peng, Z. Wang, J. Xu, D. Feng, in 2017 IEEE International Conference
on Computer Vision (ICCV). Aod-net: All-in-one dehazing network (IEEE,
2017). https://doi.org/10.1109/iccv.2017.511

W. Ren, L. Ma, J. Zhang, J. Pan, X. Cao, W. Liu, M. H. Yang, in 2078 IEEE/CVF
Conference on Computer Vision and Pattern Recognition. Gated fusion
network for single image dehazing (IEEE, 2018). https://doi.org/10.1109/
cvpr.2018.00343

C. Li, J. Guo, F. Porikli, H. Fu, Y. Pang, A cascaded convolutional neural
network for single image dehazing. IEEE Access. 6, 24877-24887 (2018)
K. He, J. Sun, X. Tang, Guided image filtering. IEEE Trans. Pattern Anal.
Mach. Intell. 6, 1397-1409 (2013)

J. P. Tarel, N. Hautire, in JEEE 12th International Conference on Computer
Vision. Fast visibility restoration from a single color or gray level image
(IEEE, 2009). https://doi.org/10.1109/iccv.2009.5459251

D. Singh, V. Kumar, Comprehensive survey on haze removal techniques.
Multimed. Tools Appl. 77(8), 9595-9620 (2018)

Z. Wang, A. C. Bovik, H.R. Sheikh, E. P. Simoncelli, Image quality
assessment: from error visibility to structural similarity. IEEE Trans. Image
Process. 13(4), 600-612 (2004)

X. Min, G. Zhai, K. Gu, Y. Zhu, J. Zhou, G. Guo, X. Yang, X. Guan, W. Zhang,
Quality evaluation of image dehazing methods using synthetic hazy
images. IEEE Trans. Multimed. 21(9), 2319-2333 (2019). https://doi.org/10.
1109/tmm.2019.2902097

A. Mittal, R. Soundararajan, A. C. Bovik, Making a completely blind image
quality analyzer. IEEE Sig. Process. Lett. 20(3), 209-212 (2013)

A. Mittal, A. K. Moorthy, A. C. Bovik, No-reference image quality assessment
in the spatial domain. IEEE Trans. Image Process. 21(12), 4695-4708 (201 2)
X. Min, G. Zhai, K. Gu, X. Yang, X. Guan, Objective quality evaluation of
dehazed images. IEEE Trans. Intell. Transp. Syst. 20(8), 2879-2892 (2018)

Publisher’s Note
Springer Nature remains neutral with regard to jurisdictional claims in
published maps and institutional affiliations.

 

 

Submit your manuscript to a SpringerOpen®
journal and benefit from:

> Convenient online submission

> Rigorous peer review

> Open access: articles freely available online
> High visibility within the field

> Retaining the copyright to your article

 

Submit your next manuscript at > springeropen.com

 

 
