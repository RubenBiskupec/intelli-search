International Journal of Electrical and Computer Engineering (J ECE)
Vol. 10, No. 6, December 2020, pp. 5678~5686
ISSN: 2088-8708, DOI: 10.1159 1/ijece.v1016.pp5678-5686 O 5678

An efficient method to classify GI tract images from WCE

using visual words

R. Ponnusamy!, S. Sathiamoorthy’, R. Visalakshi?

'Department of Computer and Information Science, Annamalai University, India
Controller of Examinations, Tamil Virtual Academy, India
’Department of Information Technology, Annamalai University, India

Article Info
Article history:

Received Jun 20, 2019
Revised May 9, 2020
Accepted May 27, 2020

Keywords:

Auto color correlogram
Center symmetric

Feature transform

Local binary pattern
Support vector machine
Wireless capsule endoscopy

ABSTRACT

The digital images made with the wireless capsule endoscopy (WCE) from
the patient's gastrointestinal tract are used to forecast abnormalities. The big
amount of information from WCE pictures could take 2 hours to review GI
tract illnesses per patient to research the digestive system and evaluate them.
It is highly time consuming and increases healthcare costs considerably.
In order to overcome this problem, the center symmetric local binary pattern
(CS-LBP) and the auto color correlogram (ACC) were proposed to use
a novel method based on a visual bag of features (VBOF). In order to solve
this issue, we suggested a visual bag of features (VBOF) method by
incorporating scale invariant feature transform (SIFT), CS-LBP and ACC.
This combination of features is able to detect the interest point, texture and
color information in an image. Features for each image are calculated to
create a descriptor with a large dimension. The proposed feature descriptors
are clustered by K- means referred to as visual words, and the support vector
machine (SVM) method is used to automatically classify multiple disease

abnormalities from the GI tract. Finally, post-processing scheme is applied
to deal with final classification results i.e. validated the performance of
multi-abnormal disease frame detection.

Copyright © 2020 Institute of Advanced Engineering and Science.
All rights reserved.

Corresponding Author:

R. Ponnusamy,

Department of Computer and Information Science,
Annamalai University,

Annamalainagar, Chidambaram, Tamilnadu, India.
Email: povi2006@ gmail.com

1. INTRODUCTION

Wireless capsule endoscope (WCE) [1] has considered as diagnostic tool for gastrointestinal (GI)
tract [1]. It offers a non-invasive direct option in contrast to conventional endoscope and empowers doctors
to investigate the GI tract which is generally not open [2]. Compared with conventional endoscopy systems,
WCE not just gets full access to the small digestive system [3, 4], yet in addition offers the patients an
effortless strategy. WCE is a pill shaped gadget consisting of a brief core length complementary metal oxide
semiconductor (CMOS) sensor consisting of four light sources, a battery, radio transmitter and other
small-scale segments as appeared in Figure 1. The container is gulped by patient, taking pictures for every
second (fps) at a speed of two images. The endoscopic container travel through the GI tract, catching and
remotely transmitting in excess of 55000 frames to the recorder attached to the patient's midriff. Whereas
WCE catches color images of the GI tract for roughly 8 hours and transmits them remotely to an outside
information recording gadget worn by the patient around the midsection. These images are then downloaded
to a computer workstation, and assessed by clinicians to settle on restorative analytic choice.

In spite of the fact that WCE is a specialized achievement, the looking into of video and elucidation
of the entire inexact 50,000 images for every patient take around two hours for an accomplished clinician [5].

Journal homepage: http://ijece.iaescore.com/index.php/IJ ECE
Int J Elec & Comp Eng ISSN: 2088-8708 O 5679

The abnormal images for the most part possess just under 5% of the entire ones. Besides, spatial qualities of
anomalous images, the shape, surface, estimate, and the diverge from their encompassing change are hard for
clinicians to recognize variation from the images in all circumstances [6]. At this point, planning an
automatic computer-aided system is essential to help clinicians investigate abnormal images. More work has
as of now been embraced on automatic abnormal images detection in WCE videos. Several works are used to
carried out to define a particular disease.

    
 

 

- —
: fa
(@°- 2€O@eé@
i 2 3 4 5 6 ? 8

 

Figure 1. Diagram for components of WCE, 1) optical dome, 2) focal point holder, 3) focal point,
4) lighting up source, 5) CMOS pictures, 6) battery, 7) transmitter, 8) reception apparatus

The manuscript is arranged according to the following. Section 2, we discussed the associated
works. The manuscript has been organized in this way. In section 3, deals about the feature extraction where
we introduced the SIFT algorithm, CS-LBP and ACC features. Then the computation of feature vector by
combining these three features were also discussed in section 3. The visual bag of words depiction using
K-means is discussed in section 4. We briefly discuss the classification algorithm in section 5. Section 6 has
experimental results where we have a brief description about the dataset with discussions about the results
and comparison with the existing systems. Finally, section 7 is where the conclusion is provided.

2. RELATED WORKS

In many works in WCE videos, automatic identification of multi-anomalies disease has been
suggested. The most common diseases in the GI tract are bleeding [7], colon [8], polyp [9], tumor [10],
stomach [11] and ulcer [12] disease. The existing system for the detection of WCE image considers only one
abnormality like bleeding or ulcer or tumor and also multi-abnormality detection is far from satisfactory.
However, much work related to GI abnormality detection has done in WCE videos [13, 14]. A single WCE
frame or picture includes distinct problems including distinct colours, poor contrast, fuzzy areas, complicated
background, form of lesions, data on texture, etc. [15]. Bleeding is a prevalent symptom of many
gastrointestinal (GI) diseases, and the identification of bleeding is therefore of excellent clinical significance
in the diagnosis of appropriate diseases. Li and Meng [16] describe chrominance time as a color
characteristic and periodic Local binary pattern (LBP) as a texture characteristic for identifying the bleeding
areas within a WCE frame. The techniques were evaluated using support vector machine (SVM), liner
discriminant analysis (LDA) and k-nearest neighbor (KNN) classifier were utilized. A small group of cells
that develops on the colon's lining are called as polyps due to unusual cell growth. For image processing
based on linear data, polyp identification using the Log Gabor filters and the SUSAN edge detection
algorithm is done in karargyris et al., [17]. In [18], a method called global geometric constraints of polyp and
local patterns of intensity variation across polyp boundaries is suggested for classifying digestive organs,
the deep CNN is used for WCE images.

For ulcer identification in WCE images, neural networks can be used for the removal of
characteristics by Gabor filters and colors and texture characteristics. for classifying images. The authors
of [19] proposed to detect the ulcer abnormality using AdaBoost learning method. Despite the efficacy of
AdaBoost, a straightforward RGB value as a hint for the assignment of ulcer discrimination is used to obtain
the specific local and global visual features [19]. In [20], characteristics such as probability of bit plane and
wavelet-based characteristics were removed from the recognized fields and used to characterize ulcer.
Hoghan et al., [21] discussed, the Hookworm present in the stomach related tract of the human from WCE
images using color model-based recognition were the shading models actualized here are the RGB and HSV
models. Yuan et al., [22] suggested an enhanced bag of features (BoF) technique to help classify polyps in

An efficient method to classify GI tract images from WCE using visual words (R. Ponnusamy)
5680 O ISSN: 2088-8708

WCE images. Instead of using a single scale-invariant function transform (SIFT) in the traditional
BoF method, different textural features such as LBP, uniLBP, CLBP and HOG from the key points
neighborhoods are integrated as synthetic descriptors to perform classification. The associated works show
that several works are carried out to define the particular disease. Color and LBP [16] characteristics are used
for the identification of bleeding. For the ulcer the Gabor filter [17], color and texture are used and for
the detection of polyp. In fact, the classification precision of the above-mentioned schemes is not yet well
achieved and there were no SIFT characteristics that are linear in scale, rotation and illumination,
except polyp.

To overcome this problem and to address the multiclass disease classification of WCE images and
to considerably increase the accuracy of disease prediction, we proposed a system using the combination of
SIFT, CS-LBP and ACC is compared with color, LBP and BOF for bleeding and polyp respectively.
The proposed combination is also tested against the aforementioned systems for tumor, colon, stomach and
ulcer diseases. Figure 2 shows the proposed work for the classification of multi-abnormalities in GI tract
using WCE images. In this proposed work, a range of anomalies disease images is drawn from GI tract using
WCE and a novel method is proposed based on BOF by integrating SIFT, CS-LBP and ACC. These features
are able to detect the interest point, texture and color information in an image more effectively. Features are
calculated to create a high-dimensional descriptor for each picture and this descriptor is grouped using
the K-means technique referred to as visual bag of features, then SVM method is used to classify
the multiple abnormalities of disease present in GI tract automatically and more effectively.

  
  

Feature
Extraction
Patches Clustering by
SIFT, CS-LEP, using K-means
Ac

     
 

a
™

a) e visual words
> Class fied
_— — images

_

git i, | |
Abnormalities Aj Classification A Histogram
occur using SYM of words

Figure 2. Proposed work for the classification of multi-abnormalities in GI tract using WCE images

Input images

0

3. FEATURE EXTRACTION
3.1. SIFT

Gaussian's Laplacian is good to find interesting points (or main points) in a picture that are maxima
and minima in the Gaussian picture distinction. Upon detection of interest points, characteristics such as
SIFT are outlined. SIFT is an algorithm for the detection and description of local characteristics in pictures
that David Lowe released in 1999 [23]. A circular region of picture with orientation is a SIFT key point.
Four parameters in this technique are key point center, the scale (the area radius) and its orientation
(an angle expressed in radians). SIFT detector is stated to be invariant and robust in translation, rotation,
scaling, and partly invariant in order to affinate changes in distortion and lighting [23].

3.2. Local binary pattern (LBP)

A strong function for texture classification is known to be the LBP [23]. In 2009, LBP and
histogram of orienting gradients (HOG) showed that detection efficiency was largely improved by
Want et al. [24]. In [25], LBP was used as an efficient, nonparametric technique for texture analysis by Unay
and Ekin. LBP was used to extract valuable data from medical images, especially magnetic brain resonance
images. A content-based picture recovery algorithm was used to extract the characteristics. Their experiment
has shown that the texture data along with spatial characteristics is better than only texture characteristics
based on intensity. In 2007, the micro-matterns were removed with LBP by Oliver et al. [26] from
mammograms. These masses are classified as benign or malignant with SVM. The findings of their research
showed LBP's efficiency, as the amount of false positive characteristics decreased in all mass sizes [27].

Int J Elec & Comp Eng, Vol. 10, No. 6, December 2020 : 5678 - 5686
Int J Elec & Comp Eng ISSN: 2088-8708 O 5681

3.3. Center-symmetric local binary pattern (LBP)

A description of the region of concern has been created for center-symmetric local binary patterns
(CS-LBP) [28, 29]. CS-LBP seeks to generate shorter histograms for a larger amount of LBP labels that are
more suitable for use in regional descriptors. In flat picture areas, CS-LBP was also intended to have greater
stability. In CS-LBP, pixel values are compared symmetrically with the center pixel, not with the center
pixel, but with the opposing pixel. In addition, robustness is achieved in flat picture areas by thresholding
variations in gray levels with a tiny value T.

N/2-1

CS — LBPry r(x, y) = ». s(nj — Ni+n/2)2', s(x) = {

i=0

1 x>T
0 otherwise

Where nj and ni+2) equally spaced pixels on a circle of radius R corresponds to the gray values of
the central-symmetric pairs of N-Pixels. The T limit value in our experiments is about 1% of the pixel value
range. Since information for the region range from O to 1, T is set to 0.01. The size of the area is 8.
The radius is set to 2. It is worth noting that CS-LBP's advantage over LBP is not just because of the decrease
of the dimensions, but because the CS-LBP is better able to capture the gradient data than the fundamental
LBP. LBP and CS-LBP experiments have demonstrated CS-LBP's advantages over LBP, particularly
substantial decrease in dimension while maintaining distinguishability.

3.4. Auto color correlogram
The suggested scheme uses the autocorrelogram to calculate the color feature. Let [D] denote a set
of {dl ... dD} fixed distances. Then the picture I correlogram is described at a range d for level pair (g;, g;).

d _
Vora) (1) = PIpicig, Pilg; IP. E Ig, |P1 ~ Py = d\|

Which provides the possibility that if a pixel pl is g; level, a pixel p2 is g; level at the range d in some
direction from the pixel pl. The spatial correlation of the same concentrations is found in the auto
correlogram.

d d
0G” (1) = p01)
It provides the likelihood that pixels pl and p2, d separate from each other, are of the same level g;.
The range measurement between histograms, auto correlograms, and correlograms is the L1 standard that is
a computationally fast technique used in [30-33].

3.5. CS-LBP, SIFT and ACC features integration
If the background is complicated or corrupted with noise, SIFT can perform badly, CS-LBP with
standardized patterns is complementary to SIFT by filtering out these noises [34]. We believe that
the characteristics of an item in a image can be faster recorded by mixing these three features. This research
therefore proposes the inclusion of SIFT, CS-LBP and ACC at patch level and picture level. We describe
pi (x, y, 6, 9) as a key point spotted by SIFT approach, where (x, y) is the position of pixel pj; in the original
image, o and @ is the scale and main direction of p; respectively. o means to the confident level of pj in
Gaussian Pyramid. Take a region with size of 8x8 as a patch where pi is the center of the patch,
then the SIFT, CS-LBP and ACC descriptors are built as follows:
— Step 1. Use 128-dimensional SIFT descriptor to describe each keypoint p; in a patch, denoted as SIFT;
the image.
— Step 2. Choose a4 x 4 region around p; and compute the uniform pattern of each pixel. These descriptors
are composed as a 64-dimensional vector, 1.e.

Fes-tep ;=[CS — LBPy{t, CS — LBPiG ... «.- CS — LBP? |

— Step 3. For every patch ACC feature are calculated
— Step 4. Finally, the feature vector computed by combining the three features is described as

(Forer,,F CS—LBP;,MAcc;,)

An efficient method to classify GI tract images from WCE using visual words (R. Ponnusamy)
5682 O ISSN: 2088-8708

4. VISUAL BAG OF WORDS
4.1. K-means algorithm

The aim of k-means algorithm is to cluster the information and is one of the easiest methods of
clustering the partitions. Clustering the picture consists of grouping the pixels according to certain features.
We must originally identify the number of clusters in the k-means algorithm [35]. Then the center of
the k-cluster is randomly selected. The distance to each cluster center between each pixel is calculated.
Euclidean distance is used in particular. Using the range formula, single pixels are likened to all cluster
centers. The pixel is transferred to a specific cluster with the shortest range between all. The center is then
reassessed. Again, each pixel is compared to all centroids and the processes mentioned above are continued
until the pixel are grouped into a suitable cluster with the following algorithm described.

4.2. Bag of features

The Bag-of-features (BOF) techniques is mainly influenced by the notion of bag-of-words [36] that
was widely used in text mining. In the BOW model, every term is considered to be autonomous although
very contra intuitive and well utilized with outstanding performance in spam filtration and _ topical
modeling [37]. Each image is characterized by a set of orderless local characteristics in the BOF model,
later study has shown it efficacy in image processing. It has two main concepts: local features and codebook.
The essential aspect of the BoF concept is to extract global image descriptor which are computed from
the collection of local properties like SIFT, CS-LBP and ACC. The SIFT patches are tiny rectangular areas
with a focus on point of concern and the CS-LBP patches are tiny round zones with the required radius and
several sampling points. Auto correlogram collects only identical color values in the spatial correlation.

Codebook is a way to represent an image by a set of local features [38]. The idea is to group
the feature descriptors for all patches on the basis of a cluster number and each cluster is a visual word to
form a codebook. Each image can be depicted, after the codebook has been obtained, by the visual codebook
graphic frequency histogram BoF.

5. CLASSIFICATION USING SVM

In the proposed method, the SVM [39] is employed to classify the WCE images. SVM classifier is
the best option to classify problem, since our problem is to classify seven classes of abnormalities present in
GI tract. Considering a training dataset which consists of N images with feature vectors xj, 1=1,2,...N,
where each M dimensional expression profile x; = x; (n), n=1,2,,....M is associated with a feature value y;(+1,-1).
The objective is to find and M dimensional decision vector w = [wl, w2.... wm]! due to the discriminating
function f(x)=f(w,x). Such that:

w! x;+b>+1, for all positive x;
w! xi+b<-1, for all negative x;

Considering an empirical vector a and (N*N) dimensional kernel matrix K with its (i, j)" element
K(xi, yi), the decision boundary is characterized by f (x) = 0,
Where:

f (x) = YM, ak (xj, x)+b

where b and a; are bj as and weights respectively.

6. EXPERIMENTAL RESULTS
6.1. Dataset

The dataset is collected from Kvasir containing images of GI tract. The anatomical features are
Z-line, pylorus and cecum, while esophagitis, bleeding, polyps and ulcerated colitis are the pathological
findings. The dataset contains images of multi-abnormalities diseases which has 3500 of images in 7 classes
i.e. 500 images from each class for 40 patients. The set of images in each class is divide into two categories:
training and testing set. A five-fold strategy to cross validation has been implemented in the proposed work.
In this work, 80% of the images were randomly selected for training for each class and the other 20% for
testing. The multi-abnormalities disease contains the Z-Line, Bleeding, Pylorus, Cecum, Esophagitis, Polyps
and Ulcerative Colitis.

Int J Elec & Comp Eng, Vol. 10, No. 6, December 2020 : 5678 - 5686
Int J Elec & Comp Eng ISSN: 2088-8708 O 5683

6.2. Results and discussion

In our proposed method, the WCE images are divided into number of patches. From the patched
images features are extracted using three methods namely CS-LBP, SIFT and combined CS-LBP+SIFT+ACC.
First, study of codebook size for CS-LBP, SIFT and CS-LBP+SIFT+ACC with SVM is calculated. We selected
the size of codebook from {250, 500, 750, 1000}. The performance is shown in Figure 3. From the experiments,
we obtained the best size of codebook is 750 with patch size 8*8 for the dataset considered in the experiments.
For measuring the accuracy, the sensitivity and specificity method is used.

Performance (in %)

 

CS-LBP+SIFT
CS-LBP+SIFT
CS-LBP4+SIFT
CS-LBP+SIFT

CS-LBP+SIFT+ACC
CS-LBP+SIFT+ACC
CS-LBP+SIFT+ACC
CS-LBP4+SIFT+ACC

Codebooksize

 

Figure 3. Performance of varying codebook size

— Specificity: The amount of right adverse statements separated by the complete negative numbers is
calculated.

wpe TN
Specificity “TN4+FP

— Sensitivity: It is calculated the number of negative predictions divided by the total number of negatives.

es TP
Sensitivity=——
TP+FN

The performance of abnormalities using CS-LBP, SIFT and combined CS-LBP+SIFT+ACC with
SVM shown in Table 1. When comparing each class, the performance of combined CS-LBP+SIFT shows an
accuracy of 79.91 % for Esophagitis, 76.21% for Z-Line, 80.23% for cecum, 84.39% for Polyps, 85.92% for
Ulcerative Colitis, 90.91% for Pylorus and 94.80% bleeding is obtained. Table 2 shows the confusion matrix
for WCE image classification.

6.3. Comparison with existing work

Further the proposed work is compared with existing WCE abnormality classification
techniques [22, 40-42]. In [22], Yuan et al., classified the images into the normal ones and polyps using VQ
and VQ is used to encode the features and also it shows local features by their nearest codewords. In [41],
statistical based color, spatial and texture are features using bag of visual methods are proposed by Hwang.
Nawarathan et al., [42] proposed a method to denote image feature by texton histogram where LBP features
are cluster to obtained textons. The accuracy of SVM with CS-LBP+SIFT+ACC for Multi-abnormalities
classification is shown in Figure 4.

In proposed work, combination SIFT+CS-LBP+ACC is used for multi-abnormality classification.
Table 3 shows the accuracy of proposed abnormalities with existing work. Majority of existing work is
focussed on only one or two type abnormality detection and the accuracy is also not up to the level of
satisfactory. But we focused on all classes of GI tract diseases and we obtained remarkable improvement in
all classes of GI tract diseases and the overall accuracy of the proposed system is significantly high and is
84.62% which is owing to the combination of proposed effective texture and color features. The results
obtained for polyp, ulcer, bleeding, Esophagitis, Z-line, Cecum, pylorus is 84.39%, 85.92%, 96.85%,
79.91%, 76.21%, 80.23% and 90.91% respectively.

An efficient method to classify GI tract images from WCE using visual words (R. Ponnusamy)
5684. O ISSN: 2088-8708
1230
100

80 ae

60

=e aC CUIacy

40

Performnace (in %5)

20

Esophagitis  Z-Line Cecum Polyps Ulcerative Pylorus Bleeding
Colitis
Multiabnormalities

Figure 4. Shows the accuracy of SVM with CS-LBP+SIFT+ACC for Multi-abnormalities classification

Table 1. Performance of Abnormalities using SVM with CS-LBP, SIFT and combined CS-LBP with SIFT

Abnormalities Performance (in %) CS-LBP+SIFT CS-LBP + SIFT+ACC
Esophagitis Accuracy 72.50 79.91
Sensitivity 72.30 78.95
Specificity 94.28 96.1
Z-Line Accuracy 75.01 76.21
Sensitivity 74.05 75.21
Specificity 95.25 95.19
Cecum Accuracy 79.21 80.23
Sensitivity 78.95 80.01
Specificity 95.6 90.9
Polyps Accuracy 83.91 84.39
Sensitivity 83.20 84.21
Specificity 95.12 90.9
Ulcerative Colitis Accuracy 80.20 85.92
Sensitivity 80.71 84.21
Specificity 93.25 93.64
Pylorus Accuracy 89.01 90.91
Sensitivity 88.20 89.57
Specificity 93.25 93.25
Bleeding Accuracy 88.92 96.85
Sensitivity 88.23 90.11
Specificity 92.28 97.12

Table 2. Confusion matrix for WCE image classification

Esophagitis Z-Line Cecum Polyps Ulcerative Pylorus Bleeding _—_ Sensitivity
Colitis

Esophagitis 78.90 21.05 0 0 0 0 0 78.95
Z-Line 10.05 75.21 0 8.23 0 6.45 0 75.21
Cecum 0 6.67 80.00 13.33 0 0 0 80.00
Polyps 0 0 14.02 80.00 0 5.95 0 80.00
Ulcerative Colitis 5.26 0 0 5.26 84.21 5.26 0 84.21
Pylorus 5.20 2.30 2.93 0 0 89.57 0 89.57
Bleeding 0 0 0 3.15 0 0 96.85 96.85

Specificity 96.10 95.19 90.9 90.90 93.64 93.25 98.12

Table 3. Performance comparison of abnormalities classification with proposed and existing work

Polyp Ulcer Bleeding —_ Esophagitis Z-Line Cecum Pylorus
Coimbra et al., [37]. 74.67 72.78 87.9 Nil Nil Nil Nil
Hwang et al., [38]. 81.33 78.33 90.95 Nil Nil Nil Nil
Nawarathna et al., [39]. 84.00 83.33 93.33 Nil Nil Nil Nil
Yuan et al., [22]. 83.50 80.33 96.60 Nil Nil Nil Nil
Proposed system 84.39 85.92 96.85 79.91 76.21 80.23 90.91

Int J Elec & Comp Eng, Vol. 10, No. 6, December 2020 : 5678 - 5686
Int J Elec & Comp Eng ISSN: 2088-8708 O 5685

7. CONCLUSION

Classifying the abnormalities from WCE images such as Z-Line, Bleeding, Pylorus, Cecum,
Esophagitis, Polyps, Ulcerative Colitis is a challenging task. It may take 2 hours per patient for reviewing GI
tract diseases. It is highly time consuming and increases healthcare costs considerably. To overcome this
problem, we proposed Multi-Abnormalities classification model using Visual Bag of Words which is
constructed using CS-LBP with SIFT and combined CS-LBP, SIFT with ACC using K-means clustering
approach. The SVM is used for classification. By varying the codebook size from {250, 500, 750, 1000},
we obtained 750 as best size for out datasets. From the experiment results, it is demonstrated that
the accuracy of 79.91 % for Esophagitis, 76.21% for Z-Line, 80.23% for cecum, 84.39% for Polyps, 85.92%
for Ulcerative Colitis, 90.91% for Pylorus and 94.80% for bleeding is obtained for combined
CS-LBP+SIFT+ACC with SVM _ which is significantly higher than the existing approaches and
the combination of CS-LBP and SIFT. In future, the performance of the proposed system may be optimized
using various parameters to improve performance.

REFERENCES

[1] G. Iddan, G. Meron, A. Glukhovsky, and P. Swain, “Wireless capsule endoscopy,” Nature, vol. 405, no. 6785,
pp. 417-418, 2000.

[2] D.K. Iakovidis and A. Koulaouzidis, “Software for enhanced video capsule endoscopy: Challenges for essential
progress,” Nat. Rev.Gastroenterol. Hepatol., vol. 12, no. 3, pp. 172-186, 2015.

[3] B. Upchurch and J. Vargo, “Small bowel endoscopy,” Rev. Gastroenterol Disorders, vol. 8, no. 3, pp. 169-177, 2007.

[4] Mauro Manno, Carmelo Barbera, Helga Bertani, Raffaele Manta, Vincenzo Giorgio Miyrante Dabizzi, Angelo Caruso,
Flavia Pigo, Giampiero Olivetti, and Rita Conigliaro, "Single-balloon endoscopy: Technical ascepts and clinical
applications" in World Journal of Gastrointestinal Endoscopy, pp. 28-32, 2012.

[5] D.K. Iakovidis and A. Koulaouzidis, “Software for enhanced video capsule endoscopy: Challenges for essential
progress,” Nature Rev. Gastroenterol, vol. 12, no. 3, pp. 172-186, 2015.

[6] Y. Yuan, B. Li, and M. Q.-H. Meng, “Improved bag of feature for automatic polyp detection in wireless capsule
endoscopy images,” IEEE Trans. Autom. Sci. Eng., vol. 13, no. 2, pp. 529-535, 2016.

[7] Said Charfi, Mohamed El Ansari, “Computer-aided diagnosis system for colon abnormalities detection in wireless
capsule endoscopy images,” Multimedia Tools and Applications, pp. 1-18, 2017

[8] T. Ghosh, S. A. Fattah, and K. A. Wahid, “Automatic Computer Aided Bleeding Detection Scheme for Wireless
Capsule Endoscopy (WCE) Video based on Higher and Lower order Statistical Features in a Composite Color,”
Journal of Medical and Biological Engineering, vol. 38, no. 3, pp. 482-496, 2018

[9] Y. Yuan, Max Q.-H. Meng, “Deep Learning for Polyp Recognition in Wireless Capsule Endoscopy Images,”
American Association of Physicists in Medicine, vol. 44, no. 4, pp. 1379-1389, 2017

[10] M. Alizadeh, et al., “Detection of Small Bowel Tumor in Wireless Capsule Endoscopy images using an Adaptive
Neuro-Fuzzy Inference System,” The Journal of Biomedical Research, vol. 31, no. 5, pp. 419-427, 2017

[11] P. Sivakumar, B. Muthu Kumar, “A novel method to detect bleeding frame and region in wireless capsule
endoscopy video,” Cluster Computing, pp. 1-7, 2017

[12] Meryem Souaidi, Abdelkaher Ait Abdelouahed, Mohamed EI Ansari, “Multi-scale completed local binary patterns
for ulcer detection in wireless capsule endoscopy images,” Multimedia Tools and Applications, pp. 1-18, 2018

[13] Michael D. Vasilakakis, et al., “Weakly supervised multi-label classification for semantic interpretation of
endoscopy video frames,” Evolving Systems, pp. 1-13, 2018

[14] Y. Yanagawa, et al., “Abnormality tracking during video capsule endoscopy using an affine triangular constraint based on
surrounding features,” IPSJ Transactions on Computer Vision and Applications, vol. 9, no. 3, pp. 1-10, 2017

[15] Dimitris K. Iakovidis, et al., “Deep Endoscopic Visual Measurements,” [EEE Journal of Biomedical and Health
Informatics, pp. 1-9, 2018

[16] Li, B. and Meng, M.Q.H., "Computer aided detection of bleeding regions for capsule endoscopy images,"
IEEE Transactions on Biomedical Engineering, vol. 56, no. 4, pp. 1032-1039, 2009.

[17] A. Karargyris and N. G. Bourbakis, “Detection of small bowel polyps and ulcers in wireless capsule endoscopy
videos,” IEEE Trans. Biomed. Eng., vol. 58, no. 10, pp. 2777-2786, 2011.

[18] Tajbakhsh N, Gurudu S. R, Liang J., “Automatic polyp detection using global geometric constraints and local
intensity variation patterns,” 17" International conference on medical image computing and computer-assisted
intervention, pp. 179-187, 2014.

[19] Htwe T. M, et al., “Adaboost learning for small ulcer detection from wireless capsule endoscopy (WCE) images,”
Asia Pacific signal and information processing association (APSIPA), pp. 653-656, 2010.

[20] H. B. Bahar, et al., “Adapted bit-plane probability and wavelet-based ulcer detection in wireless capsule
endoscopy images,” Journal of Biomedical Engineering: Applications, Basis and Communications, vol. 28, no. 4,
pp. 1650029-1 - 10, 2016.

[21] Hoghan. Chen, J. Chen, Q. Peng, G. Sun, and T. Gan, “Automatic hookworm image detection for wireless capsule
endoscopy using hybrid color gradient and contourlet transform,” 6th International Conference on biomedical
engineering and informatics Biomedical Engineering and Informatics (BME]), pp. 116-120, 2013.

[22] Y. Yuan, Baopu Li, and Max Q.-H. Meng, “WCE abnormality detection based on saliency and adaptive locality-
constrained linear coding,” IEEE Transactions on Automation Science and Engineering, pp. 149-159, 2015.

An efficient method to classify GI tract images from WCE using visual words (R. Ponnusamy)
5686 O ISSN: 2088-8708

[23] D.T. Ojala, M. Pietikinen, and T. Maenpaa, “Multiresolution gray scale and rotation invariant texture classification
with local binary patterns,” IEEE Trans on PAMI, vol. 24, no. 7, pp. 971-987, 2002.

[24] Wang, X., Han, T. X., and Yan, S, “An HOG-LBP human detector with partial occlusion handling,” IEEE 12th
International Conference on Computer Vision, pp. 32-39, 2009.

[25] Unay, D., and Ekin, A, “Intensity verus texture for medical image search and retrieval,” 5th IEEE International
Symposium on Biomedical Imaging: From Nano to Macro, pp. 241-244, 2008.

[26] Oliver, A., Llado, X., Freixenet, J., and Marta, J., “False positive reduction in mammographic mass detection
using local binary patterns,” Medical Image Computing and Computer-Assisted Intervention — MICCAI 2007,
pp. 286-293, 2007.

[27] Marghani, K. A., Dlay, S. S., Sharif, B. S., and Sims, A. J., “Morphological and texture features for cancer tissues
microscopic images,” 5th IEEE International Symposium on Medical Imaging, pp. 1757-1764, 2003.

[28] Heikkilaé, M., Pietikaéinen, M., and Schmid, C., “Description of interest regions with local binary patterns,” Pattern
Recognition, vol. 42, no. 3, pp. 425-436, 2009.

[29] Hanane. Rami, Mohammed. Hamri and Lhoucine. Masmoudi, “Objects Tracking in Images Sequence Using
Center-Symmetric Local Binary Pattern (CS-LBP),” International Journal of Computer Applications Technology
and Research, vol. 2, no. 5, pp. 504-508, 2013.

[30] K. Nirmala and A. Subramani, "Content Based Image Retrieval System Using Auto Color Correlogram," Journal of
Computer Applications (JCA), vol. VI, no. 4, pp. 111-115, 2013.

[31] Nidhi Singhai, K. Shandilya, “A Survey On: Content Based Image Retrieval Systems,” International Journal of
Computer Applications, vol. 4, no. 2, pp. 22-26, 2010.

[32] C. H. Lin, R. T. Chen and Y. K. Chan, “A smart content-based image retrieval system based on color and texture
feature,” Image and Vision Computing, vol. 27, no. 6, pp. 658-665, 2009.

[33] K. Seetharaman, S. Sathiamoorthy, “An improved edge direction histogram and edge orientation auto correlogram
for an efficient color image retrieval,” 2013 International Conference on Advanced Computing & Communication
Systems (ICACCS), pp. 19-21, 2013.

[34] Adamo, F., Carcagni, P., Mazzeo, P. L., Distante, C., and Spagnolo, P., “TLD and Struck: A Feature Descriptors
Comparative Study,” International Workshop on Activity Monitoring by Multiple Distributed Sensing, pp. 52-63, 2014.

[35] R. Visalakshi, R. Ponnusamy, and K. Manikandan, “Literature Survey of Data Mining Clustering Algorithms,”
South Asian Journal of Research in Engineering Science and Technology, vol. 1, pp. 310-313, 2016.

[36] B. Triggs and F. Jurie, “Creating efficient codebooks for visual recognition,” Tenth IEEE International Conference
on Computer Vision (ICCV'05), vol. 1, pp. 604-610, 2005.

[37] Q. Tian, and S. Zhang, “Descriptive visual words and visual phrases for image applications,” ACM Multimedia,
pp. 19-24, 2009.

[38] A. Streicher, H. Burkhardt, and J. Fehr, “A bag of features approach for 3D shape retrieval,” International
Symposium on Visual Computing, ISVC 2009, Las Vegas, NV, USA, pp. 34-43, 2009.

[39] R. Ponnusamy, S. Sathiamoorthy, “An Efficient Gastrointestinal Hemorrhage Detection and Diagnosis Model for
Wireless Capsule Endoscopy,” International Journal of Recent Technology and Engineering (IJRTE), vol. 8 no. 3,
pp. 7549-7554, 2019.

[40] P. Salehpour, H. B. Bahar, G. Karimian and M. T, Coimbra and J. P. S. Cunha, “MPEG-7 visual descriptor-
contributions for automated feature extraction in capsule endoscopy,” IEEE Trans. Cirucits Syst. Video Technol.,
vol. 16, no. 5, pp. 628-637, 2006.

[41] S. Hwang, “Bag of visual words approach to abnormal image detection in wireless capsule endoscopy videos,”
7th International Symposium Advances in Visual Computing ISVC 2011, Las Vegas, NV, USA, Part II,
pp. 320-327, 2011.

[42] R. Nawarathna et al., “Abnormal image detection in endoscopy videos using filter bank and local binary patterns,”
Neurocomputing, vol. 144, pp. 70-91, 2014.

Int J Elec & Comp Eng, Vol. 10, No. 6, December 2020 : 5678 - 5686
