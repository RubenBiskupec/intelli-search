COMPUTERS & SECURITY 99 (2020) 102023

 

 
    

   
    
     

Aivew

j
L, ¥
« aS a IZ
¢ DCAM GtP an? 8
SO
8 ¢ 34
BY

wAe=

Available online at www.sciencedirect.com

; ; Computers
ScienceDirect &

Security

journal homepage: www.elsevier.com/locate/cose

 

~ Shoulder surfing experiments: A systematic ®

literature review

Check for
updates

 

Leon Bosnjak*, BoStjan Brumen

Faculty of Electronics and Computer Science, University of Maribor, Koroska cesta 46, 2000 Maribor, Slovenia

ARTICLE INFO

Article history:

Received 10 November 2019
Revised 15 July 2020

Accepted 25 August 2020
Available online 29 August 2020

Keywords:

Shoulder surfing

Graphical passwords
Authentication

Systematic literature review
Evaluation framework
Experimental design

 

1. Introduction

ABSTRACT

In search of the silver bullet to solve the password problem, the field of knowledge-based
authentication has become bloated with novel proposals aiming to replace textual pass-
words. The emphasis on the quantity of studies as opposed to the quality of evaluation has
made it difficult to compare the methods, as well as to validate and generalize the results.
To improve the quality of security and usability evaluations, experimental design decisions
should be reviewed and standardized. In this systematic review, we focus on the evaluation
of the shoulder surfing attack (SSA) vulnerability. We formulate two research questions to
help us determine how the design of the method should affect the SSA experimental de-
sign process, and how different design decisions affect the validity and interpretability of
the results under various assumptions and threat models. To provide the researchers with
comprehensive literature on SSA evaluation, we identify empirical shoulder surfing stud-
ies conforming to a predefined set of quality criteria. Based on the design features extracted
from the experiments, we develop an evaluation framework for the assessment of the shoul-
der surfing experimental setup. In the follow-up analysis, we assess the proposed methods’
design features, and the quality of their SSA experiments, using Schaub et al.’s design aspect
and our SSA evaluation frameworks, respectively. Through exhaustive analysis, we strive to
streamline and standardize experimental decisions by showcasing their impact on the out-
come of the study, and generate guidelines for a more objective design of shoulder surfing
experiments.

© 2020 The Authors. Published by Elsevier Ltd.
This is an open access article under the CC BY-NC-ND license
(http://creativecommons.org/licenses/by-nc-nd/4.0/)

usability alike has proven to be a difficult task. Essentially, it
can be modelled as a multi-objective optimization problem
in which security and usability are the two key parameters.

For the past forty years, one of the greatest challenges in the
field of authentication has been designing schemes that are
both secure and usable. The primary aim of these studies has
been to replace or complement textual passwords, which have
been enjoying wide-spread use since the earliest days of com-
puting. However, developing a scheme that would be decid-
edly better than textual passwords in terms of security and

* Corresponding author.

In this scenario, textual passwords have remained an opti-
mal solution, which has made them unlikely to be replaced by
any existing authentication mechanisms. The famous ”pass-
word dilemma” has become a no-win situation, in which we
have to decide between continuing to use passwords despite
the growing problems and security breaches associated with

E-mail addresses: leon.bosnjak@um.si (L. BoSnjak), bostjan.brumen@um.si (B. Brumen).

https://doi.org/10.1016/j.cose.2020.102023

0167-4048/© 2020 The Authors. Published by Elsevier Ltd. This is an open access article under the CC BY-NC-ND license

(http://creativecommons.org/licenses/by-nc-nd/4.0/)
2 COMPUTERS & SECURITY 99 (2020) 102023

them, or switching for a new method with a similar or inferior
arrangement of security-usability benefits.

One potential solution to the age-old password problem
would be to develop a scheme with a superior arrangement
of key parameter values. In pursuit of this goal, a plethora of
authentication mechanisms, classified into broad categories,
have been proposed over the decades. Among them, graph-
ical passwords are particularly interesting because they aim
to preserve the textual alternative’s usability, while signifi-
cantly improving security. By employing visual elements and
cues instead of alphanumeric characters, they strive to im-
prove password memorability while also mitigating guessing
attacks. However, their visual features make them more sus-
ceptible to other potential threat channels, such as the obser-
vational attacks.

In order to accurately place novel proposals on the
security-usability continuum, the methods should be thor-
oughly evaluated against all possible threats. Considered vul-
nerable to the observation of password input due to visual
elements present, graphical passwords are often examined
in terms of their resilience to shoulder surfing. However, the
evaluation setup and study assumptions differ from one study
to another. Part of the reason for this stems from the lack
of metrics for comprehensive evaluation, and common stan-
dards for design and execution of empirical shoulder surfing
studies. In addition to that, the proposed graphical schemes
also greatly differ in how they are designed, which can in turn
affect the threat scenarios most likely to occur. As even the
smallest changes in experimental design can greatly affect the
outcome of the study and its validity, the published studies are
often not comparable and the conclusions drawn from them
cannot be generalized.

Without being familiar with the existing empirical studies
and understanding the broader context of the executed shoul-
der surfing experiments, researchers are unable to make in-
formed design decisions about their own experimental setup.
Hence, it is important to identify the empirical research al-
ready conducted in the field of graphical passwords in or-
der to provide them with a systematic breakdown of rele-
vant papers based on their experimental design. This will not
only allow the researchers to find similar graphical schemes
to their proposed method for comparison, but also shed
light on how specific design decisions affect the results, and
how they should be interpreted. The overarching goal of
this study is to provide the researchers with comprehen-
sive knowledge on design and execution of shoulder surf-
ing experiments. Toward this goal, we will critically examine
all existing works and studies in the field of authentication,
and use our insights to generate guidelines for future SSA
experiments.

To summarize, user authentication in general — and, more
specifically, textual passwords — remain one of the most
critical information security problems. In response, the last
decades have witnessed an uptrend in novel authentication
methods aiming to replace them. It is essential to compre-
hensively evaluate these methods so that they can be fairly
compared to textual passwords. This means novel schemes
should be assessed against threats relevant to them (rather
than textual passwords) such as, for instance, their suscepti-
bility to being observed. Graphical password systems repre-

sent one of the method types most susceptible to this attack
vector. However, even though many graphical methods are be-
ing proposed and evaluated, their SSA evaluations are gener-
ally poor because the existing research methodology is un-
derdeveloped. To draw well-founded conclusions about such
graphical password systems, strong experimental designs and
testing are needed.

In our paper, a framework for the evaluation of shoul-
der surfing experimental design is established based on the
conducted systematic literature review. Although we focused
on graphical passwords due to their inherent vulnerability to
shoulder surfing, the framework allows for the assessment
of any SSA experimental setup, even outside authentication.
With this, we make an important contribution toward better
evaluation of shoulder surfing vulnerability.

This can be seen as a foundational step toward a more
objective approach to creating new authentication schemes.
Whereas currently, novel methods are devised based on ex-
pert knowledge and general intuition, method design should
instead be driven by well-established experimental evalua-
tion. Ultimately, this should allow us to maximize the objec-
tively desirable features in a password scheme — a process we
dub ’password system engineering’.

 

2. Prior research

Despite the growing trend of novel proposals, there appear
to be very few systematic literature reviews (SLRs) in the
field of graphical passwords. One of the first survey papers
was published in 2005 and classified then-existing graphical
schemes into recognition-based and recall-based. The authors
discussed advantages and drawbacks of graphical passwords,
comparing them to the conventional textual passwords. They
highlighted several design challenges and implementation is-
sues to be considered by future studies (Suo et al., 2005). The
paper was followed by several smaller surveys, in which the
existing graphical methods were classified into categories and
compared (Eljetlawi and Ithnin, 2008; Lashkari and Farmand,
2009; Towhidi and Masrom). In 2012, Biddle et al. conducted
a comprehensive review of all published research in the field
of graphical passwords, focusing on the evaluation of security
and usability aspects. The authors highlighted the schemes’
novel features, showcasing the diversity in the field. Through
the review of the schemes’ security and usability features and
requirements, they identified methodological issues related to
experimental design and empirical evaluation (Biddle et al.,
2012). In 2014, van Eekelen et al. proposed a classification and
evaluation framework for graphical passwords. They defined
five broad categories divided into several variables. Using this
framework, they evaluated 35 graphical schemes, presenting
them in the form of an evaluation matrix that was discussed
through the paper (Eekelen et al., 2014). The most recent SLRs
did not focus specifically on graphical passwords. Instead,
quite a few examined broader concepts within knowledge-
based schemes, such as social authentication (Alomar et al.,
2017) and mobile touch screen schemes (Ibrahim et al., 2019),
or even authentication as a whole (Velasquez et al., 2018).
While graphical passwords were also included in the analy-
sis, they were not the focal point of the SLRs, which aimed to
COMPUTERS & SECURITY 99 (2020) 102023 3

answer different research questions (such as finding authen-
tication methods most appropriate for multi-factor authenti-
cation (Velasquez et al., 2018).

Furthermore, none of the SLRs up to date examined novel
and existing authentication methods from the perspective of
shoulder surfing attacks. Whereas most SLRs recognize shoul-
der surfing as a valid threat, dedicating a section of the se-
curity analysis to it (Biddle et al., 2012; Eekelen et al., 2014;
Suo et al., 2005; Towhidi and Masrom), few address the prob-
lems related to the evaluation of these attacks. Biddle et al.
were among the first to call attention to the lack of stan-
dards for the security and usability evaluation of graphical au-
thentication schemes. They pointed out that nearly all stud-
ies employed different measures, which makes comparisons
between them difficult, if not invalid. Even when similar mea-
sures were used, they were often calculated differently, which
could result in them representing entirely different measures.
In the paper, the authors urged for coordinated work toward
the establishment of accepted standards for the evaluation
of security and usability aspects. While not providing explicit
suggestions for the evaluation of SSA, they suggest different
experimental setups based on types of graphical passwords
evaluated (Biddle et al., 2012). In another paper, the authors
attempt to solve the problem of multiple different measures
by introducing a composite security measure. In the scope
of the proposed measure, shoulder surfing is classified into
a broader category of observational attacks (English and Poet,
2011).

The challenges and problems of empirical shoulder surfing
studies were directly investigated in a 2015 study by Wiese and
Roth. Through a review of empirical papers, they identify sev-
eral experimental design issues and discuss the implications
they can have on the results and conclusions drawn from the
study. Based on that, they form guidelines aimed to improve
the future SSA experiments, which they support by present-
ing several case studies (Wiese and Roth, 2015). Their recom-
mendations were considered in a wide-scale shoulder surfing
experiment, in which first empirical evidence was provided
that graphical passwords are indeed easier to observe, and
that vulnerability to SSA is a complex measure which needs
to be analyzed on several levels of granularity (BoSnjak and
Brumen, 2019). As a first study to discuss the methodology
of SSA evaluation, Wiese and Roth’s paper laid the ground-
work for better design of shoulder surfing studies. Despite the
important contribution, their paper is only the first step to-
ward this goal. Upon closer inspection, several critical knowl-
edge gaps can be identified. Lacking a systematic approach,
the conducted review focuses their methodology inspection
on a subset of SSA papers discovered by the authors. Although
several design decisions were identified and discussed based
on this limited set, they do not represent a complete array of
considerations that the researchers need to make when set-
ting up a SSA experiment. More importantly, the paper does
not offer ground for evaluation and comparison of SSA stud-
ies with respect to method design, and experimental setup.
This prevents it from addressing more complex research ques-
tions, such as understanding the impact of a method’s design
aspects on its SSA evaluation, and identifying experimental
decisions that contribute to the study’s quality based on these
aspects. Our study can be considered a substantial advance-

ment of Wiese and Roth’s paper by addressing these short-
comings.

Aside from the few recent efforts put into standardizing
metrics, some work has been accomplished toward improv-
ing the methodologies of experimental studies in information
security. Beyond general methodology papers discussing the
challenges, characteristics, and limitations of experimental
design (Carroll et al., 2012; Krol et al., 2016), a variety of publicly
availabe, community-driven computer science testbeds (such
as DETER (Mirkovic et al., 2010), GENI (Berman et al., 2014), etc.)
offer indispensable resources to experimenters conducting
research in IT security. Concretely, the DETER project estab-
lishes an advanced scientific instrument aimed to ensure ex-
periment repeatability, validity, and usability (Mirkovic et al.,
2010). This is a major contribution toward higher quality ex-
periments, although it is not directly applicable to human-
oriented experimental setups because it does not cover as-
pects pertaining to the physical world (e.g. attacker position-
ing, camera location, etc.). Papers focusing on the execution
of user studies provide some additional information regard-
ing the participant sample and collection of statistically rele-
vant data (Salem and Stolfo, 2011), but lessons learned from
these studies are too general to address the specifics of shoul-
der surfing evaluation.

Little work has been done in the field to improve the eval-
uation of these attacks, specifically. As a result, shoulder surf-
ing attacks are still poorly understood. Consequently, many
different experimental designs and vulnerability metrics have
been employed in empirical studies, often without considera-
tion for the validity and comparability of the results. To avoid
making ad-hoc design decisions, researchers should be famil-
iar with similar empirical studies and the implications their
experimental setups have on the results. All of the previous
SLRs answered research questions related to graphical pass-
words but did not examine specifically how their susceptibil-
ity to SSA is evaluated empirically. Furthermore, no SLRs have
been conducted in the field of graphical passwords in the past
five years, despite the growing number of publications. There-
fore, it is imperative to provide a fresh summary of the recent
works and form guidelines based on the comprehensive as-
sessment of the existing experimental designs and measures
in order to guide new research activities.

2.1. Research questions and contributions

This systematic literature review is complementary to exist-
ing research in the fields of knowledge-based authentication
and shoulder surfing. To address the issues and challenges
of shoulder surfing studies, we define and expand on two re-
search questions, as described in Table 1.

The choice of both research questions was primarily moti-
vated by the factors that should be taken into account to fa-
cilitate high-quality SSA evaluation. One such important con-
sideration is that there are fundamental differences in how
the evaluated authentication methods are designed — a con-
sideration which is highly relevant to graphical passwords,
for which such design choices are directly reflected in the
method’s visual components. What existing authentication
proposals fail to consider is that these design aspects do not
affect only the method’s security and usability, but also our
4 COMPUTERS & SECURITY 99 (2020) 102023

Table 1 - Research questions.

Research questions Discussion

RQ1: What are the design aspects of
graphical authentication methods?

Graphical methods comprise a broad group of knowledge-based authentication mechanisms that
consist of graphical elements. The diversity in design aspects has made it difficult to compare

novel schemes in terms of security and usability. By classifying the novel schemes based on their
design features, the researchers can decide which other methods to compare their novel proposal
against in terms of SSA vulnerability. Finally, we provide insight into how the design aspects affect
the methods’ vulnerability to shoulder surfing, and derive guidelines for the design of shoulder
surfing resistant graphical methods.

Experimental design has a significant impact on the results obtained from the shoulder surfing

RQ2: What is the quality of the
executed shoulder surfing
experiments?

experiment. A comprehensive review of the experimental designs used in literature provides
understanding of how the design decisions can affect the analysis, and the conclusions drawn

from the study. Primarily, this research question should raise awareness about the importance of
experimental setup, and provide the researchers with a breakdown of design choices and their
effect on the results and conclusions. This will help researchers choose an appropriate
experimental setup based on their assumptions and threat model.

ability to evaluate and compare them in terms of their sus-
ceptibility to shoulder surfing. In order to conduct sound and
reliable experiments on such methods, it is essential to un-
derstand how these design aspects impact the experimenter’s
choice of methodology — and in turn, how these choices af-
fect the overall quality of the experiment. We can utilize this
knowledge in the endeavor toward more standardized metrics
and evaluation of the SSA vulnerability by identifying experi-
mental design choices most suitable in a given context.

The above clarification outlines a two-layered research
problem, characterizing a complex interrelation between a
method’s design aspects and experimental design choices.
Analogously, RQ1 investigates the characteristics of graphi-
cal authentication methods directly, whereas RQ2 examines
how the SSA experiments evaluating these methods are car-
ried out. It is crucial to point out that SSA experiment evalu-
ation was not restricted to only graphical passwords, or even
authentication methods in general. Although over 80% of SSA
studies in fact concerned graphical passwords, shoulder surf-
ing experiments may be relevant outside the field of graphi-
cal authentication as well. This prompted us to include them
in RQ2, effectively making it cover a broader field than RQ1.
While these non-graphical proposals are considered indepen-
dently, the majority of our extensive analysis hinges on graph-
ical passwords, and how their features influence experimen-
tal decisions. As such, while important conclusions can be
drawn from considering both research questions separately,
our main contribution can be extracted from how they relate
to one another.

Through addressing the research questions, we provide the
following contributions that will help improve the quality of
future shoulder surfing studies:

e We identify 77 primary studies employing an empirical ap-
proach to evaluate novel or existing knowledge-based au-
thentication methods up to mid-2019. We encourage other
researchers to use the list of studies to gain a broad per-
spective in the field to help them further their work. The
selected studies also meet rigorous quality criteria, making
them suitable benchmarks for comparisons against similar
research.

e We establish a framework for the assessment of the shoul-
der surfing experimental setup. Objective evaluation will
help the researchers make the correct experimental design
decisions, based on their assumptions and threat model.
We conduct a comprehensive review of the 77 studies ac-
cording to the evaluation framework and present a meta-
analysis of the current empirical shoulder surfing stud-
ies. The in-depth analysis explores the reasons behind and
the impact of design decisions, supported by empirical ex-
amples. Conclusions from lessons learned can be imple-
mented in future work to improve evaluations of novel and
existing authentication methods.

We highlight the previously undervalued ideas, consider-
ations, and challenges to produce guidelines and support
future work in the field.

This paper is structured as follows: Section 3 describes
the selection process through which the primary studies were
identified and subsequently evaluated in accordance with the
quality criteria. Section 4 discusses the main findings of the
analysis in order to address the research questions defined
earlier. Section 5 concludes the research and presents some
research directions for the future.

 

3. Research methodology

To address the research questions, a systematic literature re-
view was conducted in compliance with Kitchenham’s guide-
lines (Kitchenham et al., 2009). The SLR process applied in
this research is described in detail in the following sec-
tion, and summarized in the Systematic Review Protocol (see
Appendix A).

3.1. Selection of primary studies

A systematic literature review was carried out in May 2019
without timeframe restrictions. Primary studies were identi-
fied through a keyword search in relevant electronic databases
and search engines. The inclusion of indexing data sources al-
lowed us to broaden the search for publications not originally
COMPUTERS & SECU

included in publishing sites; full texts were obtained subse-
quently following the assessment against the inclusion crite-
ria. The following platforms were searched:

ACM) ACM Digital Library

GS) Google Scholar

IEEE) IEEE Xplore

MDPI) Multidisciplinary Digital Publishing Institute
SCP) Elsevier Scopus

SD) Elsevier ScienceDirect

SL) SpringerLink

WoS) Clarivate AnalyticsWeb of Science (WoS)

ON NN NN mn ™~

Considering that inconsistent terminology is used to de-
scribe shoulder surfing phenomena in information security
studies, several synonymous keywords were selected for the
search. Search strings were combined using the Boolean oper-
ator OR for inclusiveness, yielding the following search string:

(?’?shoulder surf*’’ OR ’’*shoulder attack*’’
OR ’’observation attack*’’)

In cases when the asterisk symbol (*) could not be used, the
original search query was replaced with the following:

(?’shoulder surf’’ OR ’’shoulder surfing’ ’)
OR (’?’shoulder attack’’ OR ’’shoulder
attacks’’) OR (’’observation attack’’ OR
>? observation attacks’’) OR (’’over the
shoulder attack’’ OR ’’over-the-shoulder
attack’ ’)

The keyword searches were run against the title, abstracts
or keywords, depending on the search engine. The results
were sorted by relevancy prior to the inspection, which was
important because the lack of advanced options in some
search engines returned many non-relevant results. Conse-
quently, up to 2000 most relevant results were evaluated for
every electronic database. The initial screening of the titles,
abstracts and keywords was performed independently by the
authors. To exclude irrelevant papers, the authors followed a
set of guidelines during the screening stage. Papers passed the
stage if:

Shoulder surfing is mentioned in the context of an obser-
vational attack on an authentication method,

A knowledge-based method is examined, and the authors
are uncertain about whether shoulder surfing was consid-
ered,

A token- or biometric-based method is considered, and the
authors can confirm a shoulder surfing experiment was
performed, or

RITY 99 (2020) 102023

e Shoulder surfing attacks are addressed outside any au-

thentication method investigations.

The primary reason why such broad guidelines were em-
ployed was to ensure that no potentially relevant study was
accidentally excluded from further evaluation. At the same
time, however, the screening stage greatly decreased the num-
ber of full-text papers needing to be evaluated in subsequent
stages, allowing the examiners to focus only on potentially rel-

evant papers.

3.2. Study eligibility and evaluation

Full-texts of the identified studies were obtained for the evalu-
ation stage. If a full-text could not be found, the study was ex-
cluded. Likewise, all duplicates appearing in several databases
were excluded prior to the evaluation. To determine the eli-
gibility of the retrieved literature, the papers were examined
against a predefined set of inclusion and exclusion criteria

(see Table 2).

To proceed to the analysis stage, an evaluated article was
required to meet most of the inclusion criteria and none of the
exclusion criteria. The requirement for original, peer-reviewed
publications targeted the paper’s minimum quality, while the
other two inclusion criteria addressed the content. To answer
the defined research questions, we were primarily interested
in empirical evaluations of shoulder surfing vulnerability. Alter-
natively, studies discussing approaches to conducting shoul-
der surfing experiments were also included to help with the
last research question. All other papers (such as those in-
cluding theoretical evaluations, attack algorithms, SSA detec-
tion/prevention techniques, and surveys) were deemed non-
relevant publications and were therefore excluded from fur-
ther evaluation. To determine whether a given paper complied
with the criteria, full-texts were examined. Some electronic
databases offer additional advanced search options, which al-
lowed us to exclude certain papers (particularly patents, grey
literature, and non-English papers) without the need to exam-

ine the full-texts, however.

3.3. | Quality assessment and synthesis

The final set of papers comprised of studies that included ex-
perimental evaluations of the shoulder surfing vulnerability.
Quality assessment was performed to identify any possible
research bias, and consider the validity of the experimental
data. Publications were graded according to the following pa-

rameters:

Table 2 — Inclusion and exclusion criteria for the primary studies.

Criteria for inclusion

Original research studies

Peer-reviewed publications

Publications evaluating observation or shoulder surfing
attacks on authentication methods

Publications addressing the methodology of shoulder
surfing studies

Criteria for exclusion

Papers covering computer security in general
Patents and grey literature
Secondary research, review papers, and other non-relevant publications

Publications plagiarizing another publication

Publications not in English
COMPUTERS & SECURITY 99 (2020) 102023

Table 3 - Quality assessment parameters.

Q. Parameter Points Quality indicator

1 Assumptions of the attacker, attack scenarios, extensive threat modelling
Threat Model (Q1) 0.5 Implied assumptions, less detailed threat modelling

0 No given threat model

1 Comprehensive demographic information, recruitment procedure
Participant Profile (Q2) 0.5 Basic information (number of participants, age, sex)

0 No information given

1 Detailed explanation of the experimental procedure, easy reproducibility
Experimental Setup (Q3) 0.5 Basic information about the experimental setup, difficult reproducibility

0 No information about the experimental setup

1 Clear, quantitative metrics, statistical tests
Quantitative Results (Q4) 0.5 Qualitative metrics, subjective metrics, no statistical tests

0 No metrics

Each reviewer performed the quality assessment indepen-
dently. Afterwards, the individual quality scores were com-
pared (rate of consensus was approximately 78%). In cases
of score disparity, a discussion between the reviewers was
held until a consensus was reached. All publications with a
summed quality score of 2 or lower were excluded from the
final analysis. The remaining papers were analyzed in detail
in accordance with the proposed evaluation parameters aim-
ing to comprehensively assess the experimental setup (see
Appendix B). Knowledge-based authentication methods were
additionally evaluated by method design attributes proposed
by Schaub et al. (2013). All evaluation parameters are directly
related to the research questions and have been meticulously
chosen to aid in providing objective and comprehensive an-
swers to them.

 

4. Data analysis

To answer the defined research questions, a systematic ap-
proach was adopted. In order to provide some insight into the
current state and future trends in shoulder-surfing resistant
authentication schemes, we first performed a meta-analysis
of research papers attained through the SLR process (Fig. 1).
Following that, a detailed quantitative and qualitative analy-
sis of the selected literature was performed, focusing on ad-
dressing each research question individually.

4.1. Descriptive analysis

Following the removal of irrelevant studies, we were left with
280 papers evaluating the shoulder surfing attack. The ma-
jority (176 papers or 62.9%) represented empirical evaluations
of shoulder surfing vulnerability, which was the focus of our
study. Other studies included theoretical evaluations (61 pa-
pers or 21.8%), proposals and evaluations of SSA detection
and/or prevention techniques (17 papers or 6.1%), proposals
and improvements of SSA algorithms (13 papers or 4.6%), and
surveys detailing shoulder surfing studies (13 papers or 4.6%).
A detailed breakdown of papers by category through the years
is depicted in Fig. 2.

 

 

 

 

 

10.139
6
= ACM — 136
© GS — 6.426
= IEEE — 789
= MDPI — 26
c SCP — 1.315
A SD — 364
_ SL — 704
WoS — 379
Title, Abstract and Studies not addressing
Keyword Screening po=m> Shoulder Surfing
(n = 10.139) removed (n = 8.065)
an
£
e ;
v —==>
A
eee lila dec l(-14
2 TR cece tts 10 removed (n = 505)
= against Inclusion and
“oo Se RO Clit)
iw (n= 785) ———> Non-empirical Studies
removed (n= 104)
Empirical Shoulder Studies with Quality
Surfing Study Score < 2 removed
ss. Quality Assessment (n = 99)
#& (n= 176)
©
5
Oo
Papers included for Qualitative and Quantitative Analysis
(n=77)

 

Fig. 1 - Attrition of papers through processing.

 

It should be noted that the number of papers evaluating
shoulder surfing vulnerabilities has increased over the years.
This observation is in accordance with the growth in the field
of graphical passwords. Since the initial patent proposal by
Blonder) in 1996, we have observed a steady increase in the
number of novel graphical authentication methods aiming to
replace or complement textual passwords. As more graphi-
cal methods got developed, researchers began to identify and
later evaluate their potential drawbacks, including their sus-
ceptibility to observational attacks. In mid 2000s, the first ex-
COMPUTERS & SECURITY 99 (2020) 102023 7

45

35

30

25

20

15

10

2003 2004 2005 2006 2007 2008 2009 2010

mmm SSA attack alg. mamma SSA detection/prevention mmm SSA survey

|
td lhl dal
—, P40 Wat 0. Pedal Jak.

2011 2012 2013 2014 2015 2016 2017 2018 2019

SSA theoretical

     
     

 

mmm SSA experiment (Qs2) mmm SSA experiment (Q>2)  —-—- All papers

Fig. 2 - Count of shoulder surfing studies through the years. The green bar represents the experimental empirical papers.
The dark green portion of the bar represents the papers included for qualitative and quantitative analysis.

 

perimental evaluations were performed, and in the follow-
ing decade, more researchers began to employ empirical ap-
proaches in their studies.

Nonetheless, even as the field of graphical authentication
continues to grow, less than 25% of all studies tested the meth-
ods’ susceptibility to shoulder surfing attacks experimentally.
For example, 320 out of 505 irrelevant studies that had been
removed based on eligibility criteria deemed the proposed
methods safe against SSA simply by virtue of method design.
Furthermore, only a few papers so far have discussed and de-
veloped the methodology used in SSA studies. As a result,
the existing shoulder surfing studies are heterogeneous and
therefore difficult to compare.

The purpose of this analysis is therefore two-fold: (1) to
highlight the upward research trend in graphical authentica-
tion as an alternative to textual passwords, and (2) to prompt
researchers to devote more attention to systematic evaluation
of the proposed novel methods, particularly their suscepti-
bility to shoulder surfing attacks. The synthesis presented in
this paper should help them to select the appropriate research
methodology based on the existing literature, as well as rais-
ing awareness on the importance of this topic.

We analyzed a total of 77 selected research papers pub-
lished between 2004 and May 2019. A subset of papers with
higher quality scores was chosen for the analysis because
the experimental quality differed greatly between the em-
pirical papers. Basing the analysis on high-quality papers al-
lowed us to answer the research questions with a higher de-
gree of internal validity. Moreover, the quality assessment sets
a benchmark for any future shoulder surfing experimental
studies.

Table 4 classifies the papers by the scores they received for
each of the quality parameters. As expected, most papers in-
cluded a methodology section detailing the course of the ex-
periment. While only a few papers went as far as to define
the timeline (Aviv et al., 2017; Zakaria et al., 2011) or formalize
the experimental model (Lee, 2014; Papadopoulos et al., 2017),
the majority of papers received a point for providing a com-
prehensive description of the experimental setup. The rest of

the papers described the experiment with minor flaws. Most
often, that included missing information (such as the num-
ber of guesses, observations, and passwords per participant,
information about their training, positioning, and motivation,
etc.), assumptions (such as regarding the roles of the experi-
menter and the participant), or confusing timeline (most of-
ten due to the experimental setup mixing with threat model
and participant descriptions, or being scattered throughout
the paper). Despite that, most experiments could be repro-
duced according to the descriptions. Additionally, no papers
completely omitted the information about the experimental
setup.

Contrary to expectations, less than half of the considered
papers provided detailed information about the study partic-
ipants. The majority provided very basic information, such as
the number of participants (sometimes classified by age and
sex) and their profile. Some studies included additional infor-
mation, such as the educational background, PDA experience,
eyesight problems, shoulder surfing familiarity, and similar.
Only a few studies detailed the recruitment procedure or pro-
vided context for the choice of their sample.

Threat model and quantitative metrics can be considered
quality parameters most indicative of a given paper’s qual-
ity. They define how the obtained results should be inter-
preted and compared, which affects the validity of the study.
Most high-quality papers devoted a section to threat mod-
elling in order to define the abilities and limitations of the
attacker and describe the attack scenario. In some cases,
this information was outlined within the experimental pro-
cedure or appeared throughout the paper. About a third of pa-
pers provided incomplete information (e.g. missing informa-
tion about the environment, the attacker’s knowledge, etc.),
or the threat model was not formally defined but could be
partially assumed based on the experimental description and
the results. All but one paper included metrics, however, only
65% of papers performed any statistical tests. Future stud-
ies should endeavour to employ statistical comparisons as
opposed to simple descriptive analysis to increase external
validity.
8 COMPUTERS & SECURITY 99 (2020) 102023

 

Table 4 - Quality assessment breakdown.

 

  

ID Quality parameter QIi=1 QI=0.5 QI=0 Avg QI
Q1 Threat Model 52 21 4 0.81
Q2 Participant Profile 36 38 3 0.71
Q3 Experimental Setup 65 12 0 0.92
Q4 Quantitative Results 50 26 1 0.82
Q Quality Score 203 97 8 3.26
70- SSA Experiment Studies
, 60- = Lower quality (Qs2)
& Mm Higher quality (Q> 2)
2.507 14 Number of papers
ao
-40-
O°
+ 30-
od 24
° 10- S
4
0- |
0 No citations 1 Lowly cited 10 Highly cited 100 Veryhighly cited 1000

 

Citation count

Fig. 3 - Breakdown of papers by citation count and quality score. The citation count is portrayed on a logarithmic scale for

easier readability.

 

The quality of the final set can partially be justified by the
number of citations received per publication (see Fig. 3). A to-
tal of 44 out of 77 high quality (Q > 2) publications were
highly cited (i.e., received more than 10 citations), which is
considerably more than the number of high-citation publica-
tions in the set of low quality (Q < 2) papers. Additionally,
more than 15% of high quality publications were very highly
cited (i.e., received more than 100 citations), while the same
is true for fewer than 5% of the low quality papers. On the
other hand, more than 70% of the lower-quality set received
less than 10 citations, with 14 of these publications receiv-
ing no citations whatsoever. It should be noted that in the
context of our study, ’quality” referred to the quality of the
executed experiment rather than the merit of the idea pro-
posed in the paper, and thus cannot be considered indicative
of a paper’s general quality nor a guarantee of a high citation
count.

Quality assessment did not majorly affect any other bib-
liometrics. The continuation of the descriptive analysis con-
sequently focuses on the final set of publications. Initially,
we classified all publications by publication type. The major-
ity were published as conference papers (48/77 or 62.3%), fol-
lowed by journal papers (22/77 or 28.6%), extended abstracts
(4/77 or 5.2%), short papers (2/77 or 2.6%), and book chapters
(1/77 or 1.3%). While the first journal paper in the field has not
been published until 2013, the number of journal papers per
year has been increasing since then. Nonetheless, the number
of publications published in conference proceedings remains
steadily higher throughout the years. A comparison of cita-
tion counts by publication type did not show significant differ-
ences, although all publications with more than 100 citations
were published in conference proceedings. That was, however,
prior to 2013, which supports the claim that the newer publi-

cations have not yet had an opportunity to gain widespread
recognition.

Shoulder surfing experiments were conducted primar-
ily on graphical passwords (64/77 or 83.1%). Being inher-
ently visual, they are intuitively most susceptible to obser-
vational attacks, a claim that has been empirically proven
(BoSnjak and Brumen, 2019). A further breakdown shows that
most papers examined pure-recall schemes (42/77 or 54.5%),
followed by cued-recall schemes (11/77 or 14.3%), recogni-
tion schemes (8/77 or 10.4%), multiple schemes of differ-
ent categories (2/77 or 2.6%), and hybrid schemes (1/77 or
1.3%). Most studies focused on schemes that directly trans-
late the idea of textual passwords into the graphical do-
main (i.e. recalling graphical instead of textual characters).
A much smaller portion of studies explored the advantages
of graphical elements, namely their ability to trigger associ-
ations or provide cues for quick recognition of familiar in-
formation. Future research studies should endeavour to ex-
ploit these advantages in an effort to increase the usabil-
ity of graphical schemes. The remainder of shoulder surfing
experiments were not associated with any knowledge-based
authentication schemes. 8 studies (10.4%) were carried out
within the evaluations of behavioral-biometric schemes, to
consider the possibility of gestures being observed and sub-
sequently mimicked. The remaining 5 papers (6.5%) did not
evaluate any authentication schemes, but executed shoul-
der surfing experiments to address certain privacy-related
concerns.

In accordance with the growing trend of novel graphi-
cal scheme proposals, 52 out of 77 publications evaluated a
scheme originally introduced in the study. Most of the novel
schemes take inspiration from previously published work
(De Luca et al., 2009a; Lee, 2014; Mat Lazim and Zakaria, 2018)
COMPUTERS & SECURITY 99 (2020) 102023 9

or are direct extensions of existing schemes (Abdrabou et al.,
2019; Chakraborty and Mondal, 2014; Jenkins et al., 2014; Kwon
et al., 2014a, 2014b). The majority of these studies focus on
comprehensive evaluation of the proposed scheme, though
some papers extend the analysis by comparing their scheme
to existing ones (Aris et al., 2018; BoSnjak and Brumen, 2019;
Kim et al., 2010; Yu et al., 2017). In general, the "novelty” of a
proposed scheme is seen as a major contribution to password
literature, encouraging researchers to come up with new so-
lutions to the password dilemma. However, while the search
for novel schemes that could complement or replace textual
passwords is positive, more effort should be made to com-
prehensively evaluate the existing authentication methods.
In the course of the analysis, we identified 25 papers that as-
sessed SSA susceptibility of existing authentication schemes.
Some evaluated schemes that they proposed in their previ-
ous work (Aviv et al., 2018; Khamis et al., 2017a), while others
assessed and compared other existing schemes (Cain, 2018;
Khamis et al., 2018b; Khan et al., 2016; Schaub et al., 2012; 2013;
Wiese and Roth, 2016). We observed that the existing scheme
evaluations had both higher quality score and citation count
on average than the proposals of novel methods. Based on that
finding, we conclude and highlight that the research quality
constitutes a more prominent contribution than the ‘novelty’
of the considered idea.

4.2. Quantitative and qualitative analysis

The final set of high-quality empirical shoulder surfing studies
was selected for an in-depth analysis to aid in answering the
research questions. For that purpose, we established a frame-
work, aiming to quantify the relevant design attributes of each
considered study. We proposed and defined a total of 30 pa-
rameters: 10 describing the authentication method and 20 de-
tailing the experimental design.

Our choice of parameters was guided by prior research
conducted on the topic. Considerable work has already been
done on comprehensive evaluation of authentication method
design (Bonneau et al., 2012; Forget et al., 2015). Given that
shoulder surfing attacks mainly concern graphical passwords,
the 10 parameters proposed in Schaub et al.’s graphical pass-
word design framework were used and revised for our pur-
poses (Schaub et al., 2013). To address the evaluation of SSA
experimental setup, we originally studied papers dealing with
the methodology of shoulder surfing experiments (BoSnjak
and Brumen, 2019; Lashkari et al., 2009; Wiese and Roth,
2015). From them, we extracted a set of evaluation parame-
ters to be employed in the analysis. Throughout the evalu-
ation process, we were able to identify several experimental
design decisions not covered by this basic set (i.e. number of
guesses and passwords (Aviv et al., 2017), attacker positioning
(Papadopoulos et al., 2017), method comparison (Cain, 2018),
metrics (Khan et al., 2018), etc.). This prompted us to iteratively
update them with new ones, resulting in a total of 20 parame-
ters aimed to comprehensively evaluate the SSA experimental
setup.

The defined parameters can be analyzed either individu-
ally or collectively. Each attribute targets a specific design fea-
ture, which can affect the results, interpretation, validity and
quality of the study. A score system allows for an unambigu-

ous and unbiased grading based on a set of predefined crite-
ria. Combined, the design attributes comprehensively charac-
terize the design of a shoulder surfing study, and are closely
interrelated with the defined research questions.

The quantitative evaluation and the parameters are pre-
sented in the Appendix B for the sake of brevity. Both the
grading criteria and parameter definitions were iteratively re-
fined over the course of the evaluation. While the final set
of parameters is by no means conclusive, we believe it pro-
vides a broad, well-rounded evaluation framework that allows
for a more objective comparison of the shoulder surfing stud-
ies. The quantitative and qualitative analysis presented in the
next section hinges on the results obtained from this evalua-
tion. We analyzed only the 77 best-quality publications in or-
der to appraise the quality level of state-of-the-art shoulder
surfing studies and determine how future studies could be im-
proved upon. The synthesis presented in the following section
aims to achieve that goal.

RQ1: What are the design aspects of graphical authenti-
cation methods?

While other types of authentication methods (including tex-
tual passwords) can be susceptible to shoulder surfing attacks,
the highest probability of a successful attack has been asso-
ciated with graphical passwords. Primarily, the increased vul-
nerability can be attributed to the visibility of graphical ele-
ments, a claim that has since been empirically validated. Con-
siderably less research has been devoted to exploring design
aspects of the proposed graphical authentication schemes
and their impact on the schemes’ vulnerability to SSA, how-
ever.

Upon filtering out non-knowledge based methods, we were
left with 64 research papers evaluating graphical authentica-
tion schemes. A breakdown of papers by category is reported
in the previous section. To answer the research question, we
analyze the schemes’ design aspects, focusing particularly
on how they may affect susceptibility to shoulder surfing at-
tacks. For that purpose, we employed Schaub et al.’s frame-
work (Schaub et al., 2013) for the evaluation of graphical pass-
words’ design aspects. In their work, the authors define three
major groups of aspects, which strive to encompass the full
graphical password design space. Each group contains a set
of design features that influence the scheme’s security and
usability. For the purposes of our study, the definitions of cer-
tain design parameters were modified to relate more directly
to a particular usability aspect: the shoulder surfing vulnera-
bility. Based on the definitions, a three-point grading scale was
proposed. The revised definitions and grading criteria can be
found in B.1. The analysis is divided into three parts pertain-
ing to the major aspect groups (Tables 5-7).

4.2.1. Password characteristics

One of graphical passwords’ greatest advantages is that the
introduction of graphical elements has the potential to con-
siderably increase the theoretical search space. Despite novel
proposals often acknowledging that potential (De Luca et al.,
2013a; Gugenheimer et al., 2015; Kraus et al., 2017; Oak-
ley, 2014), only a few studies conducted shoulder surfing
experiments against passwords that were chosen from a
10 COMPUTERS & SECURITY 99 (2020) 102023

Table 5 - Descriptions of password characteristics (CHR) study features along with their absolute and percentile represen-

tations in the reviewed literature, and selected example sources.

 

Feature of a study Representation Example sources

Security

Deliberately chose passwords of sufficient length
and complexity

Proposed schemes that are sufficiently secure by the
virtue of design

Proposed schemes that are insufficiently secure

5/64 (7.8%) Anand et al. (2015), BoSnjak and Brumen (2019),
Kwon et al. (2014a), Tan (2005), Schaub et al. (2013)
Al-Ameen and Wright (2016), Clark et al. (2017),
Schaub et al. (2012), Zakaria et al. (2011)

von Zezschwitz et al. (2015b), Maqsood et al. (2016),

Dunphy et al. (2010), Nyang et al. (2018), Cain (2018)

4/64 (6.2%)

55/64 (86.0%)

Efficiency

Login times were comparable to textual passwords
( < 10 seconds)
Login times were between 10 and 60 seconds

28/64 (43.8%) Aviv et al. (2017), von Zezschwitz et al. (2015a),

Cain et al. (2017), Bianchi et al. (2016), Kraus et al. (2017)
Abdrabou et al. (2019), Still and Bell (2018),

De Luca et al. (2010), Roth et al. (2004), Tari et al. (2006)

Al-Ameen and Wright (2016)

35/64 (54.7%)

Login times were longer than a minute 1/64 (1.6%)

Memorability
Users could remember passwords in more than 90%

37/64 (57.8%) De Luca et al. (2013b), Krombholz et al., Oakley (2014),

of cases Jenkins et al. (2014), Kwon et al. (2014b)

Users could remember passwords between 70-90% 18/64 (28.1%) Khamis et al. (2018a), De Luca et al. (2014), Ali (2016),
of cases Schaub et al. (2012), Jebriel and Poet (2011)

Users could remember passwords in less than 70% 9/64 (14.1%) Gugenheimer et al. (2015), Sasamoto et al. (2008),

of cases De Luca et al. (2009a), Khamis et al. (2017c),

Chakraborty and Mondal (2014)
Observational Resistance

Blurred input when not observing from the user’s
viewpoint

Used tactile information to conceal the passwords
Concealed information by adding noise characters
Expected input of correct or wrong characters based
on cues

Mapped displayed characters to the real characters

1/64 (1.6%) Papadopoulos et al. (2017)
2/64 (3.1%)
1/64 (1.6%)
2/64 (3.1%)

Ali (2016), Chakraborty et al. (2016)
Alsuhibany (2019)

De Luca et al. (2009b), Sasamoto et al. (2008)
11/64 (17.2%) Aris et al. (2018), Chakraborty and Mondal (2014),
Ho et al. (2014), Kwon et al. (2014b), Lee (2014)
Sahami Shirazi et al. (2012), Almoctar et al. (2018),

Took no measures to increase observational 47/64 (73.4%)

resistance

sufficiently-sized pool. Regardless, only five studies deliber-
ately chose passwords of sufficient length and complexity
(Anand et al., 2015; BoSnjak and Brumen, 2019; Kwon et al.,
2014a; Schaub et al., 2013; Tan, 2005), while the remaining
few had sufficiently secure passwords by the virtue of the
scheme’s design (Al-Ameen and Wright, 2016; Clark et al.,
2017; Schaub et al., 2012; Zakaria et al., 2011).

In most of the other studies, the chosen passwords were
short and simple. Often, researchers inadvertently choose that
option in order to boost the scheme’s efficiency and memo-
rability. 28 studies (43.8%) guarantee login times comparable
to textual passwords and all but one scheme ensure the login
process to take less than a minute. Only 9 out of 64 schemes re-
port memorability under 70%; more than half of the schemes
record the participants remembering their passwords in more
than 90% of cases. These figures attempt to mask the graphical
passwords’ biggest disadvantage: usability. However, if results
are based on simple rather than theoretically safe passwords,
they may pose a threat to the credibility of the claim.

Song et al. (2015), Marques et al. (2013),
Bulling et al. (2012)

What researchers seldom consider, however, is that the
choice of a password also affects its probability of being ob-
served. From the perspective of SSA experiments, the most
important thing is to consider how to interpret the re-
sults: password complexity affects where on the optimistic-
pessimistic scenario spectrum the study is placed. The
strength of the password under observation should therefore
be a conscious choice to ensure comparability. Alternatively,
with adequate resources, passwords of different strengths can
also be compared in terms of SSA vulnerability (Aviv et al.,
2017; Schaub et al., 2013).

Finally, susceptibility to shoulder surfing attacks also de-
pends on whether the real secret can be derived from the ob-
servation of the user’s input. In the majority of considered
schemes, the real secret is input directly, similarly to textual
passwords. Consequently, if the adversary was to obtain a
high-quality video of the user inputting their password, she
would be able to recover it. A smaller subset of studies pro-
posed schemes that attempt to disguise the real password,
COMPUTERS & SECURITY 99 (2020) 102023 11

usually by providing a dynamic challenge. The password can
be concealed by adding noise characters (Alsuhibany, 2019),
by inputting correct or wrong characters based on provided
cues (De Luca et al., 2009b; Sasamoto et al., 2008), or most
typically by mapping displayed characters to the real charac-
ters (Aris et al., 2018; Chakraborty and Mondal, 2014; Ho et al.,
2014; Kwon et al., 2014b; Lee, 2014; Nyang et al., 2018; Roth
et al., 2004; Tan, 2005). Finally, three methods were designed to
be completely invulnerable to visual observation: IllusionPIN
blurs the keyboard and would require the adversary to observe
the input from an unfeasible position (Papadopoulos et al.,
2017), while H4Plock and VDLS both use tactile information to
help conceal the real password (Ali, 2016; Chakraborty et al.,
2016).

When evaluating SSA vulnerability, experimental setup
should ideally consider the level of observational resistance.
If the password input is dynamic, the researchers are advised
to conduct multiple-observation experiments. On the other
hand, if non-visual information is included, they should con-
sider investigating other potential threat channels.

4.2.2. Design features

The presentation of information on-screen, and how it
changes throughout the authentication process, greatly af-
fects the difficulty of it being observed. During the course of
our analysis, we identified many different variations of infor-
mation display. We stretched them along two axes: spatial
and temporal. The spatial axis described the positioning of
the visual elements on the screen. We were particularly in-
terested in the number of graphical elements, and whether
they appeared in fixed places, or randomly. On the temporal
axis, we observed how the visual elements changed through
time. We counted the number of challenges and observed
whether the elements remained the same or changed. The
overall score gave us an estimation of the scheme’s visual
complexity, which affects its susceptibility to shoulder surf-
ing attacks.

To illustrate these axes and the variety of schemes placed
along them, we present a few selected examples. Visually
most simple schemes present a single, static challenge, which
requires the users to draw (Clark et al., 2017; Zakaria et al.,
2011) or select a few elements (Anand et al., 2015; Cain et al.,
2016). To increase visual complexity, some schemes display
more elements (Al-Ameen and Wright, 2016; Maqsood et al.,
2016), present them in a random order (Alsuhibany, 2019; Aris
et al., 2018), or both (Alsaiari et al., 2015; Gugenheimer et al.,
2015). Alternatively, the scheme can expect multiple inputs
from the user, usually in the form of inserting several consec-
utive password characters on a fixed background (Almoctar
et al., 2018; Bulling et al., 2012; De Luca et al., 2013a; Khamis
et al., 2017b; Khan et al., 2018). To decrease the chance of a
successful shoulder surfing attack, the elements can be ran-
domized at the beginning of every login (Bianchi et al., 2016;
Kim et al., 2010; Kraus et al., 2017; Tari et al., 2006), or even af-
ter each user input (Dunphy et al., 2010; Jenkins et al., 2014;
Khamis et al., 2017a; Kwon et al., 2014b; Papadopoulos et al.,
2017; Sasamoto et al., 2008; Still and Bell, 2018; von Zezschwitz
et al., 2015a). Finally, the most visually demanding schemes
involve many random elements that change with every in-
put (Chakraborty and Mondal, 2014; De Luca et al., 2010; Kwon

et al., 2014a; Tan, 2005). When evaluating novel authentication
schemes, researchers should take visual complexity into ac-
count. Comparisons of SSA vulnerability should always be per-
formed against similar schemes. The diverse list of schemes
presented in this study should aid them in the initial search.

Cues can help the adversary determine the real secret. For
the purpose of this analysis, we classified them into visual and
non-visual cues. Observing the computer-human and human-
computer interaction, we were mostly interested in whether
the password can be retrieved through visual channels. In the
majority of cases (46/64 or 71.9%), the feedback provided by the
device was exclusively visual. Some schemes (11/64 or 17.2%)
primarily rely on visual feedback, but also provide some non-
visual cues, e.g. vibrations to provide additional information
(Ali, 2016; Krombholz et al.,) or distinguish between true and
false input (Chakraborty et al., 2016; De Luca et al., 2009b;
Sasamoto et al., 2008), or sound to indicate a successful in-
put (Abdrabou et al., 2019; Still and Bell, 2018). Finally, a few
authentication methods (7/64 or 10.9%) relied completely on
non-visual feedback, or provided no feedback at all (De Luca
et al.,2013a; Khan et al., 2016; Marques et al., 2013; Sahami Shi-
razi et al., 2012).

More authentication schemes explored the potential of
using non-conventional password input techniques. Slightly
more than half (35/64 or 54.7%) of authentication methods ex-
pected passwords to be input only using a mouse or a finger;
the latter is particularly popular for graphical passwords, as
they are often assumed for primary use on mobile devices.
8 out of 64 (14.1%) schemes allowed users to input the pass-
word using a conventional keyboard. The rest (21/64 or 32.8%)
attempted to obscure the password input by relying on non-
visual input channels, such as gestures (Maqsood et al., 2016),
behavioral (Khan et al., 2016; Sahami Shirazi et al., 2012), tac-
tile (Kim et al., 2010; Krombholz et al.,; Sasamoto et al., 2008), or
gaze-based (Almoctar et al., 2018; Bulling et al., 2012; Khamis
et al., 2018b) interfaces. When developing new schemes, re-
searchers should consider how sensitive information can be
leaked to the malicious observer. In cases where visual chan-
nels are not the only type of human-computer interaction,
they should consider potential threats other than shoulder
surfing (e.g. eavesdropping), and expand their threat analysis
accordingly.

4.2.3. Device capabilities

The choice of device used for authentication can influence
the given scheme’s susceptibility to shoulder surfing attacks.
For example, the same graphical password might be easier
to observe on a computer rather than a mobile device be-
cause of the difference in screen size (Aviv et al., 2017). Like-
wise, unfamiliar (Sasamoto et al., 2008) or difficult-to-follow
(De Luca et al., 2009a) input devices can make it harder for
the adversary to determine the password being input. Taking
such contextual information into account, we classified the
schemes based on how likely it would be for a human ob-
server to recover a password. We estimated that a little less
than a third (18/64 or 28.1%) of authentication schemes could
be compromised in a single observation by a skillful adversary,
while more than a half (35/64 or 54.7%) would likely require
several observations. However, we believe that 10 schemes
could not be easily compromised by a human observer, owing
12

COMPUTERS & SECURITY 99 (2020) 102023

Table 6 - Descriptions of design features (DSG) study features along with their absolute and percentile representations in

the reviewed literature, and selected example sources.

 

Feature of a study

Had a large number of graphical elements per
challenge (> 12)

Had a small number of graphical elements per
challenge ( < 12)
Elements in a challenge were presented in a random

order
Elements in a challenge were presented statically

There were several challenges with a random
arrangement of elements

There were several challenges with a fixed
arrangement of elements

There was only a single challenge to login

Provided visual feedback to the user

... among these, provided exclusively visual feedback
Provided haptic feedback to the user

Provided auditory feedback to the user

... among these, provided haptic/auditory and visual
feedback

Did not provide any feedback to the user

Expected input with a finger (through
drawing/swiping)

Expected password input with a mouse

... among these, expected input exclusively with a mouse
or a finger

Expected password input with a keyboard

Expected input through gestures

Expected input through eye-tracking

Expected tactile input

... among these, expected any(at least one form of)
non-visual input

Representation

Spatial arrangement

22/64 (34.4%)

42/64 (65.6%)
37/64 (57.8%)

27/64 (42.2%)

Example sources

De Luca et al. (2013b), BoSnjak and Brumen (2019),
Magsood et al. (2016), Bianchi et al. (2016), Ali and
Ketabdar (2015)

Wiese and Roth (2016), Kim et al. (2010),

Khamis et al. (2017b), Aviv et al. (2018), Bulling et al. (2012)
Tan (2005), De Luca et al. (2010), Alsaiari et al. (2015),
Khamis et al. (2017a), Yu et al. (2017)

Cain et al. (2016), De Luca et al. (2013a), Zakaria et al. (2011),
Khamis et al. (2016), Mat Lazim and Zakaria (2018)

Temporal arrangement

25/64 (39.1%)
24/64 (37.5%)

15/64 (23.4%)

Visual cues

56/64 (87.5%)
46/64 (71.9%)
9/64 (14.1%)
4/64 (6.3%)

11/64 (17.2%)

7/64 (10.9%)

Interaction method

37/64 (57.8%)
11/64 (17.2%)
35/64 (54.7%)
8/64 (12.5%)
4/64 (6.3%)

9/64 (14.1%)

10/64 (15.6%)

21/64 (32.8%)

Lee (2014), Kwon et al. (2014a), Roth et al. (2004),

De Luca et al. (2009b), Cain (2018)

Khan et al. (2018), Jebriel and Poet (2011), Ho et al. (2014),
Khamis et al. (2016), Almoctar et al. (2018)

Clark et al. (2017), Anand et al. (2015), Song et al. (2015),
Aris et al. (2018), Alsaiari et al. (2015)

von Zezschwitz et al. (2015b), Wiese and Roth (2016),
Nyang et al. (2018), Tari et al. (2006), Bianchi et al. (2016)
Alsuhibany (2019), Zakaria et al. (2011), Chakraborty and
Mondal (2014), Cain et al. (2017), Kwon et al. (2014b)
Chakraborty et al. (2016), De Luca et al. (2009b),

Schaub et al. (2013), Ali (2016), Khan et al. (2018)

Still and Bell (2018), Kwon et al. (2014a),

Maqsood et al. (2016), Abdrabou et al. (2019)

Krombholz et al., Sasamoto et al. (2008),

De Luca et al. (2009b), Schaub et al. (2013),

Abdrabou et al. (2019)

Khan et al. (2016), Sahami Shirazi et al. (2012),

De Luca et al. (2014), Marques et al. (2013), Ali and
Ketabdar (2015)

Aviv et al. (2017), Cain et al. (2016), Dunphy et al. (2010),
Yu et al. (2017), Roth et al. (2004)

De Luca et al. (2013b), Still and Bell (2018), Mat Lazim and
Zakaria (2018), Jenkins et al. (2014), Cain (2018)

Kraus et al. (2017), Chakraborty et al. (2016),

Song et al. (2015), Kwon et al. (2014b), Cain et al. (2017)
Jebriel and Poet (2011), Tari et al. (2006), Alsaiari et al. (2015),
De Luca et al. (2010), Al-Ameen and Wright (2016)
Abdrabou et al. (2019), Sahami Shirazi et al. (2012),
Khamis et al. (2018a), Ali and Ketabdar (2015)

De Luca et al. (2009a), Khamis et al. (2017c),

Bulling et al. (2012), Almoctar et al. (2018),

Abdrabou et al. (2019)

Sasamoto et al. (2008), Kim et al. (2010), Krombholz et al.,
De Luca et al. (2013a), Maqsood et al. (2016)

Khan et al. (2016), Khamis et al. (2017b),

Maqsood et al. (2016), Ali and Ketabdar (2015),

Bianchi et al. (2016)
COMPUTERS & SECURITY 99 (2020) 102023 13

Table 7 - Descriptions of device capabilities (CPB) study features along with their absolute and percentile representations

in the reviewed literature, and selected example sources.

 

Feature of a study

Representation Example sources

Context of use

Input procedure or password characters were difficult
to observe

Grouped password characters among distractors
Translated real password characters into decoys
Disguised real characters among non-valid characters
during input

Included larger, easily discernible graphical elements

Included smaller, difficult to see graphical elements

Did not include any graphical elements

27/64 (42.2%)
11/64 (17.2%)
9/64 (14.1%)
8/64 (12.5%)
42/64 (65.6%)
14/64 (21.9%)

9/64 (14.1%)

Khamis et al. (2017b), Papadopoulos et al. (2017),
Almoctar et al. (2018), Yu et al. (2017), Alsaiari et al. (2015)
Ali (2016), Chakraborty and Mondal (2014), Oakley (2014),
Tan (2005), Nyang et al. (2018)

De Luca et al. (2010), von Zezschwitz et al. (2015a),

Ho et al. (2014), Aris et al. (2018), Cain et al. (2017)
Gugenheimer et al. (2015), De Luca et al. (2013b),

De Luca et al. (2009b), Kim et al. (2010), Cain (2018)
Zakaria et al. (2011), Tari et al. (2006), Bianchi et al. (2016),
Khamis et al. (2016), De Luca et al. (2014)

Schaub et al. (2012), Kwon et al. (2014a),

De Luca et al. (2013b), Still and Bell (2018), Oakley (2014)
Sahami Shirazi et al. (2012), Almoctar et al. (2018),

Khan et al. (2016), Anand et al. (2015), Cain (2018)

Constraints

Password input possible with vision impairments

Password input possible with motoric impairments
Password input not possible with impairments

to their design. The most common reasons include the need
to observe two or more things at once (Abdrabou et al., 2019;
Tan, 2005), being unable to see all input channels in use (Ho
et al., 2014; Papadopoulos et al., 2017), and hidden informa-
tion being relayed during the authentication process (Ali, 2016;
Chakraborty et al., 2016).

Finally, constraints associated with the use of a particu-
lar authentication method should also be considered in the
experimental analysis. Certain schemes are specifically de-
signed to support easy authentication for visually-impaired
users. In fact, more than a third (23/64 or 35.9%) of consid-
ered schemes allow the users to authenticate with limited vi-
sual feedback. Most often, that includes schemes that do not
require the user to see the screen to input the password (Al-
Ameen and Wright, 2016; Clark et al., 2017; Song et al., 2015),
or schemes that rely on non-visual feedback to provide cues
(Ali, 2016; De Luca et al., 2009b; Sahami Shirazi et al., 2012).
In two cases, where only gaze-based input was needed for
successful authentication, users could authenticate despite
motoric impairments (Almoctar et al., 2018; De Luca et al.,
2009a). Whereas such solutions provide the disabled people
with alternatives to the conventional textual passwords, they
also open new attack venues (e.g. a blind person can be easily
videotaped and/or recorded without notice). Such considera-
tions should be included in the updated threat models.

RQ2: What is the quality of the executed shoulder surfing
experiments?

Experimental SSA studies represent a small portion of authen-
tication literature, which recognizes shoulder surfing as a sig-
nificant threat which warrants further investigation of vari-
ous schemes’ vulnerability. In the majority of these studies,

23/64 (35.9%)

2/64 (3.1%)
40/64 (62.5%)

Cain et al. (2016), De Luca et al. (2009b), Aviv et al. (2018),
Marques et al. (2013), Alsuhibany (2019)

Almoctar et al. (2018), De Luca et al. (2009a)

Khamis et al. (2017a), Lee (2014), Kwon et al. (2014b),
Jebriel and Poet (2011), Schaub et al. (2013)

shoulder surfing experiments are conducted secondary to se-
curity and usability tests, and are often tailored to empirically
show the proposed scheme’s resistance to SSA. Few studies
have focused primarily or exclusively on the evaluation of a
scheme’s shoulder surfing vulnerability, and almost none have
dealt with methodology related to how the SSA experiments
are conducted. Arguably the most important concern, how-
ever, is the studies’ general lack of consideration toward ex-
perimental design, and what implications it has for the ob-
tained results.

The analysis of experimental design was performed on the
final set of 77 research papers. Our main objective was to eval-
uate properties of the conducted experiments in order to un-
derstand how these design decisions may influence the re-
sults and the conclusions drawn from the studies. That is not
only important for the objective interpretation of the results,
but also for achieving impartiality in any comparisons be-
tween the proposed schemes. For that purpose, 20 parameters
(divided into four categories) were defined with the intention
of describing the experimental design in a comprehensive and
conclusive manner (Tables 8-11). Their definitions and grading
criteria can be found in the B.1. Similar comparative frame-
works can be adopted for the analyses of other experimental

types.

4.2.4. Experimental setup

Shoulder surfing is primarily a social engineering technique,
which means that its success largely depends on the human
factor. Researchers should consider the profiles of typical ad-
versaries and their victims and attempt to model them by
choosing an appropriate sample. At present, their endeavors
have been mostly unsatisfactory. The majority of the stud-
14

COMPUTERS & SECURITY 99 (2020) 102023

Table 8 —- Descriptions of experimental setup study features along with their absolute and percentile representations in the

 

reviewed literature, and selected example sources.

Feature of a study

Large-sized sample was employed (> 100
participants)

Medium-sized sample was employed (30-100
participants)

Small-sized sample was employed ( < 30
participants)

Target sample modelled the entire population
Sample was drawn from graduate and
undergraduate students

Sample targeted specific groups (i.e. companies, gov.
employees)

No sufficient information given about the sample
composition

Conducted a pilot study prior to the experiment

Allowed participants to test the method

Trained participants in shoulder surfing

Briefed the participants about the method and/or
procedure

Gave limited knowledge about the method to the
participants

Participants were allowed to take notes

Participants were not allowed to take any notes

Distractor tasks were employed between
observation and guessing

No distractor tasks were employed during the
experiment

Monetary compensation was given to participants
Material compensation was given to participants

No compensation was offered to participants

Participants acted as both victims and observers
interchangeably

Some participants were victims, others were
observers

Representation

Example sources

Number of participants

8/77 (10.4%)

25/77 (32.5%)

44/77 (57.1%)

Participant profile

13/77 (16.9%)
42/77 (54.5%)
3/77 (3.9%)

19/77 (24.7%)

Training

19/77 (24.7%)

44/77 (57.1%)
15/77 (19.5%)
12/77 (15.6%)
9/77 (11.7%)
Writing aid
33/77 (42.9%)

44/77 (57.1%)

Distractor task

6/77 (7.8%)

71/77 (92.2%)

Motivation

21/77 (27.2%)
17/77 (22.1%)

39/77 (50.6%)

Victim/Observer

14/77 (18.1%)

25/77 (32.5%)

Aviv et al. (2017), Clark et al. (2017), BoSnjak and

Brumen (2019), Jenkins et al. (2014),

Martinez-Diaz et al. (2013)

Chakraborty et al. (2016), Kraus et al. (2017), Aris et al. (2018),
Mat Lazim and Zakaria (2018), Sun et al. (2014)

Oakley (2014), Papadopoulos et al. (2017),

Khamis et al. (2018a), Dunphy et al. (2010), Song et al. (2017)

Krombholz et al., Song et al. (2015), Khamis et al. (2018a),
Jenkins et al. (2014), Nguyen and Memon (2018)
Gugenheimer et al. (2015), Aviv et al. (2018), Lee (2014),
Bulling et al. (2012), Juang and Greenstein (2011)
Sasamoto et al. (2008), Tan (2005), Muaaz and

Mayrhofer (2017)

Alsuhibany (2019), Khamis et al. (2017c), Chakraborty and
Mondal (2014), Schaub et al. (2013), Chauhan et al. (2016)

Magqsood et al. (2016), Abdrabou et al. (2019),

Almoctar et al. (2018), Kwon et al. (2014b),

Nguyen et al. (2017)

De Luca et al. (2013a), Kraus et al. (2017), Khan et al. (2018),
Cain et al. (2017), L’Yi et al. (2016)

Zakaria et al. (2011), Ali and Ketabdar (2015), Anand

et al. (2015), Nyang et al. (2018), Song et al. (2017)

Al-Ameen and Wright (2016), Khan et al. (2016), BoSnjak and
Brumen (2019), Aumi and Kratz (2014), Lee et al. (2017)
Khamis et al. (2017a), Jebriel and Poet (2011), Yu et al. (2017),
Bianchi et al. (2016), Tiller et al. (2019)

De Luca et al. (2009a), De Luca et al. (2014), von Zezschwitz
et al. (2015b), Jebriel and Poet (2011), Chauhan et al. (2016)
Clark et al. (2017), Oakley (2014), Marques et al. (2013),

Ho et al. (2014), Cain (2018)

von Zezschwitz et al. (2015b), Zakaria et al. (2011),
Mat Lazim and Zakaria (2018), Kim et al. (2010),

L’Yi et al. (2016)

Schaub et al. (2012), Ali (2016), Wiese and Roth (2016),
Aris et al. (2018), Nguyen and Memon (2018)

Magqsood et al. (2016), Khamis et al. (2017b), von Zezschwitz
et al. (2015a), Khamis et al. (2018a), L’Yi et al. (2016)

Still and Bell (2018), Aviv et al. (2017), Tan (2005),

Cain et al. (2017), Tiller et al. (2019)

Alsuhibany (2019), De Luca et al. (2009a), Oakley (2014),
Sasamoto et al. (2008), Nguyen et al. (2017)

Clark et al. (2017), Khan et al. (2016),

Papadopoulos et al. (2017), Jebriel and Poet (2011),
Martinez-Diaz et al. (2013)

Gugenheimer et al. (2015), Khamis et al. (2017b),
Chakraborty et al. (2016), Bulling et al. (2012), Aumi and
Kratz (2014)

(continued on next page)
COMPUTERS & SECURITY 99 (2020) 102023 15

Table 8 (continued)

Participants were observers, experimenters were
victims

Participants were victims, experimenters were
observers

31/77 (40.3%)

7/77 (9.1%)

Ali (2016), Kwon et al. (2014a), BoSnjak and Brumen (2019),
Tari et al. (2006), Lee et al. (2017)

De Luca et al. (2009a), De Luca et al. (2009b),

De Luca et al. (2013a), Krombholz et al., Sasamoto

et al. (2008)

Positioning

Fully restricted viewing angles and positioning
Loosely defined fixed positioning

Participants allowed to choose their own positioning

12/77 (15.6%)
13/77 (16.9%)

52/77 (67.5%)

Al-Ameen and Wright (2016), Alsuhibany (2019),

Oakley (2014), Tari et al. (2006), Kim et al. (2010)

De Luca et al. (2009a), Song et al. (2015), Khan et al. (2016),
Khamis et al. (2017a), Yu et al. (2017)

Khamis et al. (2017c), De Luca et al. (2014), Lee (2014),

Ho et al. (2014), Eiband et al. (2016)

Live/Video

Both live and video experiments were conducted

Live experiments were conducted

Video experiments were conducted

7/77 (9.1%)

23/77 (29.9%)

47/77 (61.0%)

Krombholz et al., Aviv et al. (2018), von Zezschwitz

et al. (2015a), Bianchi et al. (2016), Nyang et al. (2018)
Zakaria et al. (2011), Papadopoulos et al. (2017),

Schaub et al. (2012), Jebriel and Poet (2011), Muaaz and
Mayrhofer (2017)

De Luca et al. (2010), Khamis et al. (2017a), Roth et al. (2004),
Alsaiari et al. (2015), Sun et al. (2014)

Number of observations

Participants could observe the login unlimited
number of times
Participants could observe the login multiple times

Participants could observe the login only once

22/77 (28.6%)

22/77 (28.6%)

33/77 (42.8%)

Sahami Shirazi et al. (2012), Khan et al. (2018), Still and
Bell (2018), De Luca et al. (2009b), Aumi and Kratz (2014)
Aviv et al. (2017), Anand et al. (2015), von Zezschwitz

et al. (2015a), Kwon et al. (2014b), Mat Lazim and

Zakaria (2018)

Kraus et al. (2017), Khamis et al. (2016), Kwon et al. (2014a),
Jenkins et al. (2014), Juang and Greenstein (2011)

Number of guesses

Participants had an unlimited number of password
guesses

Participants could guess the password multiple
times

Participants could guess the password only once

5/77 (6.5%)
47/77 (61.0%)

25/77 (32.5%)

Clark et al. (2017), Song et al. (2015), Ho et al. (2014),
Sasamoto et al. (2008), De Luca et al. (2009b)

De Luca et al. (2013a), Ali and Ketabdar (2015),

Dunphy et al. (2010), Schaub et al. (2013), Eiband et al. (2016)
De Luca et al. (2013b), Chakraborty and Mondal (2014),

Cain et al. (2016), Jebriel and Poet (2011),

Martinez-Diaz et al. (2013)

Number of passwords

Participants guessed several passwords for several
schemes or groups

Participants guessed several passwords for one
scheme or group

Participants guessed one password for several
schemes or groups

Participants guessed one password for one scheme
or group

ies do not detail the recruitment procedure. A quarter even
failed to provide sufficient information about the participants
involved. Both are crucial to understand what population the
participants represent and how their choice of the sample af-
fects the validity of the study.

In the following section, we take a look at the studies that
provided information about the participants. Just over half re-
cruited undergraduate and graduate students, which consti-
tutes a common sample in the experimental research. The

35/77 (45.5%)

14/77 (18.1%)

22/77 (28.6%)

6/77 (7.8%)

Abdrabou et al. (2019), Khamis et al. (2017c),
Gugenheimer et al. (2015), Yu et al. (2017), Juang and
Greenstein (2011)

Sahami Shirazi et al. (2012), Kraus et al. (2017),

von Zezschwitz et al. (2015b), Kwon et al. (2014b),
Nguyen and Memon (2018)

Alsuhibany (2019), Marques et al. (2013),

Schaub et al. (2012), Aris et al. (2018), Cain (2018)

Alsaiari et al. (2015), Ho et al. (2014), BoSnjak and

Brumen (2019), Chauhan et al. (2016), Dunphy et al. (2010)

rest of the studies recruited participants using online ser-
vices such as Craigslist (Kraus et al., 2017; Sahami Shirazi
et al., 2012) or Amazon Mechanical Turk (Aviv et al., 2017),
mailing lists and social networks (De Luca et al., 2014; Jenk-
ins et al., 2014; Khamis et al., 2017b; Nguyen and Memon,
2018; Wiese and Roth, 2016), or ads and bulletin boards
(Krombholz et al.,; Nyang et al., 2018; Song et al., 2015). In
most cases, these samples modelled the entire population,
though some were targeting specific groups (such as Mi-
16 COMPUTERS & SECURITY 99 (2020) 102023

crosoft (Tan, 2005) or government employees (Sasamoto et al.,
2008).

There is general consensus that a sample representing a
broader population is more favorable because it models the
real-life scenario more accurately, though samples taken from
students are often used as the second-best alternative be-
cause they are much easier to obtain. While there are ar-
guments for and against in either case, researchers should
predominantly choose a sample based on their threat sce-
nario. If the participants are cast in the role of the attacker,
it is essential to define whether the said attacker is oppor-
tunistic (Bosnjak and Brumen, 2019; Still and Bell, 2018) or
malicious (Magsood et al., 2016; Tari et al., 2006); a stranger
Jenkins et al. (2014), a work colleague (Tan, 2005), a friend
(Oakley, 2014) or a family member (Jenkins et al., 2014); or if
they are clueless (Khan et al., 2016) or possess additional in-
formation (Kraus et al., 2017). Based on additional context, the
choice of asample can be justified (e.g. gamers are an excellent
sample when fast-paced eye movements are necessary to per-
form a successful attack (Kwon et al., 2014b)), which increases
the external validity of the study. Sufficient context can also
be attained by providing additional demographic data. Most
studies report the sample size, as well as some basic par-
ticipant information, such as their age, gender, and employ-
ment status. Other useful supplementary information can in-
clude handedness (Ali and Ketabdar, 2015; Aumi and Kratz,
2014; Tan, 2005), visual acuity (Cain, 2018; Lee et al., 2017; Pa-
padopoulos et al., 2017) and color-blindness (L’Yi et al., 2016),
height (Khamis et al., 2018b), native language (Tiller et al.,
2019), device use (Aviv et al., 2018; De Luca et al., 2014; Wiese
and Roth, 2016) and experience (Nguyen and Memon, 2018;
Nyang et al., 2018), and previous real-world encounters with
shoulder surfing (Still and Bell, 2018; von Zezschwitz et al.,
2015b). Depending on the focus of the study, specialised in-
formation may be gathered (e.g. height, weight, shoe size,
upper and lower leg length for shoulder surfing and imper-
sonation attacks on gait authentication systems (Muaaz and
Mayrhofer, 2017)).

Sample size is another important consideration, particu-
larly when the experimenters are conducting statistical tests.
Experimental design factors should be taken into account,
such as the complexity of the study, the number of groups,
and the assumptions of the statistical tests used. More than
half of the considered studies employed small samples of less
than 30 participants, which is tolerable for small-scale studies
with few groups (Bianchi et al., 2016; Bulling et al., 2012; Kwon
et al., 2014b; Nyang et al., 2018; Tan, 2005; von Zezschwitz
et al., 2015a) or studies not using inferential statistics (Alsaiari
et al., 2015; De Luca et al., 2010; Eiband et al., 2016; Jebriel and
Poet, 2011; Oakley, 2014; Song et al., 2015). In some cases, es-
pecially where the execution of the experiment is difficult or
time-consuming (Khamis et al., 2018b), smaller samples may
be acceptable as well, though researchers should acknowl-
edge the reduced statistical power. In general, however, stud-
ies should strive toward including as many participants as
they can. Despite the time-consuming element of typical live
shoulder surfing experiments (i.e. a victim may only be ob-
served by one or two attackers at a time), several studies have
managed to employ larger samples (Alsuhibany, 2019; BosSnjak
and Brumen, 2019; Song et al., 2015). Video-based experiments

generally provide greater flexibility, as the observations can be
executed online (Aviv et al., 2017; Wiese and Roth, 2016), or si-
multaneously in groups (Clark et al., 2017; Jenkins et al., 2014;
Martinez-Diaz et al., 2013; von Zezschwitz et al., 2015b). How-
ever, while such experimental design facilitates an increase
in sample size, it can negatively affect the scientific control.
Preemptive measures should be taken to reduce that effect.

Study complexity is an informal characterization of sev-
eral design features that contribute to the difficulty and/or
duration of the experiment. In the analysis, we present these
design choices by showcasing examples and discuss the im-
plications on the study results and validity. One of the ini-
tial considerations when conducting a shoulder surfing ex-
periment is whether we are going to carry out a pilot study.
Only a quarter of studies (19/77 or 24.8%) conducted any pilot
study prior to executing the shoulder surfing experiment. The
purpose of the pilot study was usually to determine design
or implementation details for a given authentication scheme
(Abdrabou et al., 2019; Almoctar et al., 2018; Khamis et al.,
2018b; Khan et al., 2018; Nyang et al., 2018) or to verify the pro-
posed experimental design (Jenkins et al., 2014; Khan et al.,
2016; Krombholz et al.,; Maqsood et al., 2016; Zakaria et al.,
2011). Design decisions based on pilot study results were usu-
ally reported within sections describing the experimental pro-
cedure; only three studies devoted a section to describe the
course of the pilot study (Aumi and Kratz, 2014; BoSnjak and
Brumen, 2019; Nguyen et al., 2017). Researchers are encour-
aged to put more effort into preliminary studies, as they help
identify flaws in experimental design and shed light onto why
certain design decisions were made.

The majority of the shoulder surfing studies reported that
the participants had a chance to get familiar with the authen-
tication method under investigation. One of the more com-
mon approaches to carrying out the training is to allow the
participants to test the method prior to or as a part of the us-
ability study (Ali, 2016; De Luca et al., 2009b; Ho et al., 2014;
Sasamoto et al., 2008; Still and Bell, 2018). Alternatively, the
participants can get the opportunity to try out the method
during the briefing prior to the shoulder surfing experiment
(Anand et al., 2015; Aris et al., 2018; Khamis et al., 2017c;
Khan et al., 2016; von Zezschwitz et al., 2015b). In some cases,
the participants were merely briefed about the authentication
method without having the chance to test it themselves (Al-
Ameen and Wright, 2016; Aumi and Kratz, 2014; BoSnjak and
Brumen, 2019; Bulling et al., 2012). It should be noted that the
familiarity and the experience using the method affects the
attacker’s guessing performance (Kraus et al., 2017). Primar-
ily, we are interested in worst-case scenarios, which means
that we want to model the strongest attacker. However, cer-
tain studies have explicitly investigated the success of attack-
ers with limited knowledge (BoSnjak and Brumen, 2019; Jenk-
ins et al., 2014; Khan et al., 2016). Any level of the participant’s
knowledge is acceptable as long as it addresses the estab-
lished research questions; the participants may go from be-
ing unaware of how to use the method (Bianchi et al., 2016)
or what the experiment is about (L’Yi et al., 2016), to even hav-
ing tried a test shoulder surfing attack prior to the experiment
(Zakaria et al., 2011).

Observers can also be given a chance to record their
guesses during the shoulder surfing phase. This design choice
COMPUTERS & SECURITY 99 (2020) 102023 17

corresponds with the strongest observer threat model often
exercised in shoulder surfing studies. A total of 33 out of 77
studies allowed the attackers to take notes during the obser-
vation. That suggests the use of a writing aid to be a fairly com-
mon practice in SSA experiments, particularly if we take into
account that note-taking is not relevant for any non-visual au-
thentication methods (Anand et al., 2015; Jenkins et al., 2014;
Marques et al., 2013; Muaaz and Mayrhofer, 2017; Sahami Shi-
razietal., 2012; Song et al., 2017). On the other hand, distractor
tasks are detrimental to the observer, as their purpose is to
prevent them from rehearsing the observed password. They
are often used in memory literature to simulate the partic-
ipant having to recall the information from their long-term
memory. In the context of shoulder surfing studies, distrac-
tor tasks model situations in which the malicious observers
cannot exploit the observed information immediately but in-
stead have to retain it to execute the attack later (Kim et al.,
2010). Despite their effort to portray a realistic scenario, only
Six papers have employed distractor tasks in their experimen-
tal design (Kim et al., 2010; L’Yi et al., 2016; Mat Lazim and Za-
Karia, 2018; Song et al., 2015; von Zezschwitz et al., 2015b; Za-
karia et al., 2011); a few studies have actively decided against
using them to avoid noise due to differences in memory ca-
pabilities between the participants (Schaub et al., 2012). Both
the distractor task and the use of a writing aid affect the par-
ticlpant’s memory. Rather than use these experimental de-
sign features simply because they are common in shoulder
surfing studies, researchers should instead see them as avail-
able tools to model a participant according to their threat
model.

In any study involving a sample of human participants,
motivation should be one of the researchers’ primary con-
cerns. It can safely be assumed that participants are gener-
ally unmotivated to perform well in a study, unless they have
an incentive or the sample is drawn from a pool of volun-
teers. Poor motivation can mean undervalued or even invalid
results, which can jeopardize the validity of the study. About
half of the publications (39/77 or 50.65%) did not address the
participants’ motivation. In most of the other studies, the par-
ticipants were offered either monetary (Eiband et al., 2016;
Khamis et al., 2017b; L’Yi et al., 2016; Maqsood et al., 2016) or
material (Cain et al., 2016; Kwon et al., 2014b; Tiller et al., 2019;
von Zezschwitz et al., 2015b) incentives. The reason for this
divide is that it is often difficult for researchers to obtain suf-
ficient funds or permission from the research ethics boards to
introduce a motivating factor into the study. In such cases, it
is vital to ensure that the results are not compared to the re-
sults obtained from studies that took motivation into account
(Cain et al., 2017). From this perspective, the inclusion of a mo-
tivating factor can be used to model either a deliberate or an
opportunistic attacker (Still and Bell, 2018).

Determining the role of the study participants does not
only have an effect on the threat model and the conclusions
drawn from the study, but greatly affects the course of the
experiment. We generally distinguish between three possibil-
ities: the participants can be cast in the role of the victim,
the observer, or both. Very few authors employed the par-
ticipants as victims; in almost all of such cases, the shoul-
der surfing attack was merely a follow-up study after the ini-
tial usability study during which the victims were videotaped

(De Luca et al., 2009a, 2010, 2009b, 2013a, 2013b; Sasamoto
et al., 2008). In a single live experiment, the proctor acted as
an unsuspecting shoulder surfer, modelling a possible real-life
scenario with a "trustworthy” friend observing the authenti-
cating individual (Krombholz et al.,). This experimental design
is particularly useful when wanting to model a very strong
adversary, usually simulated by an expert-user experimenter
(De Luca et al., 2009a). A much more common configuration
casts the participant in the role of the attacker, while the ex-
perimenter plays the victim. There are several advantages to
this approach. As a victim, the experimenter can make sure to
provide similar conditions for every attacker (i.e. by body and
hand positioning, input speed, etc.) (Ali, 2016; Schaub et al.,
2012; Zakaria et al., 2011). More importantly, with a sample
of attackers, we can ensure that the obtained results are not
highly dependent on the skills and experience of a single in-
dividual, but instead reflect the performance of the tested
group (Tari et al., 2006). By utilizing a between-subject (Al-
Ameen and Wright, 2016; BoSnjak and Brumen, 2019; L’Yiet al.,
2016; Mat Lazim and Zakaria, 2018), within-subject (Cain et al.,
2016; Khamis et al., 2018b; Kwon et al., 2014a; Tari et al., 2006;
von Zezschwitz et al., 2015b) or mixed-factorial (Aviv et al.,
2017, 2018) study design, this configuration also allows us to
compare several groups. A fairly similar and equally common
study design casts the participants in the roles of both victims
and observers. The main difference is that by eliminating the
experimenter from the procedure, we allow for both the vic-
tims and the observers to reflect their respective target groups,
but at the expense of experimental control. Sometimes, the
participants worked in pairs, switching their roles (Aris et al.,
2018; Jebriel and Poet, 2011; Marques et al., 2013; Papadopou-
los et al., 2017; Tan, 2005). In other cases, random participants
were selected as either attackers or victims (Chakraborty et al.,
2016; Chakraborty and Mondal, 2014; Nyang et al., 2018; Oak-
ley, 2014; Song et al., 2015). The choice affects the participants’
knowledge and experience (i.e. learning effect) and the sample
size.

The choice between live and video observations is another
important design decision affecting complexity and execu-
tion of the experiment. As outlined in the previous paragraph,
video observations are often conducted following a usability
study which examines a novel authentication method (Aumi
and Kratz, 2014; Clark et al., 2017; De Luca et al., 2013a; Gu-
genheimer et al., 2015; Khamis et al., 2017c; Krombholz et al.,).
This design choice is made primarily to save time and re-
sources, as the sample of victim authentications is simply a
side product of the usability study. The follow-up shoulder
surfing experiment is often not a focus, but rather a secondary
experiment to provide a more wholesome evaluation of the
method. In some cases, videos are filmed exclusively for the
purpose of the shoulder surfing experiment. The advantage
of this approach is that it provides greater control, as the au-
thentication procedure can be tailored to the examined threat
model (Almoctar et al., 2018; Chauhan et al., 2016; Lee, 2014;
Roth et al., 2004; Sahami Shirazi et al., 2012). Live observa-
tions, on the other hand, attempt to imitate a realistic situ-
ation to increase ecological validity (Zakaria et al., 2011). They
are the closest representation of the attacks in the wild, while
retaining some level of experimental control. That is particu-
larly useful when we want to evaluate the SSA vulnerability
18 COMPUTERS & SECURITY 99 (2020) 102023

of the method during everyday use. Because of that, they are
most commonly used to evaluate methods with visible graph-
ical elements (i.e. recognition-based graphical passwords),
which could potentially be compromised by casual observers
(Aris et al., 2018; Dunphy et al., 2010; Kim et al., 2010; Kwon
et al.,2014a; Song et al., 2015; Tari et al., 2006). In specific cases,
live observations are preferable because direct, firsthand ob-
servational experience may yield more information about the
authentication process (Marques et al., 2013; Papadopoulos
et al., 2017).

In shoulder surfing literature, there is a clear divide be-
tween the advocates for each of the two possibilities. Whereas
video shoulder surfing minimises any potential bias (Ali, 2016),
live shoulder surfing tries to model a real-world scenario
(Chakraborty and Mondal, 2014). Essentially, video SSA sim-
ulates ideal, clinical conditions for the attacker (De Luca
et al., 2009a; Khamis et al., 2017c; Khan et al., 2018); coupled
with easy replayability and video manipulation (Abdrabou
et al., 2019; De Luca et al., 2013a; Sahami Shirazi et al.,
2012), it models a strong, malicious attacker. On the other
hand, the attacker is removed from the observational situa-
tion. In live SSA, the attackers can directly observe the vic-
tim (Papadopoulos et al., 2017), and exploit the environmental
conditions available to them (Schaub et al., 2012), or choose
their optimal viewing conditions (Kraus et al., 2017; Zakaria
et al., 2011). Under multiple observations, they can take ad-
vantage of the password input variability; this situational flex-
ibility makes them ideal for opportunistic, casual attackers.
In most cases, the ideal alternative is to execute both live
and video experiments. Such experimental setup allows fora
broader evaluation of the shoulder surfing vulnerability, while
increasing the validity of the study. Unfortunately, it is of-
ten not feasible due to time and sample constraints. Only
seven studies carried out both types of experiments. In four
cases, the participants started with live observations, during
which the entire authentication process was filmed for the
same (Nyang et al., 2018; Oakley, 2014; von Zezschwitz et al.,
2015a) or different (Krombholz et al.,) participants to guess the
passwords by subsequently watching the videos. Two stud-
ies prepared a set of authentication videos in advance, so
that the participants were guessing different passwords dur-
ing live and video observations (Bianchi et al., 2016; Schaub
et al., 2013). In either case, the observations were modelled
as a series of increasingly sophisticated attacks to empiri-
cally assess different levels of resistance to SSA. Finally, a sin-
gle study conducted a live experiment to compare the results
with a similar video experiment from a prior study (Aviv et al.,
2018).

One of the main advantages of live experiments is the abil-
ity to decide how much we want to restrict the viewing con-
ditions. In cases when the researchers want to investigate the
effect of different viewing angles (Aviv et al., 2018), or estab-
lish specific viewing conditions (Chakraborty et al., 2016; Pa-
padopoulos et al., 2017), they can strictly define the attacker’s
position relative to the victim and the screen, and where they
should be facing. Most commonly, the researchers will re-
quire the observers to stand in a specific spot and assume a
comfortable position, even though only a few papers explic-
itly reported that positioning (Kraus et al., 2017; Song et al.,
2015; Yu et al., 2017). Alternatively, the participants can be

given freedom to choose their own position to observe the
victim without any constraints whatsoever (Al-Ameen and
Wright, 2016; Kim et al., 2010; Oakley, 2014; Tan, 2005; Tari
et al., 2006; Zakaria et al., 2011). While this setup decreases
the experimental control, it works in favour of the attacker
(Muaaz and Mayrhofer, 2017). At the same time, it allows the
experimenters to monitor the participants’ behavior and their
strategies (Schaub et al., 2012). Video experiments always em-
ploy fixed positioning of the cameras, which can work in the
researchers’ favour, particularly when wanting to film optimal
viewing angles (De Luca et al., 2013a; Khan et al., 2018). Sev-
eral cameras can also be used to capture the authentication
from different angles to increase the guessing probability (Ali
and Ketabdar, 2015; Almoctar et al., 2018; Khamis et al., 2017a;
Khan et al., 2016).

Guessing probability is also affected by the number of op-
portunities the attacker has to observe and guess the pass-
word. The decision is generally dependent on the experimen-
tal design and the type of attack it strives to emulate, from an
incidental shoulder-surfing attempt to a malicious, targeted
attack. This results in a high variance of the number of guesses
and observations an attacker is granted. Most commonly, re-
searchers decide between a single observation with one guess
(BosSnjak and Brumen, 2019; Cain et al., 2016; Juang and Green-
stein, 2011; Tari et al., 2006; Yu et al., 2017; Zakaria et al., 2011),
a single observation with multiple guesses (Aris et al., 2018;
Khamis et al., 2018b; Kraus et al., 2017; Maqsood et al., 2016;
Marques et al., 2013), or multiple (up to an unlimited) obser-
vations with multiple guesses (Bulling et al., 2012; Chauhan
et al., 2016; Khan et al., 2016, 2018; Sahami Shirazi et al., 2012;
Still and Bell, 2018). Such configurations allow them to test
the methods against weak or strong attackers, respectively. To
test against both, some video-based studies first allowed the
participant to watch the recordings once before the initial at-
tempts, then gave them unlimited control over the video for
additional attempts (Abdrabou et al., 2019; De Luca et al., 2014;
Gugenheimer et al., 2015). Regardless of the choice, the con-
figurations should be closely related to the established threat
model. For example, unlimited observations make sense for
video-based shoulder surfing, because we assume the attacker
has obtained footage of the authentication process and has
full control over it. Another example is limiting the num-
ber of guesses to three, which is reasonable when we want
to simulate a typical situation in which further authentica-
tion attempts are blocked after exactly three wrong inputs.
Less common configurations of observation/guess ratios gen-
erally shared poorer interconnection with the threat model
(Ho et al., 2014; Song et al., 2015).

To some extent, the chosen number of observations per
password may also be affected by how many different pass-
words we envision the attacker to observe. Six studies had
each participant attack only one password: four studies ex-
pected the attackers to guess a particular password (Alsaiari
et al., 2015; BoSnjak and Brumen, 2019; Ho et al., 2014; Still
and Bell, 2018), and the other two sorted the participants into
attacker-victim pairs, so that they could try to guess each
other’s passwords (Chauhan et al., 2016; Dunphy et al., 2010).
In between-subject design studies, it was significantly more
common for the researchers to increase internal validity by
having a participant assigned to a specific group observe mul-
COMPUTERS & SECURITY 99 (2020) 102023 19

tiple passwords of that type (Ali, 2016; Jenkins et al., 2014;
Kraus et al., 2017; Kwon et al., 2014b; Oakley, 2014; Sahami Shi-
razietal., 2012; Zakaria et al., 2011). Studies that employed the
within-subject design expected each participant to observe
passwords of several authentication methods under consid-
eration. Such study design boosts the sample size per method
and reduces comparability bias due to variation, but it also in-
creases the participants’ mental workload, fatigue, and study
duration. To decrease the impact of these disadvantages, some
studies decided to have the participants observe only one
password per each group (Almoctar et al., 2018; Cain, 2018;
Cain et al., 2017; Chakraborty and Mondal, 2014; Clark et al.,
2017; Schaub et al., 2013). Considerably more studies, however,
presumed several passwords per group for every participant
(Aviv et al., 2018; Bulling et al., 2012; Juang and Greenstein,
2011; Khamis et al., 2017b; Martinez-Diaz et al., 2013; Song
et al., 2015; Yu et al., 2017). Whereas such design allowed them
to gather a lot of data to analyze, the impact of password inter-
ference should be considered when interpreting the results.

4.2.5. Comparability

A rigorous, well-established experimental analysis provides
an objective and empirical assessment of a given authentica-
tion scheme’s vulnerability to shoulder surfing attacks, which
has been the primary goal of the publications in the final sub-
set. However, without any benchmarks to which to compare
the results, their real-world implications are rather limited
(Ali, 2016; Alsaiari et al., 2015; Ho et al., 2014; Krombholz et al.,;

Sahami Shirazi et al., 2012) - namely, they are valid for that
specific configuration of the authentication method in that
specific shoulder surfing scenario.

To broaden their analysis, the majority of considered re-
search papers (56/77 or 72.7%) carried out comparisons be-
tween different experimental groups. The focus of such com-
parisons was either to test the performance of different
variations of the method against each other, or to observe
the impact of dependent variables on the SSA susceptibil-
ity. Method variations are largely scheme-dependent. For ex-
ample, in the scope of a gesture-based method, different
gesture groups (i.e. words, numbers, shapes, abstract ges-
tures) were compared in terms of shoulder surfing vulner-
ability (Clark et al., 2017). A proposal for a similar touch-
based authentication method examined the susceptibility of
doodles versus pseudo-signatures (Martinez-Diaz et al., 2013).
In another study, three defence techniques designed to pro-
tect the DAS scheme from shoulder surfing were evaluated
(Zakaria et al., 2011). Certain touch-based schemes measured
the difficulty to observe physiological and behavioral input
features (Khan et al., 2016; Song et al., 2017). In a gait system,
authors examined the success of imitation attacks when the
observers walked behind, or alongside the victim (Muaaz and
Mayrhofer, 2017).

While some of these comparison groups could be applied
to several different schemes, they are nonetheless specialized,
and therefore frequently utilized to identify the most resilient
variation of the novel scheme. More often, comparison groups

Table 9 - Descriptions of comparability study features along with their absolute and percentile representations in the

 

reviewed literature, and selected example sources.

Feature of a study

Representation

Example sources

/w Other Groups

Multiple experimental groups were examined for
the target scheme

A single group was examined for the target scheme

56/77 (72.7%)

21/77 (27.3%)

Zakaria et al. (2011), Khamis et al. (2017b),
Oakley (2014), Jenkins et al. (2014), Muaaz and
Mayrhofer (2017)

De Luca et al. (2010), Chakraborty and
Mondal (2014), von Zezschwitz et al. (2015a),
Cain et al. (2017), Nyang et al. (2018)

/w Other schemes

Target scheme was compared to other (non-base)
schemes

Target scheme was not compared to any other
schemes

15/77 (19.5%)

62/77 (80.5%)

De Luca et al. (2009a), Khamis et al. (2017a),
Wiese and Roth (2016), Yu et al. (2017), Cain (2018)
Maqsood et al. (2016), Ali (2016), Krombholz et al.,
Bianchi et al. (2016), Song et al. (2017)

/w Base schemes

Target scheme was compared to textual passwords

Target scheme was compared to the swipe pattern

Target scheme was compared to PIN codes

Target scheme was not compared to any base
schemes

8/77 (10.4%)

5/77 (6.5%)

22/77 (28.6%)

49/77 (63.6%)

Abdrabou et al. (2019), Tan (2005), BoSnjak and
Brumen (2019), Tari et al. (2006), Juang and
Greenstein (2011)

De Luca et al. (2013a), Aviv et al. (2017),

Aviv et al. (2018), Marques et al. (2013),

Aris et al. (2018)

Kraus et al. (2017), Khamis et al. (2017c),
Almoctar et al. (2018), Kim et al. (2010),

Lee et al. (2017)

Al-Ameen and Wright (2016), Clark et al. (2017),
Chakraborty et al. (2016), Mat Lazim and
Zakaria (2018), Nguyen et al. (2017)
20 COMPUTERS & SECURITY 99 (2020) 102023

investigate the impact of generic dependent variables that
can be examined in the scope of most shoulder surfing stud-
ies. These variables include, but are not limited to: input de-
vice (Chakraborty et al., 2016), grid (Gugenheimer et al., 2015)
or phone size (Aviv et al., 2017), handedness (Ali and Ketab-
dar, 2015) and hand position (Maqsood et al., 2016), viewing
angle (Ali and Ketabdar, 2015; Aviv et al., 2018; Khan et al.,
2018), input type (Al-Ameen and Wnight, 2016; Gugenheimer
et al., 2015; Jebriel and Poet, 2011; Tari et al., 2006) and speed
(Chauhan et al., 2016; Lee, 2014), element visibility (De Luca
et al., 2013b; L’Yi et al., 2016; von Zezschwitz et al., 2015b)
or positioning (Abdrabou et al., 2019; Khamis et al., 2017b),
attack severity (De Luca et al., 2013a, 2013b; Khamis et al.,
2018b; Nguyen and Memon, 2018; Sun et al., 2014) and con-
figuration (Almoctar et al., 2018), mode switches (De Luca
et al., 2014; Khamis et al., 2016, 2017a), repeated viewings (Aviv
et al., 2018; Cain, 2018) and visual feedback (Cain et al., 2016;
Nguyen et al., 2017), participant knowledge (BoSnjak and Bru-
men, 2019; Jenkins et al., 2014), and password strength (Ali and
Ketabdar, 2015; Anand et al., 2015; Aviv et al., 2018; Maqsood
et al., 2016; Schaub et al., 2012, 2013; Wiese and Roth, 2016;
Yu et al., 2017). These dependent variables relate to the exper-
imental design more so than the design features of the au-
thentication scheme itself. Comparing methods along these
axes is encouraged in order to examine the SSA susceptibility
in different scenarios and against different threat models.
However, while these experimental groups provide means
to amore comprehensive assessment of a given method’s sus-
ceptibility to SSA, researchers should be cautious when in-
terpreting the obtained results in the context of all authenti-
cation methods. Without benchmark methods with which to
compare the results, even rigorous examinations of the pro-
posed methods in various threat scenarios suffer from poor
generalizability and limited external validity. For that pur-
pose, we introduce the concept of a base scheme, as an au-
thentication method that meets two criteria: (1) itis deployed
and widely used for the purpose of authentication in the real
world, and (2) the scheme is similar to the proposed method
in terms of their design aspects. The similarity ensures that
the two schemes are comparable; our evaluation framework
can be utilized to estimate the level of similarity. Meanwhile,
the prevalence requirement for the base scheme has impor-
tant implications for the acceptability of the compared novel
scheme. The base schemes most commonly compared to in
literature were the classic textual passwords input through a
keyboard (Abdrabou et al., 2019; BoSnjak and Brumen, 2019;
De Luca et al., 2009b; Juang and Greenstein, 2011; Kwon et al.,
2014a; Tari et al., 2006), PIN codes (Almoctar et al., 2018; Bulling
et al., 2012; De Luca et al., 2010; Khamis et al., 2017c; Khan
et al., 2018; Kim et al., 2010; Kraus et al., 2017; Lee et al., 2017;
Maqsood et al., 2016; Marques et al., 2013; Nyang et al., 2018;
Roth et al., 2004; Sasamoto et al., 2008; Still and Bell, 2018;
von Zezschwitz et al., 2015a), or a swipe pattern (Aris et al.,
2018; Aviv et al., 2017, 2018; De Luca et al., 2013a). In a few pa-
pers, several base schemes were compared against the consid-
ered method (Aris et al., 2018; Aviv et al., 2017, 2018; De Luca
et al., 2009b, 2013a). Altogether, only about a third (28/77 or
36.4%) of the papers compared the proposed method to a base
scheme. We implore more researchers to include comparisons
to base schemes in future evaluations of their novel meth-

ods. Base schemes should provide them with realistic bench-
marks, defining minimal security and usability requirements
their novel method needs to meet or, ideally, surpass.

Even fewer papers (only 15/77 or 19.5%) executed compar-
isons against other authentication schemes. In a few cases,
the authors compared several schemes they proposed in the
same paper (De Luca et al., 2009a; Kim et al., 2010) or in one
of their previous papers (Khamis et al., 2017a). This allowed
them to estimate which one of their proposed methods would
be the most resistant to shoulder surfing, but such compar-
isons provide little information about how they would per-
form against some alternatives. A better approach would be
to compare the susceptibility of several proposed methods to
base schemes, as well as some of the existing methods in lit-
erature (Lee, 2014). Comparisons against existing schemes are
advised even when the publication is evaluating just a sin-
gle novel authentication method, as is often the case. Usually,
authors compare their novel method against methods that
are conceptually similar to the proposed one (Nyang et al.,
2018; Yu et al., 2017), even though they may also intention-
ally compare them to contrasting schemes to observe the dif-
ferences (BoSnjak and Brumen, 2019). If the proposed method
was based on a particular alternative, they may also be com-
pared to determine whether the proposal is an improvement
(Chakraborty and Mondal, 2014; Kwon et al., 2014a, 2014b).

Studies focusing on the evaluation of the existing authen-
tication mechanisms are just as important as novel propos-
als. Several papers selected multiple contemporary authenti-
cation schemes and tested their resilience to shoulder surfing
attacks in comparison to one another (Cain, 2018; Cain et al.,
2017; Schaub et al., 2012, 2013; Wiese and Roth, 2016). To con-
duct the experiments, the proposed schemes should first be
implemented according to the descriptions in the original pa-
pers; alternatively, the proposed schemes can be extended or
upgraded (Khamis et al., 2018b). Conducting additional com-
parisons against different types of schemes boosts their ex-
ternal validity and helps increase the understanding of all
schemes under consideration. Ideally, all existing proposals
should be compared against as many other schemes as pos-
sible in a variety of different threat scenarios. Unfortunately,
with the current focus on novel proposals rather than thor-
ough evaluations, researchers are also unable to reuse the re-
sults of previous studies. This paper aims to highlight the im-
portance of good experimental design and transparent threat
models, in order to gain a comprehensive understanding of
the authentication mechanisms and provide a basis for objec-
tive comparison.

In conclusion, we would like to remind researchers about
the importance of inferential statistics when conducting com-
parisons. Almost two thirds of studies (50/77 or 64.9%) em-
ployed statistical tests in their analysis; however, this figure
is much lower if we include experimental studies with lower
quality scores. Additionally, crucial information related to the
executed statistical tests is often described superficially or
not at all. To ensure the obtained results are interpreted cor-
rectly, and the observed differences are meaningful and not
occurring by chance, the approach to the statistical analysis
should be meticulous and systematic. Firstly, the chosen sta-
tistical tests should be tied to hypotheses (Almoctar et al.,
2018; Aviv et al., 2017; Bulling et al., 2012; Schaub et al., 2012)
COMPUTERS & SECURITY 99 (2020) 102023 21

that address the defined research questions (BoSnjak and Bru-
men, 2019; Tari et al., 2006). Transparency can also be achieved
by explicitly defining them in separate sections (BoSnjak and
Brumen, 2019). Secondly, researchers should always check
whether all test assumptions have been met, which should
be reported in the study (Aris et al., 2018; Aviv et al., 2017;
Clark et al., 2017; Tiller et al., 2019). When conducting pair-
wise comparisons between multiple groups, the appropriate
corrections should be used (Abdrabou et al., 2019; Cain, 2018;
Kraus et al., 2017; Zakaria et al., 2011). By taking such practices
into consideration, future studies can ensure the conducted
Statistical analysis is valid, informative, and reproducible.

4.2.6. Metrics
Susceptibility of a given method to shoulder surfing attacks is
an abstract concept that can be measured in many different
ways. Unlike security or memorability, it is difficult to define
what exactly affects the method’s vulnerability to these at-
tacks. Furthermore, the lack of a straightforward metric and
various ways in which the susceptibility has been interpreted
in literature led us to observe that the susceptibility to SSA
is dependent on many different factors, which have not been
explored until recently (BoSnjak and Brumen, 2019).
Consequently, an overwhelming majority (72/77 or 93.5%)
of studies used a metric based on the accuracy of the par-
ticipant’s guess. More than a half (40/77 or 51.9%) settled for

the simplified version of the guessing accuracy, using a binary
metric to determine whether the participant had correctly
guessed the entire password, or not (Al-Ameen and Wright,
2016; Alsaiari et al., 2015; Alsuhibany, 2019; De Luca et al., 2014;
Ho et al., 2014; Sasamoto et al., 2008). The reasoning for the
choice was generally quoted to be the difficulty to find an ob-
jective and comparable distance metric that worked for dif-
ferent authentication schemes (Schaub et al., 2013). However,
despite the differences in method design, we believe that the
degree of correctness can replace the binary metric in most
cases to give a more precise estimation of the guessing accu-
racy (Bianchi et al., 2016; Cain, 2018; Chakraborty and Mondal,
2014; Kwon et al., 2014a; von Zezschwitz et al., 2015a). Unlike
the binary metric, the degree of correctness provides an ad-
ditional bit of information: it shows how close the attacker
was to guessing the full password. Based on that, it is possi-
ble to devise a probabilistic guessing algorithm, which takes
the correct partial guesses into account when estimating the
password strength (Lee, 2014). An even more precise metric
is the recognition rate per character, which provides a break-
down of guessing accuracy for every individual character in
the password (Schaub et al., 2012).

A significantly smaller percentage of studies (17/77 or
22.1%) approached the measurement of SSA susceptibility
from the perspective of a determined observer. They based
the measure on the assumption that the most dangerous hu-

Table 10 - Descriptions of metrics study features along with their absolute and percentile representations in the reviewed

literature, and selected example sources.

 

Feature of a study

Representation

Example sources

Guessing accuracy

Percentile guessing accuracy was given for the
guessed password

Binary guessing accuracy was given for the guessed
password

Guessing accuracy was not measured in the study

32/77 (41.6%)

40/77 (51.9%)

5/77 (6.5%)

von Zezschwitz et al. (2015b), Kwon et al. (2014a),
Khan et al. (2018), Roth et al. (2004), Sun et al. (2014)
Still and Bell (2018), Khan et al. (2016),

De Luca et al. (2014), Khamis et al. (2018a), Eiband
et al. (2017)

Kraus et al. (2017), Abdrabou et al. (2019),

Dunphy et al. (2010), L’Yi et al. (2016), Juang and
Greenstein (2011)

Number of observations

Examined number of passwords guessed on each
attempt

Reported only average number of observations
necessary

Did not examine number of observations to guess a
password

6/77 (7.8%)
11/77 (14.3%)

60/77 (77.9%)

Khan et al. (2018), Clark et al. (2017), Wiese and
Roth (2016), Yu et al. (2017), L’Yi et al. (2016)

Ali (2016), Lee (2014), Anand et al. (2015),

Aris et al. (2018), Cain et al. (2017)

Sahami Shirazi et al. (2012),

Papadopoulos et al. (2017), Jebriel and Poet (2011),
Schaub et al. (2013), Nguyen and Memon (2018)

Distance metrics

Employed Levenshtein distance to measure
guessing accuracy

... among these, employed exclusively Levenshtein
distance

Employed other distance measures in the study

Did not employ any distance measures in the study

13/77 (16.9%)

11/77 (14.3%)

2/77 (2.6%)

64/77 (83.1%)

De Luca et al. (2013b), Khamis et al. (2017b),
Schaub et al. (2012), Kraus et al. (2017), Tan (2005)
Maqsood et al. (2016), Abdrabou et al. (2019),
Khan et al. (2016), Khamis et al. (2017a),

De Luca et al. (2013b)

Bosnjak and Brumen (2019), Juang and
Greenstein (2011)

Alsuhibany (2019), Song et al. (2015), Sasamoto
et al. (2008), Alsaiari et al. (2015), Aumi and

Kratz (2014)
22 COMPUTERS & SECURITY 99 (2020) 102023

man shoulder surfing attacks are carried out by the victim’s
acquaintances, who often have an opportunity to observe the
authentication process several times. These papers measured
how many tries it took the observer to correctly guess the full
password. Whereas a few papers reported only the average
number of attempts until the first successful guess (Anand
et al., 2015; Aris et al., 2018), most studies detailed the number
of passwords guessed on each attempt. Some studies limited
the number of maximum observations to determine whether
the passwords could be guessed within the allowed number of
failed guesses before the lock-down (Al-Ameen and Wright,
2016; Chakraborty and Mondal, 2014; De Luca et al., 2009a;
Oakley, 2014; Still and Bell, 2018). The ones that allowed unlim-
ited attempts examined whether the participants could au-
thenticate successfully before losing motivation (Clark et al.,
2017; Khan et al., 2016). This effort was extended in another
paper, which also measured the number of observations re-
quired for partially correct guesses (Khan et al., 2018). The ra-
tionale is similar to the one behind the degree of correctness:
an attacker knowing that a method was vulnerable to partial
guesses within a number of attempts could mount a brute-
force attack to find the remaining password characters.

In practically all of the papers measuring the number of
observations necessary to retrieve a password, the guessing
accuracy was measured as well. For the sake of cross-paper
comparisons, it is important to report whether the guess-
ing accuracy was measured per guess (Kwon et al., 2014a;
Zakaria et al., 2011), or the entire guessing session. If pos-
sible, the researchers can distinguish between critical and
non-critical errors, as well (Aris et al., 2018; Aviv et al., 2017;
Krombholz et al.,). Using combinations of multiple metrics is
preferable for several reasons. With each metric targeting a
specific aspect of the SSA, together they can provide a broader
and more comprehensive assessment of a given scheme’s vul-
nerability to these attacks. By investigating the results from

several individual metrics, researchers can attempt to iden-
tify the underlying reasons for the method's susceptibility to
SSA. Finally, composite metrics can easily be established from
any number of individual metrics, allowing the researchers to
focus on certain aspects of the SSA that are more relevant to
the authentication method under consideration (BosSnjak and
Brumen, 2019).

Distance metrics were employed by only about 16.9%
(13/77) of the studies. The main idea behind distance metrics
is to estimate the size of the difference between two strings.
This concept can be applied to the task of SSA evaluation
if we represent the two strings as the real and the guessed
password (Maqsood et al., 2016). The most commonly used
distance measure in SSA studies is the Levenshtein distance,
which computes the number of single password character ed-
its (insertions, deletions, substitutions) necessary to change
the guessed password into the real password (Abdrabou et al.,
2019; De Luca et al., 2013b; Khamis et al., 2016; Kraus et al.,
2017; Maqsood et al., 2016; Schaub et al., 2012; Tan, 2005). An-
other edit distance, the Jaro-Winkler proximity, was used in
another study (Juang and Greenstein, 2011). Other distance
measures, such as the Jaccard index, Cosine similarity, and N-
grams, may also be utilized. Based on how each metric is cal-
culated, different conclusions can be drawn from the obtained
results. In a recent study, an ensemble of various measures
based on password characteristics, distance metrics, and the
guessing order was composed (BoSnjak and Brumen, 2019).
The established framework can be used to comprehensively
evaluate and compare the SSA vulnerability of the existing
and novel authentication mechanisms.

4.2.7. Other factors

To provide additional context to their repeated guesses, one
study required the participants to provide a self-estimated
level of memory accuracy (Yu et al., 2017). While a subjective

Table 11 - Descriptions of other factor study features along with their absolute and percentile representations in the re-

viewed literature, and selected example sources.

 

Feature of a study

Representation

Example sources

Effort

Statistically compared and evaluated the guessing
effort

Reported quantitative or qualitative results for the
guessing effort

Participant effort was not examined

19/77 (24.7%)

5/77 (6.5%)

53/77 (68.8%)

Maqsood et al. (2016), Khamis et al. (2016),
Al-Ameen and Wright (2016), Bulling et al. (2012),
Lee et al. (2017)

Sahami Shirazi et al. (2012),

De Luca et al. (2013a), Kraus et al. (2017),

Khamis et al. (2017c), Jenkins et al. (2014)

De Luca et al. (2010), Cain et al. (2016), Ali and
Ketabdar (2015), Nyang et al. (2018),
Martinez-Diaz et al. (2013)

Strategy

Statistically compared and evaluated participant
guessing strategies

Reported quantitative or qualitative results for the
guessing strategies

Guessing strategies were not examined

12/77 (15.6%)

17/77 (22.1%)

48/77 (62.3%)

Khan et al. (2018), Aviv et al. (2018),

Ho et al. (2014), Tari et al. (2006), L’Yi et al. (2016)
Gugenheimer et al. (2015), Khamis et al. (20174),
Chakraborty et al. (2016), Kwon et al. (2014b),
Juang and Greenstein (2011)

De Luca et al. (2009b), Almoctar et al. (2018),
Chakraborty and Mondal (2014), Cain (2018),
Chauhan et al. (2016)
COMPUTERS & SECURITY 99 (2020) 102023 23

measure, the memory accuracy modelled the participants’
level of confidence in their guess. Another study directly asked
the participants how confident they were in each of their
guesses (Khamis et al., 2018b). Both allowed the authors to
examine whether the users’ perceived guessing confidence
affected their ability to produce the real observed password.
Almost a third of the studies (24/77 or 31.2%) addressed the
effort participants needed to put into guessing the observed
passwords. A minority collected the feedback through open
interviews, in which they asked the participants about the dif-
ficulty of executing the attack (De Luca et al., 2013a; Khamis
et al., 2017c; Kraus et al., 2017). One of the main advantages
of this approach was the ability to determine what made the
attack easy or difficult to carry out (Aviv et al., 2018), bas-
ing their findings on personal experience. Alternatively, the
participants were asked to estimate their own effort (Jenkins
et al., 2014; Sahami Shirazi et al., 2012) or their opinion on
the ease of executing a successful SSA (Tari et al., 2006) ona
pre-defined scale. This quantitative approach allowed the re-
searchers to statistically compare the differences in perceived
effort between the observed methods’ groups (Juang and
Greenstein, 2011; Maqsood et al., 2016; Tari et al., 2006) or de-
mographics (Bulling et al., 2012). A combination of qualitative
and quantitative analysis has also been used (Bianchi et al.,
2016).

Relatively few papers (29/77 or 37.7%) were interested in
strategies that the participants employed in their observa-
tions. Some basic conclusions could be drawn simply from

  

Informed Password system engineering:

 

observing how the attackers and victims behaved (Abdrabou
et al., 2019; Juang and Greenstein, 2011; Oakley, 2014; Tan,
2005). By classifying these behaviours into attack categories,
the experimenters could conduct exploratory analysis with
the intention to identify new attack strategies (De Luca et al.,
2013b; Kwon et al., 2014b; Lee, 2014). This is important because
it can reveal the method’s disadvantages, which can help the
authors improve their proposed method (Bulling et al., 2012;
Lee et al., 2017). Amore common approach was to encourage
the participants to think aloud (De Luca et al., 2014; Gugen-
heimer et al., 2015) or discuss (Khamis et al., 2017a; Roth et al.,
2004) their strategies, or simply ask them about their attack
strategies directly (Bianchi et al., 2016; Khamis et al., 2017a).
Personal experiences provided additional insight into the at-
tackers’ shoulder surfing approaches (Kwon et al., 2014b; L’Yi
et al., 2016). Additionally, qualitative responses could be cate-
gorized into groups to determine which attack strategies were
the most frequent (Aviv et al., 2018; Ho et al., 2014; Khamis
et al., 2018b; Maqsood et al., 2016; Tari et al., 2006). Statisti-
cal analyses were performed to assess the differences in the
frequency of strategies (Kraus et al., 2017) and the effect of at-
tack strategies on the guessing success rate (Khan et al., 2018;
Schaub et al., 2012).

4.3. Evaluation Framework

Based on the conducted systematic literature review, we
present a comprehensive framework for the evaluation and

Fig. 4 - Diagram representing the inclusion of the evaluation framework in method and SSA experiment design process.
24 COMPUTERS & SECURITY 99 (2020) 102023

design of SSA experiments. The full framework consists of 30
parameters addressing crucial factors that play a role in ei-
ther method, or experiment design — and in turn, how these
design decisions affect the method’s susceptibility to shoul-
der surfing, as well as the comparability and validity of the
reported findings.

An emergent product of the analyses, the evaluation
framework lays the foundation for a standardised procedure
under which future SSA experiments can be conducted. It
guides researchers to make appropriate experimental de-
sign decisions based on their method’s design aspects, and
underlines the importance of reporting them in the study
for increased comparability. This highlights the framework’s
unique contribution which can be summarized in its two
primary goals: (1) comprehensive evaluation, which provides
means to select an appropriate experimental setup based
on the method’s design aspects, study assumptions, and
threat model and (2) objective comparability, which allows any
scheme to be evaluated against another scheme in a straight-
forward, easily measurable way. The parameters in question
are discussed in detail in B.1.

The established evaluation framework is illustrated in
Fig. 4, outlining how the shoulder surfing evaluation process
can be integrated into the general authentication method de-
sign. Once a novel graphical authentication method has been
developed, its design features can be determined by evaluat-
ing the method against the 10 method design parameters. The
outcome of this assessment is a model that objectively de-
scribes the method’s design features, which can then be used
to find an appropriate experimental procedure.

The said procedure is thoroughly described through an ex-
haustive set of 20 experimental setup parameters, which were
organized into several categories for clarity. These parame-
ters allow for comprehensive assessment of the entire experi-
mental procedure, from preparation and execution of the SSA
experiment, to analysis of the obtained results. All features
related to the participants, the attack itself, and the analysis
are directly tied to criteria presented in the framework. Sub-
sequent analysis of the results allows researchers to properly
assess the SSA susceptibility of their scheme.

The insight gained from the results can be utilized to guide
and improve the design of novel or existing graphical authen-
tication systems. The framework is limited by the current un-
derstanding of each feature’s effect on the scheme, but with
new studies conducted in adherence to it, this understand-
ing will grow. Through it, we foresee gradual and iterative im-
provement of the framework, both in the form of new and
revised parameters, and mechanisms to study the interplay
between them. This leads to the important enhancement of
the method and SSA experiment design process itself that we
would like to postulate.

Under the idea of password system engineering, the impact
of individual factors on scheme’s SSA susceptibility can be
viewed through objective metrics. Armed with such knowl-
edge, researchers can design — or engineer — novel schemes
in accordance with the desired outcome and understanding
of how to achieve it. This would mark a paradigm shift from
the current design methodology, which is largely based on per-
sonal intuition and expert knowledge.

 

5. Conclusions and Future Work

The emergence and proliferation of novel graphical authen-
tication proposals aiming to replace textual passwords has
generated the need for a systematic classification of the exist-
ing approaches. Previous SLRs have focused on establishing a
clear taxonomy and identifying relevant studies in the field of
graphical authentication. Circumstantially, a broad overview
of the existing authentication mechanisms allowed for the
discovery of key issues related to their evaluation, especially
when it comes to poorly understood attacks, such as shoul-
der surfing. In particular, the experiments conducted in lit-
erature often come under a variety of different setups and
assumptions, each tailored to the method under considera-
tion. Furthermore, the results obtained are generally coarse-
grained and circumstantial, owing to a lack of universally ac-
cepted metrics and evaluation standards. As a result, shoul-
der surfing studies are very difficult to compare, and their va-
lidity may be negatively affected due to poor experimental
design.

To assess the full scale of the problem, we conducted a sys-
tematic literature review in the field of shoulder surfing. The
aim of this study was to provide a wide-scale, comprehen-
sive assessment of experimental SSA studies, in order to (1)
catalogue all existing, up-to-date empirical SSA studies con-
forming to rigorous quality criteria, (2) identify possible ex-
perimental design decisions and their impact on the results
and their interpretation, and (3) generate guidelines for fu-
ture researchers on how to conduct SSA experiments based
on their threat model and study assumptions. To achieve this
objective, we have defined two research questions, and carried
out a systematic literature review in compliance with the pre-
defined methodology. Following the identification of primary
studies, evaluation against eligibility criteria, and quality as-
sessment, we have narrowed down the literature to 77 rele-
vant studies. For the purpose of the qualitative and quantita-
tive analysis, we established a framework for the all-inclusive
evaluation of the shoulder surfing experimental design. The
77 publications were then analyzed by two independent re-
viewers, in order to answer the defined research questions and
provide novel insights.

Our findings indicate that the design aspects and proper-
ties of the graphical passwords affect their security and usabil-
ity, including their susceptibility to shoulder surfing attacks.
Specifically, we have shown that the way the method is de-
signed has an impact on how difficult it is to be observed un-
der various different conditions and study assumptions. More
importantly, however, we establish that not just any experi-
mental design is appropriate for the evaluation of a given au-
thentication method. Novel proposals are often inclined to-
ward experimental designs that showcase their method’s re-
silience against these attacks without considering the con-
texts in which their method may actually be more vulnerable.
Others replicate experimental designs from previous studies
even though the schemes are conceptually very different and
therefore vulnerable to different observational setups. When
designing their shoulder surfing experiment, the researchers
should take the method’s design features, characteristics of
the graphical passwords, and device capabilities into account.
COMPUTERS & SECURITY 99 (2020) 102023 25

The synthesis performed in this SLR should help them iden-
tify conceptually similar authentication methods for compar-
ison, and determine which experimental setups are the most
suitable for their specific method. To assess the quality of
the empirical shoulder surfing studies in literature, we de-
signed and established an evaluation framework. The purpose
of the framework was not solely to identify all possible de-
sign choices and their impact on the study results and their
implications, but primarily to provide future researchers with
a comprehensive list of considerations when designing their
shoulder surfing experiments. Through the course of our anal-
ysis, SSA experiments were evaluated against a set of 20 pa-
rameters aimed to encompass all potential experimental de-
sign decisions, including comparisons against other studies,
and the employed metrics. A wide diversity of experimental
setups identified empirically demonstrates the lack of com-
mon standards for the evaluation of shoulder surfing attacks.
As a result, we have shown that many studies fail to address
and report certain design choices that may significantly im-
pact the obtained results. Furthermore, the analysis strength-
ens our hypothesis that most experimental design decisions
are either ad-hoc and arbitrary or are focused on specific se-
tups which decrease comparability and external validity.
This work lays foundations for the standardization of SSA
evaluation. Researchers are urged to adopt a systematic ap-
proach to their evaluation, and fill the gaps made by the pre-
vious empirical shoulder surfing studies. By evaluating novel
and existing schemes against the parameters, researchers

should be able to make educated design decisions based on
their method design, threat model, study assumptions and
previous similar proposals. This should increase our under-
standing of the shoulder surfing phenomena, and ultimately
the overall quality of shoulder surfing experiments.

 

Declaration of Competing Interest

The authors declare that they have no known competing fi-
nancial interests or personal relationships that could have ap-
peared to influence the work reported in this paper.

 

CRediT authorship contribution statement

Leon BoSnjak: Conceptualization, Methodology, Investiga-
tion, Formal analysis, Data curation, Writing - original draft,
Writing - review & editing, Visualization. BoStjan Brumen: In-
vestigation, Formal analysis, Writing - review & editing, Super-
vision, Project administration, Funding acquisition.

 

Acknowledgement

The authors acknowledge the financial support from the
Slovenian Research Agency (research core funding no. P2-
0057).
26 COMPUTERS & SECURITY 99 (2020) 102023

 

Appendix A. Systematic review protocol

Objective

O1: Identify empirical shoulder surfing studies conforming to defined quality criteria

O2: Establish a framework for the assessment of shoulder surfing experimental setup

03: Conduct a comprehensive review of identified studies in compliance with the evaluation framework
04: Produce guidelines for the quality improvement of future shoulder surfing experiments

Research Questions

RQ1: What are the design aspects of graphical authentication methods?
RQ2: What is the quality of the executed shoulder surfing experiments?

Reviewers

Primary Reviewer: Leon BoSsnjak, Teaching Assistant, Faculty of Electrical Engineering and Computer
Science, Maribor, Slovenia

Secondary Reviewer: Bostjan Brumen, Associate Professor, Faculty of Electrical Engineering and
Computer Science, Maribor, Slovenia

Search Methodology
Search Terms

(?’?shoulder surf*’’ OR ’’*shoulder attack*’’ OR ’’observation attack*’’)

In cases when the asterisk symbol (*) could not be used, the original search query was replaced with the
following:

(?’shoulder surf’’ OR ’’shoulder surfing’’) OR (’’shoulder attack’’ OR ’’shoulder
attacks’’) OR (’’observation attack’’ OR ’’observation attacks’’) OR (’’over the
shoulder attack’’ OR ’’over-the-shoulder attack’ ’)

Included Databases

ACM Digital Library, Elsevier ScienceDirect, Elsevier Scopus, Google Scholar, IEEE Xplore, MDPI,
SpringerLink, Web of Science

Evaluation Process

E1: Identification

A keyword search using the above search terms is performed to identify all potentially relevant studies.
E2: Relevance

Titles and abstracts are scanned for relevance to the defined research field of shoulder surfing attacks on
authentication methods.

E3: Inclusion

Studies are assessed against the defined inclusion criteria. All other studies are discarded.

E4: Categorization

Full texts are read and papers are classified based on the main focus of the study.

E5: Specificity

Research methodology and experimental procedures are analyzed and empirical shoulder surfing
studies are selected for further evaluation.

E6: Quality

Studies are assessed against the quality criteria defined in Table 3.

Study Criteria

Inclusion criteria

IC1: Original research study.

IC2: Publications evaluating shoulder surfing attacks on authentication methods.

IC3: Publications addressing the methodology of shoulder surfing studies.

Exclusion criteria

EC1: Secondary research, review papers, patents and grey literature.

EC2: Publications covering general computer security or social engineering, and other non-relevant
studies.

EC3: Publications not in English.

Record of Findings
Findings were recorded and analyzed using a spreadsheet in Google Drive.
COMPUTERS & SECURITY 99 (2020) 102023 27

 

Appendix B. Literature review

¢ = meets criteria; o = partially meets criteria; no circle = does not meet criteria.

All empirical shoulder surfing studies detailed in the literature review are grouped into the standard graphical password cate-
gories (Tables 12-14). Points are awarded to each scheme for various attributes describing the scheme’s design and the shoulder
surfing experiment conducted. Attributes describing the method’s design were originally proposed by Schaub et al. (2013). All
considered attributes and the criteria for awarding points are described on the following page.

Table 12 - Comparison of shoulder surfing experiments across the various authentication schemes. These references cited
rhe eh t melo) (om ; 5 ; 5 5

 

Method Design [84] Shoulder Surfing Experiment
CHR DSG CPB Experimental Setup Compare Metrics Other

              

         

        

~
0 5 o 8 L yw & uld
: FS S23 |e x 8 s see:
a 2Ps,2 Stans > i * S16 8 S/8 8 S
of ©. se FFs se Pe STeeSSesy Sl Vax s
Plas Pe tT VE ss RewpnFBSrsse se sess oP sg 8) &
S/S PSER ESL SRS ST SE PSE SESS aS SSS Fs &
Category Scheme PISSHESBRSESSOMERETASSSKCRRAST FT TNGHROGE
Pure-Recall 3D Magnetic Sig. [80] 0 0 0 0 @ @ 0 o ee ee e oo ° °
Bend PWs [68] 0 Oo oO o @® 0 oO ee eo 0 e o ele elo ele e
BoD Shapes [33] eo 0 @ @ 0 Oo ee e eo ele elo oO
Camouflage [8] oe e o ofo e o 0 e@ o ole e e
ColorPIN [31] oe e o oO e e 0 e elo
ColorSnakes [42] e ° oe e e 0 ele ° Oo
DAS [100]| © ° 01/0 0 @ @® @® 0 o o |e e
EmojiAuth [58] ee 0 oOo oe @ e@ eo o ole e elo e
EyePassShapes [29] ° e e ee o e@ 0 e@ e elo o
FakeCursors [34] oe @ o ° e e ° e °
ForcePIN [55] ee o 0 @ 0 of0 0 e@ @ e e 0 e/e ele e ee
Force-PIN [60] ee o 0 @ o of0 @ e@ O° e O ° e
Gaze EyePIN [1] °o 0 0 @® 0 @ e e e e 0 el]e e ele o
GazeTouchPass [48] ° ° eo o ee ee o ele ° ele
GeoPass [2] | 0 o oO ° o}lo 0 0 e e@ 0000 0 ole oO e
Gestures [28] | o O ole oe ee ee ofe ee
GTmoPass [51] e ° e@ 0 oO ee ee o ele ° ele
GTPass/PIN [49] ° oe eo e ee ° o ele e ° e Oo
GTPIN [52] Oo oe eo ee ee o ele e}o elo
H4Plock [3] e@ 0 0 0 eo eo e O° ° Oo °o oO
IlusionPIN [78] eo eo e@ e oe eo ° ° ele
Incognito [87] o @ © @ o ° oe e o oO eo o oO
LIN [66] 0 0 @ 0 e@ O° oe O° ele e efe o °
Mag. Gesture [4] ee 000 @ 0 Oo ee e oe 0 ole e
Mobile PW [83] | 0 o° 0 Oo O° o 0 6 @ o 0 0 e o ole ° ele e
MultiColor [26] Oo Oo ee O ee eo ° O e eo
PathWord [5] o e@ ° ee @e/0 0 e@ e oO o | e e|o
Pattern [96] a o|e e eee 0c o o ole e e
PatternLock [86] ee ole e eee oo e ele O° e
PIN, Pattern [12] ee ° ole eee Oo Oo o 0 ele elo
PIN, Pattern [13] ee ° olo 0 ee e0o0e 0 0 ele elo e
Secure DnT [61] | o oe @ @ o ° oe °o Oo e e ele
ShaPIN [77] eee o ° ° ee 0 0 Ole ° Oo °
SilSen, Touch [54] © ®@ 0 0 e@ @® 0 0/0 0 0 ee eo ole oe ee
Spy-res. kbd [90]}} 0 0 0 @ e@ e oe ee e Oo @ oO ° ole ele eleo
Swipe [22] ee 0/0 0 e oO ele °
SwiPIN [98] ee 0 e ° ee e ° ele e oe
SwiPIN [95] ee o O° oe eo o 0 e@ ejle O°
TapPattern [69] ee ee o/o0 0 e e o0 Oo Oo elo
TapSongs [9] | 0 °o oO ee ° oe ° 0 0 ele o Oo
VDLS [25] e@ 0 0 0 @e o e o 0 0 e o 8 Oo e/e e Oo
XSide [30] eo oe o o|o0 ee e ee e 0 ele ° °

 

 
28

COMPUTERS & SECURITY 99 (2020) 102023

Table 13 - Comparison of shoulder surfing Satan across the various Testis iat Ter These aS SES
cited in this table 5

 

      
    
    
 

   
  

  

Method Design [84]
CHR DSG

CPB

    
  

  

    

 
   
   
 

Shoulder Surfing Experiment
Experimental Setup

    

   

Compare

     

  
 

      

      

Metrics

    
 

  
 

       

Other

 

 

  

~
Q xc ov 9 v eo wn|o
g 5S s8 |x 8 5 «8 2 se c/Se
YD x 3° o < YU oO
a p> ws =d ec QO ay © = HW) Oo 0 = Oo
v =a £ 8 we 2/8 w 3 cod 0 & 8 Pion Sle as
o O& s fs S 5 o £/28 I 5 .o oe2osSs 6 SJve i MN >
els —-S Bes TOS ye FS Sw ys sSlBeeS B ISS vw FS gl s
i — a
sss Sees ze hzseS rss sess s ssbb dle s Sle
“|/o 2 € Gg a 2 S 5 ca a 8 o g B NRNR $ a © fo
Category Scheme riIcp OOSHFKESESCSUKAETASSSELCHKKAS SF THOR OAGS
Cued-Recall Assoc. Lists [19]} o o @ @ o o oO e@ oo o 0 Oo ee ee e/e e
Cog. Trapdoor [79] o 0 0 e O ° oO ° e eje e
Conceal PWs [43] o 0 @ o e e O° O° e
CueAuth [53] o 0 0 e O ° ° e ° ee
Imp. BW [62] o @e@ 0 e ° e ° ° e O
PassBYOP [15] ee 0 o ° ° e °
Saliency Mask [20] ee ° e e ° O
SyS [10] ee e Oo Oo
Two-Thumbs-Up [76] Oo Oo e e O
Undercover [82] Oo e ° e
VibraPass [32] ° e °
Recognition Dist. Tech. [71] e ° °
Doodles [45] ° ° ° O
EvoPass [99] e e e
Facelock [46] e ° e
PassFaces [91] ° ° e e
°
O°
e
O°

PassIlmages [35]
PressureFaces [56]
Various [23]
Hybrid GOT Pass
Various Various [21]
Various [84]} o

 

 

 

Table 14 - Comparison of shoulder see experiments across the various authentication schemes. These references
cited in this table (

)

b)

 

Category
Biometric

Behavioral BehavioCog

Non-Auth

 
 
  

x
e
vf 4
ojae 8%
c/s § bw &
o “CO -= 0
cif sp -& S &
‘oD es © fs 2
Scheme ele ak SQ
AirAuth [11] O
[27] ee
DooDB [70] e
DRAW-A-PIN [75] o e@
Gait [73] ee
TapMeln [74]|} 0 @ e
TFST [85] oe
TouchIn [83] oe
CloakingNote [67] oe e
Image Dist. [92] O
Purloin [47] 0 0 e@
Reflector [65] O
Scrawl [38] O

 
 

Motivation

 

Shoulder Surfing Experiment
Experimental Setup

© 0 ee 0 © © © © 0 o © | Victim/Observer
Live/Video

Positioning
000000 e © e@ e| # Observations

o o| # Guesses

Oo O00 0 0

    

e | # Passwords

@®eeoeo0oe0o0c!8dm6UUlm8DUCUOODUlUCOOlUw

 

Compare

  

w/ Other Schemes

ee © © © © 0 0 © e| w/ Other Groups

w/ Base Schemes

)

Metrics

# Observations

Distance Metrics

 

Other
Ge

¢ 2
O° Y

te xX
WH
e

 

)
COMPUTERS & SECURITY 99 (2020) 102023 29

B1. Evaluation parameters

Method design
Password characteristics (CHR)

Theoretical password space for typical passwords is sufficient against brute-force attacks (> 107°)
Brute-force attacks against typical passwords are possible, but unlikely (> 1017)
Typical passwords are not safe against brute-force attacks (< 10”)

Security

——S

Observation Resistance

—~ —
Oo e
~~ >>

Scheme is entirely resistant to video observation
Scheme is partially resistant to video observation (e.g. multiple observations required)
Scheme is not resistant to video observation

-_—
~~

Efficiency (e) Typical login time is comparable to textual passwords
Typical login time is still reasonable for users (< 60s)
Typical login time is unreasonable (> 1m)

To
—_——

Memorabilit e Users can consistently remember their passwords (> 90%

y y p

Users can remember their passwords most of the time (> 70%)
Users have trouble recalling their passwords (< 70%)

To
—_——

Design Features (DSG)

SpatialArrangement (e) Visual elements are randomized and there are many of them
(0) There are a few randomized visual elements or there are many fixed elements
() The scheme has a few fixed elements

Temporal Arrangement (e) The scheme provides multiple challenge rounds with changing cues
(0) Authentication requires multiple challenges on a fixed background

-_—
~~

The scheme assumes a single challenge

Visual Cues (e) The computer does not present any visual cues
(0) The scheme presents both visual and non-visual information
() All computer-human interaction is visual
Interaction Method (e) The scheme uses complex uni- or multimodal interfaces (e.g. gestures, auditory,
haptic, or gaze-based interfaces) for password input
(0) The password can be input through a keyboard
() The password can be input with either a mouse or a finger

Device Capabilities (CPB)

Context ofUse (e) There is a low probability of an observer guessing a password even after multiple
observations
(0) The observer can potentially guess a password after multiple observations
() The observer might guess a password after a single observation
Constraints (e) Authentication can easily be performed despite motoric and vision impairments
(0) Vision-impaired or color blind users can easily authenticate
() Users with motoric or vision impairment cannot easily authenticate

Shoulder Surfing Experiment
Experimental Setup

# Partici-pants (e) The shoulder surfing experiment contained at least 100 participants
() The experiment contained at least 30 participants
The experiment contained less than 30 participants

-_—
~~

ParticipantProfile (e) The participants represent the general population
() Most participants are university students
Profile of participants is not given

-_—
~~

Training (e) The participants had the opportunity to try out the authentication scheme
(0) The participants received explanation of the authentication system, or the system’s usage was
demonstrated
() Shoulder surfing experiment was conducted without the participants’ prior knowledge or

experience with the authentication system

Writing Aid (e) The participants were allowed to record their observations (e.g. using a pen and paper)
() Participants did not record their observations
30

Distractor Task

Motivation

Victim/Observer

Live/Video

Positioning

# Observa-tions

# Guesses

# Passwords

Comparability

/w Other Groups

/w Other Schemes

/w Base Schemes

Metrics

GuessingAccuracy

# Observa-tions

DistanceMetrics

Other Factors

Effort

Strategy

~~ ~~ ~~

~~

—_—— SS

—_—~—S

—_—— SS

—~ ~~
SS

-_—
~~

—~ ~~
SS

Oo

-_—
~~

COMPUTERS & SECURITY 99 (2020) 102023

A distractor task was employed in between the shoulder surfing stage and the password recall
stage
The participants could input observed passwords immediately after the shoulder surfing

The participants were offered monetary compensation for participation
The participants were offered material compensation for participation
No measures were taken to increase the participants’ motivation

The participants played both the roles of victims and observers
Participants acted as observers
Participants were in the role of a victim

Both live and video observations were included
The experiment consisted of live observations
The experiment included only video observations

The participants were able to choose their positioning
The participants had a fixed positioning, but were allowed to assume a comfortable position
The participants had a strictly fixed positioning

Unlimited number of observations was allowed for each password
The participants had multiple observations to guess a password
The participants had a single observation to guess a password

Unlimited number of guesses was allowed for each password
The participants were allowed to guess a password multiple times
The participants had a single attempt to guess a password

The participants had to guess several passwords for several schemes or study conditions

The participants were required to guess several passwords for one scheme or study condition or
one password for several schemes or study conditions

The participants guessed one password for a single scheme or study condition

The study includes different configurations of shoulder surfing a particular scheme (e.g. password
strength, viewing angles, device, etc.)
No comparisons between different shoulder surfing setups are conducted

The considered scheme is compared to other schemes in terms of shoulder surfing vulnerability
There are no comparisons with other authentication schemes

Comparison of shoulder surfing vulnerability with a benchmark scheme (e.g. textual passwords,
PINs, patterns) is included
The considered scheme is not compared to any base schemes

The percentage of the password being guessed correctly is measured
Binary measure of whether the password was correctly guessed or not is employed
The guessing accuracy is not measured

Guessing accuracies for all observations are recorded
Number of observations necessary to correctly guess the password is reported
Number of observations necessary to guess the password is not given

Levenshtein distance metric is employed
Other distance metrics are measured to determine similarity between the correct and guessed passwords
No distance metrics are measured

The participants’ shoulder surfing strategies are empirically evaluated
The participants’ shoulder surfing effort or confidence in their guesses is reported
Shoulder surfing effort is not considered

The participants’ shoulder surfing strategies are empirically evaluated
The participants’ shoulder surfing strategies are reported
Shoulder surfing strategies are not considered
COMPUTERS & SECURITY 99 (2020) 102023 31

REFERENCES

Abdrabou Y, Khamis M, Eisa RM, Ismail S, Elmougy A. Just gaze
and wave: exploring the use of gaze and gestures for
shoulder-surfing resilient authentication. In: Proceedings of
the 11th ACM Symposium on Eye Tracking Research &
Applications - ETRA ’19. Denver, Colorado: ACM Press; 2019.
p. 1-10. doi:10.1145/3314111.3319837.

Al-Ameen MN, Wright M. Exploring the potential of GeoPass: a
geographic location-password scheme. Interact. Comput.
2016. doi:10.1093/iwc/iww033. iwc;iww033v1

Ali A. Developing and evaluating a gestural and tactile mobile
interface to support user authentication. iConference 2016
Proceedings. Philadelphia, USA: iSchools, 2016.

Ali AE, Ketabdar H. Investigating handedness in air signatures for
magnetic 3d gestural user authentication. In: Proceedings of
the 17th International Conference on Human-Computer
Interaction with Mobile Devices and Services Adjunct -
MobileHCI ’15. Copenhagen, Denmark: ACM Press; 2015.

p. 704-11. doi:10.1145/2786567.2793691.

Almoctar H, Irani P, Peysakhovich V, Hurter C. Path word: a
multimodal password entry method for ad-hoc
authentication based on digits’ shape and smooth pursuit eye
movements. In: Proceedings of the 2018 on International
Conference on Multimodal Interaction - ICMI ’18. Boulder, CO,
USA: ACM Press; 2018. p. 268-77. doi:10.1145/3242969.
3243008.

Alomar N, Alsaleh M, Alarifi A. Social authentication
applications, attacks, defense strategies and future research
directions: a systematic review. IEEE Commun. Surv. Tut.
2017;19(2):1080-111. doi:10.1109/COMST.2017.2651741.

Alsaiari H, Papadaki M, Dowland P, Furnell S. Secure graphical
one time password (GOTPass): an empirical study. Inf. Secur. J.
2015;24(4-6):207—20. doi:10.1080/19393555.2015.1115927.

Alsuhibany SA. Usability and shoulder surfing vulnerability of
pattern passwords on mobile devices using camouflage
patterns. J. Ambient Intell. Hum. Comput. 2019.
doi:10.1007/s12652-019-01269-3.

Anand SA, Shrestha P, Saxena N. Bad sounds good sounds:
attacking and defending tap-based rhythmic passwords using
acoustic signals. In: Reiter M, Naccache D, editors. In:
Cryptology and Network Security. Cham: Springer
International Publishing; 2015. p. 95-110.

Aris H, Ibrahim Z, Azman A. Simple screen locking method using
randomly generated number grid on image:. Int. J. Mob. Hum.
Comput. Interact. 2018;10(4):42-71.
doi:10.4018/1IJMHCI.2018100103.

Aumi MTI, Kratz S. AirAuth: evaluating in-air hand gestures for
authentication. In: Proceedings of the 16th International
Conference on Human-Computer Interaction with Mobile
Devices & Services - MobileHCI ’14. Toronto, ON, Canada: ACM
Press; 2014. p. 309-18. doi:10.1145/2628363.2628388.

Aviv, A. J., Davin, J. T., Wolf, F., Kuber, R., 2017. Towards baselines
for shoulder surfing on mobile authentication. Proc. 33rd
Annu. Comput. Secur. Appl. Conf. - ACSAC 2017, 486-498
1709.04959. 10.1145/3134600.3134609.

Aviv, A.J., Wolf, F., Kuber, R., 2018. Comparing video based
shoulder surfing with live simulation. arXiv:1809.08640.

Berman M, Chase JS, Landweber L, Nakao A, Ott M,

Raychaudhuri D, Ricci R, Seskar I. Geni: A federated testbed for
innovative network experiments. Computer Networks
2014;61:5-23. doi:10.1016/).bjp.2013.12.037. Special issue on
Future Internet Testbeds- Part I

Bianchi A, Oakley I, Kim H. PassBYOP: bring your own picture for
securing graphical passwords. IEEE Trans. Hum.-Mach. Syst.
2016;46(3):380-9. doi:10.1109/THMS.2015.2487511.

Biddle R, Chiasson S, Van Oorschot P. Graphical passwords:

learning from the first twelve years. ACM Comput. Surv.
2012;44(4) >19:1-19:41. doi:10.1145/2333112.2333114.

Blonder, G. E.,. Graphical Password.

Bonneau J, Herley C, Van Oorschot PC, Stajano F. The quest to
replace passwords: a framework for comparative evaluation of
web authentication schemes. In: 2012 IEEE Symposium on
Security and Privacy. IEEE; 2012. p. 553-67.

BoSnjak L, Brumen B. Shoulder surfing: from an experimental
study to a comparative framework. Int. J. Hum.-Comput. Stud.
2019;130:1-20. doi:10.1016/j.ijhcs.2019.04.003.

Bulling A, Alt F, Schmidt A. Increasing the security of gaze-based
cued-recall graphical passwords using saliency masks. In:
Proceedings of the 2012 ACM Annual Conference on Human
Factors in Computing Systems - CHI ’12. Austin, Texas, USA:
ACM Press; 2012. p. 3011. doi:10.1145/2207676.2208712.

Cain AA. Usability comparison of over-the- shoulder attack
resistant authentication schemes 2018;13(4):24.

Cain AA, Chiu L, Santiago F, Still JD. Swipe authentication:
exploring over-the-shoulder attack performance. In:
Nicholson D, editor. In: Advances in Human Factors in
Cybersecurity. Cham: Springer International Publishing; 2016.
p. 327-36.

Cain AA, Werner S, Still JD. Graphical authentication resistance to
over-the-shoulder-attacks. In: Proceedings of the 2017 CHI
Conference Extended Abstracts on Human Factors in
Computing Systems - CHI EA ’17. Denver, Colorado, USA: ACM
Press; 2017. p. 2416-22. doi:10.1145/3027063.3053236.

Carroll TE, Manz D, Edgar T, Greitzer FL. Realizing scientific
methods for cyber security. In: Proceedings of the 2012
Workshop on Learning from Authoritative Security
Experiment Results. New York, NY, USA: Association for
Computing Machinery; 2012. p. 1924.
doi:10.1145/2379616.2379619.

Chakraborty N, Anand SV, Randhawa GS, Mondal S. On designing
leakage-resilient vibration based authentication techniques.
In: 2016 IEEE Trustcom/BigDataSE/ISPA. Tianjin, China: IEEE;
2016. p. 1875-81. doi:10.1109/TrustCom.2016.0287.

Chakraborty N, Mondal S. An improved methodology towards
providing immunity against weak shoulder surfing attack. In:
Prakash A, Shyamasundar R, editors. In: Information Systems
Security. Cham: Springer International Publishing; 2014.

p. 298-317.

Chauhan, J., Zhao, B. Z. H., Asghar, H. J., Chan, J., Kaafar, M.A.,
2016. BehavioCog: an observation resistant authentication
scheme. arXiv:1610.09044.

Clark GD, Lindqvist J, Oulasvirta A. Composition policies for
gesture passwords: user choice, security, usability and
memorability. In: 2017 IEEE Conference on Communications
and Network Security (CNS). Las Vegas, NV: IEEE; 2017. p. 1-9.
doi:10.1109/CNS.2017.8228644.

De Luca A, Denzel M, Hussmann H. Look into my eyes!: can you
guess my password?. In: Proceedings of the 5th Symposium
on Usable Privacy and Security - SOUPS ’09. Mountain View,
California: ACM Press; 2009. p. 1. doi:10.1145/1572532.1572542.

De Luca A, Harbach M, von Zezschwitz E, Maurer M-E, Slawik BE,
Hussmann H, Smith M. Now you see me, now you don’t:
protecting smartphone authentication from shoulder surfers.
In: Proceedings of the 32nd Annual ACM Conference on
Human Factors in Computing Systems - CHI 14. Toronto,
Ontario, Canada: ACM Press; 2014. p. 2937-46.
doi:10.1145/2556288.2557097.

De Luca A, Hertzschuch K, Hussmann H. ColorPIN: securing PIN
entry through indirect input. In: Proceedings of the 28th
International Conference on Human Factors in Computing
Systems - CHI ’10. Atlanta, Georgia, USA: ACM Press; 2010.

p. 1103. doi:10.1145/1753326.1753490.

De Luca A, von Zezschwitz E, Hufgmann H. Vibrapass: secure

authentication based on shared lies. In: Proceedings of the

 

 
32 COMPUTERS & SECURITY 99 (2020) 102023

27th International Conference on Human Factors in
Computing Systems - CHI 09. Boston, MA, USA: ACM Press;
2009. p. 913. doi:10.1145/1518701.1518840.

De Luca A, von Zezschwitz E, Nguyen NDH, Maurer M-E,

Rubegni E, Scipioni MP, Langheinrich M. Back-of-device
authentication on smartphones. In: Proceedings of the SIGCHI
Conference on Human Factors in Computing Systems - CHI
13. Paris, France: ACM Press; 2013. p. 2389.
doi:10.1145/2470654.2481330.

De Luca A, von Zezschwitz E, Pichler L, Hussmann H. Using fake
cursors to secure on-screen password entry. In: Proceedings of
the SIGCHI Conference on Human Factors in Computing
Systems - CHI ’13. Paris, France: ACM Press; 2013. p. 2399.
doi:10.1145/2470654.2481331.

Dunphy P, Heiner AP, Asokan N. A closer look at
recognition-based graphical passwords on mobile devices. In:
Proceedings of the Sixth Symposium on Usable Privacy and
Security - SOUPS ’10. Redmond, Washington: ACM Press; 2010.
p. 1. doi:10.1145/1837110.1837114.

Eekelen W, van den Elst J, Khan J. Dynamic layering graphical
elements for graphical password schemes; 2014. Chi Sparks
2014, 03-04-2014; 2014 ; Conference date: 03-04-2014 Through
03-04-2014

Eiband M, Khamis M, von Zezschwitz E, Hussmann H, Alt F.
Understanding shoulder surfing in the wild: stories from
users and observers. In: Proceedings of the 2017 CHI
Conference on Human Factors in Computing Systems - CHI
17. Denver, Colorado, USA: ACM Press; 2017. p. 4254-65.
doi:10.1145/3025453.3025636.

Eiband M, von Zezschwitz E, Buschek D, Hufgmann H. My scrawl
hides it all: protecting text messages against shoulder surfing
with handwritten fonts. In: Proceedings of the 2016 CHI
Conference Extended Abstracts on Human Factors in
Computing Systems - CHI EA ’16. Santa Clara, California, USA:
ACM Press; 2016. p. 2041-8. doi:10.1145/2851581.2892511.

Eljetlawi AM, Ithnin N. Graphical password: comprehensive study
of the usability features of the recognition base graphical
password methods, 2; 2008. p. 1137-43.
doi:10.1109/ICCIT.2008.20.

English R, Poet R. Towards a metric for recognition-based
graphical password security. In: 2011 5th International
Conference on Network and System Security. Milan, Italy:
IEEE; 2011. p. 239-43. doi:10.1109/ICNSS.2011.6060007.

Forget A, Chiasson S, Biddle R. User-centred authentication
feature framework. Inf. Comput. Secur. 2015.

Gugenheimer J, De Luca A, Hess H, Karg S, Wolf D, Rukzio E.
ColorSnakes: using colored decoys to secure authentication in
sensitive contexts. In: Proceedings of the 17th International
Conference on Human-Computer Interaction with Mobile
Devices and Services - MobileHCI ’15. Copenhagen, Denmark:
ACM Press; 2015. p. 274-83. doi:10.1145/2785830.2785834.

Ho PF, Kam YH-S, Wee MG, Chong YN, Por LY. Preventing
shoulder-surfing attack with the concept of concealing the
password objects’ information. Sci. World J. 2014;2014:1-12.
doi:10.1155/2014/838623.

Ibrahim TM, Abdulhamid SM, Alarood AA, Chiroma H,

Al-garadi MA, Rana N, Muhammad AN, Abubakar A, Haruna K,
Gabralla LA. Recent advances in mobile touch screen security
authentication methods: a systematic literature review.
Comput. Secur. 2019;85:1-24. doi:10.1016/j.cose.2019.04.008.

Jebriel SM, Poet R. Preventing shoulder-surfing when selecting
pass-images in challenge set. In: 2011 International
Conference on Innovations in Information Technology. Abu
Dhabi, United Arab Emirates: IEEE; 2011. p. 437-42.
doi:10.1109/INNOVATIONS.2011.5893865.

Jenkins R, McLachlan JL, Renaud K. Facelock: familiarity-based
graphical authentication. Peer] 2014;2:e444.
doi:10.7717/peer.444.

 

 

 

Juang KA, Greenstein JS. Evaluating the usability and security of
input masking techniques, 55; 2011. p. 1120-4.
doi:10.1177/1071181311551234.

Khamis M, Alt F, Hassib M, von Zezschwitz E, Hasholzner R,
Bulling A. GazeTouchPass: multimodal authentication using
gaze and touch on mobile devices. In: Proceedings of the 2016
CHI Conference Extended Abstracts on Human Factors in
Computing Systems - CHI EA ’16. Santa Clara, California, USA:
ACM Press; 2016. p. 2156-64. doi:10.1145/2851581.2892314.

Khamis M, Bandelow L, Schick S, Casadevall D, Bulling A, Alt F.
They are all after you: investigating the viability of a threat
model that involves multiple shoulder surfers. In: Proceedings
of the 16th International Conference on Mobile and
Ubiquitous Multimedia - MUM ’17. Stuttgart, Germany: ACM
Press; 2017. p. 31-5. doi:10.1145/3152832.3152851.

Khamis M, Eiband M, Zurn M, Hussmann H. EyeSpot: leveraging
gaze to protect private text content on mobile devices from
shoulder surfing. MTI 2018;2(3):45. doi:10.3390/mti2030045.

Khamis M, Hasholzner R, Bulling A, Alt F. GTmoPass: two-factor
authentication on public displays using gaze-touch passwords
and personal mobile devices. In: Proceedings of the 6th ACM
International Symposium on Pervasive Displays - PerDis ’17.
Lugano, Switzerland: ACM Press; 2017. p. 1-9.
doi:10.1145/3078810.3078815.

Khamis M, Hassib M, von Zezschwitz E, Bulling A, Alt F.
GazeTouchPIN: protecting sensitive data on mobile devices
using secure multimodal authentication. In: Proceedings of
the 19th ACM International Conference on Multimodal
Interaction - ICMI 2017. Glasgow, UK: ACM Press; 2017.

p. 446-50. doi:10.1145/3136755.3136809.

Khamis M, Trotter L, Makela V, von Zezschwitz E, Le J, Bulling A,
Alt F. CueAuth: comparing touch, mid-air gestures, and gaze
for cue-based authentication on situated displays, 2; 2018.

p. 1-22. doi:10.1145/3287052.

Khan H, Hengartner U, Vogel D. Targeted mimicry attacks on
touch input based implicit authentication schemes. In:
Proceedings of the 14th Annual International Conference on
Mobile Systems, Applications, and Services - MobiSys ’16.
Singapore, Singapore: ACM Press; 2016. p. 387-98.
doi:10.1145/2906388.2906404.

Khan H, Hengartner U, Vogel D. Evaluating attack and defense
strategies for smartphone PIN shoulder surfing. In:
Proceedings of the 2018 CHI Conference on Human Factors in
Computing Systems - CHI ’18. Montreal QC, Canada: ACM
Press; 2018. p. 1-10. doi:10.1145/3173574.3173738.

Kim D, Dunphy P, Briggs P, Hook J, Nicholson J, Nicholson J,
Olivier P. Multi-touch authentication on tabletops. In:
Proceedings of the 28th International Conference on Human
Factors in Computing Systems - CHI ’10. Atlanta, Georgia,
USA: ACM Press; 2010. p. 1093. doi:10.1145/1753326.1753489.

Kitchenham B, Brereton OP, Budgen D, Turner M, Bailey J,
Linkman S. Systematic literature reviews in software
engineering a systematic literature review. Information and
Software Technology 2009;51(1):7-15.
doi:10.1016/j.infsof.2008.09.009. Special Section - Most Cited
Articles in 2002 and Regular Research Papers

Kraus L, Schmidt R, Walch M, Schaub F, Moller S. On the use of
emojis in mobile authentication. In: De Capitani di
Vimercati S, Martinelli F, editors. In: ICT Systems Security and
Privacy Protection. Cham: Springer International Publishing;
2017. p. 265-80.

Krol K, Spring JM, Parkin S, Sasse MA. Towards robust
experimental design for user studies in security and privacy.
In: The LASER Workshop: Learning from Authoritative
Security Experiment Results (LASER 2016). San Jose, CA:
USENIX Association; 2016. p. 21-31.

Krombholz, K., Hupperich, T., Holz, T.,. Use the Force: Evaluating
Force-Sensitive Authentication for Mobile Devices, 13.

 
COMPUTERS & SECURITY 99 (2020) 102023 33

Kwon T, Na S, Park S-h. Drag-and-type: A new method for typing
with virtual keyboards on small touchscreens. IEEE Trans.
Consumer Electron. 2014;60(1):99-106.
doi:10.1109/TCE.2014.6780931.

Kwon T, Shin S, Na S. Covert attentional shoulder surfing: human
adversaries are more powerful than expected. IEEE Trans.
Syst. Man Cybern. Syst. 2014;44(6):716-27.
doi:10.1109/TSMC.2013.2270227.

Lashkari AH, Farmand S. A survey on usability and security
features in graphical user authentication algorithms. IJCSNS
Int. J. Comput. Sci.Netw. Secur. 2009;9(9):10.

Lashkari, A. H., Farmand, S., Zakaria, O. B., Saleh, R., 2009.
Shoulder surfing attack in graphical password authentication.
arXiv:0912.0951.

Lee J-I, Kim S, Fukumoto M, Lee B. Reflector:
distance-independent, private pointing on a reflective screen.
In: Proceedings of the 30th Annual ACM Symposium on User
Interface Software and Technology - UIST ’17. QU&#233;bec
City, QC, Canada: ACM Press; 2017. p. 351-64.
doi:10.1145/3126594.3126665.

Lee M-K. Security notions and advanced method for human
shoulder-surfing resistant PIN-entry. IEEE Trans. Inf. Forensics
Secur. 2014;9(4):695-708. doi:10.1109/TIFS.2014.2307671.

L’Yi S, Koh K, Jo J, Kim B, Seo J. CloakingNote: a novel desktop
interface for subtle writing using decoy texts. In: Proceedings
of the 29th Annual Symposium on User Interface Software
and Technology - UIST ’16. Tokyo, Japan: ACM Press; 2016.

p. 473-81. doi:10.1145/2984511.2984571.

Magqsood §, Chiasson S, Girouard A. Bend passwords: using
gestures to authenticate on flexible devices. Pers. Ubiquitous
Comput. 2016;20(4):573-600. doi:10.1007/s00779-016-0928-6.

Marques D, Guerreiro T, Duarte L, Carrico L. Under the table: tap
authentication for smartphones. BCS-HCI ’13 Proceedings of
the 27th International BCS Human Computer Interaction
Conference. London, Great Britain, 2013.

Martinez-Diaz M, Fierrez J, Galbally J. The DooDB graphical
password database: data analysis and benchmark results. IEEE
Access 2013;1:596-605. doi:10.1109/ACCESS.2013.2281773.

Mat Lazim MH, Zakaria NH. Security evaluation of distortion
technique for graphical authentication. In: Abdullah N, Wan
Adnan WA, Foth M, editors. In: User Science and Engineering.
Singapore: Springer Singapore; 2018. p. 313-24.

Mirkovic J, Benzel TV, Faber T, Braden R, Wroclawski JT,

Schwab S. The deter project: advancing the science of cyber
security experimentation and test. In: 2010 IEEE International
Conference on Technologies for Homeland Security (HST);
2010. p. 1-7.

Muaaz M, Mayrhofer R. Smartphone-based gait recognition: from
authentication to imitation. IEEE Trans. Mobile Comput.
2017;16(11):3209-21. doi:10.1109/TMC.2017.2686855.

Nguyen T, Memon N. Tap-based user authentication for
smartwatches. Comput. Secur. 2018;78:174-86.
doi:10.1016/j.cose.2018.07.001.

Nguyen TV, Sae-Bae N, Memon N. DRAW-A-PIN: authentication
using finger-drawn PIN on touch devices. Comput. Secur.
2017;66:115-28. doi:10.1016/j.cose.2017.01.008.

Nyang D, Kim H, Lee W, Kang S-b, Cho G, Lee M-K, Mohaisen A.
Two-thumbs-up: physical protection for PIN entry secure
against recording attacks. Comput. Secur. 2018;78:1-15.
doi:10.1016/j.cose.2018.05.012.

Oakley I. Keeping Secrets from Friends. adr 2014;111(3).
doi:10.15187/adr.2014.08.111.3.49.

Papadopoulos A, Nguyen T, Durmus E, Memon N. IllusionPIN:
shoulder-surfing resistant authentication using hybrid
images. IEEE Trans. Inf. Forensics Secur. 2017;12(12):2875-89.
doi:10.1109/TIFS.2017.2725199.

Roth V, Richter K, Freidinger R. A PIN-entry method resilient
against shoulder surfing. In: Proceedings of the 11th ACM

 

 

 

Conference on Computer and Communications Security - CCS
04. Washington DC, USA: ACM Press; 2004. p. 236.
doi:10.1145/1030083.1030116.

Sahami Shirazi A, Moghadam P, Ketabdar H, Schmidt A.
Assessing the vulnerability of magnetic gestural
authentication to video-based shoulder surfing attacks. In:
Proceedings of the 2012 ACM Annual Conference on Human
Factors in Computing Systems - CHI ’12. Austin, Texas, USA:
ACM Press; 2012. p. 2045. doi:10.1145/2207676.2208352.

Salem MB, Stolfo SJ. On the design and execution of
cyber-security user studies: methodology, challenges, and
lessons learned. In: Proceedings of the 4th Conference on
Cyber Security Experimentation and Test. USA: USENIX
Association; 2011. p. 8.

Sasamoto H, Christin N, Hayashi E. Undercover: authentication
usable in front of prying eyes. In: Proceeding of the
Twenty-Sixth Annual CHI Conference on Human Factors in
Computing Systems - CHI ’08. Florence, Italy: ACM Press; 2008.
p. 183. doi:10.1145/1357054.1357085.

Schaub F, Deyhle R, Weber M. Password entry usability and
shoulder surfing susceptibility on different smartphone
platforms. In: Proceedings of the 11th International
Conference on Mobile and Ubiquitous Multimedia - MUM ’12.
Ulm, Germany: ACM Press; 2012. p. 1.
doi:10.1145/2406367.2406384.

Schaub F, Walch M, Konings B, Weber M. Exploring the design
space of graphical passwords on smartphones. In:
Proceedings of the Ninth Symposium on Usable Privacy and
Security - SOUPS ’13. Newcastle, United Kingdom: ACM Press;
2013. p. 1. doi:10.1145/2501604.2501615.

Song Y, Cai Z, Zhang Z-L. Multi-touch authentication using hand
geometry and behavioral information. In: 2017 IEEE
Symposium on Security and Privacy (SP). San Jose, CA, USA:
IEEE; 2017. p. 357-72. doi:10.1109/SP.2017.54.

Song Y, Cho G, Oh S, Kim H, Huh JH. On the effectiveness of
pattern lock strength meters: measuring the strength of real
world pattern locks. In: Proceedings of the 33rd Annual ACM
Conference on Human Factors in Computing Systems - CHI
15. Seoul, Republic of Korea: ACM Press; 2015. p. 2343-52.
doi:10.1145/2702123.2702365.

Still JD, Bell J. Incognito: shoulder-surfing resistant selection
method. J. Inf. Secur. Appl. 2018;40:1-8.
doi:10.1016/j.jisa.2018.02.006.

Sun J, Zhang R, Zhang J, Zhang Y. TouchIn: Sightless two-factor
authentication on multi-touch mobile devices. 2014 IEEE
Conference on Communications and Network Security, 2014.

Suo X, Zhu Y, Owen G. Graphical passwords: a survey. In: 21st
Annual Computer Security Applications Conference
(ACSAC’05). IEEE; 2005. p. 463-72. doi:10.1109/CSAC.

2005.27.

Tan, D.S. 2005. Spy-Resistant Keyboard: More Secure Password
Entry on Public Touch Screen Displays, 10.

Tari F, Ozok AA, Holden SH. A comparison of perceived and real
shoulder-surfing risks between alphanumeric and graphical
passwords. In: Proceedings of the Second Symposium on
Usable Privacy and Security - SOUPS ’06. Pittsburgh,
Pennsylvania: ACM Press; 2006. p. 56.
doi:10.1145/1143120.1143128.

Tiller LN, Cain AA, Potter LN, Still JD. Graphical authentication
schemes: balancing amount of image distortion. In:

Ahram TZ, Nicholson D, editors. In: Advances in Human
Factors in Cybersecurity. Cham: Springer International
Publishing; 2019. p. 88-98.

Towhidi, F., Masrom, M.,. A Survey on Recognition-Based
Graphical User Authentication Algorithms 6 (2), 9.

Velasquez I, Caro A, Rodriguez A. Authentication schemes and
methods: a systematic literature review. Inf. Softw. Technol.
2018;94:30-7. doi:10.1016/j.infsof.2017.09.012.
34 COMPUTERS & SECURITY 99 (2020) 102023

von Zezschwitz E, De Luca A, Brunkow B, Hussmann H. SwiPIN:
fast and secure PIN-entry on smartphones. In: Proceedings of
the 33rd Annual ACM Conference on Human Factors in
Computing Systems - CHI ’15. Seoul, Republic of Korea: ACM
Press; 2015. p. 1403-6. doi:10.1145/2702123.2702212.

von Zezschwitz E, De Luca A, Janssen P, Hussmann H. Easy to
draw, but hard to trace?: On the observability of grid-based
(un)lock patterns. In: Proceedings of the 33rd Annual ACM
Conference on Human Factors in Computing Systems - CHI
15. Seoul, Republic of Korea: ACM Press; 2015. p. 2339-42.
doi:10.1145/2702123.2702202.

Wiese O, Roth V. Pitfalls of shoulder surfing studies. Proceedings
2015 Workshop on Usable Security. San Diego, CA: Internet
Society, 2015.

Wiese O, Roth V. See you next time: a model for modern shoulder
surfers. In: Proceedings of the 18th International Conference
on Human-Computer Interaction with Mobile Devices and
Services - MobileHCI 16. Florence, Italy: ACM Press; 2016.

p. 453-64. doi:10.1145/2935334.2935388.

Yu X, Wang Z, Li Y, LiL, Zhu WT, Song L. EvoPass: evolvable
graphical password against shoulder-surfing attacks. Comput.
Secur. 2017;70:179-98. doi:10.1016/j.cose.2017.05.006.

 

Zakaria NH, Griffiths D, Brostoff S, Yan J. Shoulder surfing defence
for recall-based graphical passwords. In: Proceedings of the
Seventh Symposium on Usable Privacy and Security - SOUPS
"11. Pittsburgh, Pennsylvania: ACM Press; 2011. p. 1.
doi:10.1145/2078827.2078835.

Leon BoSnjak is an assistant and researcher at the Faculty of Elec-
trical Engineering and Computer Science of University of Maribor,
Slovenia. In 2014, he received his master’s degree in Informatics
and Technologies of Communication, and is currently a doctoral
student of Computer Science and Information Technologies. His
research interests include system security, textual and graphical
passwords, and authentication methods.

BoStjan Brumen received doctor’s degree in informatics in 2004. He
is an associate professor at University of Maribor, Faculty of Elec-
trical engineering and computer science. He was Secretary Gen-
eral (Provost) of University of Maribor for two consecutive terms
between 2004 and 2011. His research interests include intelligent
data analysis, automated learning and learning models, data secu-
rity and data quality. He has published several articles about pass-
words in prestigious journals, among them International Journal
of Human-Computer Studies and Journal of Medical Internet Re-
search.
