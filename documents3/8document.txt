Almasri et al. EURASIP Journal on Wireless Communications and j
Networking (2020) 2020.145 EURASIP Journal on Wireless

https://doi.org/10.1186/s13638-020-01738-w Communications and Networking

RESEARCH Open Access

Distributed algorithm under ®
cooperative or competitive priority users in ~~
cognitive networks

Mahmoud Almasri'’, Ali Mansour!, Christophe Moy?, Ammar Assoum?, Christophe Osswald!
and Denis Lejeune!

 

 

*Correspondence:

mahmoud.almasri@esnta-bretagne.org Abstract

'LABSTICC, UMR 6285 CNRS, ENSTA |. Opportunistic spectrum access (OSA) problem in cognitive radio (CR) networks allows a
Became Fr Werny, 29800, secondary (unlicensed) user (SU) to access a vacant channel allocated to a primary

Full list of author information is (licensed) user (PU). By finding the availability of the best channel, i.e., the channel that

available at the end of the article has the highest availability probability, a SU can increase its transmission time and rate.
To maximize the transmission opportunities of a SU, various learning algorithms are
suggested: Thompson sampling (TS), upper confidence bound (UCB), e-greedy, etc. In
our study, we propose a modified UCB version called AUCB (Arctan-UCB) that can
achieve a logarithmic regret similar to TS or UCB while further reducing the total regret,
defined as the reward loss resulting from the selection of non-optimal channels. To

evaluate AUCB's performance for the multi-user case, we propose a novel
uncooperative policy for a priority access where the kth user should access the kth best
channel. This manuscript theoretically establishes the upper bound on the sum regret
of AUCB under the single or multi-user cases. The users thus may, after finite time slots,
converge to their dedicated channels. It also focuses on the Quality of Service AUCB
(QoS-AUCB) using the proposed policy for the priority access. Our simulations
corroborate AUCB’s performance compared to TS or UCB.

Keywords: Cooperative or competitive priority access, Cognitive radio, Opportunistic
spectrum access, Multi-armed bandit algorithms, Upper bound of regret

 

1 Introduction

1.1 Cognitive radio

The static spectrum allocation has nowadays become a major problem in wireless net-
works as it results in an inefficient use of the spectrum and can generate holes or white
spaces therein. The opportunistic spectrum access (OSA) concept aims at reducing the
inefficient use of the spectrum by sharing available spectrum of primary users (PUs), i-e.,
licensed users who have full access to a frequency band, with opportunistic users called
secondary users (SUs). According to OSA, a SU may at any time access an unoccupied
frequency band, but it must abandon the targeted channel whenever a PU restarts its

. © The Author(s). 2020 Open Access This article is licensed under a Creative Commons Attribution 4.0 International License,
GQ) Springer O pen which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate
— credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were
made. The images or other third party material in this article are included in the article’s Creative Commons licence, unless
indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons licence and your
intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly
from the copyright holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0/.
Almasri et al. EURASIP Journal on Wireless Communications and Networking (2020) 2020:145 Page 2 of 31

transmission in its channel. Indeed, OSA optimizes the use of the spectrum with min-
imum impacts on PUs and minimizing interference among SUs. OSA is an important
strategy for the cognitive radio (CR) [1]; indeed, a CR unit must execute a cognitive cycle
in order to implement an OSA strategy. The main three steps of the cognitive cycle are as

follows:

e Spectrum sensing: A cognitive radio should be able to sense and detect possible holes
in the spectrum. Indeed, the main challenge of a CR is to obtain an accurate status of
the spectrum bandwidths (vacant/busy), so that a SU can access a vacant channel
without interfering with the transmission of PUs. In the literature, several spectrum
sensing algorithms have been proposed to detect primary users’ activities, such as
cumulative power spectral density (CPSD) [2], energy detection (ED) [3-6], or
waveform-based sensing (WBS) [7, 8].

e Learning and information extraction: This function generates a clear vision about a
RF (radio frequency) environment. As a result, a spectrum environment database is
constructed and maintained. This database is used to optimize and adapt
transmission parameters. The learning and information extraction capabilities of a
CR can be achieved using learning algorithms, such as Thompson sampling (TS) [9],
upper confidence bound (UCB) [10], and €-greedy [11]. In [12], we proposed a
learning algorithm based on the UCB that monitors the quality of service UCB
(QoS-UCB) for the multi-user case. In this paper, we have also developed the QoS
aspect of the new proposed AUCB (Arctan-UCB) algorithm.

e Decision making: Following the learning process, the decision about the occupancy
of a spectrum should be made to access a particular spectrum bandwidth. Any good
decision should depend on the environment parameters as well as on the nature of

the SUs’ cooperative or competitive behaviors.

This paper investigates two major scenarios: SUs network with cooperative or compet-
itive behaviors, under two different policies: Side channel [13] and a novel policy called
PLA (priority learning access) for the multi-user case.

1.2 Related work

The past decade has witnessed an explosive demand of wireless spectrum that led
to the major stress and the scarcity in the frequency bands. Moreover, the radio land-
scape has become progressively heterogeneous and very complex (e.g., several radio
standards, diversity of services offered). Nowadays, the rise of new applications and tech-
nologies encourages wireless transmission and accelerates the spectrum scarcity problem.
The coming wireless technologies (e.g., 5G) will support high-speed data transfer rates
including voice, video, and multimedia.

In many countries, the priority bands for 5G include incumbent users, and it is essen-
tial that regulators make high effort to evacuate these frequencies for 5G use—especially
in the 3.5 GHz range (3.3—3.8 GHz) [14]. These efforts may consist of (1) putting in place
incentives to migrate licensees upstream of frequency allocation, (2) moving licensees to
other bands or to a single portion of the frequency range, and (3) allowing licensees to
exchange their licenses with mobile operators. When it is not possible to free up a band,
the reserving frequencies for 5G bands (i.e., 3.5/26/28 GHz) may lead to the success of
5G services while wasting frequencies. Indeed, according to several recent studies, the
Almasri et al. EURASIP Journal on Wireless Communications and Networking (2020) 2020:145 Page 3 of 31

frequency sharing approaches represent an efficient solution that can be used to sup-
port both potential 5G users and the incumbent users. For instance, the Finnish regulator
has chosen to adopt this approach instead of reserving frequencies for the 5G users [14].
Sharing approach will contribute to access new frequencies for 5G in areas where they
are needed but underutilized by incumbent users. In this work, we are interested in the
opportunistic spectrum access (OSA) that represents a sharing approach in which the SUs
can access the frequency bands in opportunistic manner without any cooperation with
the PUs.

Before making any decision, a SU should make spectrum sensing process in order to
reduce the interference with the primary users. In [15], the authors focus on different
spectrum sensing techniques and their efficiency trying to obtain accurate information
about the status of the selected channel by a SU at a given time. Moreover, the proposed
techniques are analytically evaluated under Gaussian and Rayleigh fading channels. In this
work, we focus on the decision making process to help the SU reach the best channel with
the highest availability probability. This channel, on the one hand, mitigates any harmful
interference with the PU as a result that this channel not often used by this latter. On the
other hand, accessing the best channel in the long term can increase the SU’s transmission
time and throughput capacity.

Many recent works, in the CR, have attempted to maximize the transmission rate of
the secondary user (SU) without generating any harmful interference to the primary user
(PU) [16, 17]. To reach this goal, the latter works investigate the effects of using differ-
ent types of modulation such as OFDM (orthogonal frequency-division multiple access)
and SC-FDMA (single-carrier frequency-division multiple access). The main drawback
of using OFDM modulation is related to its large peak-to-average power ratio (PAPR)
that may increase the interference with the PU. While SC-FDMA has seen as a favor-
able modulation to maximize the SU’s transmission due to its lower PAPR as well its
complexity [18]. Moreover, SC-FDMA is used in several mobile generation such as the
third-generation partnership project long-term evolution (3GPP-LTE) and the fourth
generation (4G). It is also considered as a promising radio access technology and having
an optimal energy-efficient power allocation framework for future generation of wireless
networks [19, 20].

In this work, we choose to focus on the multi-armed bandit (MAB) approach in order to
help a SU make a good decision, reduce the interference among PU and SU, and maximize
the opportunities of this latter. In MAB, the agent may play an arm at each time slot and
collect a reward. The main goal of the agent is to maximize its long-term reward or to
minimize its total regret, defined as the reward loss resulting from the selection of bad
arms. In [21—24], the authors considered the MAB approach in an OSA to improve the
spectrum learning!.

In MAB, the arm reward can be modeled with different models, such as the independent
identically distributed (i.i.d.) or Markovian models. In this paper, we focus on the i.i.d. that
represents the widely used model for a single user [24, 25] or multi-user case [23, 26, 27].

Based on the MAB problem introduced by Lai and Robbins in [10], the authors of
[28] proposed several versions of UCB: UCB1, UCB2, and UCB-normal. All these ver-
sions achieve a logarithmic regret with respect to the number of played slots in the

 

1A SU in OSA is equivalent to a MAB agent trying to access a channel at each time slot in order to increase its gain.
Almasri et al. EURASIP Journal on Wireless Communications and Networking (2020) 2020:145 Page 4 of 31

single-user case. For multiple users, we proposed respectively in [13] and [29] cooperative
and competitive policies to collectively learn the vacancy probabilities of channels and
decrease the number of collisions among users. The latter policies are simulated under
TS, UCB, and €-greedy algorithms. The previous simulations were conducted without any
proof about the analytical convergences of these algorithms or the number of collisions
among SUs. In this work, we show that the same policies achieve a better performance
with AUCB compared to several existing algorithms. We also investigate the analytical
convergence of these two policies under AUCB, and we show that the number of colli-
sions in the competitive access has a logarithmic behavior with respect to time. Therefore,
after a finite number of collisions the users converge to their dedicated channels.

The authors of [30] proposed a distributed learning for multiple SUs called time-
division fair share (TDFS) and proved that the proposed method achieves a logarithmic
regret with respect to the number of slots. Moreover, TDFS considers that the users can
access the channels with different offsets in their time-sharing schedule and each of them
achieves almost the same throughput. The work of [31] proposed a musical chair that
represents a random access policy to manage the secondary network where the users
achieve a different throughput. According to [31], each user selects a random channel up
to time 7p in order to estimate the vacancy probabilities of channels and the number of
users U in the network. After To, each user randomly selects one of the U best channels.
Nevertheless, the musical chair suffers several limitations as follows:

1. The user should have a prior knowledge about the number of channels in order to
estimate the number of users in the network.

2. It cannot be used under the dynamic availability probability since the exploration
and exploitation phases are independent.

3. It does not take the priority access into account.

To find the U/ best channels, the authors of [32] proposed a multi-user €-greedy collision
avoiding (MEGA) algorithm based on the €-greedy previously proposed in [28]. However,
the MEGA has the same drawbacks of the musical chair. In the literature, various learning
algorithms have been proposed to take into account the priority access, such as selective
learning of the kth largest expected rewards (SLK) [33] and kth MAB [34]. SLK is based
on the UCB algorithm, while the Ath MAB is based on both UCB and €-greedy.

1.3. Contributions and paper organization

The main contributions of this manuscript are as follows:

e An improved version of UCB algorithm called AUCB: In the literature, several UCB
versions have been proposed to achieve a better performance compared to the
classical one [28, 35—37]. However, we show that AUCB achieves a better
performance compared to previous versions of UCB. By considering the widely used
i.i.d. model, the regret for a single or multiple SUs can achieve a logarithmic
asymptotic behavior with respect to the number of slots, so that the user may quickly
find and access the best channel in order to maximize its transmission time.

¢ Competitive policy for the priority learning access (PLA): To manage a decentralized
secondary network, we propose a learning policy, called PLA, that takes the priority
access into account. To the best of our knowledge, PLA represents the first
Almasri et al. EURASIP Journal on Wireless Communications and Networking (2020) 2020:145 Page 5 of 31

competitive learning policy that successfully handles the priority dynamic access
where the number of SUs changes over time [38], while only the priority access or the
dynamic access are considered in several learning policies, such as musical chair and
dynamic musical chair [31], MEGA [32], SLK [33], and Ath MAB [34]. In [38], PLA
shows its superiority under UCB and TS compared to SLK, MEGA, musical chair,
and dynamic musical chair. In this work, we evaluate the performance of AUCB in
the multi-user case based on PLA.

e The upper bound of regret: We analytically prove the asymptotical convergence of
AUCEB for single or multiple SUs based on our PLA and side channel policies.

e Investigation AUCB’s performance of TS is known to exceed the state of the art in
MAB algorithms [35, 39, 40]. Several studies found a concrete bound for its optimal
regret [41-43]. Based on these facts, we adopt TS as a reference to evaluate AUCB’s
performance.

e Wealso investigate the QoS of AUCB algorithm under our PLA policy.

Concerning this manuscript’s organization, Section 2 introduces the system model for
single and multi-user cases. Section 3 presents the AUCB approach for a single user as
well as a novel learning policy to manage a secondary network. AUCB’s performance for
both single and multi-user cases are investigated in Section 4. This section also compares
the performance of the PLA policy for the multi-user case to recent works. Section 5

concludes the paper.

2 Problem formulation

In this section, we investigate the MAB problem for both single and multi-users cases. We
also define the regret that can be used to evaluate a given policy’s performance (Table 1).
All parameters used in this section can be found in Table 1.

2.1 Single-user case

Let C be the number of i.i.d. channels where each channel must be in one of two binary
states S: S equals 0 if the channel is occupied, and 1 otherwise. For each time slot ¢, SU
should sense a channel in order to see whether it is occupied or vacant and receives a
reward r;(¢) from the ith channel. Without any loss of generality, we will then assume that
a good decision’s reward, e.g., the channel is vacant, equals to its binary state, i.e., r;(t) =
S;(£). SU can transmit its data on a vacant channel; otherwise, it must wait for the next slot
to sense and use another channel. We suppose that all channels are ordered by their mean
availability probabilities, i.e, uc < Uc-1 < +--+ < m4. The availability vector [ = (yj) is
initially unknown to the secondary user, but our goal is to estimate it over many sensing
slots. If a SU has a perfect knowledge about the channels and their jz;, then it can select
the best available channel, i.e., the first one, to increase its transmission rate. As ju; is
unknown for that user, we will define the regret as the sum of the reward loss due to the
selection of a sub-optimal channel at each slot. The regret minimization determines the
efficiency of the selected strategy to find the best channel. In a single user case, the regret
R(n, 6) up to the total number of slots 7 under a policy 6 can be defined as follows:

R(n, B) = np — Y> weOW (1)

t=1
Almasri et al. EURASIP Journal on Wireless Communications and Networking

(2020) 2020:145 Page 6 of 31

Table 1 List of notations used through the paper

 

n Total number of time slots

UandC Number of users and channels respectively

Si(t) Observed state of the ith channel at slot t

ri(t) Reward obtained from the /th channel at slot t

fy and uj Availability of the best and ith channels respectively

Agi = M1 = bi
Bt)

 

Difference between the best and worst channels
Channel selected at slot t using a policy 6 for single or multiple-users cases

 

 

 

T(t) Number of times the ith channel was sensed up to slot t

Xi(Tj(t)) Exploitation contribution of the ith channel that depends on 7;(t)

Ait, Ti(t)) Exploration contribution of the ith channel that depends on t and 7;(t)

By(t, T;(t)) Index assigned of the ith channel that takes into consideration the availability

a Exploration-exploitation factor

SPO (t) Global reward obtained by all users at slot t from the selected channels A(t)

it) Non-collision in the ith channel under the jth user at slot t

Pij(n) Total number of non-collision in the ith channel under the jth user up to n

gi(t) Quality of ith channel at slot t

Gi(T;(t)) Quality collected from the ith channel up to slot t

Gmax(t) Maximum expected quality over channels up to slot t

Q(t, T(t) Quality factor that depends on t and 7;(t)

Bet, T(t)) Index assigned of the ‘th channel that takes into consideration both availability and quality

y Weight of the quality factor

we Global mean reward of the /th channel that takes into consideration both availability and
quality

Ou(n) Total number of collisions in U-best channels up ton

p Probability of non-collision in best channels

Appendix

Aki) = Kk bi Difference between the kth best channel and the ith one

Oc(n) Total number of collisions in all channels up to n

Oj;(N) Total number of collisions in the ‘th channel up ton

Dy(n) Total number of collisions under the kth priority user up ton

T,(n) Total number of times where the kth user badly identifies its dedicated channel, the kth
best one

Ss Needed time for a user to return to its prior rank

Tg;>8, (N) Total number of times in which the index of the ith channel exceeds the kth best one up
ton

78, <B, (1) Total number of times in which the index of the kth best channel exceeds the mth best

 

one up ton

 

where x is the total number of slots; mj11 is the selected channel in an ideal scenario, i.e.,

when the SU has prior knowledge and always selects the best channel; 6(t) denotes the
B(t)
i

the i” channel selected at the time slot t and B(t) = i. The main target of a SU is to
estimate the channels availability as soon as possible to attain the highest available one.

channel selected under the policy 6 at time ¢; and wz; ~’ is the mean reward obtained for

To reach this goal, UCB was firstly proposed in [10] and applied in [25] to optimize the
access over channels and identify the best one with the highest availability probability.
UCB contains two dimensions: exploitation and exploration. These latter are respectively
represented by X;(7;(¢)) and A;(, T;(t)).

The index assigned to the ith channel can be defined as follows:

Bj (t, Ti(t)) = Xi Ti) + Ait, Ti) (2)
Almasri et al. EURASIP Journal on Wireless Communications and Networking (2020) 2020:145 Page 7 of 31

where 7;(t) is the number of times the channel i is sensed by a SU up to the time slot t.
The user selects the channel §(¢) at slot t that maximizes its index in the previous slot,

B(t) = arg max B; (t — 1, T;(t — 1))

After a sufficient time, the user establishes a good estimation of the availability
probabilities and thus can converge towards the optimal channel.

2.2 Multi-user case

Let us consider U SUs trying to maximize their network’s global reward. At every time
slot t, each user can access a channel when available and transmits its own data. However,
multiple SUs can work in cooperative or uncooperative modes. In the cooperative one,
the users should coordinate their decisions to minimize the global regret of the network.
On the other hand, in a non-cooperative mode, each user independently makes its own
optimal decision to maximize its local reward. The regret for the multi-user case, under

cooperative or competitive modes, can be written as follows:

U n
R(t, U, B) = 2D ux — YE (S?OW) (3)

k=1 t=1
where ju; is the mean availability of the kth best channel; S° (t) is defined by the global
reward obtained by all users at the time slot ¢; E(.) represents the mathematical expecta-
tion, and A(t) represents all the selected channels” by users at t. We can define S? (£) by:

U C

POD = Y SOLO (4)

j=l i=l
where the state variable® S;(t) = 0 indicates that the channel i is occupied by the PU at
slot t; otherwise, S;(¢) = 1; J,;(¢) = 1 if the jth user is the sole occupant in channel i at the
slot ¢ and 0 otherwise. In the multi-user case, the regret can be affected by the collision
among SUs and the channel occupancy which allows us to define the regret for LU SUs as

shown in the following equation:

u ueoc
Rn, U,B) =n ue—Y_)>- Pi (Mui (5)
k=1 j=l i=1
N
where Pj (1) = DUE [Z ij (t) | stands for the expectation of times when the user j is the only
t=1

occupant of the channel i up to v, and the mean of reward can be given by:
1 N
bi = = dX Si(t)

3 Methods

In this section, we present a new approach inspired from the classical UCB in a single-
user case, and later on, we generalize our study to consider the case of multi-user. The
new approach can find the optimal channel faster than the classical UCB while achieving
a lower regret. The classical UCB contains the exploration-exploitation trade-off to find

 

2 B(t) indicates the channel selected by the user at instant t in the single-user case while in the multi-access it indicates
the selected channels by all users at slot t.
3 The variable S;(¢) may represent the reward of the ith channel at slot t.
Almasri et al. EURASIP Journal on Wireless Communications and Networking (2020) 2020:145 Page 8 of 31

a good estimate of the channels status and converges to the best one (see Eq. (2)). In
UCB, a non-linear function for the exploration factor, A;(t, T;(t)), is used to ensure the

convergence:

a In(t)

Ais TO) = | Fc

 

(6)

where a is the exploration-exploitation factor. The effect of a on the classical UCB is
well studied in the literature [22, 44, 45]. According to [28, 44, 46, 47], the best value
of a should be in the range of [1, 2] in order to make a balance between exploration-
exploitation epochs. However, if a decreases, the exploration factor of UCB decreases
and the exploitation factor dominates, then the algorithm converges quickly to the chan-
nel with the highest empirical reward. All previous works study the effect of A;(¢, T;(t))
on the UCB with different values of a. In this study, we focus on another form of the
exploration factor A;(t, T;(t)) based on another non-linear function in order to enhance
the convergence to the best channel of the classical UCB. Different non-linear functions
of Eq. (6) with similar characteristics can be investigated. We should mention that this

function was chosen because it has two main properties:

e A positive function with respect to time t.
e An increasing non-linear function to limit the effect of the exploration.

Therefore, the square-root function introduced in Eq. (6) is widely accepted [24, 28,
46, 47] in order to restrict the exploration factor after the learning phase. Classical UCB
ensures the balance between the exploration-exploitation phases at each time slot up to
n, using two factors, A;(t, T;(t)) and X;(7;(0)). Indeed, A;(t, T;(£)) is used to explore chan-
nels’ availability in order to access the best one with the highest expected availability
probability X;(7;(£)). The classical UCB gives the same impact of the exploration factor
Aj(t, T;(t)) at each time slot up to m. However, our proposal is based on the idea that the
exploration factor A;(t, T;(¢)) should have an important role during the learning phase
while it becomes less important after this period. Indeed, after the learning phase, the
user will have a good estimation of channels’ availability, then it can regularly access the
best channel. Subsequently, the big challenge is to restrict A;(¢t, T;(¢)) after the learning
phase by using another non-linear function with the following features:

e It should be an increasing function with a high derivative with respect to time at the
beginning to boost the exploration factor during the learning phase in order to
accelerate the estimation of channels’ availability.

e It should have a strong asymptotic behavior in order to restrict the exploration factor
Aj,(t, T;(t)) under a certain limit, when the user collects some information about
channels’ availability.

Subsequently, our study finds that the exploration factor can be adjusted by using the
arctan function which has the above features; this proposed UCB version is called AUCB.
Indeed, the arctan enhances the convergence speed to the best channel compared to the
one obtained with the square-root, and the effect of the exploration factor A,(¢, T;(£)) can
be reduced after the learning phase. The algorithm then gives an additional weight to the
exploitation factor X; (T;(£)) in the maximization of the index B;(t, T;(t)) (see Eq. (2)). In
the next section, we will prove that AUCB’s regret has a logarithmic asymptotic behavior.
Almasri et al. EURASIP Journal on Wireless Communications and Networking (2020) 2020:145 Page 9 of 31

3.1 AUCB fora single user
This section focuses on the AUCB’s regret convergence for a single user. For the sake

of simplicity with regard to the mathematical developments, the regret of Eq. (1) can be

written as:
C C
R(n, B) = ELT] wa — DEL Tiny] pai
i=1 i=1
C
=) (m1 — MAE Ti(n)] (7)

i=1

where 7;(7) represents the number of time slots that the channel i was sensed by the
SU up to the total number of slots 1. According to Eq. (7), the regret depends on
the channels’ occupancy probability (for stationary channels, the availability probabil-
ities are considered as constant) and the expectation of 7;(”) which is a stationary
random variable process. Then, the upper bound of E[T7;(u)] indirectly implies the
regret’s upper bound. Subsequently, the regret of our AUCB approach under the single-
user case has a logarithmic asymptotic behavior as shown in the following equation
(see Appendix A):

 

c In(n) mr c
R(n, AUCB) < 8) — ; + (1 + ~) S > Aaa (8)
i=1

jan LOD
where A(1,3) = 41 — i represents the difference between the best and worst channels.

3.2 Multi-user case under uncooperative or cooperative access

To evaluate the performance of our proposed algorithm in the multi-user case, we will
propose an uncooperative policy for the priority learning access (PLA) to manage a sec-
ondary network. We will also prove the PLA’s convergence, as well as the side channel
policies with AUCB.

3.2.1. Uncooperative learning policy for the priority access

We investigate the case where the SUs should take decisions according to their priority
ranks. In this section, we propose a competitive learning policy that can share the avail-
able spectrum among SUs. In addition, we prove the theoretical convergence of the PLA
policy with our AUCB approach. In the multi-user case, the big challenge becomes how
to collectively learn the channels’ availability for each SU; at the same time, the number of
collisions should be set below a certain threshold. Our goal is to ensure that the U/ users
are spread separately to the U best channels. In the classical priority access method, the
first priority user SU should sense and access the best channel, j11, at each time slot, while
the target of the second priority user SU is to access the second best channel. To reach
this goal, SU should sense to find the two best channels at the same time, i-e., 41 and [12,
in order to compute their availabilities and thus access the second best channel if avail-
able. Similarly, the Uth user should estimate the availability of all U/ first best channels at
each time slot to access the Uth best one. However, it is a costly and impractical method to
settle down each user to its dedicated channel. For this reason, we propose PLA where, at
each time slot, SU can sense one channel in order to find its dedicated one. In our policy,
Almasri et al. EURASIP Journal on Wireless Communications and Networking (2020) 2020:145 Page 10 of 31

Algorithm 1: Priority Learning Policy (PLA) under AUCB

1 Input: a,C,n,

2 Parameters: k, &;(t), 7r;(t),

3 k: indicates the k user,

4 &;,(t): indicates a presence of collision under the k” user at the instant ¢,
5 r;(t): indicates the state of the /” channel at instant ¢,

6 %r;(t) = 1if the channel is free and 0 otherwise,

7 Output: B;,(¢, T;(),

8 Bj, x(t, Tj(t)): represents the index of the i” channel for the k™ user,

9 fort = 1toCdo

10 SU; senses each channel once,
11 SU; updates its index Bj x(t, T;(4)),
12 SU; generates a random rank from the set {1, ..., k},

13 fort=Ctondo

14 SU, senses a channel in its index B; x(t, T;(t)) according to its rank,
15 if r;(t)=1 then

16 SU; transmits its data,

17 if €,(t)=1 then

18 | SU, regenerates its rank randomly from the set {1,..., k},

19 else

20 L SU; keeps its previous rank,

21 else

22 L SU; stops transmitting at the instant f¢,

23 SU, updates its index B;,(t, T;(t)) according to eq (2).

each user has a dedicated rank, k € {1,..., UV}, and its target remains the access of the kth
best channel. In PLA, each user generates a rank around its prior one to have informa-
tion about the channels availability, (see Algorithm 1). In this case, the kth user can scan
the k best channels and its target is the kth best one. However, if the generated rank of
the Ath user is different than k, then it accesses a channel that has a vacancy probability
in the set {{11, 42, ..., 4x1} and may collide with top priority users {SU}, SUp, ..., SUx_1}.
Moreover, after each collision, SU, should regenerate its rank in the set {]1,...,k}.
Thus, after a finite number of iterations, each user settles down to its dedicated
channel.

Equation (9) shows that the expectation of collisions in the U best channels E[ Oy (”)|
for PLA based on our AUCB approach has a logarithmic asymptotic behavior. Therefore,
after a finite number of collisions each user may converge to its dedicated channel (see

u 8 In(n) 1
(gg)

k=1 Aix k+1)

Appendix B):

“(81
ElOu(m)| < —? ly (Sr 14 <3

k= (k—Lk)

where p indicates the probability of non-collision and A(gy) = Ua — Lp.
Almasri et al. EURASIP Journal on Wireless Communications and Networking (2020) 2020:145 Page 11 of 31

We have also proven that the total regret of our policy PLA has a logarithmic asymp-
totic behavior. It is also worth mentioning that the upper regret bound not only depends
on the collisions among users but also on the selection of the worst channels (see
Appendix C):

 

ust 8 In(n) mr?
Rpa(n, U,AUCB) < in| YY) (=s— +147) +£l0u) (10)

The first term of the above equation reflects the selection of the worst channels while
the second one represents the reward loss due to collisions among users in the best
channels. The upper bound of the regret presented in Eq. (10) can be affected by three

parameters:

e The number of users, U, represented through the first summation, where k denotes
the kth best channels for the kth SU.

e The number of channels, C, in the second summation of the regret.

e The total number of time slots, n.

3.2.2 Cooperative learning with side channel policy

The coordination among SUs can enhance the efficiency of their network, instead
of dealing with their partial information about the environment. To manage a coop-
erative network, we propose a policy based on the use of a side channel in order
to exchange simple information among SUs with a very low information rate. The
side channels are widely used in wireless telecommunication networks to share data
among the base-stations [48], and specifically in the context of cognitive network.
However, in [49] and [50], the authors considered the cooperative spectrum shar-
ing among PUs and SUs to enhance the transmission rate of the PUs using a side
channel.

The signaling channel in our policy is not wide enough to allow high-data rate trans-
mission unlike that used in [49] and [50] which should have a high rate to ensure the
data transmission among PUs and SUs. In our policy, the transmission is done over peri-
ods. During the first period, i.e., Sub-Slotl, SU; (the highest priority user) searches for
the best channel by maximizing its index according to Eq. (2). At the same time, and
via the secure channel, SU; must inform the other users to evacuate its selected channel
in order to avoid any collision with them. While avoiding the first selected channel, the
second user SU should repeat the same process and so on. If SU2 does not receive the
choice of SU; in the first Sub-Slot1 (suppose that SL, does not need to transmit during
this Sub-Slot), it can directly choose the first suggested channel by maximizing its index
Bio (t, Ti,2(0)).

To the best of our knowledge, all proposed policies, such as SLK, kth MAB consider a
fixed priority, i.e., the kth best channel is reserved for the Ath user all the time. Later on, if
SU, does not transmit for a certain time, then other users cannot select better channels.
Subsequently, the main advantages of the cooperation in this policy are as follows:

e Anefficient use of the spectrum where best channels are constantly accessed by users.
e An increase in the transmission time of users by avoiding the collision among them.

e Reaching a lower regret compared to several existing policies.
Almasri et al. EURASIP Journal on Wireless Communications and Networking (2020) 2020:145 Page 12 of 31

Hence, AUCB’s regret under the side channel policy can achieve a logarithmic efficiency

according to the following equation (see Appendix D):

 

ue 8 In(n) 1?
Rsc(n, U, AUCB) < ) ) + Aki) (1 + =) (11)
i (ki) 3
k=1 i=U+1 \ y

Term Term2

where Ai) = Uk — Li. k and i, respectively, represent the best and worst channels. The

upper bound of this regret contains two terms:

e Term 1 achieves a logarithmic behavior over time.

e Term 2 depends on the vacant channels.

3.3 Quality of service of AUCB

In [12], we study UCB’s quality of service (QoS) for the restless model. The QoS has been
studied for both single and multi-users cases using the random rank policy proposed in
[23] to manage a secondary network. Based on the QoS-UCB, the user is able to learn
channels’ availability and quality.

In this work, we also study the QoS of AUCB using our proposed PLA policy for the
priority access of the i.i.d. channels. Supposing that each channel has a binary quality rep-
resented by q;(t) at the slot ¢: q;(t) = 1 if the channel has a good quality and 0 otherwise.
Then, the expected quality collected from the channel i up to x is given as follows:

1 Tj(n)
GTO) = Foy LL HO) (12)

 

The global mean reward, that takes into account all channels’ quality and availability, can
be defined as follows [12]:

pe = Gi(Ti(n)).ui (13)

The index assigned to the ith channel that takes into account the availability and quality
of the ith channel can be defined by:

BS (t, Ti(t)) = Xi(Ti(0) — Qilt, Ti()) + Ault, Ti(D)) (14)

According to [12], the term Q;(¢, T;(t)) that represents the quality factor is given by the
following equation:
yMi(E, T;(£)) In(é)
T;(£)
where the parameter y stands for the weight of the quality factor; M;(¢,T;()) =

Qi(t, Ti(t)) =

Gmax(t) — G;(Ti(t)) being the difference between the maximum expected quality over
channels at time ¢, ie., Gmax(f), and the one collected from channel i up to time
slot t, i.e, G;(Tj(t)). However, when the ith channel has a good quality G;(T;(t)) as
well as a good availability X;(7Tj;(f)) at time t. Then, the quality factor Q;(¢, T;(¢))
decreases while X;(T;(¢)) increases. Subsequently, by selecting the maximum of its index
Be (t, T;(t)), the user has a large choice to access the ith channel with a high quality and
availability.

To conclude this part, a comparative study in terms of the complexity and convergence
speed to the optimal channel has been presented in Table 2 for UCB, AUCB, QoS-UCB,
Almasri et al. EURASIP Journal on Wireless Communications and Networking (2020) 2020:145 Page 13 of 31

Table 2 Algorithms complexity

 

 

Learning algorithms = Running time complexity — Selection criteria Theoretical © Convergence
guarantee speed

UCB [28] On(5C + 4)) Availability Yes Medium

AUCB O(n(6C + 4)) Availability Yes Fast

QoS-UCB [12] O(n(8C + 6)) Availability and quality Yes Medium

QoS-AUCB O(n(9C + 6)) Availability and quality No Fast

 

and QoS-AUCB. The latter algorithms behave in O(nC) for large n and C that repre-
sent the number of time slots and channels, respectively. Despite the low complexity of
UCB compared to AUCB, this latter can quickly converge to the optimal channel with the
highest availability probability.

4 Results and discussion

4.1 AUCB’s performance

In our simulations, we will consider that the SU can access a single-available channel at
each time slot to transmit its data. In this section, we investigate AUCB’s performance for
both single and multi-users cases. Many simulations have been conducted using Monte
Carlo methods.

4.1.1 Single user tests

At first, let us consider the simple case of a single SU and let channels’ availability be
represented by I. =[ 0.9 0.8 0.7 0.6 0.5 0.45 0.4 0.3 0.25 0.1]. The percentage of times,
Prest, that the SU selects the optimal channel is given by:

n
L(g t)=
Phest = 100 x Ho a)
t=1

where
1 _ | lfa=b
(a=) ~ 0 otherwise
In Fig. 1, Pest shows three parts:

e The first part from 1 to C represents the initialization where the SU plays each
channel once to obtain a prior knowledge about the availability of each channel.

 

 

 

 

 

 

          
 

 

 

 

‘2100 -

Ee AUCB

£ UCB

Oo

om 80Fr

8

2 Initialization Adaptation i Convergence

wn 60 I

w

2

©

© l a
o 40

D

>

= 20 ; 4
Oo |

Oo

@D

Qo, O '

wo

f= 10° 10! 10° 10° 104 10°
r Number of slots
Fig. 1 Phest of the two approaches

 

 

 
Almasri et al. EURASIP Journal on Wireless Communications and Networking (2020) 2020:145 Page 14 of 31

e The second part from C'+1 to 2000 slots represents the adaptation phase.
e In the last part, the user asymptotically converges towards the optimal channel 11.

After the initialization part, the two curves evolve in a similar way. After hundreds of
slots, the proposed AUCB outperforms the classical UCB. AUCB achieved 65% of the best
channel in about 1000 slots, while classical UCB achieved only 45%.

Figure 2 shows AUCB and UCB’s regret factor, evaluated according to Eq. (1) fora single
user. As shown in this figure, the regret has a logarithmic asymptotic behavior for the
two approaches over time. This result can confirm the theoretical upper bound of regret
calculated in Eq. (8) and also presented in Fig. 2, where the upper bound of regret is
logarithmic. The same figure shows that AUCB produces a lower regret compared to the
classical UCB. This means that our algorithm can rapidly recognize the best channel while
the classical UCB required more time to find it.

Figure 3 shows the number of times that the two algorithms sense the sub-optimal chan-
nels up to time v. For worst channels, our approach and classical UCB have approximately
the same behavior. On the other hand, for almost optimal channels (in our example, chan-
nels 2 and 3 which respectively have the availability probabilities of 0.8 and 0.7), the UCB
could not clearly switch to the optimal channel and spends a lot of time exploring the
almost optimal ones.

Figure 4 evaluates AUCB and UCB’s performance with respect to various values of the
exploration-exploitation factor a in the interval ]1, 2]. This figure shows that our approach
outperforms the classical UCB and achieves a lower regret. Moreover, by increasing a, the
classical UCB spends more time to explore the channels in order to find the best channel
while our approach can reach the best one with a lower number of slots. The latter result,
increases the transmission opportunities for the SU, subsequently decreasing the total
regret. In the following sections, we will consider a = 1.5.

4.1.2 Multiple SUs tests
In this section, we consider U = 3 with C = 10 channels and their availabilities are
given by:

I =[0.9 0.8 0.7 0.6 0.5 0.45 0.4 0.3 0.2 0.1]. Figure 5 shows the comparison between the
regret under the multi-user case defined in Eq. (5) for the two approaches (i-e., UCB and
AUCB) under the random rank policy [23]. The latter was used under the UCB; however,

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

2500
1000
400
2g
=> 150
@®
oc
@®
=
ow
=
10
3
—— AUCB
—— Classical UCB
1 —— The upper bound of regret according to equation (8)
O 1000 2000 3000 4000 5000 6000 7000 8000 9000 10000

Number of slots

 

 

Fig. 2 Regret of the two approaches

 
Almasri et al. EURASIP Journal on Wireless Communications and Networking (2020) 2020:145 Page 15 of 31

 

 

800 -

 

 

 

 

 

 

 

 

 

@

w

= GE AUCB
S 700 MM Classical UCB
® 600

<=

<

S 500

=

+ 400

@®

S

7 300

fab)

= 200

oO

B 100

E 0 i. Re Ee ee ee =e
Zz #3 #4 #5 #6 #7 #8

#2 #9 #10

Channels index

Fig. 3 Access sub-optimal channels of the two approaches

 

 

 

it is easy to implement this policy under AUCB to study both algorithms’ performance in
the multi-user case.

In the random rank policy, when a collision occurs among the users, each of them
should generate a random rank in {1,..., UW}. Although, both approaches’ regret achieves a
logarithmic asymptotic behavior, our algorithm achieves a lower asymptotical regret and
converges faster than the classical UCB.

Under the random rank policy, Fig. 6 shows the number of collisions in the UW best
channels (1, 2, and 3 having availability probabilities of 0.9, 0.8, and 0.7, respectively)
for AUCB and classical UCB. Let us remind that, when a collision occurs among users,
no-transmission can be achieved and each of them should generate a random rank
€ {1,..,U}. The same figure shows that the number of collisions under a random rank
policy with AUCB or classical UCB is quite similar. This can be justified based on a nice
random rank policy property; indeed, this policy does not favor any user over another.
Therefore, each user has an equal chance of settling down in any of U-best channels. In
other word, the random rank policy can naturally achieve a probabilistic fairness access

 

Alpha=1.1 Alpha=1.5

 

 

300 300

    

—— AUCB
=== Classical UCB

— AUCB
=——= Classical UCB

   
   

    

 

 

 

 

200 200
~ 100 100
©
oD
®o
Or oO 0
Y 0 2000 4000 6000 8000 10000 0 2000 4000 6000 8000 10000
s Alphaz=1.75
5 a=1. -
& 400 AUCE 400 Alpha=2
a —— AUCB
300 Classical UCB —— Classical UCB
200
100

 

 

 

0 1 l 1 L
0 1 1 1 1
0 2000 40006000 8000 10000 0 2000 4000 6000 8000 10000
Number of slots Number of slots

Fig. 4 Regret of the two approaches with different values of a

 

 

 
Almasri et al. EURASIP Journal on Wireless Communications and Networking (2020) 2020:145 Page 16 of 31

 

 

1600 AUCB ! ! ! T

1400 =—— Classical UCB |

 

 

1200

a
Oo
Oo
oO

800

600

Cumulative Regret

400

 

200

 

 

Number of slots x 10+

Fig. 5 Regret comparison for two approaches under the random rank policy

 

 

among users. Moreover, in the case of AUCB, the user switches to the optimal chan-
nel faster than in the classical one, as shown in Fig. 3 for the single-user case. This fact
decreases the number of collisions among users.

Figure 7 depicts the regret of AUCB and classical UCB under the side channel policy.
As expected, both approaches’ regret increase rapidly at the beginning. At a later time,
the increase is slower for the AUCB compared to the classical one. We thus notice that
our algorithm presents the smaller regret.

4.2 The performance of the PLA policy

This section investigates the performance of the PLA policy under AUCB and UCB
compared to the musical chair [31] and SLK [33], and 4 priority users are considered to
access the channels based on their prior rank. We then compare UCB and AUCB’s QoS
based on the PLA policy.

Figure 8 compares the regret of PLA to SLK and the musical chair policies on a set of
9 channels where PLA achieves the lower regret under AUCB. It is worth mentioning
that our policy and SLK take into account the priority access while in the case of the
musical chair, users access the channels randomly. As shown in Fig. 8, the musical chair
produces a constant regret after a finite number of slots while other methods’ regret is
logarithmic. However, during the learning time To in the case of the musical chair, the

 

 

 

 

 

 

  

2000 5 ME AUcB
MM Classical UCB

an

® 1500 -

<=

wo

—

Oo

8

© 1000 PF

=

<=

Ss

‘DB

S 5007

O
#A #2
Best Channels

Fig. 6 Number of collisions in the best channels under the random rank policy

 

 
Almasri et al. EURASIP Journal on Wireless Communications and Networking (2020) 2020:145 Page 17 of 31

 

 

700 T T T T T T T
—— AUCB
600 Classical UC

500

   

i
Oo
Oo

Cumulative Regret

 

 

 

 

 

 

Number of slots x 104

Fig. 7 Regret comparison for two approaches under the side channel policy

 

 

 

users randomly access the channels to estimate their availability probabilities as well as
the number of users, after that the users just access the U/ best channels in the long run.
Consequently, the musical chair does not follow the dynamism of channels (e.g., assuming
that the vacancy probabilities can change with time). The same figure shows that SLK
achieves the worst regret.

In Table 3, we compare the regret of the four methods with a fixed number of SUs
(U = 4) and different number of channels (C = 5, 9, 13, 17, and 21). As the users spend
more time to learn the availability of channels, the regret may increase significantly. This
result is due to the access to worst channels and to the collision produced among users.
As shown in Table 3, the regret increases with the number of channels, while our PLA
policy under AUCB achieves the lowest regret for different considered scenarios (i.e., C
= 5, 9, 13, 17, and 21). Thanks to the fact that, under our policy, the SUs quickly learn
channels’ vacancy probabilities compared to the others.

To study AUCB’s QoS, let us define the empirical mean of the quality collected from
channels as follows: G =[0.75 0.99 0.2 0.8 0.9 0.7 0.75 0.85 0.8], then the global mean
reward that takes into account the quality as well as the availability [gQ can be given by:
'g =[0.67 0.79 0.14 0.48 0.37 0.28 0.22 0.17 0.08]. After estimating channels’ availabil-
ity and quality (i.e., g) and based on the PLA policy, the first priority user SU; should
converge to the channel that has the highest global mean, i.e., channel 2, while the target

 

 

8000
—«— PLA under AUCB

—S— PLA under UCB
Musical Chair
—4A— SLK

 
 
    
   

 

 

 

 

 

o
oO
oO
oO

 

 

Cumulative Regret
iA
oO
oO
oO

N
oO
oO
oO

 

 

 

 

 

 

   

a !
0 1 2 3 4 5 6 7 8 9 10
Number of slots x 10%

Fig. 8 PLA, SLK, and musical chair regret

 

 

 
Almasri et al. EURASIP Journal on Wireless Communications and Networking (2020) 2020:145 Page 18 of 31

Table 3 Regret comparison in the multi-user case with n = 10° using the four algorithms PLA-AUCB,
PLA-UCB, musical chair, and SLK with a changing number of channels

 

 

Number of PLA- PLA- Musical SLK
channels (C) AUCB UCB chair

5 968 4769 1702 6790
9 1192 5391 4213 7241
13 1413 6332 5769 8361
17 174] 7466 7202 9313
21 2089 8823 8636 10570

 

of SU2, SU3, and SU, should respectively be channels 1, 4, and 5. This result can be con-
firmed in Fig. 9, where the priority users access their dedicated channels in the case of
QoS-UCB or QoS-AUCB. Moreover, QoS-AUCB significantly grants users access of their
dedicated channels more often than in QoS-UCB.

Figure 10 diplays the achievable regret of QoS-AUCB and QoS-UCEB in the multi-user
case. In [12], the performance of QoS-UCB in the restless MAB problem is compared to
several learning algorithms, such as the regenerative cycle algorithm (RCA) [51], the rest-
less UCB (RUCB) [52], and Q-learning [53] where Qos-UCB achieved the lowest regret.
From Fig. 10, one can notice that the QoS-AUCB policy achieves better performance
compared to QoS-UCB.

4.3 AUCB compared to Thompson sampling
Thompson sampling has shown its superiority to a variety of versions of UCB and other
bandit algorithms [35]. Instead of comparing different versions of UCB to AUCB, in this
section, we will study TS and AUCB’ performance in the multi-user case based on the
PLA policy for the priority access. We will thus use two factors to make this comparison:
access the best channels by each user and the regret that depends not only on the selection
of worst-channels but also on the number of collisions among users.

In Fig. 11, we display Ppest (the percentage of times where the priority users access suc-
cessfully their dedicated channels) and the cumulative regret using the PLA policy for 4
SUs based on AUCB, UCB, and TS.

 

 

I SU1 QoS-AUCB
MH SU1 QoS-UCB
ME SU2 QoS-AUCB
(IWS SsU2 QoS-UCB

 
 
 
 
 
 
 
   

 

SU3 QoS-AUCB
ME SU3 QoS-UCB

SU4 QoS-AUCB
LJ] SU4 QoS-UCB

 

 

 

 

 

 

 

 

Number of times where users access channels

Oo

FFA #2

3 # #5 #6 #7
Channels

Fig.9 Access channels by the priority users using QOS-AUCB and QoS-UCB

 

 

 
Almasri et al. EURASIP Journal on Wireless Communications and Networking (2020) 2020:145

 

 

4 T T T T T T T
000 — QoS-AUCB

 

 

 

3000

2500

2000

1500

Cumulative Regret

1000

500

 

 

 

 

Number of slots x 104

Fig. 10 QoS-AUCB and QoS-UCB regret

To)

 

 

 

In Figs. 11a, b, the first priority user SU converges to its channel, i.e., the best one,
followed by SU2, SU3, and SU4, respectively. Figure 11c compares Phest of the first prior-
ity user under AUCB and TS. According to this figure, the first priority user can quickly
converge to its dedicated channel using the AUCB algorithm while in the case of TS, the
user needs more time to find the best channel. Figure 11d compares the regret of AUCB,
UCB, and TS in the multi-user case using the PLA policy for the priority access. How-
ever, in TS algorithm, users have to spend more time exploring the C — U worst channels;
while in AUCB’s case, the users reach quickly their desired channels. However, a lower
regret can increase the successful opportunities of transmission for users. Moreover,
selecting dedicated channels in a short period becomes a significant event in a dynamic

environment.

5 Conclusion

In this paper, we investigated the problem of opportunistic spectrum access (OSA) in
cognitive radio networks, where a SU tries to access PUs’ channels and find the best avail-
able channel as fast as possible. We also proposed a new AUCB algorithm to achieve a
logarithmic regret with a single user. On the other hand, to evaluate AUCB’s performance
in the multi-user case, we proposed a learning policy called PLA for secondary networks
that takes into account the priority access. We have also investigated PLA’s performance
compared to recent works, such as SLK and the musical chair. We have theoretically found
the upper bounds for AUCB’s total regret for a single user as well as for the multi-user case
under the proposed policy. Our simulation results show logarithmic regret under AUCB

 

a: The percentage to access the best channels under AUCB
Pbest of SU1 under AUCB ] ] }
Pbest of SU2 under AUCB
Pbest of SU3 under AUCB
Pbest of SU4 under AUCB

c: The percentage that SU1 accesses his channel under AUCB and TS
Pbest of SU1 under AUCB
Pbest of SU1 under TS

 

   
  

  
 
 
 

 

 

 

    

 

Aa 1 1 ‘a ° i ii Giiil |
° 10! 107 10° 107 10° 10° 10! 107 10° 10+ 10°

 

b: The percentage to access the best channels under TS
Pbest of SU1 under TS ] ] ]
Pbest of SU2 under TS
80 Pbest of SU3 under TS
Pbest of SU4 under TS

d: Cumulative Regret for 4 SUs under AUCB, UCB and TS

AUCB T T 7 T T T
—s— UCB
—4— Thompson Sampling

 

    
 
 

 

6000

       

B
°
°
°

nN
°
°
°

 

Cumulative Regret

 

 

L
102 10°
Number of slots

° 4 4 5 6
10 10 Number of slots

Fig. 11 The performance of AUCB, UCB, and TS

 

 

 

Page 19 of 31
Almasri et al. EURASIP Journal on Wireless Communications and Networking (2020) 2020:145 Page 20 of 31

and corroborate AUCB’s performance compared to UCB or TS. It has also been shown
that AUCB rapidly converges to the best channel while achieving a lower regret, improv-
ing the transmission time and rate of SUs. Moreover, PLA under AUCB can decrease the
number of collisions among users under the competitive scenario, thanks to a faster esti-
mation of the channels’ vacancy probability.

Like most important works in OSA, this work focused on the independent identical dis-
tributed (IID) model in which the state of each channel is supposed to be drawn from an
ID process. In future work, we are planning to consider the Markov process that may rep-
resent a dynamic memory model to describe the state of available channels; however, it is
a more complex process compared to IID. Moreover, our actual model ignores dynamic
traffics at the secondary nodes; therefore, the extension of our algorithm to include a
queueing-theoretic formulation is desirable.

For a more realistic model, the future work will also investigate the effects of using the
state of the art of spectrum sensing techniques to detect the activity of the primary
users on the performance of the learning and decision-making. Moreover, considering
the imperfect sensing, i.e., the probability of false alarm and miss detection, represents a
new challenge to developing a more realistic network.

Appendix A: Convergence proof of AUCB

In this Appendix, we show that the upper bound of the regret of AUCB is logarithmic with
respect to time that means that after a finite time, the user will luckily find and access the
best channel with the availability w;. The regret for a single user up to the total number
of slots m under a policy 6 can be expressed as follows:

C
R(n, B) = Ya — MAE [Tin] (15)
i=l
where C represents the number of channels; 1 and pu; being the availability proba-
bilities of the best channel and ith worst one respectively; E(.) represents the math-
ematical expectation; 7;(”) is the number of times that the ith channel has been
sensed by the user up to nv. According to Eq. (15) and with constant availabili-
ties of channels, the upper bound of 7;(”) can contribute to find an upper bound
of R(n, PB).
Normally, the user senses the ith channel during the initialization stage and every time
B(t) =i, and where f(t) represents the selected channel at the instant ¢ under the policy
B; then, T;(1) can be expressed as follows:

nN
Tin) =1+ D> lgw=i (16)
t=C+1
where the logic operator 11,g(¢)=i) equals one if B(t) = i and zero otherwise. Let us con-
sider that a SU senses at least / times each channel up to un, then according to Eq. (16),
T;(”) should be bounded as follows:

N
Tin) <1+ Yo Ugeozsre—yz=0 (17)
t=C+1

As AUCB selects at each time slot the channel with the highest index obtained in the
previous slot, the user may access, at the slot ¢, a non-optimal channel if the index of
Almasri et al. EURASIP Journal on Wireless Communications and Networking (2020) 2020:145 Page 21 of 31

this channel at (¢ — 1), Bj(t — 1, T;(t — 1)), is higher than the index of the best channel
B,(t — 1, T*(t — 1)). In this case, we can develop further Eq. (17) as follows:

nN

Tin) <1+ Yo Upe-1,ree—v) <B,e-1,.THt—-D)sTHt-D =) (18)
t=C+1

According to Eq. (2), the index of channels B;(¢,7;(£)) = X;(T;()) + Aj(t, T;(@) is
based on:

e The exploitation factor X;(T;(¢)) representing the expected availability probability.
e The exploration factor A;(t, T;(¢)) that forces the algorithm to explore different
channels. This factor under AUCB is defined as follows:

Ag (t, T;(t)) = arctan (a0),

 

Using Eq. (18), we can prove that:

nN

Ti(n) <1+ So lpyer«e—v)+Aat-LT*(t-D)<
t=C+1 (19)

X;(T;(t—-1)) +A (t-1,T;(t-1));Ti(t-D = 1}

The summation argument in the above equation follows Bernoulli’s distribution (ie.,
E{X} = P{X = 1}). In this case, the expectation of Tj;(1) should satisfy the following
constraint:

E[T(n)]<l+ > P{X(T*(t-1))+
t=C+1

(20)
Ag(t —1,T*(t¢—1)) < X(T — 1))+
Aqg(t — 1, T;(t — 1)) and T;(t — 1) > J}
The probability in Eq. (20) becomes:
Prob = P [xurre —1))—X;,(T;(t-1)) <
arctan (<r) — arctan (see) (21)
T;(t — 1) T*(t — 1)

and T;(t — 1) > i

After the learning period where 7;(¢ — 1) > J, the user will have a good estima-
tion of channels availability and thus may access regularly the best channel. Therefore,
T(t —1) < T*(t — 1); and arctan (+ ne) > arctan (2255). Using the asymptotic
behaviors of the non-linear functions sgrt and arctan, the probability in Eq. (21) becomes
bounded by:

 

 

Prob < P [cre —1)) — X\(Ti(t — 1) <

jain fen) args 1
T;(t — 1) T*(t — 1)

(22)
Almasri et al. EURASIP Journal on Wireless Communications and Networking (2020) 2020:145

By taking the minimum value of X;(T*(t — 1)) + me and the maximum value of

 

 

X;(T;(t — 1)) + Tr me at each time slot, we can upper bound Eq. (20) by the following

equation:

E[Ti(m)]<i+ >

t=C+1

P| min x (s*) + | < (23)

 

0<S* <t S*

max 9 + “ a |

 

l<S;<t 1

where S; > / to fulfill the condition 7;(t — 1) > J. Then, we obtain:

n t—l1 t-l

E[T(m)<!+ >So

t=1 S*=1 S;=I (24)
P{Xj(S*) + Alt, S*) < Xi(Si) + Ait, Si)}

The inequality X;(S*) + Aj(t,S*) < X;(S;) + Aji(¢, Sj) is satisfied when at least one
inequality among the three following ones does:

Xj (S*) < 1 — Ai (t, S*) (25a)
Xj(Sij) = wi + Ail, Si) (25b)
[1 < bi + 2A,(E, Sj) (25c)

In fact, if all three inequalities are wrong, then we should have:

Xj (S*) + Aj (t,S*) > 1 = mi + 2Ai(t, Si)
> Xj(Sj) + Ait, Sj)

which gives a contradiction with the inequality (24). Using the ceiling operator |], let
l= pe), where A(1,3) = 1 — i and S; > 1, then Eq. (25c) becomes false, in fact:
(Li)

 

 

a In(t)
Ly — Wi — 2Aj(E, Si) = wy — pi — 2 S,
Ll

a In(n)
> hy — bi — 2 j

> U1 — wi — Agi) = 0

Based on Eqs. (24), (25a), and (25b), we obtain:

E[ T;( 4a In(n) n t-1t-1
t n)| = A? 4 S- > y

(1,7) t=1 S*=1 S;=1
{P {Xi(S*) < w1 — Ai(t, S*)} +
P{X;(Sj) > wi + Ailt, Si}

 

(26)

Page 22 of 31
Almasri et al. EURASIP Journal on Wireless Communications and Networking (2020) 2020:145

Using Chernoff-Hoeffding bound? [54], we can prove that:

P{X,(S*) < 1 — Ault, S*)} < exp”
= ¢ 2 (27)

 

P{X\(S) > uj + Aj(t, S;)} < exp * a(S: sea)

= ¢ (28)

The two equations above and Eq. (26) lead us to:

Aw | n t—l1 t-l
ELT) < * or | 2t-24
Awi) t=1 S*=1 S;=I
4a |
< —_ $1420 (29)

(1,2) t=1
According to Cauchy series [55], the parameter aw should be higher than 3 in order to find

nN
an upper bound of the second term in the above equation. Let a = 2, to resolve )~ t~?

t=1
we consider the Taylor’s series expansion of sin(t):
8 skal p2k+1
sin(t) =t——+..+(-l ————— + ,., 30
©) 3! (“)) (2k + 1)! (30)

As sin(t) = 0 when t = +k7, then we obtain:

t? t?
sin(f) =ftx (: — =) X we X ( _— a2) eee

a a ot.
i=1

where q; is a general coefficient. By comparing the above equation with Eq. (30), we obtain

4 = x Finally, we obtain the upper bound of E[ T;(1)] as follows:

Ms

i=1

 

(31)

Appendix B: Upper bound the collision number under PLA
Here, we show that the total number of collisions occurs among secondary users in the

U best channels, Oy(”) = y Ox(v), under our policy PLA has a logarithmic asymptotic
k=
behavior. In this case, after a finite number of collisions, the users may converge to their

dedicated channels, the U/ best ones. Let Oc(”) = x O;(n) be the total number of col-
i=1
lisions encountered by users in all channels, where C represents the number of available

channels. Let Dx(u) be the total number of collisions under the kth priority user in all
channels. To clarify our idea, Table 4 presents a case study with corresponding D;() and
O,(n). E[ Oy (n)] can be expressed as follows:

 

4 According to [54], Chernoff- Hoeffding theorem is defined as follows: Let Xj, ...,X, be random variables in [0,1], and
2 2
E{ X¢] = p, and let S =X, Then, V a > 0, we have P{S, > nu + a} < exp a and P{S, < nu — a} < exp ae

i=1

Page 23 of 31
Almasri et al. EURASIP Journal on Wireless Communications and Networking (2020) 2020:145 Page 24 of 31

Table 4 Two SUs access three available channels

 

 

SU1 SU2 Dsui(t) Dsu2(t) Oc (£) Oc2(E) Oc3(E)
t=1 CI CI ] ] 2 0 0
t=2 C2 C3 0 0 0 0 0
t=3 C2 C2 ] ] 0 2 0
t=4 C3 C2 0 0 0 0 0
t=5 C3 C3 ] ] 0 0 2
t=6 CI CI ] ] 2 0 0

 

U
In this case, the total number of collisions for the two users is D(n) = >) Dg(n) = Dsyi (Nn) + Dsu2(n). The number of collisions in
k=1
C
all channels produced by the users is Oc(n) =

|

O(N) = Oc) (2) + O@2(N) + Oc3(/n), while the number of collisions in the best
1

U
channels, i.e.,C1 and C2, is Oy(n) = >> Ox(n) = Oci (N) + Oc2(N)
k=1

U C
E[Ou(n)] = ) > EL Ox(n)] < > EL O;(n)]
k=1 i=1
U
=) E[D,(n)| (32)
k=1

We assume that when users have a good estimation of channel availabilities and each
one accesses its dedicated channel, then non-collision state can be achieved. On the other
hand, the Ath user may collide with other users in two cases:

e If it does not clearly identify its dedicated channel.
e If it does not respect its prior rank.

Let T,(n) and S; be respectively the total number of times, where the kth user
badly identifies its dedicated channel and the time needed to return to its prior rank.
After each bad estimation, the user will change its dedicated channel. In this case, it
may collide with other users till the convergence to its prior rank. Subsequently, for

all values of m, the total number of collisions for the kth user Dz(m) can be upper
bounded by:

Dy(n) < Ty(n)Ss (33)
As T, (1) and S, are independent, we have:
E[ Dx(n)] < El T;(n)] E[ Ss] (34)

Let us find an upper bound of E[ T,(n)], and let A;(t) be the event that the Ath user
identifies its dedicated channel, the kth best one, at the instant t. Then, VkK+1<i<C
and 1 < m < k —1, the event A,(t) takes place when the following condition is
satisfied:

Ax(t) : Bit) < By(t) < Bm()

For a bad estimation event at instant ¢, Ji € {k +. 1,...,C} andi me {l,...,k — 1}, Ak

is true when we have the following condition:

A(t) : [Bi(t) > By (t)] or [Bg(t) > Bn (t)]

 

» After each collision and according to our policy PLA, the user should regenerate a rank.
Almasri et al. EURASIP Journal on Wireless Communications and Networking (2020) 2020:145 Page 25 of 31

Then, the total number of times of a bad estimation where the kth priority user does
not access its channel up to n, E 7; (n)|, can be upper bounded as follows:

E|T,(n)| < E[Ta~H()] + E[Tr,,<3(0)] (35)

where Tz,~3,(”) represents the number of times in which the index of the ith channel
exceeds that of the kth best one for alli € {k + 1,...,C} up to m; and Tz, <p, (”) repre-
sents the number of times in which the index of the kth best channel exceeds the mth
one for allm e ({1,..,k — 1}. It is worth mentioning that, for the first priority user,
E [ TB, <By (n) | should equal 0, since its dedicated channel has the highest availability
probability. Tz,~8,(”) for the kth user has the similar definition as in Eq. (31) for a single
user, then this term, for the k” user, can be upper bound as in Appendix A by:

2
E[Tp,>8,(n)| < sin) 4140 (36)

(k,i) 5
where Aq = Mk — Mi. AS i < Msi for alli € {k + 1,...,C} and wy, > Wey = = UC,

 

then Axi) = AK +1). Subsequently, E [ T2,> By (n) | can be upper bounded by:

 

8 In(n) 1
E|Tg;>B,(")|] < +1+ > (37)
(k,k+1)

Similarly, the second term E[ Tz, <g,(”)] in Eq. (35) should satisfy:

2
E[Tey<a,()] < ee 414 (38)

(m,k) 3

 

where Aqyx) = Ack-1,k forall m € {1,...,k — 1}. Then, we obtain,

2
E[T5,<n(0)] < 41+ (39)

(k—1,k) 3

 

Based on Eq. (35), (37), and (39), E [7 (n) | can be expressed as follows:

u u
e[rom] <> (e414 S) yo (SM 14) (40)
k=1 (k,k+1) k=2 (k—1,k)

Let us estimate the time S; and let us consider U users with different priority levels
based on our policy PLA. At a certain moment, supposing that each user has a random
rank, then at least two of them may have the same rank, and a collision may occur. In this
case, each user with a collision case should regenerate a random rank around its prior
rank®. After a finite number of collisions, the system will converge to the steady state
where each user has a unique rank, i.e., its prior rank. Let S; be a random variable with a
countable set of finite outcomes 1,2,... occurring with the probability pj, po... respectively,
where p; represents a non-collision at instant t. The expectation of S; can be expressed as
follows:

E [Ss] = S tp| Ss = t] (41)
t=1

where the random variable S, follows the probability p| S; = ¢]:

plS; =t]=(1—p)'p

 

°For SUk, it should regenerate a rank in the set {1, ...k}.
Almasri et al. EURASIP Journal on Wireless Communications and Networking (2020) 2020:145 Page 26 of 31

Table 5 Three SUs trying to converge towards a steady state where each one finds its prior rank. The
roman number indicates the number of users selecting the same rank

 

 

Cases Rank 1 Rank 2 Rank 3
| | | 0
2 ||| 0 0
3 | | |
4 | | 0
5 | 0 |

 

and p indicates the probability of non-collision at an instant tf, while (1 — p)’ indicates the
probability of having collisions from the instant 0 till t — 1. Then, we obtain:

CO
Ss]= >) t0 —p)'p (42)
Let I,(«) be defined as follows:
CO
In(x) = (1—a) )_(ax)' (43)
t=1
where a is a constant number such that ax < 1. /(x) can converge to:
(1 — a)ax
Ig (x) = ————
l—ax

Based on the previous equation, we have:
d1q(x) (1—a)a
dx (1 — ax)?
Using the previous equation, we obtain:
d1q(x) a
dx |x-1 (1 — a)

 

 

 

(44)

Considering that a = 1—p, we conclude that E[ S,] = =. To clarify the idea and estimate
the probability p, we consider that three SUs are trying to find their prior rank where
the Table 5 displays all the possible cases. Subsequently, the probability to converge to a
steady state, i.e., the case 3, is p = f, and E| S,] = 4.

To estimate the value of p as well E[ S;], let us introduce the problem suggested in [[56]
Chapter 5] , to count the number of ways of putting U/ identical balls into U different
boxes. According to [[56] Chapter 5], the probability p to converge to a steady state where

GH) and E[ S;| = (su_-v) — 1. However, our problem
of convergence to a steady state ar) a restricted case of the problem introduced in

each box has just one ball is p =

[56]. Then, the expected time to converge to a steady state of our policy PLA for UU SUs
can be upper bounded by:

E[ Ss] < Gu i) —1 (45)

Based on Eqs. (32), (34), (40), and (45) the total number of collisions in the best channels
for U SUs can be upper bounded by:

U
soul =|!" )- 1

“(8 In) “(8 mn) mr? (46)
k=1 (k, a k=2 Ai LD

 

 
Almasri et al. EURASIP Journal on Wireless Communications and Networking (2020) 2020:145 Page 27 of 31

The above equation shows that there is a finite number of collisions in the U best
channels for PLA based on AUCB before each user converges to its dedicated channel.

Appendix C: Upper bound the regret of PLA under AUCB
The global regret under the multi-user case according to Eq. (5) can be defined as follows:

u uc

R(n, U, B) =n Y oe DDE [Pi] mi (47)
k=1 j=l i=l

where jx is the availability probability of the Ath best channel and P;;(1) represents the

total number of non-collision up to 1 in the channel i for user j. Let T;,;(”) be the total

u
number of times where the jth user senses the ith channel up to n. Let T;(1) = )° T;;(n)
j=l

u
and P;(n) = >  P;;() represent, respectively, the total number of times, where the ith

channel is sensed by all users, and the total number of times, where the users access
the ith channel without making any collision with each other up to nv. Let Ox(n) be
the number of collisions in the kth best channel (as defined at the beginning of the
Appendix B). Based on 7;(m) and P;(n) for the kth best channel (T;(m) and P;(n) rep-
resent, respectively, the total number of times where the Ath best channel is sensed
by all users and the total number of times where the users access the Ath best chan-
nel without making any collision with each other up to 1), Oxg(m) can be expressed as
follows:

Ox(n) = Ty(n) — Px(n) (48)

It is worth mentioning that the number of channels C should be higher than the number
of users U, otherwise:

e Using a learning algorithm to find the best channels does not make any sense, since
all channels need to be accessed.

e Considering that the user should sense one channel at each time slot, at least one
collision may occur among users, then users cannot converge to free-collision state

under any learning policy.

Subsequently, by supposing that C > U and 1; > pj, V i, we can upper bound the regret
in Eq. (47) of our policy PLA under our algorithm AUCB by the following equation:

U U U
Rpta(n, U, AUCB) <2) te — So weE (Pe) < 11 G -ScE cn

k=1 k=1 k=1
At each time slot, the user can sense one channel, then we can consider that:
C U C
SY). Ti) = Y° Ti(n) = Un (49)
i=1 j=1 i=1

Based on the above expression, the regret can be expressed as follows:

C U
Rpia(n, U, AUCB) < p11 (de [Ti(n)] — \“E en (50)
Almasri et al. EURASIP Journal on Wireless Communications and Networking (2020) 2020:145

C
We can break 5° E [T;()] into two terms:

i=]
C U C
SJ ELT) = QF Tn) + SY  ELTi(n)] (51)
i=1 i=U+1
Based on Eq. (50) and (51), we obtain the following equation:
C
Rpia(n, U, AUCB) < p11 ( \) El rn + EL0u0n!| (52)
i=U+1

It is worth mentioning that the global regret in the multi-user case depends on the
selection of worst channels as well as the number of collisions among users. However,
Eq. (52) confirms the definition of the regret where the first term 7;(”) represents the
access of worst channels for all users, and the second term Oy() is the number of
collisions for all users in the UU best channels. In order to bound the regret, we need
to bound the two terms E [T;(m)] and E [Oy()]. In Eq. (31), we calculated the upper
bound of E[ 7;(1)] for a single user. In fact, E[ T;(1)] in Appendix A has the same
properties of E[ T;;()] in the multi-user case. The difference is that, in the single-user
case [lj € {l2,43,..,c} while in the multi-user case, and according to Eq. (52), ku;
should be in {(1+1), M(u+2))+-» Mc}. Therefore, for each user in the multi-user case,
we obtain:

8 In(1) 1
x +t1+>

E|Ti:(n)| < 3

 

(1,7)

 

8 In(1) 1
5 +1+ —

E[Tiu()] < 3

(U,i)

Consequently, the upper bound of E| T;()] for all users becomes:

u u 8 In(n) 1
E( Ti(n))= SC E[Tj] < >- az tit+> (53)

 

Finally, based on Eqs. (46), (52), and (53), the global regret of users for AUCB and under
PLA can be expressed as follows:

Rpza(n, U, AUCB) <

mps S (es +)

k=1 i=U+1 AKA)

_ 2 (54)
Py (are rie)

P k=2 (k—1,k)

u 8 In(n) mr
Sy) {|= + 1+ >
kal \OK K+)

The above regret contains three components: The first one is due to the loss of reward

 

 

 

when selecting worst channels by all users. The second and third components represent
the loss of reward due to collisions among users in the LU best channel. In fact, the regret

of PLA is worse than the regret under the side channel policy that will be introduced in

Page 28 of 31
Almasri et al. EURASIP Journal on Wireless Communications and Networking (2020) 2020:145 Page 29 of 31

Appendix D, Eq. (60). Indeed, the cooperation among the SUs under the side channel can
avoid the collisions and achieve a lower regret compared to PLA.

Appendix D: Upper bound the regret of the side channel under AUCB

In this section, we prove that the upper bound of regret of our algorithm AUCB
for the multi-user case under the side channel policy has a logarithmic asymp-
totic behavior. In this policy, we supposed that no-collision occurs among users
when the priority user broadcast the choice of its channel, without considering that
the broadcast packet of the priority user may loss. However, considering the lat-
ter scenario may add some constant values to the regret as a result of the colli-
sions among users so that the regret under the cooperative access can be defined

as below:
Rsc(n, U, AUCB) = n y Mk - y > pik [Tij(n)] (55)
i=1 j=1
According to Eq. (49), we obtain:
Cc U C
DDE LT] = DE [Ti] = Un (56)
i=1 j=1 i=1

Based on Eqs. (55) and (56), the regret can be expressed as follows:

Rsc(n,U,AUCB) =

UC
id HE [Ti(n)] — Sine [ Ti(n)]

UC
dod, HEL Ti)| MEL Ti)

Ss

Sle
>~
II
ray
iv
—

E(Ti(n)) Awa (57)

me
Mes
Meo

i=1

>
II
_
|

where A(x ji) = Mk — Li, kK and i represent, respectively, the Ath best channel and the ith
channel. To simplify the above equation, we consider the summation over worst and best
channels as follows:

Rsc(n, U, AUCB) = Lye T(n)] Awe + = LS SE [ Ti(n)] Aci (58)

U kal U i icutl

The first term of the regret in Eq. (58) equals 0, then we obtain:

Rsc(n, U, AUCB) = 1s Se [Ti] Mea (59)
ui 1i=U+1

E| T;()] has the same properties and definition to that calculated in Appendix C, Eq. (53).
Finally, the regret of AUCB under the side channel policy is bounded as:

ust 8 In(n) 1
Rsc(n, U, AUCB) < S S + A«i) (1 + =) (60)

k=1 i=U+1 Aki)

 

In this Appendix, we proved that the global regret of AUCB under the side channel
policy has a logarithmic asymptotic behavior with repspect to 1, which means that after a
Almasri et al. EURASIP Journal on Wireless Communications and Networking (2020) 2020:145 Page 30 of 31

period of time, each user will have a good estimation of the channels availability and will
access a channel based on its rank.

Abbreviations

OSA: Opportunistic spectrum access; CR: Cognitive radio; PU: Primary user; SU: Secondary user; TS: Thompson sampling;
UCB: Upper confidence bound; AUCB: Arctan-UCB; ED: Energy dectection; CPSD: Cumulative power spectral density;
WBS: Waveform-based sensing; PLA: Priority learning access; TDFS: Time-division fair share; MEGA: Multi-user e-greedy
collision avoiding; SLK: Selective learning of the kth largest expected rewards

Authors’ contributions
All authors have contributed to the analytic and numerical results. The authors read and approved the final manuscript.

Availability of data and materials
The authors declare that all the data and materials in this manuscript are available from the authors.

Competing interests
The authors declare that they have no competing interests.

Author details
'LABSTICC, UMR 6285 CNRS, ENSTA Bretagne, 2 rue F. Verny, 29806, Brest, France. *Univ Rennes, CNRS, IETR - UMR 6164,
F-35000 Rennes, France. ? Lebanese University, Faculty of Science, Tripoli, Lebanon.

Received: 25 December 2019 Accepted: 21 May 2020
Published online: 08 July 2020

References

1. J. Mitola, G. Maguire, Cognitive radio: making software radios more personal. IEEE Pers. Com. 6(4), 13-18 (1999)

2. A.Nasser, A. Mansour, K. C. Yao, H. a. Abdallah, Spectrum sensing based on cumulative power spectral density.
EURASIP J Adv. Sig. Process. 2017(1), 38 (2017)

3. D.Bhargavi, C. Murthy, in SPAWC, Performance comparison of energy, matched-filter and cyclostationarity-based
spectrum sensing (IEEE, Marrakech, Morocco, 2010)

4. H. Urkowitz, Energy detection of unknown deterministic signals. Proc. IEEE. 55(4), 523-531 (1967)

5. J. Wu, T. Luo, G. Yue, in International Conference on Information Science and Engineering, An energy detection
algorithm based on double-threshold in cognitive radio systems (IEEE, Nanjing, China, 2009)

6. C.Liu, M. Li, M.-L. Jin, Blind energy-based detection for spatial spectrum sensing. IEEE Wirel. Com. Lett. 4(1), 98-101
(2014)

7. A. Sahai, R. Tandra, S. M. Mishra, N. Hoven, in International Workshop on Technology and Policy for Accessing Spectrum,
Fundamental design tradeoffs in cognitive radio systems (ACM Press, Boston, USA, 2006)

8. _H. Tang, in International Symposium on New Frontiers in Dynamic Spectrum Access Networks, Some physical layer
issues of wide-band cognitive radio systems (IEEE, Baltimore, USA, 2005)

9, W.R. Thompson, On the likelihood that one unknown probability exceeds another in view of the evidence of two
samples. Biometrika. 25(3), 285-294 (1933)

10. T. Lai, H. Robbins, Asymptotically efficient adaptive allocation rules. Adv. Appl. Math. 6(1), 4-22 (1985)

11. C.J.C.H. Watkins, Learning from delayed rewards. PhD thesis, University of Cambridge (1989)

12. N.Modi, P. Mary, C. Moy, Qos driven channel selection algorithm for cognitive radio network: Multi-user multi-armed
bandit approach. IEEE Trans. Cog. Com. Networking. 3(1), 1-6 (2017)

13. M.Almasri, A. Mansour, C. Moy, A. Assoum, C. Osswald, D. Lejeune, in FECS, Opportunistic spectrum access in
cognitive radio for tactical network (IEEE, Bern, Switzerland, 2018)

14. GSMA Report: Spectre 5g position de politique publique de la GSMA (2019)

15. A.Nasser, A. Mansour, K. Yao, H. A. H., Charara: spectrum sensing based on cumulative power spectral density.
EURASIP J Adv. Sig. Process. 2017(1), 38 (2017)

16. X. Kang, Y.-C. Liang, A. Nallanathan, H. K. Garg, R. Zhang, Optimal power allocation for fading channels in cognitive
radio networks: Ergodic capacity and outage capacity. IEEE Trans. Wirel. Commun. 8(2), 940-950 (2009)

17. X. Kang, H. K. Garg, Y.-C. Liang, R. Zhang, Optimal power allocation for OFDM-based cognitive radio with new
primary transmission protection criteria. IEEE Trans. Wirel. Commun. 9(6), 2066-2075 (2010)

18. H.G.Myung, J. Lim, D. J. Goodman, Single carrier FDMA for uplink wireless transmission. IEEE Veh. Technol. Mag. 1(3),
30-38 (2006)

19. E. E. Tsiropoulou, A. Kapoukakis, S. Papavassiliou, in /F/P Networking Conference, Energy-efficient subcarrier allocation
in SC-FDMA wireless networks based on multilateral model of bargaining (IFIP, New York, 2013)

20. E.E. Tsiropoulou, A. Kapoukakis, S. Papavassiliou, Uplink resource allocation in SC-FDMA wireless networks: a survey
and taxonomy. Comput. Netw. 96, 1-28 (2016)

21. W.Jouini, C. Moy, J. Palicot, Decision making for cognitive radio equipment: analysis of the first 10 years of
exploration. Eurasip J. Wirel. Commun. Netw. 2012(1), 26 (2012)

22. L.Melian-Gutierrez, N. Modi, C. Moy, F. Bader, |. Perez-lvarez, S. Zazo, Hybrid UCB-HMM: a machine learning strategy
for cognitive radio in HF band. IEEE Trans. on Cog. Com. Networking. 1(3), 347-358 (2015)

23. A.Anandkumar, N. Michael, A. Tang, A. Swami, Distributed algorithms for learning and cognitive medium access
with logarithmic regret. IEEE J. Sel. Areas Com. 29(4), 731-745 (2011)

24. R. Agrawal, Sample mean based index policies with o(log n) regret for the multi-armed bandit problem. Adv. Appl.
Probab. 27(4), 1054-1078 (1995)

 
Almasri et al. EURASIP Journal on Wireless Communications and Networking (2020) 2020:145 Page 31 of 31

25,

26.

2/.

28.

29,

30.

31.
32.

33.

34.

35.

36.

37.

38.

 

50.

W. Jouini, D. Ernst, C. Moy, J. Palicot, in /CC, Upper confidence bound based decision making strategies and dynamic
spectrum access (IEEE, Cape Town, South Africa, 2010)

K. Liu, Q. Zhao, Distributed learning in multi-armed bandit with multiple players. IEEE Trans. Sig. Process. 58(11),
5667-5681 (2010)

Y. Gai, B. Krishnamachari, R. Jain, in /EEE Symp. on Dynamic Spectrum Access Networks, Learning multiuser channel
allocations in cognitive radio networks: a combinatorial multi-armed bandit formulation (IEEE, Singapore, 2010)

P. Auer, N. Cesa-Bianchi, P. Fischer, Finite-time analysis of the multiarmed bandit problem. Mach. Learn. 47(2),
235-256 (2002)

M. Almasri, A. Mansour, C. Moy, A. Assoum, C. Osswald, D. Lejeune, in /SC/T, Distributed algorithm to learn OSA
channels availability and enhance the transmission rate of secondary users (IEEE, HoChiMinh, Vietnam, 2019)

K. Liu, Q. Zhao, B. Krishnamachari, in 2070 48th Annual Allerton Conference on Communication, Control, and Computing,
Decentralizedmulti-armed bandit with imperfect observations (IEEE, Monticello, USA, 2010)

J. Rosenski, O. Shamir, L. Szlak, Multi-player bandits-a musical chairs approach. (ICML, New York, 2016)

O. Avner, S. Mannor, in European Conf. on Machine Learning and Principles and Practice of Knowledge Discovery in
Databases, Concurrent bandit and cognitive radio networks (Springer, Nancy, France, 2014)

Y. Gai, B. Krishnamachari, in GLOBECOM, Decentralized online learning algorithms for opportunistic spectrum access
(IEEE, Texas, USA, 2011)

N. Torabi, K. Rostamzadeh, V. C. Leung, in GLOBECOM, Rank-optimal channel selection strategy in cognitive networks
(IEEE, California, USA, 2012)

G. Burtini, J. Loeppky, R. Lawrence, A survey of online experiment design with the stochastic multi-armed bandit.
arXiv preprint arXiv:1510.00757 (2015)

E. Kaufmann, O. Cappé, A. Garivier, in Artificial Intelligence and Statistics, On Bayesian upper confidence bounds for
bandit problems (AISTATS, La Palma, Canary Islands, 2012)

O.-A. Maillard, R. Munos, G. Stoltz, in Annual Conf. On Learning Theory, A finite-time analysis of multi-armed bandits
problems with Kullback-Leibler divergences (Association for Computational Learning, Budapest, Hungary, 2011)

M. Almasri, A. Mansour, C. Moy, A. Assoum, C. Osswald, D. Lejeune, in EUS/PCO, All-powerful learning algorithm for
the priority access in cognitive network (IEEE, A Coruna, Spain, 2019)

S. L. Scott, A modern Bayesian look at the multi-armed bandit. Appl. Stoch. Model. Bus. Ind. 26(6), 639-658 (2010)

O. Chapelle, L. Li, in Advances in Neural Information Processing Systems, An empirical evaluation of thompson
sampling, (Granada, Spain, 2011)

S. Agrawal, N. Goyal, in Conf. on Learning Theory, Analysis of thompson sampling for the multi-armed bandit problem
(Association for Computational Learning, Edinburgh, Scotland, 2012)

E. Kaufmann, N. Korda, R. Munos, in /nternational Conf. on Algorithmic Learning Theory, Thompson sampling: an
asymptotically optimal finite-time analysis (Springer Berlin Heidelberg, Lyon, France, 2012)

S. Agrawal, N. Goyal, in Artificial Intelligence and Statistics, Further optimal regret bounds for thompson sampling
(AISTATS, Scottsdale, 2013)

W. Jouini, D. Ernst, C. Moy, J. Palicot, in International Conf. on Signals, Circuits and Systems, Multi-armed bandit based
policies for cognitive radio's decision making issues (IEEE, Djerba, Tunisia, 2009)

L. Melian-Gutiérrez, N. Modi, C. Moy, |. Pérez-Alvarez, F. Bader, S. Zazo, in ICC Workshop, Upper confidence bound
learning approach for real HF measurements (IEEE, London, UK, 2015)

C. Tekin, M. Liu, in Annual Allerton Conf. on Com., Control, and Computing, Online algorithms for the multi-armed
bandit problem with Markovian rewards (IEEE, Monticello, USA, 2010)

B. Giuseppe, J. Loeppky, R. Lawrence, A survey of online experiment design with the stochastic multi-armed bandit.
In: arXiv Preprint arXiv:1510.00757 (2015)

J.G.V. Bosse, F. U. Devetak, Signaling in Telecommunication Networks, 2nd edn. John Wiley & Sons, Canada, 2006)

M. Lopez-Martinez, J. Alcaraz, L. Badia, M. Zorzi, A superprocess with upper confidence bounds for cooperative
spectrum sharing. IEEE Trans. Mob. Comput. 15(1 2), 2939-2953 (2016)

X. Feng, G. Sun, X. Gan, F. Yang, X. Tian, X. Wang, M. Guizani, Cooperative spectrum sharing in cognitive radio
networks: a distributed matching approach. IEEE Trans. Com. 62(8), 2651-2664 (2014)

51. C. Tekin, M. Liu, in INFOCOM, Online learning in opportunistic spectrum access: a restless bandit approach (IEEE,
Shanghai, China, 2011)

52. H.Liu, K. Liu, Q. Zhao, Learning in a changing world: restless multiarmed bandit with unknown dynamics. IEEE Trans.
Inf. Theory. 59(3), 1902-1916 (2013)

53. X. Chen, Z. Zhao, H. Zhang, Stochastic power adaptation with multiagent reinforcement learning for cognitive
wireless mesh networks. IEEE Trans. Mob. Comput. 12(11), 2155-2166 (2013)

54. W.Hoeffding, Probability inequalities for sums of bounded random variables. J. Am. Stat. Assoc. 58(301), 13-30 (1963)

55. A. Cauchy, Surla Convergence des Séries, Oeuvres completes Ser. 2, 7, Gauthier-Villars, (1889), pp. 267-279

56. M.Bona, A walk through combinatorics: an introduction to enumeration and graph theory, 2nd edn. (World Scientific
Publishing Company, London, 2006)

Publisher’s Note

Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.
