Lépez et al. EPJ Data Science

https://doi.org/10.1140/epjds/s13688-020-00251-w

EP] °'s

REGULAR ARTICLE Open Access

A network theory of inter-firm labor flows

© EPJ Data Science

a SpringerOpen Journal

(2020) 9:33

Check for
updates

 

Eduardo Lopez'*’@, Omar A. Guerrero** and Robert L. Axtell!

 

“Correspondence:
elopez22@gmu.edu

'Department of Computational and
Data Sciences, George Mason
University, 4400 University Drive, MS
6A2, Fairfax, VA, USA

*Green Templeton College,
University of Oxford, 43 Woodstock
Rd, OX2 6HG, Oxford, UK

Full list of author information is
available at the end of the article

Y) Springer

Abstract

Using detailed administrative microdata for two countries, we build a modeling
framework that yields new explanations for the origin of firm sizes, the firm
contributions to unemployment, and the job-to-job mobility of workers between
firms. Firms are organized as nodes in networks where connections represent low
mobility barriers for workers. These labor flow networks are determined empirically,
and serve as the substrate in which workers transition between jobs. We show that
highly skewed firm size distributions are predicted from the connectivity of firms.
Further, our model permits the reconceptualization of unemployment as a local
network phenomenon related to both a notion of firm-specific unemployment and
the network vicinity of each firm. We find that firm-specific unemployment has a
highly skewed distribution. In coupling the study of job mobility and firm dynamics
the model provides a new analytical tool for industrial organization and makes it
possible to synthesize more targeted policies managing job mobility.

Keywords: Micro to macro models; Firm-size distribution; Employee mobility; Labor
flow networks

 

1 Introduction

The explanation of macro-phenomena on the basis of microscopic rules is a classic prob-
lem in social, economic and natural sciences [1]. Theoretical frameworks such as analyti-
cal sociology [2], economic microfoundations [3], and agent-based-modelling [4, 5] have
emerged to address the need to connect the known rules of behavior at the individual level,
along with interactions between those individuals, and the characteristics of the macro-
behavior these rules generate. A distinctive element of micro to macro studies is their abil-
ity to address system heterogeneity [6, 7] where agent-based modelling (computational or
otherwise) is especially useful due to its flexibility.

In the context of employment, the micro to macro problem is also present. However, its
study has mostly been done through fundamentally macro-level approaches [8, 9] at the
exclusion of much underlying micro-behavior. These approaches have utilized aggregation
as one of their pillars, eliminating the numerous non-trivial and potentially dominant ef-
fects played by the ecology of heterogeneous employers, the firms [10, 11]. Most of the
approaches that do incorporate some of the heterogeneity in the system [12, 13] do so by
sectorizing the economy and coarsening the firm-level view (recent notable exceptions

are [14-16] that incorporate firms).

© The Author(s) 2020. This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use,
sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original
author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other
third party material in this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line
to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by
statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a
copy of this licence, visit http://creativecommons.org/licenses/by/4.0/.
Lopez et al. EPJ Data Science (2020) 9:33 Page 2 of 41

Recently, through the use of microdata, the study of inter-firm networks of job-to-job
mobility [14, 17, 18] (the phenomenon of an individual separating from one firm, poten-
tially spending some unemployment time, and eventually reaching another firm) suggests
that there is a rich set of phenomena taking place at the micro-level of the system that
couples employers (firms) and their workers. Neither work on firm dynamics, nor work
on employment had been able to identify or characterize such phenomena. Development
of a new disaggregate model of the behavior of the firm-employee joint system, disciplined
by microdata, is our main goal here.

Guided by micro-level empirical observations of the behavior of workers (which we also
call agents) and the firms in which they work, we develop a model of job-to-job mobil-
ity that successfully establishes the micro-to-macro connection, empirically grounded at
both levels. Our model is designed to understand the dynamics of agents in the firm land-
scape of large socioeconomic systems, and accurately predict large scale system behavior.
We base our work on high resolution, extensive firm-employee matched records in two
separate countries (Finland and Mexico), with data spanning large numbers of workers,
firms, and multiple decades. The model we introduce is consistent with known key micro
and macro-level regularities of the problem.

One of the main features of our model is that agents move between jobs inside an empir-
ically constructed network of firms [14, 19]. This inter-firm network, acts as the substrate
for workforce mobility. With this framework, we achieve some important results. First, we
find that firm-size distributions are synthesized in the combination of the connectivity of
firms in the firm network and the steady state movements of agents in the network. Fur-
thermore, we propose a new notion of firm-specific unemployment, an intermediate state
of agents between employment spells that offers a disaggregate picture of job-to-job mo-
bility at the level of individual firms, and how each firm may contribute to unemployment.
The use of a high resolution model to deal with job-to-job mobility is in itself an advance
because it moves away from aggregate approaches to deal with the problem; aggregation
destroys information about local effects like the specific dynamics of agent movements
between close-neighbor firms in the network. Finally, our approach leads to the possibil-
ity to connect two areas of study that have traditionally been separate: job-to-job mobility
and distribution of firm sizes.

We believe our framework has the great virtue of being applicable to a wide spectrum of
situations, from calibrated models of true behavior, to idealized situations of academic or
exploratory value. The reason for this flexibility is that the model captures and isolates the
main ingredients of movement dynamics of workers and employers. These ingredients are:
1) the firm environment, where individuals travel as they change jobs, and 2) the rules of
movement and behavior that individuals and firms satisfy. In this article, we choose those
ingredients with enough realism to allow us to show proof of principle, i.e., to reproduce
some important known facts about firms and worker dynamics at the best resolutions
yet studied. However, the framework can be deployed with different environments and
behavior to address many useful scenarios such as the potential consequences of policy
interventions or the construction of baseline statistical models, to name a few.

It is important to emphasize that the dynamics that emerge from the coupled firm-
employee system are of great practical interest. These dynamics have received atten-
tion in labour studies [8, 9], firm dynamics [20—23], and employment mobility [24, 25].
Usually, this research is parcelled into two separate problems: employment [8, 26] and
Lopez et al. EPJ Data Science (2020) 9:33 Page 3 of 41

firms [23, 27, 28]. Such division reflects the absence of a theoretical framework capable
of coupling them together. This division is mainly rooted on modelling choices. On one
hand, employment models are often fully aggregate or very course-grained, eliminating
the role of firm heterogeneity and the structure of job-to-job mobility. On the other, mod-
els of firm dynamics do not consider the reallocation of workers, discarding employment
trajectories (e.g., Gibrat’s law [29-31] focuses on the firm abstracted from its workers).
Our model connects the labor mobility and firm dynamics literature, providing an inte-
grated framework. Since our model is disaggregate and constructed to match data, it can
serve as the starting point for more detailed work on dynamical aspects of employment
and firms. Such work may be particularly useful to inform policy (specific measures with
specific targets), provide better analysis of economic scenarios, and develop better fore-

casting frameworks.

2 Labor flow network

Evidence suggests that a worker’s transition from a firm (i) to another firm (j) increases
the probability of observing one or more subsequent worker transitions between the same
firms i and j [18]. Such firm-to-firm transitions are the result of a confluence of factors
(geography, social ties, skills, industry types, etc.) that affect choices made by individuals
when navigating the employment landscape, and of firms when deciding to hire workers.
Considerable research has been directed at the social ties factor [32—34] which has shown
to be relevant but still constitutes just one out of numerous factors that play a large, if not
larger roles.

A more data-driven and simultaneously disaggregate approach has been taken by Guer-
rero and Axtell [14] who proposed to represent firm-to-firm transitions with the use of a
so-called labor flow network (LFN), where firms (nodes) are connected to one another if a
job-to-job transition has been observed between them. Using administrative records from
Finland and Mexico (see Sect. A.1), the authors constructed empirical networks, studied
their structural properties, and found a highly heterogeneous firm environment with in-
teresting regularities in the flow of workers such as virtually balanced flows in and out of
individual firms. The advantage of the approach in Ref. [14] is that it takes into account all
transitions regardless of their driving mechanism.

Our approach is to directly tackle the problem of modeling job-to-job transitions on
the basis of empirically justified mechanisms, using as a starting point the evidence that
previous job-to-job transitions may be predictive of new ones in the future, and that this
justifies the use of inter-firm networks as part of the modeling framework for this problem.
We model an agents-and-firms system by establishing: i) the LFN in which agents move
on the basis of data, ii) a set of basic rules of how agents choose to navigate this network,
and iii) how firms deal with the inflow and outflow of agents. In this section we focus on
i), while ii) and iii) are developed in the next section.

Given available data for firms and agents, one would like to determine those persistent
firm-to-firm transitions that, collected together as a set of edges interconnecting firms,
constitute the substrate for a considerable fraction of the steady flow of the workforce.
Intuitively, there is reason to believe in such a network (e.g., medical professionals move
between hospitals, auto-technicians between car repair shops, the unemployed are more

likely to search for a job where they live rather than far away, etc.), notions also captured
Lépez et al. EPJ Data Science (2020) 9:33 Page 4 of 41

in work such as [13, 35]. Note that persistent transitions justify the use of labor flow net-
works. If transitions were a consequence of simple random events with no repeated tran-
sitions other than by chance, then there would be no need for a network: a transition from
one node would simply be a random jump to any other node (this is a view consistently
presented in current literature on aggregate studies in labor economics [8]). Transitions
for which one cannot build evidence that they will occur again in the future are labelled
random.

To understand persistent transitions and their consequences better, we proceed as fol-

lows.

2.1 Testing flow persistence between firms

The work by Collet and Hedstr6m [18] focused on virtually comprehensive data for Stock-
holm found that the probability that two firms i and j experience new worker transitions
between them after having had at least one prior transition is approximately 1027 times
larger than transitions between any two random firms in the same system. The implication
of this is that observing one transition between firms is a strong indicator of future tran-
sitions and thus, a strong suggestion that worker movements can be reliably modelled by
introducing links between firms that exhibit certain flow amounts between them. In this
article, we perform three’ related tests (the last one is mainly contained in Sect. A.3.3) to
confirm that employee transitions between firms have the same temporal predictability
reported in Ref. [18]. Two of our tests are designed to adjust for firm sizes (an improve-
ment over the methods in [18]); our results support the notion that past transitions are
predictive of future ones.

We focus on the Finnish data. Consider worker flows in a window of time of 2At¢ years
centered around a given year t. Loosely speaking, we want to test for every pair of firms
with flows in the first At years, from t — At + 1 to ¢, if they also tend to have flows in the
second At years from ft + 1 to t+ At, above what would be expected from chance. We label
the two time periods of size At before and after t as 7. = [t— At+1,t] and J, = [t+1,t+ At].
To be specific, we define f(t) as the number of individuals changing jobs from firm i to
firm j in year t, F(t) = fj(¢) + fi(t) the total undirected flow between i andj int, Fi(t, At) =
Yo iet Apel F;(t') the total flow between a pair ij during 7., and F(t, At) = my F,(t') the
flow between ij during 7,. Let us introduce an arbitrary threshold W for Fj such that, if
the pair of nodes i andj satisfy it (Fj; > VW), we check if the pair ij has flow Fi > 0. In other
words, we require a minimum flow amount YW to track a pair of nodes from 7. during 73.
We then test how informative the value of WV is when trying to forecast which node pairs
have flow in 7,. If W successfully helps forecast active node pairs in the future, then we
can treat WV as an acceptance criterion for adding a link between i and j, thus generating a
labor flow network.

To determine if the criterion is useful, we define several quantities. First, we cap-
ture the set of flows €(t, At, W) = {(i/)|Fi(t, At) > W}, ie. the pairs of nodes during 7.
that achieve threshold WV. Together with these node pairs, we collect the unique nodes
N(t, At, W) = {q\(q=iV g=j) A (ij) € E(t, At, W)}, that is, all the nodes that take part in
any of the node pairs in E(t, At, W). We also define a set E(t, At, 1) = {(if)|Fi(t, At) > 1},
the node pairs that have at least one flow event during 7,. Associated with this, we de-
fine V(t, At, W = 1) = {q\(q=ivag =f) A (ij) € E(t, At, 1)}, the nodes that take part in
E(t, At, 1). Since the nodes in M(t, At, W) or in N(t, At, 1) may not all be present through
Lopez et al. EPJ Data Science (2020) 9:33 Page 5 of 41

 

(— \
Raw flows Ew O Raw flows 2’, 1 _
Nodes involved Ny © Nodes involved N 1

\ O
O O
O
Threshold oO Common Threshold
flows ,hodes _ flows
on common Ny =Ny AN, on common
nodes nodes
oO Overlapping a
7 * 5 ?
ew flows _ é
| E\ ‘

 

/——— ar ——_+———- st ———]

t-At+] T. f T, t+At

 

Figure 1 Illustration of the various sets defined to determine flow persistence and the usefulness of the
threshold W. From the data for flows in the time period Jz = [t- At+ 1,t], we identify those node pairs with a
flow equal or exceeding W (width of lines represents flow amounts) and construct a set Ey whose elements
are those pairs. Similarly, in the time period 7s = [t+ 1,t+ At] we identify node pairs with flow and build the
set of pairs €;. The set of nodes present in the pairs Eyy is Mwy, and the set of those present in € is Nj. The
common nodes (in red) are Nyy =Nw AN;. The node pairs of Ey and E, that involve exclusively the
nodes Wyj, are, respectively, Ey,, and EF. The intersection (in blue) EY, 1 EF is the set of node pairs both in
Ey, and EF. Our statistical model tests whether the observed |E}), M EF| is larger than expected from chance
N J

 

 

the entirety of the time period between ¢ — At + 1 and t + At, we also define the inter-
section \V*(t, At, W) = N(t, At, W) A Nt, AG 1), composed of nodes that are present in
both E(t, At, W) and E(t, At, 1), and also the sets €*(t, At, W) and E*(t, At, 1) which are,
respectively, the subsets of E(t, At, W) and E(t, At, 1) that only include node pairs where
both nodes are in N’*(t, At, W). This guarantees that comparisons between flows before
and after year ¢t are well defined. To avoid cumbersome notation, from here we use the
shortened notation €},, = €*(t, At, W), ot = €*(t, At,1), and Nyy = N*(t, At, W) (an il-
lustrative diagram of the process can be found in Fig. 1).

If the information of which pairs “are connected” in €}), allows us to predict to some
extend the flows in €*, then it means that the criterion used to create Ey is informative.
To test if there is a relationship between €),, and E*, we determine the number of firm-
pair flows in the period 7, that were also firm-pair flows (> W) in the years 7_; to obtain

a fraction, we divide the number by |€},,|. This produces the density g(t), defined as

EX NEF
ew(t, At) = lew OFT (1)
Ey |

The denominator counts the opportunities for a node pair that satisfies the flow threshold
during 7. to also have flow subsequently; the numerator counts how many times the op-
portunities are actually realized. Note that if the fraction took the value of 1 it would mean
that all pairs that had flows of magnitude > W up to year ¢ also had flows after year tf; if the
value were 0, it would mean that none of the pairs with flows > VV up to year ¢ had flows
after that year. Crucially (establishing a null model, developed in detail in Sect. A.3.1), if

the flows captured in €},, provided no relevant information about the flows captured in
Lopez et al. EPJ Data Science (2020) 9:33 Page 6 of 41

 

 

0
10 F-
E SST FE OR a
F Of SSS SEN
p *

Ww

   

—
2,
N
TT TTTTT
|

Probabilities

—
2,

w

| TTTTTT

 

 

 

10 —

 

1990 1995~~SSCS 000008
Year

Figure 2 The densities go(t, At) and gow (t, At) with the following color and symbol code: black without

symbols represents At = 2, red with + represents At = 3, green with * represents At = 4, blue with x

represents At = 5; (—) lines represent W = 1, (- - -—) lines represent W = 2, (- — —) lines represent W = 3;

thin lines represent go(t, At), and thick lines represent soy (t, At). The brackets signal the location of ga(t, At)

and gow (t, At) in the plot

 

 

E*(t, At, 1), one would expect goyy(t, At) to be the same as

Ex
p(t, At) = ay (2)
2

the density of node pairs with a flow of at least 1 during 7,. The numerator in Eq. (2) counts

 

the number of node pairs with flow and the denominator the total number of possible node
pairs (this equation is the usual link density equation of a network). An intuitive way to
understand why go and soy should be the same when the flows before and after ¢ are not
related is to note that by pure chance the expectation (|E},, E*|) of the number of times
a node pair in €},, is also in Ex is given by |€),,|, i.e. the number of trials |E},,| of finding
a connection times the success rate 9; if we insert this expectation into the numerator of
Eq. (1), we confirm our claim. In fact, the null model is described by a hypergeometric
distribution for which go is the expected value for soy (in Sect. A.3.1 we explain this and
estimate the p-value which confirms the significance of our threshold test). If the flows

yw are indicative of the flows EX, we expect soy > go. To test this, we calculate the excess

probability xy, given by the ratio

_ §9W (t, At)

that highlights any potential increase of soy over g.

We compute go(t, Af), pw(t, At), and x(t, At) for a combination of years ¢ and time
windows At to get a comprehensive picture of the situation (see Sect. A.1 for details on
data). Note that the size of the time window At impacts the range of years used: since the
earliest dataset is for 1988 and the latest for 2007, then a window of time At means the
years of analysis are 1987 + At < t < 2007 — At. In Fig. 2 we present results for thresholds
W = 1,2,3, and for time windows At = 2,3, 4,5 (additional analysis and robustness checks

are shown in Sect. A.7). Clearly, soy >> # by orders of magnitude across all combinations
Lépez et al. EPJ Data Science

 

 

 

 

 

 

 

 

 

(2020) 9:33
( >)
l
— W=1
--+ W=2
-- W=3
z
Oo
° cemeee
6. ™ x wwor™. eT tes
a N 7 ~ \ “
oO oc7N ~.eee , 7
Q ee NS \
nO - _
SY a cots -
SLY SO? ~\ ne
N 7
\/
10° ! | ! | ! | L |
1990 1995 2000 2005
Year
Figure 3 Excess probability xy for W=1 (—), W=2 (-- -), and W =3 (- - -)
L J

 

 

 

of W, At. This is because the observed values of |E},, E*| are indeed also orders of mag-
nitude larger than their expectations (|E€),, E*|) = pl|E;,,| (see Table 3). The size of the
time window At does not have a pronounced effect on any of the probabilities, although so
seems slightly more sensitive to it than soy. On the other hand, W increases all the prob-
abilities in the plot. More importantly, specifically for gy we can see that as W increases
from 1 to 3, the likelihoods of any of the flows in €},, to also appear in E* increase from
over (gy *) 10% to around (gy ~) 50-60% and in some years even more.?

The excess probabilities for some of the previous curves are presented next, restricted
only to At = 2 given the minor impact of At on the results, but including the thresholds
W = 1,2,3 (see Fig. 3). For W = 1, the excess probability is largest, which means that the
first flow event generates the greatest fractional increase between g9 and gow (an increase
of more than 10°, the same order of magnitude as in [18]). The threshold W = 2 has an
excess probability in the 400 to 500 range. Threshold W = 3 has excess probabilities in the
range of 150 to 350. The decrease of the, still considerably large, excess probabilities xy
with W is a consequence of the saturation effect that gy undergoes (as it approaches 1
with increasing YV) in comparison to the unsaturated evolution of 9 with W.

To improve on the previous test, we present a modification that addresses the hetero-
geneity of firm sizes. Concretely, note that if flow occurs between two large firms within
the time interval 7., then just by random chance the likelihood that another flow event
occurs between these firms in the interval 7, should be larger than when the same situ-
ation occurs between two small firms. Thus, one could wonder if oy >> ~ might break
down due to the firm-size heterogeneity.

The modification we introduce concerns a change to the null model. In the previous
test, the null model predicts that soy should approach the value of g9, but is instead found
to be orders of magnitude larger. That test rests on the assumption that any of the flows
in €* are equally likely to occur among any pair of nodes in \%,, despite the differences
in those nodes.

The new null model is constructed via Monte Carlo by randomizing the flows contained
in €* among the nodes i € NV. yw with each node i preserving its observed in- and out-flows.
For each random rewiring of €* we obtain a set of simulated flows S*, and determine the
size |ES\, S*| of their overlap with the flows for the period 7.. For M realizations, we can
calculate an expectation value (|Ej,, S*|) He) where HF stands for heterogeneous firms.

Page 7 of 41
Lopez et al. EPJ Data Science (2020) 9:33 Page 8 of 41

 

 

Probabilities and excess

 

 

 

 

102 ! | ! | ! | L |
1985 1990 1995 2000 2005
Year

Figure 4 The densities go“ (t, At), goyy(t, At) and the excess probability xe (t, At), where At = 2 with the
following symbol code: (—) lines represent W = 1, (— - -—-) lines represent W = 2, (— — —-) lines represent
W = 3; thin lines represent go) (t, At), thick lines represent goyy(t, At), and thick lines with o represent
S(t, At). The brackets signal the location of go(t, At), fow(t, Ad), and x(t, At) in the plot. The plot has
been constructed with M = 104 simulations

 

 

In a similar way to the previous test, we compare sow against the average density

EX S*
o" =(9(t, AD). = (NEw Deir (4)
Ey |

x(AP) = Oyy)/o'#). The results are shown in Fig. 4. In a

as well as the excess probability
similar way to the previous test, we find that gy > eo"), The excess probability a has
values that roughly correspond to a factor of 10, not as large as xy but still significant;
the fact that a)

Additional considerations, including a discussion of p-values can be found in Sect. A.3.2.

< xy provides an a posteriori justification for the need for this new test.

Asa final check, we present in Sect. A.3.3 an additional test that focuses on the amount of
flow predicted by our threshold method in comparison with the heterogeneous firm null
model. We find that the node pairs identified by the threshold method carry anywhere
from about 30% to as much as 70% of the overall flow in the network depending on the
specific t. The flows carried by the node pairs emerging from the null model consistently
carry about a tenth of this flow.

Summarizing the results of the previous three tests, it is clear that the use of a threshold
W identifies flows that persist into the future, and carry a very large fraction of the overall
flow of the system. Furthermore, the likelihood that these flows are seen again increases
monotonically with W. For W = 2, we already find that the likelihood of a pair of nodes
having repeated flows is around (goyw-2 *) 40%. As we argue in Sect. A.7, the qualitative
results of our analyses do not change by increasing this parameter, and therefore, in the
main article we present results with WV = 2 which balances size of the sample with a sig-
nificant certainty that flows are persistent.

2.2 Assembling the labor flow network

We construct the LFN G for a given dataset (Finland or Mexico) by assembling all N firms
together with the edges that are found to be persistent according to the criterion above.
The network is unweighted and undirected, characterized by the symmetric adjacency
matrix A of dimension N x N, with Aj = Aj; = 1ifiandj are connected and zero otherwise.
Lopez et al. EPJ Data Science (2020) 9:33 Page 9 of 41

In order to make better use of the data, we construct a network on the basis of the entire
time frame for each dataset (20 years for Finland, and just over 29 years for Mexico). This
is supported by results in Sect. A.8, specially those associated with Fig. 24. The LFNs built
by this procedure (W = 2) are found to carry a large portion of the job-to-job transitions:
in Finland © 60.33% out of the total of 1,808,412 transitions observed, and in Mexico,
~ 33.7% out of the total of 624,880 transitions. Extending the criterion to include edges
where transitions occur 3 times or more (YW = 3), the number of transitions captured is
still high, with © 51.17% for Finland, and © 24.8% for Mexico.

The network that results from this procedure is characterized by a skew distributions
of degree k; (number of neighbors of i), total transitions through each node 7; (typically
called node strength in the networks literature), and link weights Fj. Beyond the non-
trivial nature of the distributions, it is worth mentioning that each of the quantities is
necessary for a full description of the network: for instance, it is not enough to know the
strength of a node t (or even its directed versions t), t°“”) in order to know k. This is
important to realize as it indicates that the network structure or the results we describe
later do not emerge directly from a single mechanism such as labor supply (which would
imply that t statistically describes k). The distributions, along with a lengthy discussion
of their interpretation, are shown in the Appendix, Sect. A.4.

As a final point in this section, let us discuss the unweighted undirected nature of G.
Qualitatively, LFNs are defined to reflect the presence (or absence when there is no edge)
of employment “affinity” between two firms, necessary for firm-to-firm transitions. This
approach captures the notion of a categorical relationship between firms [36]. Considering
the limited microscopic data available, this is the most unbiased choice we can make when
modelling observed persistent transitions between firms. If the choice is sound, the model
should be able to accurately reproduce observations, as we confirm in this article. The
choice of considering an edge as a categorical relationship also leads to the undirected
assumption, as there is no a priori reason to discard transitions in either direction, and

since the weights are all equal, there is no need to have directed edges.

3 Modelling firms and individuals
Having established that LFNs capture a large number of job-to-job transitions, we proceed
to model agents navigating these networks.

Given that the specific choices made by agents travelling in the LFN are likely to be
partially driven by chance, we introduce a discrete time stochastic model that encodes
the behavior of agents and firms in the network.‘ The rules of the model are given by the
following:

1. Agents: These can have two states, employed or unemployed. At the start of the time

step, an employed agent remains in its firm, say i, with probability 1 — A;, and leaves

(or separates) with probability 4;. An unemployed agent at the start of the time step

first determines whether neighbors of firm i are accepting applications and, if any of
them are, chooses one of them to apply to with uniform probability.

2. Firms: At the start of the time step, firms make a choice to receive applications with
probability v; or not receive them with probability 1 — v,. If firms choose to receive
applicants, then each is accepted with a probability ;.

The set of neighbors of i is denoted by I’;, and has size k; = |I’;|, the degree of i. A specific
subset of neighbors of node i receiving applicants in a given time step is denoted by },,
Lopez et al. EPJ Data Science (2020) 9:33 Page 10 of 41

and this can change from step to step. In this time step, the number of open neighbors is
|y;|. Our calculation contains terms for configurations for which we condition y; to have
neighbor j open, and in those cases the configuration is denoted by y. The occurrence
of configuration y; is a random event with probability Pr(y;) = I Tey, vit eer,\(y;y — Vp).
We also find it useful to define the average hiring rate (h),, = ier; h;/|y;| of neighbors of
i given yj.

To track the state of the system, we define the probabilities r(i, t) and s(i, t) that an agent
is, respectively, employed or unemployed at node i at time t. These two probabilities, ex-

plained in detail below, satisfy the equations

r(i,t) = (1-4) “Deh sGe-1 rs

(i)
= Pr(y;") (5)
Yj

and

s(i,t) = A;r(i,t — 1)

s(t-1 Pro Da h;) + Pr(y; -0)} (6)

{yi 7B} JEYi

The first equation states that the probability for an agent to be employed at node i at time
t is given by the probability to be employed at node i at time ¢ — 1 and to not separate, plus
the probability that the agent is unemployed at one of the neighbors of i, that i is accepting
applications, that the agent chooses to apply to i, and that the application by the agent leads
to being hired. The second equation states that the probability to be unemployed at i at
time ¢ is given by the probability to be employed at i at time ¢ — 1 and be separated, or
to have been unemployed at time ¢ — 1 at i but not find a job among the neighbors of i,
either because none of them are receiving applications, or because the agent chooses to
apply to one of the neighbors and is not hired. Note that the brackets in Eq. (6) simplify to
LY pyigu U4) Pr).

The rules and equations above (Eqs. (5) and (6)) give rise to a Markov chain, where
workers act independently of one another, and the model parameters are static in time.
We assume that the parameters /;; and v; are independent of k;, and that 0 < hj, v; < 1. With
these assumptions, and by calibrating from data the remaining model parameters, namely
k; and A;, we show below that the model reproduces key empirical observations. To explore
the model, we now present an analysis of its steady state for the cases of heterogeneous v;
(each firm has its on value of v) and homogeneous v; = v (constant v).

In the steady state, the conditions r(i,t) — r(i,t - 1) = 0 and s(i,t) — s(i,t — 1) = 0 are

satisfied. Using the notation r(i,t) > roo(i) and s(i, £) > so(i) we find

1
0 = ~Airooli) + hid) Sool) )) a Pr(y;”): (7)
jel my |
0 = AiFrool(i) — Scot) D> (hy, Priv), (8)

{vi7D}
Lopez et al. EPJ Data Science (2020) 9:33 Page 11 of 41

which, when solved for r..(i), lead to the matrix equation
AX =0, (9)
where A is an N x N matrix given by

hi D0) Pry yj"

A, := Aj
’ ’ Diy) (h)y Pr(y)

— dl J], (10)

and X and 0 are column matrices of size N x 1 with X; = A,;r..(i) and 0; = 0, and 6[i,j] is
the Kronecker delta. To determine s,,(i) one can either construct a similar expression to
Eq. (9) or solve for X and then apply Eq. (8).

A unique solution? to Eq. (9) can be obtained upon introduction of the normalization
condition 1 = }),[r(i,t) + s(i,t)] = >0,[roo(i) + Soo(i)] (details in Sect. A.6). For the general
case where for each i the parameters v;, A; and h; have different values, there is no simple
closed form solution. However, for the simpler case v; = v, the probability Pr(y;) simplifies
to vivl(1 — v)S-l”l, making the matrix elements Aj take the form Ajhj/(kj(A)r,) — |i Jl,

leading to
7) (i) = Xhihhe) rik (1)
hi
sM (i) = a (12)
x Sachtnkle +1 us)

(hp, 1-(-v) i]

The expression for s®)(i) can be rewritten by noting that the agent unemployed at i has
the same probability €; for any time step to find a job among its neighbors, given by &; =
(1)r,[1 - (1 - v)X], This is because the likelihood that at least one of the I; neighbors is
open is 1 — (1 — v) for all time steps, and over configurations, the effective probability to
be hired at any of them is (1) ,. With this result

song) = AA (14)
é

The rates A; and &; play similar roles for employment and unemployment, respectively.
An agent has a probability 4;(1 — 4;)*" to be employed at i for ¢ time steps, and similarly a
probability &;(1 — &;)’"! to be unemployed t¢ time steps at i. These are geometric distribu-
tions, for which the average times of employment (job tenure) and unemployment (spells)
are, respectively, 1/A; and 1/é;. Fortunately, in data sets where the span of time spent un-
employed is available (such as for the Mexican data we utilize here), €; can be empirically
estimated (together with k; and 4;), adding important practical value to this new param-
eter. As we explain below, &; plays an important role when studying the unemployment

consequences of our approach.
Lopez et al. EPJ Data Science (2020) 9:33 Page 12 of 41

If the system has H agents, the steady state probabilities for the numbers of employed
(L;) and unemployed (U;) agents at firm i can then be computed via

Pr(Li) = (7 ) [rool ]""[1 = rool] (15)
and
Pr(Uii) = (7; ) [Soo(i)]" [1 = Soli) J. (16)

These expressions are broadly useful because they are always valid in the steady state.
Thus, even if r..(i) and s..(i) cannot be determined analytically but, say, numerically, their
values can be used directly to determine Pr(Z;) and Pr(li;).

One other important concept arises from this derivation: the quantity U; can be inter-
preted as a firm-specific unemployment, which corresponds to the number of individuals
that had i as their last employer but that are yet to find new employment. This notion
is a powerful one, as it captures the essential nature of the network effect on mobility: if
firm neighbors are not receiving new agents (probability 1 — v), there is no place for the
unemployed from i to go.

To illustrate some possible circumstances in which U; can be useful we now discuss
three scenarios. These represent examples of how the network introduces local effects to
job markets, which cannot be captured in aggregate models, and can only be understood
through firm-specific notions like those defined here. First, consider that there are regions
of the LFN in which links are present because the connected firms hire similar individuals,
and thus agents in one firm can more easily change jobs by going to the other firms in
the same region of the network. This is a common situation and in numerous cases the
regions of the network are rather cohesive (composed, say, of firms in the same or adjacent
industrial sectors). This means that nodes in that region of the network are likely to react
in similar ways to economic shocks. Therefore, if the firms in this region begin to lay off
workers, they will quickly flood the local network neighborhood with job-seekers, most
of which would have a hard time finding work. In addition to this, there would be nodes
adjacent to the affected network region that would soon feel the effects of the employment
shock by being flooded with new job seekers. In contrast, nodes in distant regions of the
economy would feel a much more attenuated effect in a considerably longer time frame.
In this shock scenario, the specific initial nodes affected, their unemployment values Uj,
and the structure of the local network play significant roles.

There are other scenarios that can take place where U; is informative. For example, in
some cases links may be present due to differences in nodes rather than similarities (in two
firms that react in opposite ways to an economic shock, for instance, one firm can become
an alternative destinations for the workforce of the other firm). Knowing firm-specific
unemployment for the neighboring nodes could be used to measure how anticorrelated
their reactions are to economic shocks.

One more example is related to the steady state behavior of U; for any given firm. Note
that firms that have simultaneously large 4; and h; have a tendency to contribute large U/;
to the network, and thus influence their neighboring nodes with a correspondingly large
number of unemployed individuals seeking jobs, rapidly flooding their hiring capacities
and then creating local unemployment in the network.
Lopez et al. EPJ Data Science (2020) 9:33 Page 13 of 41

It is important to note that many individuals perform job searches while still employed.
Therefore, to assume as we do that an agent must first separate from a job before looking
for another job is an idiosyncratic choice. However, performing a job search while still
employed is not fundamentally different from our approach since the individual still has
to seek jobs with similar rules among firm neighbors, and thus the results of the Markov
process are not qualitatively different, with the caveat that additional parameters are re-
quired to model the more nuanced case. Fortunately, as we see in our empirical analysis
below, our current model assumptions seem to be effective in practice.

Note the versatility of our approach: since the equations are fully disaggregate, it is al-
ways possible to construct coarse-grained versions of the problem that can range from
partially to fully aggregate. For instance, one known improvement over fully aggregate la-
bor models are sectoral specialization models [12], which segment the labor market into
submarkets each with its own set of shared employment mechanisms and parameters (also
called matching technologies). In this context, one can picture the economy as constituted
by an aggregation of several sectors (say, healthcare, technology, etc.) which have internal
and external employment dynamics. In our model, this partial aggregation can be effi-
ciently tackled by fully connecting all firms in a given sector and also adding links from
each of these firms to all other firms in all other sectors of the economy. On the basis of the
equations above, all firms ofa given sector behave identically, effectively becoming a single
representative firm. Representative firms connect to all other representative firms in the
economy with appropriate weights (possibly adjusted on the basis of survey data such as
the Job Openings and Labor Turnover Survey from the US Bureau of Labor Statistics). The
result of applying our methods directly to the disaggregate description while introducing
sectorized information or, alternatively, creating from scratch a reduced economy made
of only representative firms are equivalent, and it is a matter of choice which approach to
take, or even how to decide what firms are assigned to what sectors.

4 Empirical tests and results of the model

Armed with tools to determine the labor flow network as well as rules to model the be-
havior of agents, we now proceed to test the quality of our model. First, we focus on de-
termining whether the system can be reliably modeled in the steady state. After that, we
contrast the predictions emerging from the model with data from Finland and Mexico .°
As we see below, the data and the model are consistent.

4.1 Testing the steady state assumption

In the previous section, we have constructed solutions for the steady state. In order to
determine if such solutions are representative of typical economic situations, we check
whether the number of individuals entering and exiting a node approximately match one
another. In Fig. 5 we present the distribution of net flow at a node.

It is clear from our results that indeed firms typically operate around a steady state where
the number of workers entering and leaving a firm approximately balance out. This pro-
vides empirical validity at the micro-level. For further support, in the Appendix we present
several other tests that highlight the steady state nature of the system (see Sect. A.8).

4.2 Firm sizes
Data available to explore the dynamics of the firm-employee system do not contain infor-
mation about {v;};-1,.,.n or {h;};=1,...v- However, data is available to estimate the values of
Lépez et al. EPJ Data Science (2020) 9:33 Page 14 of 41

 

 

— Finland
— Mexico

 

 

 

Prob. node inflow - outflow

 

 

 

 

2x10" -1x10° 0 1x10" 2x10"
Node inflow - outflow

Figure 5 Distribution of the difference between flow of workers into and out of a firm. In this plot, there are
over 49,000 firms for Mexico and close to 300,000 firms for Finland

 

 

X

i;. For Finland, this is done by calculating the ratio of agents leaving a firm with respect to
the size of the firm. A value of 4; is created for every year of the sample, and then all the
values for a given firm are averaged over those yearly samples.

To deal with the absence of information for h;, v;, we concentrate on comparing the data
with the homogeneous v; = v version of our model in the hope that, if some of the main
qualitative features of the system have been properly captured, we could find a reasonable
level of agreement between data and prediction.

We now proceed to test the homogeneous model with v; = v (a constant) for all i. How-
ever, we retain the freedom for each firm i to have its own independent acceptance rate h;
in order to conform with experience (there are more selective and less selective firms in
terms of hiring). Focusing first on the sizes of firms, we make use of Eqs. (11) and (15) to
find that the most probable (or mode) firm size L? is

Ay hth) p,k;

Li = |(H + 1)r@)|

(17)
This is a model prediction. One possible check for our model against the available data is
to determine whether the measured L* and k;/A; relate as predicted by Eq. (17), assum-
ing independence among the variables h;, k;, and 4;. Furthermore, we can also study the
distribution Pr(L;|k;/A;) to develop a broader picture.

To simultaneously learn about Pr(Z;|kj/A;) and L7, we use the Finnish data to generate
Fig. 6, a 3-dimensional plot of log, [Pr(Zi|ki/A;)/ Pr(L7|ki/A;)] as a function of log,) Z; and
log io (Ki/A;), where each L; is the size of a Finnish firm, k; its degree based on repeated ob-
served transitions, and A; its separation rate estimated over the years of data as explained
above. Here, Pr(L*|k;/A;) is the probability associated with the conditional mode L*. For a
given k;/A;, the logarithm of the ratio Pr(Z;|kj/A;)/ Pr(L7|kj/Ai) becomes 0 when L; = L¥, and
is < 0 for other values of L;. To interpret the plot, we introduce a plane P parametrized
as indicated in Fig. 6, normal to the base plane log,, Lj, log,9(k;/A;) and running parallel
to its diagonal (which means it is a proportionality plane between L; and k;/A;). This nor-
mal plane also cuts the ratio log, )[Pr(Li|kj/A;)/ Pr(L7 |k;/A;)] at or very close to 0, i.e., when
L; = L;. Therefore, it means that L* from the data is proportional to k;/A;, supporting the
prediction from Eq. (17). The correspondence we observe between the data and prediction
Lopez et al. EPJ Data Science (2020) 9:33 Page 15 of 41

 

 

0

Figure 6 Behavior of log; o[Pr(Li|ki/Ai)/ Pr(L7|ki/A;)] (surface S) with respect to 1ogj9 Li and 10gjg kj/A; for
Finland. The data is logarithmically binned as follows: Lj; belongs to bin b (a non-negative integer) if

Lmin€? < Lj <Lmin€°*! with € > 1 (for this plot € = 2) and Lmin = min[{L;}] (smallest firm size in the data); kj/A,
is binned in the same way with ¢ and (k/A)min = min[{(kj/A,)}]. Blue points represent the local maximum of S
at each bin. The vertical plane P is parametrized as (kj/A;, C. kj/X;,Z) where z is a free parameter. C, is chosen
to minimize Vole —C,(k/A)p)? with the first three bins excluded because the smallest firm size is 1. The large
range within which the intersection of P and S runs parallel to the maxima of S strongly supports Eq. (17)

 

 

also supports the assumption that, on average, the parameters /; and (i), do not depend
strongly on k; or A; [15] (see Table 1 for a summary of the relation between parameters
and results).

Ifindeed k;/A; is strongly correlated to L; as indicated by the results above, we can assume

the relation

k;
Li Cy i (18)
where C, is independent of k; and A; (but still depends on the remaining model parameters
v, {h;}, x). Under this assumption, the distributions of both L; and k;/A; should be related

by the change of variables theorem, which (written in the continuous limit) yields
Pr(L,)dL; = Pr(kj/d;)d(kj/j). (19)

In Fig. 7, we show the probability distributions of both L; and k;/A; which are close to
parallel, and display a heavy tail, indeed supporting our assumption. It has been known
for a long time that Pr(Z;) satisfies Zipf’s law [20—23], which supports the notion that the
probabilities in Fig. 7 follow a power law. Employing this functional form in Eq. (19) with
decay exponent Z, i.e., Pr(k;/A;) ~ (k;/A;)*, we find

Pr(L;) ~ L;*. (20)
The value of z estimated from a least squares fit of the slope of log Pr(k;/A;) with respect

to k;/A; turns out to be © 1.97 + 0.02, consistent with the exponent of the decay of Pr(Z;)

that we measure against our data (see Table 2). Note also that this exponent is consistent
Lopez et al. EPJ Data Science (2020) 9:33 Page 16 of 41

 

 

 
    

a Pr(L,)
: @ Pr(k/X,)
10 1 1

1 1

1

Pr(L.) and Pr(k/X.)
S

 

0
L, and k IX,

Figure 7 Probability distributions of L; (red) and kj/A; (blue) for Finland binned logarithmically with 30 bins
for the range of values of both sets. For most of the range of L; and kj/A;, the two distributions are almost

parallel, supporting the validity of Eq. (19) to explain Pr(L))
X /

 

 

with the decay exponent close to —1 of the cumulative distributions of L; observed for
numerous countries [23].

This result offers a new interpretation for the origin of the power law distribution of
firm sizes [20-22]. In our picture, the collection of employment affinities, and hence con-
nectivity distribution, plays a dominant role (together with the separation rates) in the
observed distribution of firm sizes. We should emphasize that this does not equate to a
statement of causality (ultimate causes of employment affinity are structural variables such
as geography, employee skills, etc.), but rather the realization that employment affinities
are highly useful quantities with which to model because they possess a great power of
synthesis about the system behavior.

4.3 Firm-specific unemployment

The homogeneous model with v; = v also provides an estimate for our new concept of
firm-specific unemployment. This quantity can be calculated in a similar way as L?, and
it is given by

Hyh;th)_,k;
ux ~ x (A)r,

21
gi en

Although we do not have enough information in the Finnish dataset to determine the
set {&;}, we do for the Mexican dataset. From the latter, we determine the {é&;} through
maximum likelihood (see Sect. A.5). We test Eq. (21) in a similar way as Eq. (17),
through a 3-dimensional plot of log,)[Pr(Ui|ki/&;)/ Pr(U;|ki/&)] as a function of logy, Uj
and log j9(k;/&;), where U;,k;, and &; are all determined empirically for Mexico. The results
are shown in Fig. 8, and support the conclusion that LU* ~ k;/&;. For Mexico, we average
U; over the whole observation window of D = 10,612 days to obtain stable values for firm-
specific unemployment.

To better understand firm-specific unemployment, we present in Fig. 9 its probability
distribution. This is the first time this quantity is reported. Its importance revolves around
the fact that firms which have a large contribution to unemployment may constitute a ma-
jor problem for economies as a whole. In the same plot, we also display the probability
Lopez et al. EPJ Data Science (2020) 9:33 Page 17 of 41

 

 

kj
2 Logio z,

 

0
0

Figure 8 Behavior of logjg[Pr(U;|ki/&;)/ Pr(U* |k;/&;)] (surface S) with respect to logy9 U; and logjg ki/&; for
Mexico. The data is logarithmically binned as in the same way as in Fig. 6 (¢ = 2) with Umin = min[{U;} i]
(smallest firm-specific unemployment size in the data) and (k/&) min = min[{(ki/&)} 49]. Blue points represent
the local maximum of S at each bin. The vertical plane P is parametrized as (kj/&), Cyki/&,z) where z is a free
parameter. Cy is chosen to minimize }°,,(UF - Cy(k/&)p)* with the last five bins excluded at the point where
the linear relationship breaks down. The large range within which the intersection of P and S runs parallel to
the maxima of S strongly supports Eq. (21)

 

 

 

 

 

  
    

 

 

Ne S
(— \
10° T T TTTOIt T T T TTT T T TTT
@ Pr(U,)
10° mw Pr(k/,)
ws
<
& 10°
ow
a
CS
> 1-9
ZS 10
QQ.
10
10° 10° 10° 10°
U, and kJ/§,

Figure 9 Probability distributions of U; (red) and k;/&; (blue) for Mexico binned logarithmically with 30 bins for

the range of values of both sets. For most of the range of U; and k;/&;, the two distributions are almost parallel
L J

 

 

distribution of k;/&;. The parallel between the two distributions mirrors the situation with
L, and k;/d;: Eq. (21), which connects U; to k;/&;, allows explaining Pr(U;)dU; through a
change of variables so that Pr(U;)dU; = Pr(k;/&;)d(k;/&;). This plot also indicates the pres-
ence of a heavy-tail distribution for Pr(U;). Some care must be taken in interpreting Fig. 9
due to the way in which the Mexican data was collected, focusing on uniformly sampling
individuals rather than firms. This may play a role in the cross-over in slopes observed in
the distributions of both U; and k;/&;.
Lopez et al. EPJ Data Science (2020) 9:33 Page 18 of 41

 

300000
mean = 1.00 + 2e — 05

250000 L] mode = 1. 0065

200000

150000

Frequency

100000

50000

 

0.85 0.90 0.95 1.00 1.05

Figure 10 Distribution of B obtained form 1,000,000 estimations of the RANSAC algorithm, using OLS as the

underlying model
\ )

 

 

4.4 Ratio of firm separation to waiting rates
An additional test can be performed on the basis of the symmetry between Eqs. (17) and
(21). The ratio between these leads to

‘ p
hil Eb o( =) (22)
Ki

 

with a and 6 equal to 1. To determine if the prediction is matched by the data, we ap-
plied the re-sample consensus algorithm (RANSAC) [37] (see Sect. A.10) with 10° es-
timations for the Mexican data. The results can be seen in Fig. 10. The average f is
1.00000 + 2 x 10-°, while the most frequent is 1.0065. The average estimator a of the
intercept is 1.13637 +5 x 10-°. These results are quite close to the theoretical prediction
of (22).!

5 Discussion and conclusions

Detailed microdata, such as the one analyzed in this article, provides an opportunity to
construct new, highly resolved models of macro level phenomena from micro level empir-
ically justified mechanisms. In our particular case, our approach offers a picture of firms
and employment that links them together in a precise way, opening the opportunity for
an integrated theory of these two areas of research.

Our network picture of firms and employment offers the novel idea that the sizes of firms
become encoded in the number of independent connections firms have with other firms.
These connections, which reflect an economic affinity (low mobility barriers) relevant to
employment transitions, synthesize the numerous possible structural variables (skills, ge-
ography, social contacts, etc.) that an agent is affected by when searching for employment,
but because the connections are determined from the data (empirically calibrated), even
those variables that may not be traditionally tracked are taken into account.

The ability of this data-driven approach to incorporate both known and unknown mech-
anisms in the firm-employee system makes our method less prone to idiosyncrasies asso-
ciated with methods of modelling that require choosing a set of starting assumptions and
then trying to model from that point on. For instance, if one had assumed that labor supply
Lopez et al. EPJ Data Science (2020) 9:33 Page 19 of 41

was the main mechanism, the result would be that the model would not fit the data, and
thus additional assumptions would have been needed to explain observation. This strategy
would create a model that has to be adjusted ad hoc, is not parsimonious (due to the need
for additional variables to control the adjustments), and is thus less tractable conceptually.
Even if additional well-known mechanisms are incorporated into the modelling to try to
achieve the adjustments, there is no guarantee that one can capture all relevant effects,
producing the same incomplete and non-parsimonious modelling situation.

A new concept of firm-specific unemployment is also introduced here. From the stand-
point of the theory of processes on graphs, it is a useful tool to account for a ‘search’ state
of the agent, as one would see in queuing processes such as data routing on computer net-
works. In our particular case of employment and firm sizes, beyond its technical value,
firm-specific unemployment introduces new economic notions about employment, relat-
ing to the relevance that specific firms along with their surroundings contribute to the
overall unemployment rate.

The time scales that our model addresses (and their relation to real time scales), de-
pend on whether the economy is steady enough that its behaviour between samples is not
changing a great deal (see the discussion on the steady state in Sect. A.8) or if, in contrast,
it is very dynamic. In the steady (or even in the slow dynamic) state, the model time scale
and the real-world time scales basically match as the solutions to the model quickly ad-
just to the model parameters for that sampling period. When the dynamics are very rapid
due to a fast economic shock, the time scales of the model need to be considered within
the sampling period, a problematic situation since we would be unable to compare model
results with data. In this regime, the time scale of the dynamics would be dictated by the
first eigenvalue of the stochastic matrix of the Markov chain.

In the future, as our models improve and further data is gathered and analyzed, it may
become possible to develop even more detailed models that could tackle more complex
problems such as the formation of new firms and the construction of realistic shock sce-
narios, which are necessary to design real-time high resolution forecasting of employment
flow. This task, which has not yet been possible, may be within our reach for the first time,
with considerable potential for social policy design that is well grounded empirically and
for which its effect can be forecast in great detail.

Appendix A

A.1 Data

We use two different datasets of employer-employee matched records. The first is the
Finnish Longitudinal Employer-Employee Data (FLEED), which consists of an annual
panel of employer-employee matched records of the universe of firms and employees in
Finland. The panel was constructed by Statistics Finland from social security registries by
recording the association between each worker and each firm (enterprise codes, not es-
tablishments), at the end of each calendar year. If a worker is not employed, it is not part of
the corresponding cross-section. The result is a panel of 20 years (1988 to 2007) that tracks
every firm and every employed individual at the end of each year (approximately 3 x 10°
firms and 2 x 10° workers). From two consecutive years of this data, one can determine if
an employee in one firm has moved to another, hence generating data for inter-firm job-
to-job transitions. We have direct access to this data on transition, but not the entirety of
FLEED.
Lopez et al. EPJ Data Science (2020) 9:33 Page 20 of 41

Table 1 Parameters that are either used directly as inputs in our model, Eqs. (5) and (6), or used to
determine or postulate those input parameters. The firm-size distribution (FSD) emerges for the
conditions stated in the table, particularly that there are no interdependencies among the
parameters for a node (one particularly problematic one would be that h; and/or k; were correlated,
but our results do not support this)

Parameter Empirical Model Model conditions for FSD

Xi Vv v -

&j V V (function of hj, vj) —

hj - v 0 <hj < 1,no parameter interdependencies
Vj - v 0 <v; < 1,no parameter interdependencies
fi v - ~

dij — Vv (determined from fj) —

Table 2 Quantities predicted by the model against measured counterparts

Quantity Prediction Measurement

Z [Eq. (20)] —1.97+0.02 [from Pr(ki/A;)] ~1.97+0.03 [from Pr(L;)]
a [Eq. (22)] 1 1.13637 +5 x 10>

B (Eq. (22)] 1 1.00000 + 2 x 10°

Unemployment periods cannot be determined from FLEED. For this we use a dataset
from Mexico consisting of employer-employee matched records with daily resolution. The
data was obtained by sampling raw social security records from the Mexican Social Se-
curity Institute. Approximately 4 x 10° individuals who were active between 1989 and
2008 were randomly selected and their entire employment history was extracted (hence,
covering dates prior to 1989). This procedure generates a dataset with nearly 2 x 10°
firms. The records contain information about the exact date in which a person became
hired/separated by/from a firm. Therefore, it is possible to identify unemployment spells,
duration of each spell, and associations between job seekers and their last employer.

As a supplementary dataset, useful for determining sizes of firms and separation rates,
we use Statistics Finland’s Business Register, constructed from administrative data from
the Tax Administration, and from direct inquiries from Statistics Finland to business with

more than 20 employees. This data provides firm sizes and profits from different sources.

A.2 Summary of empirical and model parameters. Model predictions
To facilitate the presentation as well as provide a summary of the role of the parameters of
the model, we present in this section Table 1 with all the parameters that bear relevance to
the inputs of the model. We also indicate the conditions under which these parameters are
consistent with the empirical observations we attempt to reproduce in this work, namely
the firm-size distribution (FSD).

In Table 2, we provide a summary of the quantities predicted by the model and those

that are measured empirically and matched against the model.

A.3 Testing persistence in the Finnish dataset
In this section we explain further details, particularly regarding the null models, about
the effectiveness of the threshold criterion in determining which node pairs should be

connected using a link on the basis of the flow of individuals between the firms.
Lopez et al. EPJ Data Science (2020) 9:33 Page 21 of 41

A.3.1 Null model and p-values for threshold criterion

To address the construction of a p-value for the analysis of persistence carried out in
Sect. 2.1, we can define the null model mathematically. For this purpose, suppose that
among the nodes N*(t, At, W), the null model is defined by the fact that the flows cap-
tured in €*(t, At, WV) and those captured in E*(t, At, 1) overlap only as a consequence of
random chance. Concretely, every flow in €*(t, At, W) that also belongs to E*(t, At,1) is
considered a successful random trial, which takes away a success state (sampling without
replacement). The success states are the flows in €*(t, At, 1). The overall population, i.e.,
places where the flows €*(t, At, 1) can be placed, consists of all the unique pairs of nodes
among \*(t, At, W). Therefore, the likelihood that there are |E*(t, At, W) N E*(t, At, 1)|

successful trials is given by the hypergeometric distribution

. IN“ |) _ ex
(enn (E02 ooken)
IN*|
(‘ 2 ))

|E*|

Pr(|&* Nn é*|) = | (23)

where, for brevity, we use the shortened notation €},,, o* and N yw: Therefore, the expec-
tation value (|E},, 9 E*|) for |Ey 9 EX| is given by
_ (ERIES)

(Ey) N Ef |) = (ly (24)
2

where |€y,,|/ (‘Nw ) is the probability of picking a pair of nodes among V},, between which
there is flow that belongs to €},,; if Pr(l€y, 9 E*|) were given by a binomial instead, the
expectation value would be the same (this is relevant below). Rewriting the last expression
somewhat, we find

(Iyer) Et

el py? ”

 

where the second equality comes from the definition of go in Eq. (2) above. Note also that
the left hand side is the expectation value for goyy in the null model. In other words, Eq. (25)
is a proof of our statement that, in the random model, the expected value for soy should
correspond to go. However, the observed goyy are much larger than g9, supporting the use
of W as a selection criterion for links. To estimate a p-value using the hypergeometric
distribution is difficult because the values of €},,, E*, and Nyy) are quite large (see the ta-
ble below). Therefore, we estimate the p-values using a normal distribution which can,
in turn, be explained from a binomial distribution approximation to the hypergeomatric
WN!) > |EYyI, |E*|. In the binomial ap-
proximation, in order to maintain the same expectation value, the success probability p,

distribution, well justified in our case given that (

is given by
ley
2

which says that to pick a node pair where there was flow during 7., the chances are propor-
tional to the number of node pairs |€j,,| in that time period. In the normal approximation
Lopez et al. EPJ Data Science (2020) 9:33 Page 22 of 41

to this binomial distribution, the mean and standard deviation are given by

= |E*|ps, Q= y/|EF|es(1 — ps) (27)

since |E*| is the number of trials. For this approximation, the p-value is then given by the
integral

(d=)
2

p-value of ES q E | ~ Qo? dd. (28)

1 oe _
——— e
/ 20 O? [ nee |
On the basis of the values in the table below, the magnitude of ¢ is very large in comparison

to yz and therefore, one can approximate the integral via an asymptotic expansion of first

order derived by integration by parts, giving estimates for the p-value of

_ 1 O _Mepy ret -w?
p-value of ES Cr) EF | ~ Jin EX NE — 20? . (29)
W 1!

Subsequent terms in the expansion are also dominated by the exponential term and there-
fore, it is reasonable to truncate the expansion at first order. The values of the exponent

are large enough that it is better to express these results under a logarithm, producing

In[ p-value of EW On & ]

ee eae” inf 1 OQ
2Q? J2n |Ex, MEX — pw
(JEx) M EF| — pw)? Hiei
wy Wn} SY in
202 n J/20 n( Jr)
~ WWE =H? EW NEM (EW OED?
~ 202 ~ 20? ) (30)

where the last equality uses the fact that ju = ERNE (AW) = (|EF E*l), and drops
the logarithmic term and the constant since they are much smaller in magnitude than the
quadratic term.

The p-value estimates are contained in Table 3. The order of magnitude of these results
is overwhelmingly below the usual significance threshold of 10~°. To illustrate this with
one of the combinations of values below (t = 1989, At = 2, W = 1), note that p, = 2.2 x
10-*, w= |E* | = 8.78, and QO =,/ |E*|o5(1 — 0;) = 2.96. Therefore, our estimate produces
In[p-value] + —4.64 x 10° « In 10-3. For reference, In 10~? + —6.91 where 107? comes from
a p-value = 10°°. All other results in the table show similar behavior, orders of magnitude
removed from the 10-? significance threshold. This provides convincing evidence for the
validity of our method. The results of our tests for several combinations of years, time
windows At, and values of W is shown in Table 3.

A.3.2 Null model and p-values for threshold criterion for heterogeneous firms
The p-values for the null model addressing the heterogeneity are calculated from the

Monte Carlo simulations. As explained in the main text, we generate random realizations
Lépez et al. EPJ Data Science

(2020) 9:33

Table 3 Table for test of threshold method for the cases that ignore or take into account the firm
heterogeneity (HF). The table only includes At = 2, as other values of At have only a minor effect on
the probability densities go, "and goyy. We show a selection of years for each of the three values
of W = 1,2,3. Note that the p-values are exceedingly small for both tests

 

 

t WIN! Es) |EF| b= (lEyy 1 EF) Hue = (lEyy S71) lEyy NEF
(In[p-value]) (In[p-value])
19901 20,181 49,855 25,213 6.17 (-3.16 x 10®) 1144.30 (-1.78 x 10%) 6253
1995 1 22,707 33,398 39424 5.11 (-3.50 x 10°) 975.66 (-2.01 x 10°) 5986
2000 «1 32,913 68,225 64,381 8.11 (-6.83 x 10°) 1793.58 (-3.56 x 10%) 10,532
2005s 40,037 72,123 88,335 7.95 (-8.64x 10°) 2278.98 (-3.15 x 10°) 11,727
1990 2 6505 7584 12,986 4.66 (-7.08 x 10°) 516.73 (-9.23 x 10°) 2571
1995 2 5200 4470 16817 5.56 (-3.51 x 10°) 398.19 (-6.93 x 10°) 1981
2000 2 7888 8462 27,800 7.56 (-8.92 x 10°) 761.25 (-1.40 x 10°) 3680
2005 2 8584 7630 38,601 8.00 (-7.95 x 10°) 830.87 (-1.09 x 10°) 3573
1990 3 3488 3202 8494. 4.47 (-2.61 x 10°) 340.20 (-5.18 x 10°) 1532
1995 3 2631 1853 10,403 5.57 (-9.83 x 10%) 219.36 (-4.84 x 10°) 1052
2000 «3 3716 3263 17,121 8.09 (-2.37 x 10°) 448.39 (-7.86 x 10°) 1967
2005 3 4388 2826 25,735 7.56 (-2.10 x 10°) 474.05 (-5.33 x 10°) 1789

S* of the flows €* (for 7;) that respect the total in- and out-flows of each of the nodes
in Nj. We then determine for each S* its overlap Ey S* with the flows in the period

; ; ; ; EX St ;
T.. The equivalent quantity to ¢ of the previous test is go) = Ce ae (defined in
w

Eq. (4)) or, alternatively we can calculate the distribution P(e) from the values of
Jey S* |/|Ey,,| of each realization. Both 4) or the distribution over realizations can be
compared against soy, but we require the distribution to determine a p-value. Our results
indicate that a Gaussian fits well the distribution Pr(o”).

Since both g and go") are defined with the || in the denominator, we can determine
p-values equally well by comparing Pr(|E},, S* |) and Ef, E*|. This can be seen in a
general way using ¢ = ¢/a and p = ji/a, which lead to the identity

1 CO (¢-n)? 1
| e 202 do =

270 20

 

 

 

Co (Gi?
| e 2 dd, (31)
@

9 /at

where o is the standard deviation for x, and its transformed version ow = 0 provides the
standard deviation for ¢. This transformation also highlights that, in terms of functional
form, if Pr(go“"") is Gaussian, then so is Pr(|Ej,, M S*|).

In Fig. 11(a) we present histograms h(|Ey,, nS* |) for ¢ = 1992 and in Fig. 11(b) histograms
for t = 2000, both for W = 1, 2,3, as well as their regressions (described next). Since we do
not have a theoretical way to specify (|E},, S*|) aap) or its distribution Pr(|E},, 9 S* l);
we resort to regression to determine the parameters of the histogram and subsequently
estimate p-values using Eq. (30) (results in Table 3). With @ = |E},, 9 S*|, we use

_ (¢-uyE)”

h(o)=he Hr, (32)

where /Jyf and ong emerge from the regression. These are the two parameters we care
about, as the normalization constant of the Gaussian is determined by oy. The quality of

the fit is clear from Fig. 11.

Page 23 of 41
Lépez et al. EPJ Data Science (2020) 9:33 Page 24 of 41

 

 

 
 
  
 

h(IE* S* 1)

 

 

 

 

 

 

 

 

 

 

 

h(IE* ,S* 1)

 

 

 

  

| | ( GD
1000 _ 1500 2000
IE*,9S*
Figure 11 Histograms h(|Ey,, 9 S* |) from simulations (symbols) and their least square fits (lines) with W = 1

(black o), 2 (red CL), 3 (green ) for years t = 1992 (top) and t = 2000 (bottom). All histograms have been
constructed from M = 104 Monte Carlo realizations
Ne

 

 

 

 

 

 

A.3.3 Overall flows captured by threshold criterion
The final test we carry out concerns how the threshold criterion performs with regards to
accounting for the overall flow in the network.

Specifically, we define the total flow

Fi(t,AtlE*(t,At,1))= Yo FRAO, (33)

(i,j)€E* (t,At,1)

that is, the total number of individuals changing firms over the pairs of nodes in
E*(t, At, 1). As above, we use the simplified notation F* (E*) to mean F*(t, At\E*(t, At, 1))
as typically there is no confusion about the time ¢ and time window At we are concen-
trating on. Note that F* (Ex) counts all the repeated transitions between node pairs, i.e.,
all the flows happening during 7,.

Our test consists of comparing F*(E*) to the average of the quantity

F(t, AtlE*(t, At, W) N E*(t, At, 1) = S F(t, At), (34)

(i,j)EE* (t, At, W)NE* (t,At,1)

which is the number of individuals that change jobs in the time period 7; exclusively on
those node pairs that also had flows > W in the time period 7.. We denote this flow as
Lopez et al. EPJ Data Science (2020) 9:33 Page 25 of 41

Fe (Ey 9 E*). The main purpose of this test is to show that a considerable percentage of
future flow is captured using the threshold criterion, much more than the flow predicted
by the null model for heterogeneous firm sizes presented above in Sects. 2.1 and A.3.2.

The overall flow during 7, associated with a given Monte Carlo realization of the null
model for heterogeneous firm sizes is denoted by F “(Ey S*) where S* is the set of
flows that emerges from one random rewiring that preserves in- and out-flows for each
and every firm. As we discussed in Sect. A.3.2, flows 7; are reliably predicted by flows
in the interval 72. Thus, we expect that typically F* (Ey O E*) is greater or even much
greater than any typical F*(€},, 0 S}). To confirm this is the case, we generate the his-
togram h(F* (EX S*)) of the overall flows predicted by the null model in order to com-
pute Pr(F "(EQ O S* )), its average (F* (Ey) 9 S*)\ up, and the p-value for the actual mea-
sured flow F* (Ey E*). In addition, following the same conceptual framework as for the
previous two tests, we define the fractions

oywi(t, At) = 2 Ew) (35)
F(E{)
and
a" (¢, At) = (A(t, Ad), = eee (36)
and the excess probability
Oyw(t, At) 37)

YW * GAPE, AD)’

Figure 12 corresponds to 6y,6", and yyy. In consistent fashion with the results for

(HE) oy, and xy, the values of Oy are roughly an order of magnitude larger than those

§?
for 9"), measured by yyy. The values for Oy in particular are largely in a range that spans
between 30% and 50% and reaches as high as just over 70%.

The calculation of p-values follows the same approach as the two previous tests. Fig-
ure 13 shows the histograms h(F. “(EY 9 S*)) for W = 1,2,3 and the years (a) ¢ = 1992
and (b) ¢ = 2000, along with their least square fit (solid lines). The histograms were cre-
ate with M = 10* rewirings of each individual yearly network. From the fits we estimate
Pr(F* (Ey S*)), its average (F* (EQ O S*)\ up and standard deviation, which we then use
in estimating the p-value of each set of years and thresholds. The results of this analysis
are shown in Table 4.

A.4 Topological properties of labor flow network

The use of the criteria developed in Sects. 2.1 and A.3 leads to a labor flow network
with certain topological properties that are captured in the distributions of degree, node
strength, and link weights. These distributions are found in Figs. 14, 15, and 16 fora range
of values of W. A satisfactory feature of these distributions is that their functional forms
remain stable even as YV increases.

An important observation that it worth highlighting is that, while k; and 1; are clearly
related, one is not predictive of the other. In other words, as has been found in prior re-
search on real weighted networks compared to weighted network models, a full descrip-
tion of such networks typically requires knowledge of all the variables describing a node i,
Lopez et al. EPJ Data Science (2020) 9:33 Page 26 of 41

 

 

 

 

 

 

(— \
10°£ T T T T 4
2 10°F 3
8 C 1
5 of |
mo) | 4
5 0
S10 & 4
5 L 1
2 L |
g
101 7
102 | | | I
1985 1990 1995 2000 2005
Year

Figure 12 The fractions @(t, At) and Oy(t, At) and the excess probability yet At), where At = 2 with the
following symbol code: (—) lines represent W = 1, (— - --) lines represent W = 2, (- - —-) lines represent

W = 3; thin lines represent 64) (t, At), thick lines represent Oyy(t, At), and thick lines with o represent

yan (t, At). The brackets signal the location of 0(t, At), P(t, At), and yy (t, At) in the plot

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

F . 1200
F.*(E*,05*,)

 

10

h(F.*(E*, S*,))

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

350

 

Figure 13 Histograms h(F*. (Eyy 9 S*)) from simulations (symbols) and their least square fits (lines) with
W = 1 (black o), 2 (red LZ), 3 (green >) for years t = 1992 (top) and t = 2000 (bottom). All histograms have

been constructed from M = 10* Monte Carlo realizations
\ S

 

 

 

 

 

 

including k;, t; and the distribution of the link weights Fj [38]. The relevance of this point
stems from the fact that it confirms that the labor flow network is not simply a direct effect

of the sizes of firms present in the economy: the observed {; is not trivially predicted as the
Lopez et al. EPJ Data Science (2020) 9:33 Page 27 of 41

Table 4 Table for test of overall flow carried by node pairs predicted by threshold test. The table only
includes At = 2, as other values of At have only a minor effect on the probability densities @7™) and
Oy. We show a selection of years for each of the three values of W = 1, 2,3. Note that the p-values
are exceedingly small

 

 

 

 

 

 

 

 

 

 

t W F*( w Nn E*) FrEX, Nn S*) F*(E*) In p-value
1990 1 17,520 1762.32 44,754 -~79,197.93
1995 1 17,322 1527.78 61,896 —86,403.38
2000 1 27,944 3396.18 96,933 —98,918.60
2005 1 34,484 4848.07 131,740 —101,314.57
1990 2 10,979 1375.66 28,013 —39,196.11
1995 2 10,217 1295.19 33,601 —35,239.02
2000 2 16,522 3009.81 52,207 —36,770.46
2005 2 20,864 2320.71 69,983 —83,855.28
1990 3 8298 1015.37 20,547 —32,485.19
1995 3 7942 949.05 24,333 —27,038.30
2000 3 12,921 2292.62 38,423 —31,750.46
2005 3 15,814 2229.20 53,088 —48,158.52
( \

LO) Eo

10" E 3

10° 3

~ Ff |

E [ |

10° E 3

10° 3

|. Lo tel @> Gents qeapap¢-© © an

10 10° 10! 10° 10° 10°
k
Figure 14 Distributions of degree Pr(kj) of the networks created by applying the threshold criterion W = 2
(black 0), W = 3 (red LF), W =4 (green 9), and W =5 (blue A)

 

 

XX 7

result of the t; transitions firm i exhibits. If this were true, the system could be explained
by so called labor supply assumptions, i.e., that the sizes of firms (numbers of employees
or numbers of individuals moving through the firms) determine other properties of the
firms such as their degree; for the labor supply assumption to be sufficient to explain the
system, transitions between firms would need to be considered random so that additional
assumptions can be avoided. Thus, a configuration model reconstruction of the labor net-
work only fixing t; per node would confirm (or reject) the labor supply assumption.

The counter-side to the labor supply assumption is that meaningful links between firms
do exist which cannot be simply a consequence of the random jumps of individuals be-
tween firms. We have already provided evidence that indeed links are meaningful in our
persistence tests above. Here we provide further evidence of the need for a labor flow net-
work with specific links by showing that the configuration network model where only the
observed 1; are fixed does not match observation.

In Figs. 17, 18, and 19 we show, respectively, comparisons of the observed distributions
of kj, t;, F; with respect to their Monte Carlo simulated versions k*, 1, Ee. The Monte

Carlo distributions have been generated with M = 10° realizations. Distributions Pr(z;)
Lépez et al. EP/ Data Science (2020) 9:33

 

 

hd
“a TULL |

aT

 

 

 

 

Figure 15 Distributions of total flow Pr(z;) through nodes of the networks created by applying the threshold
criterion W = 2 (black 0), W =3 (red O), W =4 (green 0), and W =5 (blue A)

 

 

 

 

 

 

 

 

 

 

 

 

Ne J
(— \
10°} 4
10°> 4
wo
a
10°- 4
| ul | |
10° 10: 10° 10° 10° 10°

Figure 16 Distributions of flow weights Pr(Fij) through node pairs of the networks created by applying the
threshold criterion W = 2 (black o), W =3 (red LO), W =4 (green 0), and W =5 (blue A)

XN S

 

 

 

 

 

 

and Pr(r,”) are virtually identical given the condition of the Monte Carlo to fix t; per node
to satisfy the labor supply assumption.® The other distributions, however, differ between
their observed and random versions. The fixed flow condition has a tendency to spread
flows evenly over nodes which leads simultaneously to nodes that tend to have larger de-
gree in simulation than in reality and links that tend to have more homogenized flows
than in the real system. The effect on weights is strong enough that it is patently easy to
see in the distributions. However, it is slightly harder to see the effect on k;, but an elo-
quent illustration of the effect can be found in the scatter plot Fig. 20. In this plot, we
see that virtually none of the degrees generated as a result of the labor flow assumption
is smaller than k;. The results systematically generated larger degree. If labor supply was
properly descriptive of the real network, the cloud of generated degrees should lie evenly
along the diagonal. It is of note that only approximately 0.12% of the nodes have a degree
in the simulated networks that is less than the actual degree of the node; most simulated
degrees are equal or larger than observed degrees. This makes clear the disparity between

the networks that emerge from the labor supply assumption versus the observed network.

 
Lépez et al. EPJ Data Science

(2020) 9:33

 

 

1

1

Pr(k.) and Pr(k.°”)
oS
I

 

10°

  
 
    
  

   

 

—k
1
——k.

1

(s)

 

 

 

 

 

10

0

10'

10°

10°

k, and k.®

10°

 

 

 

 

Figure 17 Distributions Pr(k;) (black ‘o’) and Pr(k’) (red ‘X’) for M = 10° Monte Carlo realizations. The
distributions are similar but Pr(k”) systematically deviates to become more skewed as kk increase,
signaling that fixing the overall flow through a node and allowing the degree to emerge as a consequence of
this leads to larger degree than in observation

 

 

 

\ 7

 

 

10 T1117

 

    

 

 

 

1

Pr(t,) and Pr(t,”)
S

an

 

 

 

Oo
NN
ue
f
oN

 

 

 

Figure 18 Distributions Pr(t;)) (black ‘o’) and Prt”) (red ‘O) for M = 10° Monte Carlo realizations. The
distributions are virtually identical as the Monte Carlo has been set up to preserve each node's overall flow 7;

 

 

 

\ 7

A.5 Determining &; from the data via MLE

We determine the values of &; by using the fact they are the rates of success of the geometric
distributions of the waiting times to be hired. Consider S; agents that have experienced
an unemployment spell from i, each with duration t,,,m = 1,...,S;. The log-likelihood to

observe those unemployment spells is given by

Si
log I] E(1—&)* | = S,[log & + ((t)s, — 1) log(1 - &)], (38)

t=1

where (f)5, = yey t;/S;. The maximum likelihood estimator for €; corresponds to

Page 29 of 41
Lopez et al. EPJ Data Science (2020) 9:33 Page 30 of 41

 

 

 

 

 

 

y

y

Pr(F..) and Pr(F.°”)

 

 

 

1 boii l 1 boii l 1 mii l 1 boii l 1 Lois
10° 10° 10° 10° 10° 10°

F.. and F
ij ij

 

Figure 19 Distributions Pr(Fjj) (black ‘C©') and Pr(F;) (red ‘C’) for M = 10° Monte Carlo realizations. The

distributions differ widely, with Pr(F,) considerably steeper than Pr(Fj), illustrating the way that the condition
to fix T for each node has the effect of spreading flows evenly over the network, thereby eliminating large
flow between node pairs

 

 

X

 

 

(s,r)

Simulated degree k. ’

 

 

10° 4 1 iil po st iil po pt iil a
0

10 10 10° 10°
Observed degree k,

Figure 20 Scatter plot of observed kj versus kK‘) Itis clear from this plot that the model with only a constraint

of 1", c'"” predicts the wrong degree for the nodes

\ 7

 

 

Thus, to determine &;, we calculate the average length of time agents that last worked at i
spend waiting to get their next job.

A.6 Unique solutions of the model
Equations (7) and (8) of the main text constitute a homogeneous system of linear equations
for the steady state probabilities of being employed at firm i. Repeating the equations here,

we have
AX =0 (40)
with
hy Dy (0, Pry yy
Aj = Ai —7—_____ - fi, j] (41)

Dyfi) (h) y, Pr(yj)
Lopez et al. EPJ Data Science (2020) 9:33 Page 31 of 41

and
Xj = AiPoo (i), (42)

where A is the adjacency matrix of the LFN. A homogeneous system such as the one above
always has, at least, the trivial solution X = 0. For there to be interesting, non-trivial so-
lutions, it is necessary for the matrix A to be singular, i.e., to have determinant equal to
zero [39].

In this section we show that A is indeed singular and, furthermore, that for a connected
network with adjacency matrix A, the singularity stems from matrix A having a reduced
rank of N — 1, where WN is the number of network nodes (matrix A is N x N). This means
that there is a 1-dimensional space of solutions for X which satisfies AX = 0. To obtain a

unique solution, one simply needs to make use of the normalization condition

together with [4] of the main text," which makes Eq. (43) take on the form

N

|= ‘—— Jarwt =1. (44)
Kj yi) (h) y, Pr(y)

i=1

Before we embark on showing the proofs, we should note the intuitive reason why A
is not of full rank, but instead has a rank reduced by one unit: since the probability flow
is conserved, it is not necessary to know the probabilities at all nodes. Clearly, due to
conservation, if we know the probabilities in N — 1 nodes, then the probability for the Nth
node can be determined from Eqs. (43) or (44). Matrix A encodes the way the probabilities
flow across the system without normalizing them.

To show first that A is singular, it is sufficient to show that all of its columns add to zero,
which is equivalent to saying that at least one of its rows is linearly dependent on other

rows. This can be seen if we first sum Aj over i

NAD 0, Prog Vy,"

N
A; =-1+) A,

45
tj20) 4) 4 Pry) (45)

where —1 comes from — )°, 5[i,j]. We can now show that the numerator and denominator
of the second term are indeed equal. To see this in detail, we organize the elements of y}

by cardinality iy,” |, and rewrite the numerator as

N [P|

. 1
) Ajih; ) Pr(y,)/|y,"| = ) c ) Ajihij ) Pr(y,”), (46)
i=l (y?} c=1 i ti? \=c}

where the last sum is over all elements of y} with equal size c. Now, the sum over i

guarantees that each neighbor of j belonging to a particular yi? is summed, along with the
Lopez et al. EPJ Data Science (2020) 9:33 Page 32 of 41

corresponding h,, where r € yy? Therefore, the sum over i can be rewritten as

Avs TO Prly)= (Sb) Prt (47)

(yj? =e) tIyleed 7%

and inserting this into the sum over c leads to

ml Sh
rey, oT
DED (Lh) Po = Yo SE Po = Yo Pao 4s)
llyjlzc Srey; vj 1 (yj)
Therefore,
N ° .
Ashi DS Pr(y? ly? | = DO yy, Pry), (49)
i=l 07) (yj)

which means that for all j, (45) is identically zero.
In order to determine the rank of matrix A, we first highlight the following relations to
the flow probabilities of the random walker. First, note that

hjs(j, t) S Pr(y,)/|y,| = Nii» (50)
ry?)

is the probability current for the transition s(j, t) > r(i,t + 1) from unemployment at node
j to employment at node i. Also,

s(i,t) )Pr(y)()y = ny (51)

7

is the entire probability flow out of j, which is to say s(j,t) > r(Tj,£+ 1) (ie., the probability
of being employed at any of the neighbors of j). Due to conservation of probability, it is
clear that

Nj. = S Niis (52)

ieDj

which we use below.
The proof that A has incomplete rank can also be written by making use of Eq. (52).
Hence

 

jer Mi
DA S> Pr(y)/ | = maith = GH 5 = DP) th (53)

{y Oy Vt ¥j7D

In addition to this simplification, one can also make use of this reformulation to test for
the rank of a reduced matrix A’ which is equivalent to A but missing a row and a column.
In this case, we choose to eliminate the Nth row/column, which is a fully general choice
given the arbitrary nature of the labeling of nodes.
Lopez et al. EPJ Data Science (2020) 9:33 Page 33 of 41

We want to show that, for a connected graph, the rows of A’ forma linearly independent
set of vectors. Thus, defining

A; =(Ai1.-.,Ain-1), [i=1,...,.N-1], (54)
where each Aj, when rewritten by using Eqs. (50) and (51), is
Nii Le
Aj = Ai— — 5b], (55)
Nj.
we can form an equation on the coefficients {j1;}

0 = So midi (56)

and show that it can only be satisfied if all jz; are zero, which would prove that the set of
vectors Ai, bees A n-1 are linearly independent. Expanding the right hand side of this last

expression, we obtain

N-1 N-1 N-1 N-1
S Li Aj = (> Mika, S LiNi2,.++, S bd
i=l i=l i=l i=l

N-1 N-1
N-T Ayn; NT AN NN 1;
_ (24 MiAiiNii — Wyeees el LiAN-1,i7N-1,i _ av-1). (57)
M1. NN-1.
Equating this to 0, we obtain the set of equations
dier! MiNi
———— -pj=0 [Vj=1,...,N-1], (58)

Nj.

where I’; represents the graph neighbors of j excluding node N. With the aid of Eq. (52),

this set of equations can be rewritten as

YS) wings — Mj Djs = 0 [Vj=1,...,N—-1], (59)

ie’; ieTj

where one should note that for n;,, the set of neighbors used includes N. Explicitly sepa-

rating the (possible) flow between j and N, this becomes

S Ling — Lj S Niji = WjA,NN)N

jel” jel’
Ll j LE j

=> So (ui — Lj) ni = WA nnn (Vj =1,...,N-1]. (60)

jie!
sj

The last expression highlights the relationships that need to hold among the otherwise
independent link flows to satisfy Eq. (56). From a physical standpoint, these relations tell
us that the vectors in Eq. (54) are indeed linearly independent in contrast to the case when
Lépez et al. EPJ Data Science (2020) 9:33 Page 34 of 41

all the nodes are present (i.e., the full matrix A as opposed to the reduced matrix A’). In
matrix A, there is redundant information because knowing all the flows for N — 1 nodes
provides the information needed to determine the flows to the remaining node. But for
the row vectors of A’, that is Eq. (54), the absence of the variables accounting for the flows
going into and out of one of the nodes (in our case N) breaks the linear dependence. We
see this in more detail next.

In order to find the {j;} that solve Eq. (56), or equivalently Eq. (60), we proceed as fol-
lows. Out of the N — 1 members of Eq. (60), consider the ones where j is not a neighbor
of N. This means that Aj, = 0, making the right hand sides equal to 0. It also means that,
for this case, I”; = I’; because there are no connections to N. Then, the only admissible so-
lutions require that 4; = 4; (which we label jz for simplicity) for all i ¢ Tj, since the flows
nji # O. In other words

Yo(ui- enn =) (ue -w)ni=0 ETI. (61)

ielj ielj

Furthermore, we note that the jz chosen for one j “propagates” to other nodes since the
network is connected (has a single cluster). To understand this, let us consider two situa-
tions for i: 1) i is itself not a neighbor of N, in which case it also needs to satisfy Eq. (61),
but because this i is connected to j, also satisfying Eq. (61), then they must share the same
yu value for consistency, or 2) i is a neighbor of N (which we consider next). Before we
tackle 2), note that 1) implies all the neighbors of N (Iw) also have jj; = 4 because the
nodes that are at distance 2 from W all propagate ju to the nodes in I'y.

When a node j is a neighbor of N, Ajj = 1, and it is clearer to write Eq. (60) in the
form (59), and use Eq. (52) to obtain

S Ling — Win, =90 YEeTyl. (62)

ie’;
But because all the jz; above have been shown to be equal to jz, we have

lL S ni — LN. = KY. -— NN) - BN. =—enjnw=9 eT, (63)

iE’
wi

which cannot be generally satisfied unless jz = 0, showing that indeed the only solution for
Eq. (56) is uw; =0,Vi=1,...,N.
If all nodes are neighbors of N, Eq. (60) for all nodes is given by

Sui — Lj) Nji = LiN,N (64)
jel

but because the nj; are independent, the only way to satisfy the equation is if j1; = 0 for all
i.

A.7 Robustness of results to changes in the W threshold

In the main text and in Sect. A.3, we discuss how we construct the network encoded in A.
We indicate that the edges are considered significant if multiple transitions take place be-
tween the two firms connected by the edge, and we set the minimum number of transitions
Lopez et al. EPJ Data Science (2020) 9:33 Page 35 of 41

to W = 2. This choice ensures maximum amount of data to increase statistical significance
of the results.

However, for this threshold to be acceptable, we have to check whether our results are
robust to increasing VV. This is the purpose of this section and, as we indicated in the main
text, the results below support our choice to use WV = 2 for our main analysis. To under-
take the robustness test, we construct plots of the quantity log,)[Pr(Zi|kj/A;)/ Pr(Z#|kj/1i)]
which are equivalent to Fig. 2 of the main text, but here we use the minimum number of
job-to-job transitions to be W = 3,4,5 (Fig. 21). If the key characteristics of the surface
logy [Pr(Li|ki/Ai)/ Pr(L7|k;/A;)] remain as WV increases, it means that the results for W = 2
are not an artifact of such a choice. The key characteristic we care about is the typical
functional relation between L* and k;/A;. Just as for the plot discussed in the main text,
we can see that the level sets of maximum probability are parallel to the linear “best fit”
planes. Note that in all the plots, for values of L; ~ 10? and above together with k;/A; ~ 107
and above, the level sets of highest probability run parallel to the linear planes of “best fit”
Furthermore, we can observe that as W increases, the range of the level sets that deviates
from the “best fit” planes is located at the small values of L¥ and k;/A;, which should not be
surprising since an increase in WV means that firms with very few numbers of employees
cannot be well represented.

Therefore, the overall conclusion is that the match between the homogeneous model,
represented by Eqs. (15) and (16) with r.,(i) = ©) (i) and s..(i) = si from Eqs. (11) and
(12), respectively, are supported by our analysis of the Finnish data even as the criterion

for including a link in A is made more stringent.

A.8 Further evidence of steady-state behavior

While the balanced-flows plot presented in the main text provide evidence of steady-state
behavior in the data, the reader might be concerned about other types of fluctuations that
are not addressed by such test. For example, it might be the case that, even with balanced
flows and a constant population, the firm size cumulative distribution might change its
shape through time. Figure 22 shows the firm size cumulative distribution obtained for
yearly measurements from the Finnish data. It is clear that the distribution is robust across
time, and that the only changes are upward shifts due to the population growth through
several years. This way of showing evidence of steady-state behavior is more standard in
the study of firm dynamics.

In addition to the previous test, we also check that the effects that may be proportional
to firm size do not hide systematic behavior that we cannot see in the simple study of raw
flows. In Fig. 23, we plot the histogram of the net fractional flow for Finland. Here too,
we see a very large concentration of the histogram around a zero fractional flow. Note the
vertical logarithmic scale.

As a final test, we look at the changes in the network structure from year to year using
the time dimension of our data. Consider V(t) the set of network links that are accepted
to the overall labor flow network when the data is analyzed starting from the year ¢ and
going to the end of the data in year ty (the data spans from ft, = 1988 to ty = 2007). In other
words, the links in V(t) are between node pairs that had flow at or above the threshold
W = 2 between years ¢ and t7. Now, we calculate V(¢) for all possible ¢ (i.e. systematically
varying the starting year) which creates the series V(¢,), V(t, +1),..., V(¢ — 1). From these
Lépez et al. EPJ Data Science (2020) 9:33 Page 36 of 41

2
LOg4o L;

Figure 21 Behavior of logyo[Pr(Li|ki/Ai)/ Pr(L*|ki/A;)] (surface S) with respect to logjg Lj and 10g ki/A; for
Finland when A is created with links where the traffic has a minimum of 3,4,5 transitions (top, middle, bottom
plots). The data is logarithmically binned as follows: L; belongs to bin 6 (a non-negative integer) if

Lmin€? <Lj< Lmin€ Ot with ¢ > 1 (for this plot € = 2) and Lmin = min[{L;}] (smallest firm size in the data); kj/A;
is binned in the same way with ¢ and (k/A)min = min[{(kj/A;)}]. Blue points represent the local maximum of S
at each bin. The vertical plane P (linear “best fit”) is parametrized as (kj/Aj, Ci ki/X;,Z) where z is a free
parameter. C; is chosen to minimize dolls ~C,(k/A)4)* with the first three bins excluded because the
smallest firm size is 1. The large range within which the intersection of P and S runs parallel to the maxima of
S strongly supports Eq. (18) of the main text

 
Lopez et al. EPJ Data Science (2020) 9:33 Page 37 of 41

 

 

10°
10° 10? 107 103 104
L

 

 

Figure 22 Annual firm size cumulative distributions for Finland between 1988 and 2008
\ J

 

 

10 £

_—
Oo
iN
TTTT

—
oO

Ww

TT T TTT

—
oS

N

TT TTTTTT

Frequency of fractional flow

_
TTTTTT

10

 

 

 

10; 08 06 04 -02 0 02 04 06
Fractional Flow

Figure 23 Histogram of fractional net flows with respect to firm size for the Finnish dataset. The results are

concentrated around 0, supporting the steady state assumption
Ne J

 

 

results, we define the Jaccard index J(t) of the links as the quotient
(t+ 1)
t) = ——______—__, 65
I(t) (+1) (65)

where the numerator counts how many links that are accepted into V(t) from analyzing
the data from year ¢ to ¢ are also accepted into V(t + 1) using years ¢ + 1 to ¢ of the data,
and the denominator counts the number of unique links that belong to either V(t) or
V(t + 1) including links belonging to both. In other words, /(t) measures how similar V(t)
and V(t +1) are to one another; at its limit values, /(t) is equal to 1 when V(f) = V(t + 1)
and 0 when V(t) 1 V(t + 1) = G, ie., V(t) and V(t + 1) do not have any common links.
Figure 24 shows the results of this analysis. For the vast majority of years, the Jaccard
index is close to 1 and decays slightly towards the later years due to the short time range
available to test links against the acceptance criterion. The meaning of these results is that
despite the dynamics of the network, the labor flow network determined from persistent
links changes by 10% or less in any typical year. Thus our method should be stable to yearly

changes in the network over time to a level that generally exceeds 90%.
Lopez et al. EPJ Data Science (2020) 9:33 Page 38 of 41

 

 

 

 

 

 

 

 

( \
1
0.8 4
= 0.6 7
3
i
zy
S 0.4- -
3
0.2, |
0. ! | ! | ! | ! |
1985 1990 1995 2000 2005
Year t
Figure 24 Jaccard index for the link sets V(t) of the data, defined as J(t) = |V(Q) N V(t + 1)|/V(Q U V(t + 1)|. The
solid line corresponds to the points (to, J(to)), (to + 1, (to + 1). (t¢ — 1,J(t¢ — 1))
L J

 

A.9 Firm sizes for Mexican data

In the main text, we present the analysis of firm sizes for Finland and the firm-specific
unemployment for Mexico but, because there is no data available to deal with Finnish
firm-specific unemployment, we do not present results for this case. However, there is
data for firm sizes for Mexico which, in the interest of space, we do not show in the main
text. Here, we present this analysis as a supplement to our main analysis. Because of the
method of collection of the data for Mexico, it is not possible to have results as clean as
those for Finland since the sampling has not been done uniformly on firms but rather
on individuals. However, the results for the Mexican data are not inconsistent with the
Finnish results.

As in the main text, we use the data to draw a comparison with the homogeneous model
that assumes v; = v. This model predicts that L; ~ k;/;, as seen from Eq. (18) of the
main article. Therefore, in Fig. 25, we present the 3-dimensional plot of log,)[Pr(L;|kj/A;)/
Pr(L*|k;j/A;)] as a function of log, )L; and log, (kj/A;). Once again, Pr(Z;|k;/A;) corre-
sponds to the probability associated with the conditional mode L;. The normal plane is
parametrized as indicated in the caption. The relation between L; and k;/A; is again sup-
ported by this plot, although more fluctuations appear towards firms of larger size and/or
of large degree k;. These firms are less likely to be properly sampled because, even though
they have more employees, there are fewer of them (the same complication emerges for
the plots of firm-specific unemployment, by the way).

A.10 RANSAC

The RANSAC algorithm [37] is a popular method to estimate parametric models when
data has large amounts of outliers, which is our case. The algorithm performs an OLS
estimation by randomly sampling the minimum number of data points needed to fit the
model. Then, it identifies those data points from the entire dataset that fall within a given
distance from the estimated model. These two steps are repeated until a model with a max-
imum number of inlier data points is found. Since RANSAC is non-deterministic, it yields
slightly different estimations every time it is performed. For this reason, we performed 1
million RANSAC estimations and analyzed the distribution of their estimates. We em-

ployed the default parameters of 2 minimum observations, the median absolute deviation
Lépez et al. EPJ Data Science

(2020) 9:33

 

 

 

2

Figure 25 Behavior of logjg[Pr(Li|ki/Aj)/ Pr(L#*|ki/A;)] (surface S) with respect to logyg L; and 10g; ki/Aj for
Mexico. The data is logarithmically binned as follows: L; belongs to bin 6 (a non-negative integer) if

Lmin€? < Lj <Lmin€°*! with € > 1 (for this plot € = 2) and Lmin = min[{L;}] (smallest firm size in the data); kj/A,
is binned in the same way with ¢ and (k/A)min = min[{(kj/A,)}]. Blue points represent the local maximum of S
at each bin. The vertical plane P is parametrized as (kj/A;, C. kj/X;,Z) where z is a free parameter. C, is chosen
to minimize dp (le —C,(k/A)p)? with the first three bins excluded because the smallest firm size is 1. The large
range within which the intersection of P and S runs parallel to the maxima of S strongly supports Eq. (18) of
the main text

 

 

as a threshold to distinguish between inliers and outliers, and the maximum number of
trials of 100 which are standard values in the literature.

To be specific, each RANSAC run consists of two steps. First, a data subset is sampled
and the model is estimated. The sample size has to be of the minimum necessary to esti-
mate the model. Second, the data that was not sampled is compared against the predictions
of the estimated model. Given an error threshold, those data points that are not predicted
by the model are considered outliers. The points that are correctly predicted form the
consensus set. If the consensus set contains too few data points, the estimated model is
dropped and the algorithm goes back to step one. Otherwise, the model is re-estimated
with the consensus set and the error is computed. These steps are repeated until the error
term reaches a threshold. Parameter calibration used default values from the implemen-
tation in the SciKit Learn package.

Acknowledgements
EL, OAG, and RLA would like to acknowledge helpful discussions with Andrew Elliot, José Javier Ramasco, Felix
Reed-Tsochas, Gesine Reinert, Matteo Richiardi, Owen Riddall, and Margaret Stevens.

Funding
EL and OAG would like to acknowledge funding from the James Martin 21st Century Foundation (LC1213-006) and the
Institute for New Economic Thinking (INET12-9001).

Abbreviations
FLEED, Finnish Longitudinal Employer-Employee Data; FSD, Firm Size Distribution; LFN, Labor Flow Network; OLS,
Ordinary Least Squares; RANSAC, Random Sample Consensus.

Availability of data and materials
The data used in this article is directly available from the sources, Tilastokeskus (Statistics Finland), and the Instituto
Mexicano del Seguro Social (Mexican Social Security Institute).

Competing interests
The authors declare that they have no competing interests.

Page 39 of 41
Lépez et al. EPJ Data Science (2020) 9:33 Page 40 of 41

Authors’ contributions
EL and OAG designed research; EL performed calculations; EL and OAG analyzed data; EL, OAG, and RAA wrote
manuscript. All authors read and approved the final manuscript.

Author details

'Department of Computational and Data Sciences, George Mason University, 4400 University Drive, MS 6A2, Fairfax, VA,
USA. *Green Templeton College, University of Oxford, 43 Woodstock Rd, OX2 6HG, Oxford, UK. ?The Alan Turing Institute,
96 Euston Rd, Kings Cross, NW1 2DB, London, UK. *Department of Economics, University College London, Drayton House,
30 Gordon St, Kings Cross, WC1H OAX, London, UK.

Endnotes
4 In fact, beyond the temporal tests presented in this Sec., we conducted non-temporal tests not reported here.
However, these tests are inappropriate for this context because they have a tendency to suggest that flows
between small firms are significantly non-random and those for large firms are, instead, more likely to be random.
Crucially, every time that one finds a pair of nodes with a single flow event, such tests suggest strong significance,
even though this flow may never be seen again, undermining the entire meaning of a network of steady flows.

The increase of go as a function of W may seem surprising at first. However, we must remember that go depends on
E* and Ny, (and on €%,, through V%,,), and thus as W increases, the density of the resulting set of flows among
the pairs of nodes in Nyy, increases because the nodes selected tend to be those with more overall flows anyway.
Note that the increases of go with respect to W appear more pronounced than those of gow, but this is because
fow Is already large and starts to have less room for increase as it begins to approach 1 (a saturation effect).

The parameters that control the stochastic model, defined in the main text, can be systematically chosen on the
basis of well structured economic models that optimize certain economic features (see e.g. [15])

For a connected graph, the solution is unique, but if the graph is separated into disconnected components, one can
set up calculations identical to the one here for each component and obtain a unique result for the set of all
components.

In this manuscript, prediction does not refer to temporal forecasting. Rather, it specifically means the result of
solving our model and using it to calculate quantities that can be contrasted with their empirically measured
equivalents.

Even more surprisingly, the estimate for @ to be close to 1 is usually difficult to obtain when RANSAC is performed
without restriction. The usual procedure is to assume @ has a given value and estimate 6 only, but in our case, this is
not necessary.

g Although most of the distribution of 7° is identical to that of T;, there are differences at the right tail. This is because
the algorithm for rewiring the flows sometimes produces networks with a small number of unmatched flows (in a
sample of M = 10° rewired networks, an average of 919.5 + 30.3 flows were missed out of * 1.8 x 10° for each
random network). This happens when the algorithm tries to rewire a node with itself. If this happens, we simply
ignore this attempt and move onto the next match of in- and out-flows. The probability of this happening is very
small, hence leading to only a fraction of about 5 x 10~* missed flows. Large nodes are mores susceptible to this.
Around k, = 750, each node j with k; > k, is likely to have at least one missed flow per realization. There are only 97
such nodes in the network of 292,614 nodes. The average number of flows missed among those nodes is less than
10 per node.

Using [4] from the main text allows us to write 5,9(/) in terms of rgo(/), and hence have the normalization condition
written purely in terms of X.

Publisher’s Note
Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.

Received: 21 February 2018 Accepted: 12 October 2020 Published online: 02 November 2020

References
1. Parsons T (1937) The structure of social action, volume |. Marshall, Pareto. McGraw-Hill Book Company, New York
Hedstrdm P, Bearman P (eds) (2009) The Oxford handbook of analytical sociology Oxford University Press, Oxford
Kydland FE, Prescott EC (1982) Time to build and aggregate fluctuations. Econometrica 50(6):1345-1370
Epstein JM, Axtell RL (1996) Growing artificial societies. Brookings Institution Press & MIT Press, Washington Dc
Simon H (1996) The sciences of the artificial. MIT Press, Cambridge
Dosi G, Fagiolo G, Roventini A (2010) Schumpeter meeting Keynes: a policy-friendly model of endogenous growth
and business cycles. J Econ Dyn Control 34(9):1 748-1767
7. Guerrero OA, Lopez E (2017) Understanding unemployment in the era of big data: policy informed by data-driven
theory. Policy Internet 9:28-54
8. Petrongolo B, Pissarides C (2001) Looking into the black box: a survey of the matching function. J Econ Lit 39:390-431
9. Mortensen D, Pissarides C (1994) Job creation and job destruction in the theory of unemployment. Rev Econ Stud
61:397-415
10. Gabaix X (2011) The granular origins of aggregate fluctuations. Econometrica 79(3):733-772
11. Garicano L, Lelarge C, Van Reenen J (2016) Firm size distortions and the productivity distribution: evidence from
France. Am Econ Rev 106(11):3439-3479
12. Barinchon R, Figura A (2015) Labor market heterogeneity and the aggregate matching function. Am Econ J
Macroecon 7(4):222-249
13. Maliranta M, Nikulainen T (2008) Labour force paths as industry linkages: a perspective on clusters and industry life
cycles. ETLA Discussion Papers 1168

AWM RWN
Lépez et al. EPJ Data Science (2020) 9:33 Page 41 of 41

20.
21.

22.
23.

24.

25.

26.
27.
28.
29,
30.
31.
32.
33.

34.
35.

36.

37.

38.
39.

Guerrero OA, Axtell RL (2013) Employment growth through labor flow networks. PLoS ONE.
https://doi.org/10.1371/journal.pone.0060808

. Axtell RL, Guerrero OA, Lopez E (2019) Frictional unemployment on labor flow networks. J Econ Behav Control

160:184-201

Park J, Wood IB, Jing E, Nematzadeh A, Ghosh S, Conover MD, Ahn Y-Y (2019) Global labor flow network reveals the
hierarchical organization and dynamics of geo-industrial clusters in the world economy. Nat Commun 10:3449
Atalay E, Hortagsu A, Roberts J, Syverson C (2011) Network structure of production. Proc Natl Acad Sci USA
108(13):5199-5202

Collet F, Hedstromb P (2013) Old friends and new acquaintances: tie formation mechanisms in an interorganizational
network generated by employee mobility. Soc Netw 35:288-299

Guerrero OA, Lopez E (2015) Labor flows and the aggregate matching function: a network-based test using
employer-employee matched records. Econ Lett 136:9-12

Simon HA, Bonini CP (1958) The size distribution of business firms. Am Econ Rev 48:607-617

Stanley MHR, Amaral LAN, Buldyrev SV, Havlin S, Leschhorn H, Maass P, Salinger MA, Stanley HE (1996) Scaling
behavior in the growth of companies. Nature 379:804—806

Axtell RL (2001) Zipf distribution of USS. firm sizes. Science 293:1818-1820

Aoyama H, Fujiwara Y, Ikeda Y, lyetomi H, Souma W (2010) Econophysics and companies. Cambridge University Press,
Cambridge

Agarwal R, Ohyama A (2012) Industry or academia, basic or applied? Career choices and earnings trajectories of
scientists. Manag Sci 59(4):950-970

Campbell BA, Ganco M, Franco AM, Agarwal R (2011) Who leaves, where to, and why worry? Employee mobility,
entrepreneurship and effects on source firm performance. Strateg Manag J 33(1):65-87

Rogerson R, Shimer R, Wright R (2005) Search-theoretic models of the labor market: a survey. J Econ Lit 43:959-988
Coad A (2009) The growth of firms. A survey of theories and empirical evidence. Edward Elgar, Cheltenham Glos
Stendl J (1965) Random processes and the growth of firms. A study of the Pareto law. Hafner, New York

Gibrat R (1931) Les inégalités economiques. Sirey, Paris

Gabaix X (1999) Zipf’s law for cities: an explanation. Q J Econ 114:739-767

Luttmer EGJ (2012) Technology diffusion and growth. J Econ Theory 147:602-622

Granovetter M (1973) The strength of weak ties. Am J Sociol 78:1360-1380

Calvo-Armengol A, Jackson MO (2004) The effects of social networks on employment and inequality. Am Econ Rev
94(3):426-454

Jackson MO (2010) Social and economic networks. Princeton University Press, Princeton

Gianelle C (2011) Exploring the complex structure of labour mobility networks: evidence from Veneto microdata.
WP2011 13

Garlaschelli D, Ahnert SE, Fink TMA, Caldarelli G (2013) Optimal scales in weighted networks social informatics. Lect
Notes Comput Sci 8238: 346-359

Fischler M, Bolles R (1981) Random sample consensus: a paradigm for model fitting with applications to image
analysis and automated cartography. Commun ACM 24:381-395

Serrano MA, Bogunha M, Pastor-Satorras R (2006) Correlations in weighted networks. Phys Rev E 74:055101

Hoffman K, Kunze R (1971) Linear algebra, 2nd edn. Prentice-Hall, Upper Saddle River

 

Submit your manuscript to a SpringerOpen®
journal and benefit from:

> Convenient online submission

> Rigorous peer review

> Open access: articles freely available online
> High visibility within the field

> Retaining the copyright to your article

Submit your next manuscript at > springeropen.com

 

 

 
