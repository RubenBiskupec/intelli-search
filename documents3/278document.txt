Brati¢ et al. Smart Learning Environments (2020) 7:15 Smart Learni ng Environments
https://doi.org/10.1186/s40561-020-00123-w

RESEARCH Open Access

Role of interactive presentation platform ®
ASQ in delivering web design course

updates
Brankica Bratié!”, Vasileios Triglianos?, Vladimir Kurbalija', Cesare Pautasso* and Mirjana lvanovié

 

1

 

*Correspondence:

brankica.bratic@dmi.uns.ac.rs Abstract

‘University of Novi Sad, Faculty of Contemporary technology enhanced learning together with different innovative

000 Nowead coke >, learning methodologies are significantly initiating progress in educational ecosystems.
Full list of author information is Educational systems and tools that invoke active participation of learners are excellent

available at the end of the article facilitators of modern education. One such system is ASQ. ASQ is an interactive
presentation platform that allows teachers to incorporate interactive questions in their
presentations. Learners are then answering these questions on site on their digital

devices. In that way teachers have immediate feedback from learners, allowing them to
adjust course of presentation. In this paper we tried to determine in what extent is ASQ
beneficial for learners. For that purpose we conducted analysis on the data collected
from Web Design course, where ASQ was utilized during two school years. Results of
the analysis suggest that ASQ has a positive influence on learners’ acquired knowledge.

Keywords: ASQ, Web design, Active learning, Interactive presentations

 

Introduction
Contemporary trends in technology enhanced education and research increasingly
require introduction and application of innovative, “intelligent’, personalized systems
adjusted to learners’ needs. One of the main directions in this area is oriented towards
promotion of active participation of learners. Immediate learning feedback is important
for learners but also for teachers in order to properly support and increase effects of teach-
ing and learning (Triglianos et al. 2017; Freeman et al. 2014; Brusilovsky et al. 2015; Lin et
al. 2019). Pervasive technologies have been incorporated in modern educational environ-
ments to allow learners and teachers to fully benefit from learning ecosystems (Hung et
al. 2018; Denden et al. 2019; KlaSnja-Milicevic et al. 2018). The real advances in improv-
ing learning and teaching activities can be achieved by capturing and analyzing various
data generated during educational processes. Wide variety of useful educational data can
be collected from diverse learning spaces and activities like: clickstream data (Triglianos
et al. 2016), grades, assessment data, and even physiological types of data.

Additionally it is necessary to increase quality of theoretical research and practical
implementation of educational tools, systems, and environments that will offer teachers
a multifunctional, technology-enhanced educational milieu able to collect, integrate, and

. © The Author(s). 2020 Open Access This article is licensed under a Creative Commons Attribution 4.0 International License,
GQ) Springer O pen which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate
— credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were
made. The images or other third party material in this article are included in the article’s Creative Commons licence, unless
indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons licence and your
intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly
from the copyright holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0/.
Brati¢ et al. Smart Learning Environments (2020) 7:15 Page 2 of 16

harmonize educational data to achieve higher potential (Manzoor et al. 2019; Lin et al.
2019; GaSevic et al. 2019) and increase learners’ performances and achievements.

Recently, educational data mining, learning analytics (KlaSnja-Milicevic and Ivanovic
2018) and appropriate tools influence higher awareness of necessity to use innovative
sorts of assessment employing single virtual learning environment or utilizing one learn-
ing management system. Enhancement of learners’ performances through active learning
from constructivist point of view (Freeman et al. 2014) is getting more important. Active
learning and learners’ reactions about presented topics increase learners’ participation in
the classroom and provide teachers with adequate feedback.

Our main intention was to change the usual predominant passive traditional teach-
ing style by applying a new lecture pattern in Web Design course: teaching short pieces
of new material and after that immediately asking learners related questions. Based on
their answers teacher can gauge the level of understanding of the taught material. Such
particular pattern of lecturing is vital for students but even more for teachers. Learners
can confront their understanding of the taught concepts momentarily. Based on learners’
immediate feedback teachers can adapt their teaching method in real-time and adjust it
to the learners’ results, expectations, and needs.

ASQ (Triglianos and Pautasso 2014) was developed to support active learning educa-
tional scenarios including the aforementioned lecture pattern. Its core feature is the ability
to seamlessly embed various types of questions within presentation slides and stream
them to students’ devices. Students’ answers are aggregated in real-time and presented to
the teacher to help them adjust the lecture to attain desired educational goals.

In this paper we report on our experiences of using ASQ, we discuss lessons learned,
identify some of the problems that arose and we propose ways how to address them. The
primary contribution of this paper is a case study in a real-world classroom about how a
group of students being taught in a novel lecture pattern, that utilizes a directed use of
technology to foster active learning, can learn better than a control group following the
traditional lecture paradigm.

The rest of the paper is organized as follows. In the second section related work is
briefly presented. Section three is devoted to the concise presentation of the role of ASQ in
the educational process. In the fourth section experimental setup is presented describing
the organization of Web Design course. Fifth and sixth sections bring respectively results
and discussion about statistical analysis performed on data collected during the course
activities in two school years. Last section draws some concluding remarks.

Background and related work
In this paper we are primary oriented to consider, analyze and draw useful conclusions
about higher education classroom experience by using digital devices with the aim to
adopt active learning style in a programming oriented course. In conventional, traditional
classrooms teachers often ask learners to express their opinion and give answers on orally
posed questions by speaking out loud, drawing on a whiteboard or discussing with their
peers. However, usually small number of students participate in these activities while
majority of others are passive.

One strategy to scale these interactions to multiple students is to utilize digital devices
in the classroom. It should be noted though that the undirected use of technology

may produce negative effects on learning achievements and outcomes. Some authors
Brati¢ et al. Smart Learning Environments (2020) 7:15 Page 3 of 16

performed experiments and studied effects on learners’ achievements in multi-tasking
during the lectures with digital devices. In the experiment presented in (Wood et al.
2012) learners were randomly assigned to one of several different conditions and use of
technology instruments. Authors finally concluded that learners’ achievements were even
negatively impacted.

In order to minimize such possible negative effects, a lot of innovative online learn-
ing platforms expect learners to answer different types of questions and also rather short
questions or programming tasks. Recently going a step ahead, many widely available
online learning platforms support multiple ways of presenting teaching materials and
obtaining students responses, like in-video quizzes for flipped classrooms and MOOCs.
For example in the paper (Kim et al. 2015) authors explore an advanced method using
specially developed system. RIMES system facilitates “easy authoring, recording, and
reviewing interactive multimedia exercises embedded in lecture videos” With RIMES
learners can make video or audio recordings of their responses to the videos presented in
classroom. Teachers can immediately review responses in aggregated gallery and react on
the students’ responses. After performed experiments with 25 students, teachers found
out that the system is highly useful in identifying variety of misconceptions which help
them to improve teaching content.

Also an interesting study was presented in the paper (Ravizza et al. 2017). During the
class, learners’ activities on Internet were observed. Online activities were classified in
two groups: related or not related to the class topic. Final conclusion was that Inter-
net use not related to the class topic was predominant among learners who used their
laptops in class. Expectedly such behavior negatively affected learning performances.
More surprisingly, use of Internet related to class topic was not beneficial for learners’
performances.

It is definitely clear that modern education based on technology enhanced learning
requires innovative approaches to use digital devices, to make learning more attractive but
also more productive and with better learners’ performances. So designers and developers
of the distributed event collection and analysis architecture of ASQ, produced modern,
attractive and very useful educational environment that enables practice questions during
lectures (Triglianos et al. 2017; Triglianos and Pautasso 2014). Learners can easily and rel-
atively unobtrusively use and work with the system in wide variety of courses. Learners’
interactions with the web application generate different types of events that are captured
and stored in appropriate database. Collected data about particular tasks/questions is
processed immediately and results are visually shown to the teacher who can properly
react and change style and dynamics of teaching giving additional explanations or skip-
ping some well known elements. The ASQ system has been intensively used in teaching
activities for students at various universities and interesting results have been published
(Triglianos et al. 2017; Triglianos and Pautasso 2014).

Developers of ASQ did not explicitly mention social dimension of their platform. How-
ever, group/summary results of all students for particular question are visually presented
to all of them in privacy-preserving way, after processing all collected answers. So each
student can personally assess his/her position and learning performance and compare
them with results of other peers. This approach is not as comprehensive as one offered
by MasteryGrids OSSM (Open Social Student Modeling) interface (Brusilovsky et al.
2015) but have some similar basic useful elements. MasteryGrids uses parallel social
Brati¢ et al. Smart Learning Environments (2020) 7:15 Page 4 of 16

visualization approach. It shows progress of student knowledge in wide range of subse-
quently organized educational topics. Personal performances and progress is compared
and visually presented with the progress of the class. In majority of cases it is motiva-
tional for students with lower learning performances to try more tasks and questions with
non-mandatory learning content in order to achieve better results.

As a consequence of joint SCOPES project, colleagues from Technical Univer-
sity from Bratislava also used ASQ for interaction with students in their classroom.
In the paper (Triglianos et al. 2017), experiences of use of ASQ in a Functional
and Logic Programming course were presented. Authors collected and analyzed data
about students’ activities and achievements. Based on students’ immediate feedback
on complex types of questions, that has been used during classes, authors man-
aged to aggregate students’ answers in real time. In the paper several requirements
and useful guidelines for successfully adoption of ASQ were identified. However the
essential one and highly important for both students and teachers is: find proper
moment when to stop collecting the students’ answers and proceed to their pre-
sentation and evaluation. After that particular moment, it is important to discuss
findings together with the class and adjust further topics to the current students’
performances.

Our experiments with ASQ had gone in the similar directions i.e to determine if ASQ
helps students to gain higher knowledge and achieve better learning performance in
friendly and not stressful technology enhanced learning. The methodology applied and
discussion on obtained results, are presented in the rest of the paper.

The role of ASQ in the educational process

Taking tests on studied material to promote active learning, as opposed to using tests
only as an evaluation tool, is beneficial to retention and leads to better scores in final tests
(Bartlett 1977; Darley and Murdock 1971; Hanawalt and Tarr 1961; Hogan and Kintsch
1971; McDaniel et al. 1989; McDaniel and Masson 1985; Whitten II and Bjork 1977).
There is also strong evidence (Glover 1989; Morris et al. 1977; McDaniel et al. 2007; Kang
et al. 2007) that suggests that the more effort-full free recall format for quizzes (such as
short text quizzes or programming tasks) perform better in terms of learning outcomes
compared to cued recall or recognition formats (such as “fill the gaps” or multi-choice
quiz types). Mixing theoretical explanations with interactive exercise activities benefits
long-term recall as it helps students to reflect on the taught material (which is still in
their working memory) and prevent misconceptions from taking root (as teachers can
give early feedback).

ASQ is a Web application designed to enable practice questions during lectures.
Questions of various types can be embedded in the slides of a presentation which
are streamed to the students’ devices (Fig. 1). All students can participate and their
answers are aggregated in real-time allowing presenters to gauge the level of under-
standing in the classroom, catch misconceptions early and give timely feedback to
their audience.

The goals of the ASQ application are to: a) turn student devices from distractions to
affordances for learning; b) use technology to scale active learning to large audiences; c)
raise teachers awareness for each and all of their students’ level of comprehension of the
taught material, during and after the lecture.
Brati¢ et al. Smart Learning Environments (2020) 7:15 Page 5 of 16

 

 

“a (antl |
NN y

Fig. 1 ASQ in the classroom: most students’ laptops are connected and focused on a slide that contains the
results of an interactive question

 

 

 

ASQ offers the opportunity to present complex question types in class to hundreds of
students and to receive real-time feedback about the students’ focus, understanding and
their performance on the tasks.

Questions are not limited to closed types of questions, such as multiple choice, but
include many general and informatics-related domain-specific question types that pro-
mote active learning and experimentation with the taught material. Example question
types include live JavaScript programming; programming Java code and testing it against
unit tests; creating Web pages with HTML, CSS and JavaScript (Fig. 2); formulating
database queries; creating and editing visual diagrams; using CSS selectors; highlighting
text and classifying and rating items. With these question types, students are asked to
demonstrate their understanding and apply their knowledge in concrete scenarios. This
way they realize very quickly whether they are capable of solving the given challenges.
At the same time, aggregating all students’ answers allows presenters to assess the level
of comprehension of the whole audience, provide timely feedback while students are
attempting to construct solutions and detect and address misconceptions before they take

root.

Experimental setup
Web design is an elective course at the Department of Mathematics and Informatics, Uni-
versity of Novi Sad, Serbia. It is intended for first-year students in second semester of
following two study programs: computer science and information technology. However,
it is possible to choose this course on second or even on third year. The first-year students
have obtained the necessary Java programming prior-knowledge from the obligatory
first-semester course Introduction to Programming.

Besides some basics about Internet and Web (which include history, client-server archi-
tecture, web browsers, web servers, definition of URL, DNS etc.) the content of the course

is divided into three main topics:
Brati¢ et al. Smart Learning Environments (2020) 7:15 Page 6 of 16

 

Create a header and print a message in the console when clicked

HTML JS CSS_ Result
1 <hi>This is a header</h1> // Log a message when the
// header is clicked
var el = document.querySelector('h1');

~ el.addEventListener('click', e => { This is a header

console. log('header clicked")

Our WNPR

Audience view
Create a header and print a message in the console when clicked

HTML JS CSS_ Result
1 <hi>This is a header</hi> // Log a message when the
// header is clicked Submissions
var el = document.querySelector('h1

~ el.addEventListener('click', e => { This is a header

console.log('header clicked") <hl>This is a
b; header</h1>

auf wnr

<hi1>just a
header</h1>

#2
Presenter view

Fig. 2 Example ofan< asq-fiddle-q> question type element that allows students to build a webpage
with HTML, CSS and JavaScript

 

 

 

e HTML: history, tags, elements of web page, attributes, text formatting, links, images,
tables, lists, frames, forms.

e CSS: positioning, CSS rules, selectors, declaration blocks, box model (padding,
border, margin), page flow, floating.

e JavaScript: variables, statements, operators, functions, arrays, objects, events,
Document Object Model (DOM), Browser Object Model (BOM), form validation,
HTML5 canvas.

The course consists of one hour of lectures and three hours of lab exercises per week.
During the lectures general and only theoretical concepts are presented. The lectures are
performed in large classrooms with one big group of students (usually around 60) and
without individual access to digital devices. In such circumstances, the utilization of ASQ
during lectures was not possible.

On the other hand, during lab exercises students are divided into smaller groups (less
than 15), where each student has access to a computer. The main goal during labs is to
support the practical work of students. However, there are some parts of the exercises
where teaching assistant introduces and explains some new concepts. These introductory
parts of exercises are ideal for utilization of ASQ.

The main goal of our research was to determine if ASQ helps students to gain higher
knowledge in the topic. In order to verify that, we performed an experiment with ASQ
in Web Design course during two school years: 2016/2017 and 2017/2018. In each year,
students were divided into two groups:

e Control group (NA group): The introductory parts of exercises are presented to
students in this group using traditional PowerPoint slides and HTML/CSS/JavaScript

examples.
Brati¢ et al. Smart Learning Environments (2020) 7:15 Page 7 of 16

e Test group (A group): The introductory parts of exercises are presented to students
in this group using ASQ.

We tried to balance these two groups in terms of number of students and their prior-
knowledge as much as possible. The prior-knowledge was measured by students’ scores
earned on practical tests from Introduction to Programming course. The characteristics
of students’ distribution is given in Table 1. This distribution could not be ideal due to

two main reasons:

e Some students could not be assigned to an arbitrary group due to time constraints in
their schedule.
e There are some students who skipped Introduction to Programming course, so we

did not have data about their programming skills.

The final step in the experimental setup was to define an objective evaluation of stu-
dents’ performance. The simplest way would be to use students’ final grades in the course.
The grade is formed by summing the results from three individual projects which cor-
respond to three main topics: HTML, CSS and JavaScript. However, different groups of
students are assessed by different teaching assistants, so this final grade might be biased.
In order to avoid subjective bias, we introduced an unified final test at the end of semester.
It contained thirty questions (ten per each course’s topic), each question being worth one
point. By introducing this test, we were able to obtain an unbiased evaluation of students’
performance. It was used only for the purpose of ASQ evaluation and it did not influence
students’ final grades. The detailed structure of the test can be found in the Appendix.

Our final data sample includes 107 students, 51 of them being from the school year
2016/2017, and 56 from the school year 2017/2018. The students were mostly first year
students, hence without much programming experience. For each student we recorded
three scores obtained on the final unified test — one score for HTML, one for CSS and one
for JavaScript. Besides that, for each student we also recorded information about their
group, i.e. for each student we know whether they belong to A or NA group. The sample
contains 54 students that belong to group A, and 53 students that belong to group NA.

The goal of this research was to determine how does ASQ influence students’ learning
performance in Web Design course. To meet this goal, we compared the results of the
students who belonged to the group A with the results of the students who belonged to
the group NA. Besides that, we also wanted to see how the influence of ASQ changes over
different question types and over different topics, i.e. we wanted to define in which cases
is ASQ most suitable. For that purpose, we analyzed the results of individual questions
and tried to find correlations between question type and students’ performance. We also
analyzed and compared the results of each separate topic (HTML, CSS and JavaScript),
in order to see if ASQ affects learning performance differently over different topics.

Table 1 Properties of NA and A groups for two school years

 

 

2016/2017 2017/2018

NA A NA A
Number 25 26 28 28
Prior-knowledge 44.3] 44.22 47.53 41.52

 

Prior-knowledge is expressed as an average of scores earned on Introduction to Programming course, where the maximum is 60
Brati¢ et al. Smart Learning Environments

(2020) 7:15

Results
In this section we present the results of statistical analysis that was performed on the
collected data.

Firstly, we wanted to see if the distribution of the scores obtained by NA group is the
same as the distribution of the scores obtained by A group. If the distributions were iden-
tical, that would mean that ASQ did not introduce any changes. For that purpose we
conducted Mann-Whitney U test on two sets of data: one contained of NA group’s scores,
and the other of A group’s scores. P-value of 0.0232 was obtained, meaning that we could
reject null hypothesis and that the two sets have significantly different distributions.

In order to compare performances of NA and A groups on individual questions, we
calculated mean values of scores for each question. Mean values are separately calculated
for NA and A groups and are also separately calculated for years 2016/2017, 2017/2018,
and for both years together. Let us now introduce question ratio value denoted as R(q,g),
which is shown in Eq. 1. Function M(q, g) returns mean value of the scores for question
q and group g, while the function /(g) returns inverse of the group g, i.e. if the group g
was A function J returns NA, and vice versa. Finally, for a given question q and group g
value R(q,g) tells us how good group g performs compared to group /(g) (value closer to
0 indicates worse and value closer to 1 indicates better performance). Throughout this
section, for a question g and group g we will say that group g outperformed group /(g) iff
R(q,g) > 0.55, similarly group g underperformed group /(g) iff R(g,g) < 0.45, otherwise,
if 0.45 < R(q,g) < 0.55 performance of two groups is said to be similar.

_ M(qg)
KO8) = TG) + MGI@) ©)

Table 2 contains the aforementioned mean values, while Fig. 3 visualizes them. Distribu-
tions of question grades for NA and A groups over each separate topic are visualized with
violin plots in Fig. 4.

Table 2 Mean values of scores for each individual question in the final test

HTML HTML
NA]|0.68/0.16|0.96]0.88] 1.0 |0.48|0.68|0.92|0.88|0.16 0.82|0.41/0.82|0.89|0.91|0.41|0.59|0.82|0.82|0.21
A Ses o-olo-s7 1.0 oazlo7s|0-88 ae 073 aor 0.8 ites vee es eee

CSS CSS
NA|0.64/0.54/0.26/0.58/0.84/0.76| 0.3 |0.58/0.33/0.46 0.59/0.53/0.13/0.73|0.45|0.86|0.24|0.52|0.41|0.55
A |0.58] 0.5 |0.44|0.87/0.54|0.58/0.43/0.56/0.54/0.69 0.64/0.52/0.18]0.77/0.68]0.73/0.42|0.59/0.45/0.55

JavaScript JavaScript
NA|0.66/0.28/0.84/0.88]0.26| 0.2 |0.26/0.08/0.79|0.14 0.71/0.23/0.64/0.68/0.14)0.09/ 0.2 |0.07/0.68/0.14
A {0.88} 0.5 |0.69/0.85|0.37/0.23/0.43/0.29/0.88/0.37 0.78/0.59/0.68/0.73/0.36/0.27/0.15/0.05/0.82/0.19

(a) Year 2016/2017. (b) Year 2017/2018.

 

 

 

HTML
NA|0.74/0.28]0.89/0.88/0.96/0.45/0.64/0.87/0.85/0.19
A {0.69} 0.5 |0.85/0.83/0.98/0.44/0.67) 0.9 /0.71)0.24

CSS
NA|0.62|0.53} 0.2 |0.65|0.66/0.81)0.27/0.55|0.37| 0.5
A | 0.6 |0.51/0.32}0.82| 0.6 |0.65/0.42/0.57) 0.5 |0.62

JavaScript
NA|0.68/0.26/0.74/0.79] 0.2 |0.15/0.23|0.07|0.74/0.14
A |0.84}0.54/0.69/0.79|0.37/0.25] 0.3 |0.18/0.85/0.29

(c) Years 2016/2017. and 2017/2018.

 

 

 

 

 

The values are separately calculated for NA and A group. Yellow color indicates that performance of the two groups is equal, red
color indicates that given group under-performs other group, while the green color indicates that given group outperforms other

group

Page 8 of 16
Brati¢ et al. Smart Learning Environments (2020) 7:15 Page 9 of 16

oS >

% v » > S © & ©
WW vw Y ves! & ~ SF eo SF S Se So EF s EMP PPPS SS
SLL S “s SS sg ee v

 

NA

2017.

 

>

N

>
2018.

>

N

>
2017. and 2018.

>

Fig. 3 Overview of ratios between scores of A and NA groups on each individual question from final test.
Three charts from top to bottom represent following data: data for year 2016/2017, data for year 2017/2018,
and averaged data for both years. In each chart top part of stacked bar represents NA group, while the
bottom part represents A group. Yellow bar color indicates that performance of the two groups is equal, red
bar color indicates that given group under-performs other group, while the green bar color indicates that
given group outperforms other group

 

 

Discussion
In this section an analysis of the obtained results is given. First an overview of the limita-
tions of our research is given, and then scores on individual questions and scores of the
three main topics are analyzed.

Even though we put a lot of effort into avoiding any noise and biases in the data, our
research still has certain limitations. First and major limitation is that A and NA groups

might not be ideally balanced. Instead of randomly dividing students into the two groups,

 

Methodology
Dn A
[] NA

Average grades

 

HTML CSS Js
Course topic

 

 

Fig. 4 Distribution of question grades over whole examination period (i.e. data of both years is included)

 
Brati¢ et al. Smart Learning Environments (2020) 7:15 Page 10 of 16

we used students’ grade from Introduction to Programming course, assuming that stu-
dents’ performances on the two courses would be similar. However, it might be the case
that this assumption is not correct for non negligible amount of students, and unfortu-
nately, we could not do much about this issue. Besides this, we had an additional difficulty
during the balancing — dealing with students’ schedule. Consequently, some students
could not be assigned to the preferred groups. For that reason groups in school year
2017/2018. were not as balanced as groups in school year 2016/2017.

Second limitation is regarded to the final unified test. Namely, the test was not intro-
duced for the purpose of grading, but only for the purpose of our research. Therefore,
we had to conduct this test anonymously, which might have caused students’ lack of
motivation to do this test as good as they can.

Data (see Table 2 and Fig. 3) shows that in the year 2016/2017 group A outperformed
group NA in 13 questions, while group NA outperformed group A in 3 questions; in
the rest of the questions groups performed equally well. In the year 2017/2018 group
A outperformed group NA in 7 questions, while group NA outperformed group A in
3 questions. If we look at means of whole period that includes both years we can see
that group A outperformed group NA in 14 questions, while group NA outperformed
group A in only 1 question. First important thing to note is that group A indeed has a
significant advantage over group NA in terms of number of outperforming questions.
This result suggests that in this case ASQ did influence students’ performance posi-
tively. Second thing to note is that relative performance of group A over group NA
slightly dropped in year 2017/2018. One possible reason for this could be the struc-
ture of the groups. Namely, in the year 2017/2018 group NA had non-negligibly better
students in terms of number of points from Introduction to Programming course (see
Table 1). This slight unbalance increased possibility of good NA group performance. With
that circumstance, even equal performance of NA and A groups could mean that ASQ
influenced students’ performance positively, since that could mean that students with
less potential who used ASQ perform as well as students with more potential who did
not use ASQ.

In order to understand in which cases is ASQ beneficial to students, we analyzed scores
of concrete, individual questions in which group A drastically outperformed group NA
and vice versa — the questions in which group NA drastically outperformed group A.

Some of such examples are given below:

e In question HTML2 in year 2016/2017 group A drastically outperformed group NA.
In order to answer the question correctly students needed to know how to distinguish
between following HTML concepts: element, tag and attribute. During the
traditional labs with group NA, teaching assistant explained each mentioned HTML
concept, while during the ASQ labs with group A, after each explanation students had
an interactive ASQ slide in which they had to distinguish between the three concepts.

e In question CSS3 group A also outperformed group NA. The students’ task here was
to write a CSS selector. During the traditional labs, examples of CSS selectors were
presented on the blackboard, while during the ASQ labs, students had an interactive
slide where they could write selectors themselves and immediately see their outcome.

e In question CSS6 group NA outperformed group A. The accent of this question was
CSS syntax. Namely, students needed to say what does the third number of padding
Brati¢ et al. Smart Learning Environments (2020) 7:15 Page 11 of 16

value mean. Students of traditional labs had more time to code since ASQ labs lasted
longer, leaving less time for pure coding. As a consequence students from group NA

might remembered syntax-related concepts better.
e In question CSS7 group A outperformed group NA. Students needed to explain the

difference between block and inline elements. Both traditional and ASO labs were

performed in the same way regarded this topic.
e In question JS2 group A outperformed group NA. As a part of this question students

needed to distinguish between local and global JavaScript variables. In traditional labs
local and global variables are pointed out in preprepared JavaScript code, while in
ASQ labs students had an interactive slide where they had to distinguish between two

variable types by themselves.
e In question JS7 during the year 2017/2018. group NA outperformed group A. In this

question students needed to write JavaScript code that does DOM manipulations.
Both groups had similar programming tasks regarded this question during the labs,

but group NA had more time to do it.
e In question JS10 group A drastically outperformed group NA. In this question

students needed to explain how would they implement an animation by using
HTML5 canvas. Both traditional and ASQ labs were performed in the same way
regarded this topic.

As it can be seen, most questions in which group A outperformed group NA are those
that had relevant interactive ASQ slide which forced students to answer simple questions
during the lectures. On the other hand, poor performance of the group A is detected
in the situations where they had to deal with pure syntax. The reason for that might
be that group A had less time for programming during the labs since presentation part
lasted longer with ASQ. Nevertheless, it is much more important that students adopt deep
knowledge in the topic rather than just syntax rules. From that perspective ASQ is proved
to be really beneficial.

Next part of analysis is regarded to influence of ASQ on adopting concepts from three
main course’s topics: HTML, CSS and JavaScript. Namely, we wanted to see for which
topics ASQ introduced most benefits. Violin plot in Fig. 4 shows the distributions of ques-
tion grades for NA and A groups, each topic being shown separately. For HTML part ASQ
managed to decrease a number of students who scored less than six. Still, unlike group
NA, group A has some extreme cases where students performed really badly. The reason
for this is not completely clear, but it might be the case that these few students did not
attend corresponding classes or lacked with motivation. Number of students that scored
more than six has also increased for the CSS part. However, the best influence of ASQ is
detected for JavaScript part, which might be a sign that ASQ is better suited for this part
of the course.

Conclusions and future work

Technology enhanced learning offers enormous opportunities to increase quality of
teaching and learning in modern educational ecosystems. In this paper we put atten-
tion on assessment of students’ achievements and specifically we considered effects of
active learning on students’ learning performances and outcomes. Particularly we con-
centrated on possibilities that emerging information communication technologies offer
to delivering programming-oriented courses and use of a modern web-based dynamic

educational architecture.
Brati¢ et al. Smart Learning Environments (2020) 7:15 Page 12 of 16

Thanks to joint project with colleagues who developed ASQ (Triglianos et al. 2017;
Triglianos and Pautasso 2014), members of the project have had opportunity to test it in
their educational environments and programming courses (Triglianos et al. 2017). ASQ
offers balanced way of mixing theoretical explanations with interactive exercise activities.
Such combined lecturing helps students to adopt taught material and prevent misconcep-
tions by giving them teacher’s feedback. ASQ was positively accepted by both the students
and the teachers during the Web design course at University of Novi Sad.

Studies in the past have shown increased learning benefits when using personal
response systems (i.e. clickers) (for example (Mayer et al. 2009; Gauci et al. 2009)), through
the use of recognition format question types. While these systems are not integrated with
presentation functionality, thus imposing high context switching costs, their most impor-
tant limitation is the lack of support for free recall format questions. With ASQ we hope
to shift lecturing to a paradigm where the majority of students can answer free recall
questions without overwhelming the teacher and benefit from the associated gains in
retention.

In this paper the results of experimenting with several types of interactive, construc-
tive, and domain-specific questions within Web Design course are presented. During two
school years within lab exercises we observed two groups of students: group NA which
did not use ASQ and group A which used ASQ for testing learning achievements and per-
formances. Collected data was analyzed and results show that ASQ did influence students’
performance very positively. In spite the fact that for few types of questions group NA
showed better results, in majority of cases group that used ASQ showed significantly bet-
ter learning performances. The questions where ASQ showed lower performance are the
ones that deal with pure syntax. The lower performance is probably caused by the fact
that ASQ presentations last longer, leaving less time for coding. Nevertheless, the con-
cepts which were improved by ASQ seem to be more valuable — deep understanding of
the main concepts is more important than memorizing syntax rules.

We can conclude that ASQ definitely has great potential to help to quickly identify com-
mon students’ mistakes and misconceptions. Based on immediately available answers
from students the teacher can comment on them timely and give the students chance at
the same class to understand concepts better and be more successful.

ASQ definitively offers numerous resources and high potential to methodologi-
cally and technically improve delivery of teaching material for students especially for
programming-oriented courses, and improve their learning performances. Accordingly
we plan to continue to use ASQ in other similar programming-oriented courses and moti-
vate teachers to prepare material in more attractive way that will additionally motivate

students and improve their active role in lecturing.

Appendix

Student performance assessment

In order to do an unbiased assessment of students’ performance, we created an unified
test with thirty questions that cover all course’s topics. Each question from the test is
worth one point, whole test being worth thirty points. At the end of semester each student
had to solve the test, so we were able to collect each student’s score. Evaluation of the ASQ
is then performed by statistical analysis of the collected scores. Deeper insight of the test

is given in the Table 3.
Brati¢ et al. Smart Learning Environments (2020) 7:15 Page 13 of 16

Table 3 Overview of the unified final test that was used for students’ performance evaluation
Topic: HTML

1. Will a HTML page be erroneous if we use capital letters in HTML tags (e.g. <P></P>instead of
<p></p>)?

a) yes, b) no.

 

2. <body style=” color:blue” >is:
a) tag, b) element, c) attribute.

 

3. Give an example of HTML element that does not have closing tag.

Open-ended question.

4. What are two main parts of each HTML document?
Open-ended question.

5. What should be given as a value of "href’ attribute of "a” tag?

a) path of image that will be shown, b) path of the CSS file that will be imported, c) path of the resource that
will be opened when user clicks on the link.

6. Attribute target” can be given inside of what element?

a) iframe, b) a, c) img, d) p.
7. What attribute was used for the cell marked with the question mark?

a) colspan="2”, b) colspan=" 3”, c) rowspan=" 2”, d) rowspan=" 3".

 

8. Element "ol” is used for making:

a) ordered list, b) unordered list, c) description list.

9. Element "iframe” is used for making:

a) nested HTML page, b) frame around a HTML element.

10. Name at least three distinct HTML elements that are used for user input and that are usually placed inside
HTML forms.

Open-ended question.

Topic: CSS

1. Take a look at the following code, and then choose the correct answer.
<img width=100 src=image.jpg />

a) given code has inline CSS, b) given code has internal CSS, c) given code has external CSS, d) given code does
not have CSS at all.

 

2. What primitive selector types are present in the following complex selector: ”.dark, a:hover’.

a) element type selector, b) id selector, c) class selector, d) pseudo-class selector, e) inter-sectional selector, f)
grouping selector, g) descendant selector.

3. Write a selector that selects all a” elements of class ” menu” that are placed inside element ”span” of class
navigation” .

Open-ended question.
4. CSS segment "color: rgb(0,255,0)” is used for setting:

a) blue background color; b) blue text color, c) green background color, d) blue text color, e) purple background
color, f) purple text color.

5. What CSS manipulation needs to be applied on elements from a) in order to get to b).

»COCIC00 9)
»COCICIOC)

a) increase paddings, b) increase margins, c) increase borders, d) increase elements’ widths.
What is the meaning of the third number from the following CSS segment:
* padding: 5px 7px 6px 2px;

 

a) left padding, b) top padding, c) bottom padding, d) right padding.

 

7. What is the difference between block and inline elements?

Open-ended question.

 

8. Which CSS positionings remove elements from normal flow?

 
Brati¢ et al. Smart Learning Environments (2020) 7:15 Page 14 of 16

Table 3 Overview of the unified final test that was used for students’ performance evaluation.
Continued

a) static, b) fixed, c) absolute, d) relative.

9. What would be the layout of the elements given in the image bellow (which are all of size 60x40) if green
element becomes styled with following CSS: ” position:relative; top:50px;” ?

oO Oo = =
a)= © >») == >.) @ od)

 

10. What would be the layout of the elements given in the image bellow if red element becomes styled with
following CSS: ” position:absolute; top:0px; left:0px;” ? (Important notes: elements that are given in the images
do not have margins; black frame in the given images represents borders of the HTML page.)

a) Nothing would change, b) | == c) = , d) =

Topic: JavaScript
1. What does ” window.alert(” abc” )” do?

Open-ended question.

2. What variables from the code given bellow are local variables?
function sum(a, b){

c=a+b;

var str = "the sum is ”;

return str + C;

var first = 2;

var second = 3;

var result = sum(first, second);

a) c, b) str, c) first, d) second, e) result.

3. What value does the variable ”a” have after the following expression: ”var a, b = 10;”?
a) 10, b) undefined.

4. What value does the variable ”a” have after the following expression: "var a = 1; var a;”?

a) 1, b) undefined.
5. What happens after user clicks on the submit button of the form given bellow?
<form action=” info.html” onsubmit=” return false;” >
<input type=” submit” value=” Info” >
</form>
Open-ended question.
6. What does the code given bellow do?
var new = document.createElement(” div” );
new.innerHTML = ” New element” ;

 

a) adds empty div at the end of the page, b) adds div with text "New element” at the end of the page, c) does
not change the page.

7. Write JavaScript code that dynamically changes text color of the element that is stored in variable ” element”.
Newly set text color should be blue.

Open-ended question.
8. Write JavaScript code that assigns value of the input field ”name” to some variable.
<form name=”form1” onsubmit=” return validate();” >
<input type="text” name=” name” >
<input type="text” name=” surname” >
</form>

Open-ended question.

9. What is the output of JavaScript code given bellow?
ctx.moveTo(0,0);

ctx.lineTo(200,100);

ctx.moveTo(200,0);

ctx.lineTo(0,100);

a)
10.Shortly describe how could animation be implemented by using HTML5 canvas.

Open-ended question.

 

Acknowledgments
This is work is a partial result of the collaboration within the SNF SCOPES JRP/IP, No. 160480/2015, between Switzerland,
Slovakia and Serbia.

Authors’ contributions
All authors contributed to the study conception, design, material preparation, data collection and analysis. All authors
read and approved the final manuscript.
Brati¢ et al. Smart Learning Environments (2020) 7:15 Page 15 of 16

Funding
This is work was funded by SNF SCOPES JRP/IP, No. 160480/2015, between Switzerland, Slovakia and Serbia.

Availability of data and materials
The datasets used and analysed during the current study are available from the corresponding author on reasonable
request.

Competing interests
The authors declare that they have no competing interests.

Author details
"University of Novi Sad, Faculty of Sciences, Trg Dositeja Obradoviéa 3, 21000 Novi Sad, Serbia. *University of Lugano,
Faculty of Informatics, Via Buffi 13, 6900 Lugano, Switzerland.

Received: 23 January 2020 Accepted: 15 April 2020
Published online: 20 May 2020

References

Bartlett, J.C. (1977). Effects of immediate testing on delayed retrieval: Search and recovery operations with four types of
cue. Journal of Experimental Psychology: Human Learning and Memory, 3(6), 719.

Darley, C.F., & Murdock, B.B. (1971). Effects of prior free recall testing on final recall and recognition. Journal of Experimental
Psychology, 91(1), 66.

Brusilovsky, P., Somyurek, S., Guerra, J., Hosseini, R., Zadorozhny, V. (2015). The value of social: Comparing open student
modeling and open social student modeling, In International Conference on User Modeling, Adaptation, and
Personalization (pp. 44-55). Cham: Springer.

Denden, M., Tlili, A., Essalmi, F., Jemni, M., Chang, M., Huang, R., et al (2019). imoodle: An intelligent gamified moodle to
predict “at-risk” students using learning analytics approaches, In Data Analytics Approaches in Educational Games and
Gamification Systems (pp. 113-126). Singapore: Springer.

Freeman, S., Eddy, S.L., McDonough, M., Smith, M.K., Okoroafor, N., Jordt, H., Wenderoth, M.P. (2014). Active learning
increases student performance in science, engineering, and mathematics. Proceedings of the National Academy of
Sciences, 111(23), 8410-8415.

Gasevic¢, D., Joksimovic, S., Eagan, B.R., Shaffer, D.W. (2019). Sens: Network analytics to combine social and cognitive
perspectives of collaborative learning. Computers in Human Behavior, 92, 562-577.

Gauci, S.A., Dantas, A.M., Williams, D.A., Kemm, R.E. (2009). Promoting student-centered active learning in lectures with a
personal response system. Advances in Physiology Education, 33(1), 60-71.

Glover, J.A. (1989). The “testing” phenomenon: Not gone but nearly forgotten. Journal of Educational Psychology, 81(3), 392.

Hanawalt, N.G., & Tarr, A.G. (1961). The effect of recall upon recognition. Journal of Experimental Psychology, 62(4), 361.

Hogan, R.M., & Kintsch, W. (1971). Differential effects of study and test trials on long-term recognition and recall. Journal of
Verbal Learning and Verbal Behavior, 10(5), 562-567.

Hung, |.-C., Chen, N.-S., et al (2018). Embodied interactive video lectures for improving learning comprehension and
retention. Computers & Education, 117, 116-131.

Kang, S.H., McDermott, K.B., Roediger Ill, H.L. (2007). Test format and corrective feedback modify the effect of testing on
long-term retention. European Journal of Cognitive Psychology, 19(4-5), 528-558.

Kim, J., Glassman, E.L., Monroy-Hernandez, A., Morris, M.R. (2015). Rimes: Embedding interactive multimedia exercises in
lecture videos, ln Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems
(pp. 1535-1544). New York: ACM.

Kla$nja-Milicevic, A., & lvanovic, M. (2018). Learning analytics—new flavor and benefits for educational environments.
Informatics in Education, 17(2), 285-300.

KlaSnja-Milicevic, A., lvanovic, M., Vesin, B., Budimac, Z. (2018). Enhancing e-learning systems with personalized
recommendation based on collaborative tagging techniques. Applied Intelligence, 48(6), 1519-1535.

Lin, Y.-L., Parra, D., Trattner, C., Brusilovsky, P. (2019). Tag-based information access in image collections: insights from log
and eye-gaze analyses. Knowledge and Information Systems, 61, 1715-1742.

Manzoor, H., Akhuseyinoglu, K., Wonderly, J., Brusilovsky, P., Shaffer, CA. (2019). Crossing the borders: Re-use of smart
learning objects in advanced content access systems. Future Internet, 11(7), 160.

Mayer, R.E., Stull, A., DeLeeuw, K., Almeroth, K., Bimber, B., Chun, D., Bulger, M., Campbell, J., Knight, A., Zhang, H. (2009).
Clickers in college classrooms: Fostering learning with questioning methods in large lecture classes. Contemporary
educational psychology, 34(1), 51-57.

McDaniel, M.A., Anderson, J.L., Derbish, M.H., Morrisette, N. (2007). Testing the testing effect in the classroom. European
Journal of Cognitive Psychology, 19(4-5), 494-513.

McDaniel, M.A., Kowitz, M.D., Dunay, P.K. (1989). Altering memory through recall: The effects of cue-guided retrieval
processing. Memory & Cognition, 17(4), 423-434.

McDaniel, M.A., & Masson, M.E. (1985). Altering memory representations through retrieval. Journal of Experimental
Psychology: Learning, Memory, and Cognition, 11(2), 371.

Morris, C.D., Bransford, J.D., Franks, JJ. (1977). Levels of processing versus transfer appropriate processing. Journal of verbal
learning and verbal behavior, 16(5), 519-533.

Ravizza, S.M., Uitvlugt, M.G., Fenn, K.M. (2017). Logged in and zoned out: How laptop internet use relates to classroom
learning. Psychological science, 28(2), 171-180.

Triglianos, V., Labaj, M., Moro, R., Simko, J., Hucko, M., Tvarozek, J., Pautasso, C., Bielikova, M. (2017). Experiences using an
interactive presentation platform in a functional and logic programming course, In Adjunct Publication of the 25th
Conference on User Modeling, Adaptation and Personalization (pp. 311-316). New York: ACM.
Brati¢ et al. Smart Learning Environments (2020) 7:15 Page 16 of 16

Triglianos, V., & Pautasso, C. (2014). Interactive scalable lectures with ASQ, In /nternational Conference on Web Engineering

(ICWE) (pp. 515-518). Cham: Springer.

Triglianos, V., Pautasso, C., Bozzon, A., Hauff, C. (2016). Inferring student attention with ASQ, In 77th European Conference

on Technology Enhanced Learning (EC-TEL). Lyon: Springer.

Triglianos, V., Praharaj, S., Pautasso, C., Bozzon, A., Hauff, C. (2017). Measuring student behaviour dynamics in a large
interactive classroom setting, In Proceedings of the 25th Conference on User Modeling, Adaptation and Personalization
(pp. 212-220). New York: ACM.

Whitten II, W.B., & Bjork, R.A. (1977). Learning from tests: Effects of spacing. Journal of Verbal Learning and Verbal Behavior,
16(4), 465-478.

Wood, E., Zivcakova, L., Gentile, P., Archer, K., De Pasquale, D., Nosko, A. (2012). Examining the impact of off-task

multi-tasking with technology on real-time classroom learning. Computers & Education, 58(1), 365-374.

 

Publisher’s Note
Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.

 

Submit your manuscript to a SpringerOpen®
journal and benefit from:

> Convenient online submission

> Rigorous peer review

> Open access: articles freely available online
> High visibility within the field

> Retaining the copyright to your article

Submit your next manuscript at > springeropen.com

 

 

 
