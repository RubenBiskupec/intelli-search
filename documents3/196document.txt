Kitamura and Yatabe EURASI/P Journal on Advances in Signal
Processing (2020) 2020:46
https://doi.org/10.1186/s13634-020-00704-4

EURASIP Journal on Advances
in Signal Processing

RESEARCH Open Access

Consistent independent low-rank
matrix analysis for determined blind source

Separation

Daichi Kitamura!” ® and Kohei Yatabe2"

Abstract

Check for
updates

 

Independent low-rank matrix analysis (ILRMA) is the state-of-the-art algorithm for blind source separation (BSS) in the
determined situation (the number of microphones is greater than or equal to that of source signals). ILRMA achieves
a great separation performance by modeling the power spectrograms of the source signals via the nonnegative
matrix factorization (NMF). Such a highly developed source model can solve the permutation problem of the
frequency-domain BSS to a large extent, which is the reason for the excellence of ILRMA. In this paper, we further
improve the separation performance of ILRMA by additionally considering the general structure of spectrograms,
which is called consistency, and hence, we call the proposed method Consistent ILRMA. Since a spectrogram is
calculated by an overlapping window (and a window function induces spectral smearing called main- and side-lobes),
the time-frequency bins depend on each other. In other words, the time-frequency components are related to each
other via the uncertainty principle. Such co-occurrence among the spectral components can function as an assistant
for solving the permutation problem, which has been demonstrated by a recent study. On the basis of these facts, we
propose an algorithm for realizing Consistent ILRMA by slightly modifying the original algorithm. Its performance was
extensively evaluated through experiments performed with various window lengths and shift lengths. The results
indicated several tendencies of the original and proposed ILRMA that include some topics not fully discussed in the
literature. For example, the proposed Consistent ILRMA tends to outperform the original ILRMA when the window
length is sufficiently long compared to the reverberation time of the mixing system.

Keywords: Audio source separation, Convolutive mixture, Demixing filter estimation, Phase-aware signal processing,
Spectrogram consistency

1 Introduction

Blind source separation (BSS) is a technique for separat-
ing individual sources from an observed mixture without
knowing how they were mixed. BSS for multichannel
audio signals observed by multiple microphones has been
particularly studied [1-13]. The BSS problem can be
divided into two situations: underdetermined (the num-
ber of microphones is less than the number of sources)
and (over-)determined (the number of microphones is

 

*Correspondence: d-kitamura@ieee.org

'Daichi Kitamura and Kohei Yatabe contributed equally to this work.
‘National Institute of Technology, Kagawa College, 355 Chokushi, Takamatsu,
Kagawa, 761-8058, Japan

Full list of author information is available at the end of the article

o) Springer Open

 

greater than or equal to the number of sources) cases.
This paper focuses on the determined BSS problem, as
high-quality separation can be achieved compared with
the underdetermined BSS methods.

Independent component analysis (ICA) is the most pop-
ular and successful algorithm for solving the determined
BSS problem [1]. It estimates a demixing matrix (the
inverse system of the mixing process) by assuming sta-
tistical independence between the sources. For a mixture
of audio signals, ICA is usually applied in the time-
frequency domain via the short-time Fourier transform
(STFT) because the sources are mixed up by convolution.
This strategy is called frequency-domain ICA (FDICA)

© The Author(s). 2020 Open Access This article is licensed under a Creative Commons Attribution 4.0 International License, which
permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit
to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The

images or other third party material in this article are included in the article’s Creative Commons licence, unless indicated
otherwise in a credit line to the material. If material is not included in the article’s Creative Commons licence and your intended
use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the
copyright holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0/.
Kitamura and Yatabe EURASIP Journal on Advances in Signal Processing

[2] and independently applies ICA to the complex-valued
signals in each frequency. Then, the estimated frequency-
wise demixing matrices must be aligned over all frequen-
cies so that the frequency components of the same source
are grouped together. Such alignment of the frequency
components is called a permutation problem [3-6], anda
complete solution to it has not been established. There-
fore, a great deal of research has tackled this problem.

To avoid the permutation misalignment as much as
possible, various sophisticated source models have been
proposed. Independent vector analysis (IVA) [7-10] is
one of the most successful methods in the early stage
of the development. It assumes higher-order dependen-
cies (co-occurrence among the frequency components) of
each source by utilizing a spherical generative model of
the source frequency vector. This assumption enables IVA
to simultaneously estimate the frequency-wise demix-
ing matrices and solve the permutation problem to a
large extent using only one objective function. It has
been further developed by improving its source model.
One natural and powerful extension of IVA is indepen-
dent low-rank matrix analysis (ILRMA) [11, 12], which
integrates the source model of nonnegative matrix fac-
torization (NMF) [14, 15] based on the Itakura—Saito
divergence (IS-NMF) [16] into IVA. This extension has
greatly improved the performance of separation by tak-
ing the low-rank time-frequency structure (co-occurrence
among the time-frequency bins) of the source signals into
account. ILRMA has achieved the state-of-the-art perfor-
mance and been further developed by several researchers
[17-29]. In this respect, ILRMA can be considered the
new standard of the determined BSS algorithms. How-
ever, the separation performance of IVA and ILRMA
is still inferior compared to the ideal performance of
ICA-based frequency-domain BSS. In [30], the perfor-
mances of IVA and ILRMA were compared with that of
FDICA with perfect permutation alignment using refer-
ence sources (ideal permutation solver), and it was con-
firmed that there is still a noticeable room for improve-
ment of ILRMA-based BSS. In fact, [VA and ILRMA often
encounter the block permutation problem, that is, group-
wise permutation misalignment of components between
sources [31].

The consistency of a spectrogram is another promis-
ing approach for solving the permutation problem. A
recent study has shown that STFT can provide some effec-
tive information related to the co-occurrence among the
time-frequency bins [32]. Since an overlapping window is
utilized in STFT, the time-frequency bins are related to
each other based on the overlapping segments. The fre-
quency components within a segment are also related to
each other because of the spectral smearing called main-
and side-lobes of the window. In other words, the time-
frequency components are not independent but related to

(2020) 2020:46 Page 2 of 35

each other via the uncertainty principle of time-frequency
representation. Such relations have been well-studied in
phase-aware signal processing [33-43] by the name of
spectrogram consistency [44-47]. In the previous study
[32], the spectrogram consistency was imposed on BSS
to help the algorithm solve the permutation problem.
This is an approach very different from the conventional
studies of determined BSS because it utilizes the general
property of STFT independent of the source model (in
contrast to the abovementioned methods that focused on
modeling of the source signals without considering the
property of STFT). As the spectrogram consistency can
be incorporated with any source model, its combination
with the state-of-the-art algorithm should achieve a high
separation performance.

However, the paper that proposed the combination of
consistency and determined BSS [32] only showed the
potential of consistency in an experiment using FDICA
and IVA. The paper claimed that it was a first step of
incorporating the spectrogram consistency with deter-
mined BSS, and no advanced method was tested. In par-
ticular, IERMA was not considered because its algorithm
is far more complicated than that derived in [32], and
thus, it is not clear whether (and how much) the spectro-
gram consistency might improve the state-of-the-art BSS
algorithm.

In this paper, we propose a new variant of ILRMA
called Consistent ILRMA that considers the spectrogram
consistency within the algorithm of ILRMA. The combi-
nation of IS-NMF and spectral smoothing of the inverse
STFT (see Figs. 1 and 2 in Section 2.3) achieves the
source modeling for a complex spectrogram. In particu-
lar, the spectral smearing in the frequency direction ties
the adjacent frequency bins together, and this effect of
spectrogram consistency helps ILRMA to solve the per-
mutation problem. Since consistency is a concept depend-
ing on the parameters related to a window function, we
extensively tested the separation performance of Consis-
tent ILRMA through experiments with various window
lengths and shift lengths. The results clarified several
tendencies of the conventional and proposed methods,
including that the proposed method outperforms the
original ILRMA when the window length is sufficiently
long compared to the reverberation time of the mixing
system.

2 Permutation problem of frequency-domain BSS
and spectrogram consistency

2.1 Formulation of frequency-domain BSS

Let the /th sample of a time-domain signal be denoted
as x[/], and N source signals be observed by M micro-
phones. Then, the /th samples of the multichannel source,
observed, and separated signals are respectively denoted
as:
Kitamura and Yatabe EURASIP Journal on Advances in Signal Processing

(2020) 2020:46 Page 3 of 35

 

| Sart |?

Frequency

 
 
 

Frequency

Frequency

Time

Fig. 1 Inconsistent power spectrograms |Sart|* (left column) and their consistent version (right column) obtained by applying inverse STFT and
STFT. The top-left spectrogram is artificially produced with random phase. The middle-left and the bottom-left spectrograms are music and speech
signals with random dropout. Enforcing spectrogram consistency can be viewed as a smoothing process of the inconsistent spectrogram along

both time and frequency axes

s{J] =[si[Z],s2[1],---,sn[l],---swd] J’ ERY, (1)
x[1] = [oi [l],xol,---%mEl],---xul 0] € RY, (2)
WA] = [nl 2l4,--- anol, ll] I eRY, (3)

where 1 = 1,---,N,m=1,---,M,and/=1,--- ,Lare
the indexes of sources, microphones (channels), and dis-
crete time, respectively, and -' denotes the transpose. BSS
aims at recovering the source signal s from the observed
signal x, i.e., making y as close to s as possible.

In the frequency-domain BSS, those signals are handled
in the time-frequency domain via STFT. Let the window
length and shifting step of STFT be denoted as Q and
T, respectively. Then, the jth segment of a signal z[/] is
defined as:

el =[2[G-rt1],2[G-Dr+2],--- .{@—-De+Q]]",
= [41,24 [21,-- 2g], 2 Q] l E RY,
(4)

where j = 1,---,/ and g = 1,--- ,Q are the indexes of
the segments and in-segment samples, respectively, and

ISTFTy (ISTFT 3, (Sart))|?

 
 

 

Time

 

the number of segments is given by J] = L/t with some
zero-padding for adjusting the signal length L if necessary.
STFT of a signal z = [ z[1], z[2],---,z[Z] ]'€ R* is

denoted by:
Z =STFT»(z) €C'”, (5)
where the (i, /)th bin of the spectrogram Z is given as:
Q
zy = > olq) Lg) et VEVIE (6)
q=l

i = 1,--- ,/ is the index of frequency bins, F is an inte-
ger satisfying |F/2| + 1 = J, [-| is the floor function,
1 denotes the imaginary unit, and @ is an analysis win-
dow. The inverse STFT with a synthesis window @ is also
defined in the usual way and denoted as ISTFT93(-). In
this paper, we assume that the window pair satisfies the
following perfect reconstruction condition:

z = ISTETs (STET@(z)) Vz eR’. (7)
Kitamura and Yatabe EURAS/P Journal on Advances in Signal Processing

(2020) 2020:46 Page 4 of 35

 

|S?

600 600

BK
oO
oO

400

NO
So
oO

200

Frequency [Hz]

 

0 5

|S2|?
600 600

400

200

Frequency [Hz]

 

0
0 5 10 15 0 5

Time [s]

|$,|?

Frequency i

||?

Frequency oa

Time [s]

original source signals |Sp|?,

 

Ise)

   

seme

 

Time [s]

(a) Music signals: guitar (top row) and vocals (bottom row)

soem)|

. Bes tl ay pr

seem)|

- AEE pike Ee

Time [s]
(b) Speech signals: female (top row) and male (bottom row)

Fig. 2 Smoothing effect of spectrogram consistency applied to permutation misaligned signals: a music and b speech. The left column shows the

and the center column shows their randomly permuted versions, which simulates the permutation problem and is

denoted as seem) The right column shows the consistent versions of sere), The smoothing effect mixes up the signals

ISTFT., (ISTFT=(S?™))) 2

600

400

200

 

0
10 15 0 5 10 15

500 SEF SwUISTFTS (sm) 2

400

200

 

0
10 15 0 5 10 15

Time [s]

   
 

ISTFT.Y(ISTFT ire)

 
 

srr re (ISTFT;, serm))

Time [s]

 

 

By applying STFT, the (i, /)th bin of the spectrograms of
source, observed, and separated signals can be written as:

T
Sij = [ sii, Sij25 ve » Sijns .° - Sin | € CN (8)
T
xy = [xij Xi20°+ + Xijims Xm | €C™, (9)
T
Vij = [ vin Vij25 "9 Vins ** “yin | € CN, (10)

We also denote the spectrograms corresponding to the
nth or mth signals in (8)—-(10) as S, € C/*/, X, € CY,
and Y, € C!*/, whose elements are Sijins Xijm, and Yijn;
respectively. In the ordinary frequency-domain BSS, an
instantaneous mixing process for each frequency bin is
assumed:

xij = Ajsij, (11)

where A; ¢ C™** is a frequency-wise mixing matrix. The

mixture model (11) is approximately valid when the rever-
beration time is sufficiently shorter than the length of the
analysis window used in STFT [48].

Hereafter, we consider the determined case, i.e, M = N.
In this case, BSS can be achieved by estimating the inverse
of A; for all frequency bins. By denoting an approximate
inverse as W; & A", the separation process can be
written as:

Vii = Wixi, (12)
where W; = [Wi1,Wi2,--- Win] e CNX isa frequency-
wise demixing matrix and - denotes the Hermitian trans-
pose. The aim of a determined BSS algorithm is to find
Kitamura and Yatabe EURASIP Journal on Advances in Signal Processing

the demixing matrices for all frequency bins so that the
separated signals approximate the source signals.

2.2 Permutation problem in determined BSS

In practice, the scale and permutation of the separated sig-
nals are unknown because the information of the mixing
process is missing. That is, when the separation is cor-
rectly performed by some demixing matrix W; as in (12),
the following signal is also a solution to the BSS problem:

Vj = Wixi (Wi = D;P; Wi) (13)
where D; €¢ CN*% and P; € {0,1}*** are arbitrary diag-
onal and permutation matrices, respectively. While the
signal scale can easily be recovered by applying the back
projection [49], the permutation of the estimated signals
Vij must be aligned for all frequency bins, i.e., P; must be
the same for all i. This alignment of the permutation of
estimated signals is the permutation problem, which is the
main obstacle of the frequency-domain determined BSS.

In FDICA, a permutation solver (realignment pro-
cess of Pj) is utilized as a post-processing applied to
the frequency-wise separated signals Vij [4-6]. In recent
frequency-domain BSS methods, an additional assump-
tion on sources (or source model) is introduced to circum-
vent the permutation problem. For example, IVA assumes
simultaneous co-occurrence of all frequency components
in the same source, and ILRMA assumes a low-rank struc-
ture of the power spectrogram Y,. Other source models
have also been proposed for improving the separation per-
formance [50—52]. These source models can avoid the
permutation problem to some extent during the estima-
tion of W;. Recent developments of determined BSS have
been achieved via the quest to find a better source model
that represents the source signals more precisely.

2.3 Solving permutation problem by spectrogram
consistency

A recent paper reported another approach for solving the
permutation problem based on the general property of
STFT called spectrogram consistency [32]. The consis-
tency is a fundamental property of a spectrogram. Since
any time-frequency representation has a theoretical limi-
tation called the uncertainty principle, the time-frequency
bins of a spectrogram are not independent but related to
each other. The inverse STFT always modifies the spec-
trogram Z,, that violates this kind of inter-time-frequency
relation so that the relation is recovered. That is, a
spectrogram Z,, properly retains the inter-time-frequency

relation if and only if
E(Zy) = Zy — STFT» UISTFTS(Z,)) (14)

is zero, i.e., ||E(Z,,)|| = 0 for anorm ||-||. Such spectrogram
Zy satisfying ||E(Z,,)|| = 0 is said to be consistent.

(2020) 2020:46 Page 5 of 35

Figure 1 demonstrates the effect of spectrogram con-
sistency, where Sart € Cc! is an artificially produced
complex-valued spectrogram and |Sart| is its power spec-
trogram. The notation | - |? for a matrix input repre-
sents the element-wise squared absolute value. By apply-
ing STFT, (ISTFT53(.)), the inconsistent spectrogram Sart
shown in the left column of Fig. 1 is converted into the cor-
responding consistent spectrogram, which is a smoothed
version of Sat, as Shown in the right column. This smooth-
ing process occurs because the main- and side-lobes of the
window function (and the overlap-add process) spread the
energy of a time-frequency bin.

Since the inverse STFT is a process of recovering the
consistency (the inter-time-frequency relation), it has the
capability of aligning the frequency components. This is
also demonstrated in Fig. 2. As a simulation of the per-
mutation problem, the frequency bins in S; and S2 were
randomly shuffled to obtain the spectrogram with per-
mutation misalignment, giperm) (the center column in the
figure), which is a typical output signal of FDICA. Note
that these misaligned spectrograms are perfectly sepa-
rated for each frequency because each time-frequency bin
contains only one of the two sources. By enforcing spec-
trogram consistency, the smoothing process spreads the
time-frequency components as shown in the right col-
umn of Fig. 2. In other words, the inverse STFT mixes up
the separated signals if the frequency-wise permutation
is not aligned correctly. Therefore, enforcing consistency
within a BSS algorithm by applying STFT,USTFT3(-))
can improve the separation performance to some extent
[32].

3 Proposed method

By incorporating spectrogram consistency into ILRMA,
we propose a novel BSS method named Consistent
ILRMA. In this section, after stating our motivation and
contributions, we first review the standard ILRMA intro-
duced in [11, 12] and then propose the consistent version
of ILRMA with an algorithm that achieves Consistent
ILRMA and is openly available on the web.

3.1 Motivations and contributions

The previous paper [32] only reported that the perfor-
mances of traditional BSS algorithms, FDICA and IVA,
were improved by enforcing consistency during the esti-
mation of the demixing matrix Wj. In addition, no
detailed experimental analysis related to STFT parame-
ters was provided, even though the parameters of window
functions in the STFT and inverse STFT directly affect the
smoothing effect of spectrogram consistency.

The spectrogram consistency is a general property of
STFT, and therefore, it can be combined with any source
model for determined BSS. Its combination with state-
of-the-art models, including ILRMA, is of great interest
Kitamura and Yatabe EURASIP Journal on Advances in Signal Processing

because the current mainstream algorithm for determined
audio source separation is centered on ILRMA, which
is based on an NMF-based richer time-frequency source
model. Indeed, many recent papers are based on the
framework of ILRMA [17-29]. Even though combining
ILRMA with the spectrogram consistency should be able
to exceed the limit of existing BSS algorithms, no such
method has been investigated in the literature.

In this paper, we propose a new BSS algorithm that com-
bines ILRMA and spectrogram consistency. Our first con-
tribution is an algorithm that achieves Consistent ILRMA
by inserting STFT,(ISTFT%(-)) into the iterative opti-
mization algorithm of ILRMA. The second contribution
is to apply a scale-aligning process called iterative back
projection within the iterative algorithm. This process
enhances the separation performance when it is combined
with spectrogram consistency. The third contribution is
an experimental finding that spectrogram consistency
can work properly with the iterative back projection. We
found that both Consistent IVA and Consistent ILRMA
require iterative back projection to achieve a good perfor-
mance. Our fourth contribution is to provide the massive
experimental results for several window functions, win-
dow lengths, shift lengths, reverberation times, and source
types. We also provide discussions for clarifying the ten-
dency of ILRMA with spectrogram consistency.

3.2 Standard ILRMA [12]

The original ILRMA [12] was derived from the follow-
ing generative model of the spectrograms of the separated
signals:

1 , |?
Fr ~ ps) = [TNC (orn) =[T peso (—2),

ij ij

 

(15)

where N; (1,17) is the circularly symmetric complex Gaus-
sian distribution with mean yw and variance r. In this
model, the source component yj, is assumed to obey a
zero-mean and isotropic distribution, i.e., the phase of
yin is generated from the uniform distribution in the
range [0,27) and the real and imaginary parts of yi,
are mutually independent. The validity of this assump-
tion is shown in the Appendix. The variance rj, can be
viewed as an expectation value of Lviinl?- This variance
rin aS a two-dimensional array indexed by (i,j) is denoted

as Ry € Roe , which is called the variance spectrogram
corresponding to the uth source. In ILRMA, the variance
matrix R,, is modeled using the rank-K NMF, as:

R, = TV (16)

where T,, € ROS and V,, € Ree ! are the basis and acti-
vation matrices in NMF. The basis vectors in 7T,,, which

(2020) 2020:46 Page 6 of 35

represent spectral patterns of the nth source signal, are
indexed by k = 1,---,K. As in FDICA, statistical inde-
pendence between the source signals is also assumed in
ILRMA:

PY, Yo,---,¥n) =| [ p(n). (17)

ILRMA estimates the demixing matrix W; so that the
power spectrograms of the separated signals |Y,,|* have
a low-rank structure that can be well-approximated by
T,V, with small K. This BSS principle of ILRMA is
illustrated in Fig. 3. When the low-rank source model
can appropriately fit to the power spectrograms of the
original source signals |S,,|”, ILRMA provides an excel-
lent separation performance without explicitly solving the
permutation problem afterward.

The demixing matrix W; and the nonnegative matrices
T,, and V,, can be obtained through maximum likelihood
estimation. The negative log-likelihood to be minimized,
denoted by Z, is given as [12]:

L XM);

— log p(¥1, Y2,---

— log p(X1, X2,°°-
— } ‘log |det Ww?

ij

aD aay (ee fal

ijn » k Likn Vkjin

, YN),

lle

+log S likn vs ,
k

(18)

where = denotes equality up to constant factors, and
tikn > O and vg, > O are the elements of T, and Vy,
respectively. The minimization of (18) can be performed
by iterating the following update rules for the spatial
model parameters,

   

Win <— xix, (19)
m 7 Stans <a iknYkin
Win <— Willy) en (20)
1
Win <— Win (wij UinWin) *, (21)
Vijn <— Win Xijp (22)
and for the source model parameters,
2 —2
i Lyvijn| oe tik'nVk'jn) Vin
likn <— likn | Too] (23)
je tiknYK in) Vein
2 ~2
: +. ) t; 1 VE t;
Vkin < Vkjin i \vijn| (Oy ik’n Kin) in (24)

i Oe tik nVk'jn) ' likn

where e,, € {0,1} is the unit vector with the mth element
equal to unity. Update rules (19)—(24) ensure the mono-
tonic non-increase of the negative log-likelihood function
Kitamura and Yatabe EURASIP Journal on Advances in Signal Processing (2020) 2020:46 Page 7 of 35

 

! Low-rank approximation by NMF

Observed signal

2;|I]

£1] ww

Update demixing matrix so that estimated signals
are mutually independent and have low-rank
time-frequency structures

Fig. 3 BSS principle of standard ILRMA

yi(l]

Frequency-wise
demixing matrix

 

 

Estimated signal I

— iis malay | |?

 

   
  

 

>

 

 

 

 

 

 

 

L. After iterative calculations of updates (19)—(24), the
separated signal can be obtained by (12).

Equation 22 is equivalent to beamforming [53] to xj
with the beamformer coefficients w;,. Thus, FDICA, IVA,
and ILRMA can be interpreted as an adaptive estima-
tion process of beamforming coefficients without having
to know the geometry of microphones and sources [54].
For this reason, the estimated signal Y,, obtained by (22)
is a complex-valued spectrogram, and we do not need to
recover its phase components using, for example, Griffin—
Lim algorithm-based techniques [37—40, 43, 55-59]. Both
the amplitude and phase components of each source are
recovered by the complex-valued linear separation filter
Win.

3.3. Proposed Consistent ILRMA

To further improve the separation performance of the
standard ILRMA, we introduce the spectrogram consis-
tency into the parameter update procedure. In the pro-
posed Consistent ILRMA, the following combination of
forward and inverse STFT is performed at the beginning
of each iteration of parameter updates:

Y, <— STFT,CUSTFTS(Yx,)). (25)

This procedure is the projection of the spectrogram of
a separated signal Y, onto the set of consistent spec-
trograms [32]. That is, STFT,(UISTFTS(Y,,)) performs
nothing if Y, is consistent, but otherwise, it smooths
the complex spectrogram Y,, by going through the time
domain, so that the uncertainty principle is satisfied.

In Consistent ILRMA, the calculation of (25) is per-
formed in each iteration of parameter updates based on
(19)—(24). Enforcing the spectrogram consistency for the
temporary separated signal Y, in each iteration guides
the parameters W;, T,,, and V,, to better solutions, which
results in higher separation performance compared to that
of conventional ILRMA.

Note that this simple update (25) may increase the value
of the negative log-likelihood function (18), and therefore,
the monotonicity of the algorithm is no longer guaran-
teed. However, we will see later in the experiments that

the value of the negative log-likelihood function stably
decreases as in the standard ILRMA. The amount of the
inconsistent component (14) also settles down to some
specific value after several iterations.

3.4 Iterative back projection
Since frequency-domain BSS cannot determine the scales
of estimated signals (represented by D; in (13)), the spec-
trogram of a separated signal Y,, after an iteration is
inconsistent due to the scale irregularity. To take full
advantage of the projection enforcing spectrogram con-
sistency in (25), we also propose applying the following
back projection at the end of each iteration so that the
frequency-wise scales are aligned.

In determined BSS, the back projection is a standard
procedure for recovering the frequency-wise scales. It can
be written as [49]:

Vin — Ww; (e, 09) = VijnXins (26)

where Yin = [ Vint» Vijn2s ot Jiinm | € C™ is the (i, j)th
bin of the scale-fitted spectrogram of the nth separated
signal, Xin = [AimiAin2--- sAinm]: € C™ is a coeffi-
cient vector of back projection for the nth signal at the ith
frequency, and o denotes the element-wise multiplication.
In the proposed method, this update (26) is performed
at the end of each iteration so that the projection (25) at
the beginning of the next iteration properly smooths the
spectrograms without the effect of scale indeterminacy.

One side effect of this back projection is that the value
of the negative log-likelihood function (18) is also changed
due to the scale modification. In IVA, this problem can-
not be avoided because the only parameter in IVA is the
demixing matrix W;. However, in ILRMA, since both
the demixing matrix W; and the source model parame-
ter T,,V,, can determine the scale of estimated signal Y,,
the likelihood variation can be avoided by appropriately
adjusting w;, and T,, after the back projection. To pre-
vent the likelihood variation, the following updates are
required after performing (26):
Kitamura and Yatabe EURASIP Journal on Advances in Signal Processing

Algorithm 1 Consistent ILRMA
LJ
i=1j=1’
LJ

Output: (957) jos

1: Initialize {Tn}y_y {Vinny (Wit,

2: for iter = 1,2,--- ,maxliter do

3: | Ensure consistency by calculating (25) Vu

4: Update source model by calculating (23) and (24)

Input: {xi} maxliter

Vi,j,k,n
5: Update spatial model by calculating (19)-—(22)
Vi, j,n
6: Apply back projection by calculating (26) Vi, j, 1
7: Update parameters by calculating (27)-(29)
Vi,j,k,n
s: end for
Win <—— Win diner? (27)
Vijn <— Win Xijp (28)
2
likn <— likn JA inamtges , (29)

 

where Mref is the index of the reference channel utilized in
the back projection.

The overall algorithm of the proposed Consistent
ILRMA is summarized in Algorithm 1. The iterative
loop for the parameter optimization appears in the sec-
ond to eighth lines. The spectrogram consistency of
the temporary separated signal Y, is ensured in the
third line, and the iterative back projection is applied
in the sixth and seventh lines. Note that an algo-
rithm for the conventional ILRMA can be obtained
by performing only the fourth and fifth lines (ie.
ignoring the third, sixth, and seventh lines). A Python
code of the conventional ILRMA is openly avail-
able online (https://pyroomacoustics.readthedocs.io/en/
pypi-release/pyroomacoustics.bss.ilrma.html), and there-
fore, the proposed Consistent ILRMA with Python
can be easily implemented by slightly modifying the
codes. A MATLAB code of Consistent ILRMA is also
available online (https://github.com/d-kitamura/ILRMA/
blob/master/consistentILRMA.m).

4 Experiments

In this section, we conducted two experiments using
synthesized and real-recorded mixtures. The synthesized
mixtures were produced by convoluting the impulse
responses to dry audio sources, while the real-recorded
mixtures were actually recorded by using a microphone
array in an ordinary room with ambient noise.

(2020) 2020:46 Page 8 of 35

4.1 BSS of synthesized mixtures

4.1.1 Conditions

We conducted determined BSS experiments using synthe-
sized music and speech mixtures with two sources and
two microphones (N = M = 2). The dry sources of music
and speech signals, listed in Table 1, were respectively
obtained from professionally produced music
and underdetermined separation tasks pro-
vided as a part of SiSEC2011 [60]. They were convoluted
with the impulse response E2A (Tg = 300 ms) or JR2
(Té9 = 470ms), obtained from the RWCP database
[61], to simulate the multichannel observation signals.
The recording conditions of these impulse responses are
shown in Fig. 4.

In this experiment, we compared the performance of
six methods: three conventional and three proposed. The
conventional methods were the standard IVA [10], Con-
sistent IVA [32], and standard ILRMA [11]. The proposed
methods were Consistent IVA with iterative back projec-
tion (Consistent IVA+BP), Consistent ILRMA, and Con-
sistent ILRMA with iterative back projection (Consistent
ILRMA+BP). For all methods, the initial demixing matrix
was set to an identity matrix. For the ILRMA-based

Table 1 Music and speech dry sources obtained from SiSEC2011

 

 

 

 

Signal Data name Source (1/2)
Music 1 bearlin-roads acoustic_guit_
main/vocals
Music 2 bearlin-roads piano /acoustic_
guit_main
Music 3 bearlin-roads piano/vocals
Music 4 another_dreamer-the_ones_we_love — guitar/vocals
Music 5 another_dreamer-the_ones_we_love — drums/guitar
Music 6 fort_minor-remember_the_name violins_synth/
vocals
Music 7 fort_minor-remember_the_name vocals /drums
Music 8 tamy-que_pena_tanto_faz guitar/vocals
Music 9 ultimate_nz_tour guitar/synth
Music 10 ultimate_nz_tour drums/vocals
Speech 1 dev1_female4 src_1/src_2
Speech 2 dev1_female4 src_1/src_4
Speech 3 dev1_female4 src_2/src_3
Speech 4 dev1_female4 src_2/src_4
Speech 5 dev1_female4 src_3/src_4
Speech 6 dev1_male4 src_1/src_2
Speech 7 dev1_male4 src_1/src_4
Speech 8 dev1_male4 src_2/src_3
Speech 9 dev1_male4 src_2/src_4
Speech 10 dev1_male4 src_3/src_4

 
Kitamura and Yatabe EURASIP Journal on Advances in Signal Processing

(2020) 2020:46 Page 9 of 35

 

Impulse response E2A
(reverberation time: 769 = 300 ms)

 

5.66cm
(a)

Fig. 4 Recording conditions of impulse responses: a E2A and b JR2

 

Impulse response JR2
(reverberation time: T 5) = 470 ms)

 

 

 

methods, the nonnegative matrices T,, and V, were ini-
tialized using uniformly distributed random values in the
range (0, 1). Five trials were performed for each condition
using different pseudorandom seeds. The number of bases
for each source, K, was set to 10 for music mixtures and
2 for speech mixtures, where it was experimentally con-
firmed that these conditions provide the best performance
for the conventional ILRMA [11]. To satisfy the perfect
reconstruction condition (7), the inverse STFT was imple-
mented by the canonical dual of the analysis window. For
both Consistent IVA+BP and Consistent ILRMA+BP, the
iterative back projection was applied, where the reference
channel was set to Mre¢ = 1. Since the property of spec-
trogram consistency depends on the window length, shift
length, and type of window function, various combina-
tions of them were tested. The experimental conditions
are summarized in Table 2

For quantitative evaluation of the separation perfor-
mance, we measured the source-to-distortion ratio (SDR),
source-to-interference ratio (SIR), and source-to-artifact
ratio (SAR). In a noiseless situation, SDR, SIR, and SAR
are defined as follows [62]:

2

SDR = 10log,, Tle ial i = (30)
SIR = 10log,, eae sl 7 (31)
SAR = 10log,, dui lsll = 4 P (32)

deal

where s;[ J], ej[/], and e,[/] are the /th sample of tar-
get signal, interference, and artificial components of the
estimated signal, respectively, in the time domain. SIR

and SAR are used to quantify the amount of interfer-
ence rejection and the absence of artificial distortion of
the estimated signal, respectively. SDR is used to quan-
tify the overall separation performance, as SDR is in good
agreement with both SIR and SAR for determined BSS.

In this experiment, the energy of sources was not
adjusted, i.e., the energy ratio of sources (source-to-source
ratio) was automatically determined by the initial vol-
ume of the dry sources and the level of the impulse
responses. That is, the source-to-source ratio of each
mixture signal is different from the others. To equally eval-
uate the performances of different mixtures, we calculated
SDR improvement (ASDR) and SIR improvement (ASIR)
defined as:

ASDR = SDRsep —_ SDRinput
ASIR = SIR sep —_ SIRinput:

where SDRsep and SIRsep are the SDR and SIR of the sep-
arated signal, and SDRinput and SIRinput are the SDR and
SIR of the initial mixture signal input to the BSS methods.
Note that SAR improvement cannot be defined because
its value of the signal without artificial processing cannot
be defined (SARinput = 00).

Table 2 Experimental conditions

 

Hann/Hamming/Blackman window
64, 128, 256, 512, 768, 1024 ms
1/16, 1/8, 1/4, 1/2 of window length

Window function
Window length
Window shift length

Number of bases K for each source
in ILRMA

10 for music signals and 2 for
speech signals

Number of iterations 100

 
Kitamura and Yatabe EURASIP Journal on Advances in Signal Processing

(2020) 2020:46 Page 10 of 35

 

Value of cost function

 

 

Fig. 5 Values of negative log-likelihood function (18) of Consistent ILRMA+BP (window length, 256 ms; shift length, 32 ms)

Music 1 (E2A)

Speech 1 (E2A)
- = =Music 1 (JR2)
====Speech 1 (JR2)

Iteration

 

 

4.1.2 Results and discussions

Figure 5 shows examples of the value of the negative
log-likelihood function (18) of Consistent ILRMA+BP.
Although the algorithmic convergence of the proposed
method has not been theoretically justified because of the
additional projection (25), we experimentally confirmed a
smooth decrease of the cost function. We also confirmed
that such behavior was common for the other experi-
mental conditions and mixtures. This result indicates that
the additional procedure in the proposed method does
not have a harmful effect on the behavior of the overall
algorithm.

Figures 6 and 7 show examples of the energy of the
inconsistent components (14) of standard ILRMA and
Consistent ILRMA+BP. The energy was normalized by
that of the initial spectrograms in order to align the
vertical axis. Note that the energy of inconsistency com-
ponents is not directly related to the degree of per-
mutation misalignment or the separation performance.
These figures are shown to confirm whether the proposed
algorithm can properly reduce the degree of inconsis-
tency. These values are completely zero when the sep-
arated spectrograms are consistent, and hence, those at
the Oth iteration (the leftmost values) are zero because
no processing is performed at that point. By iterating
the algorithms, this energy rapidly increased because the
demixing matrix for each frequency independently tried
to process and separate the signals. However, the nor-
malized energy tended toward some specific values after
several iterations. We confirmed that the converged values
of Consistent ILRMA+BP were always lower than those
of standard ILRMA. This result indicates that Consis-
tent ILRMA+BP reduces the amount of the inconsistent
components and tries to make the separated spectrogram
more consistent. In addition, similar to Fig. 5, the algorith-
mic stability of Consistent ILRMA+BP can be confirmed
from Figs. 6 and 7.

Figures 8 and 9 summarize the SDR improvements for
the music mixtures and speech mixtures, respectively. The
window function was the Hann window. Each box con-
tains 50 results (i.e., 5 pseudorandom seeds x 10 mixtures
in Table 1), where ASDRs of the two separated sources in
each mixture were averaged. The central lines of the box
plots indicate the median, and the bottom and top edges
of the box indicate the 25th and 75th percentiles, respec-
tively. Each row corresponds to the same window length,
while each column corresponds to the same shift length.
As we conducted the experiment for six window lengths,
four shift lengths, and two impulse responses, each figure
consists of 6 x 4 x 2 subfigures. In each subfigure, six
boxes are shown to illustrate the results of (1) IVA, (2)
Consistent IVA, (3) Consistent IVA+BP, (4) ILRMA, (5)
Consistent ILRMA, and (6) Consistent ILRMA+BP. Since
the tendency of the results was the same as Figs. 8 and
9, we provide the SDR improvements for the other win-
dows (Hamming and Blackman) in the Appendix. The SIR
improvement and SAR are also given in the Appendix.

Since IVA and ILRMA assume the instantaneous mix-
ing model (11) for each frequency in the time-frequency
domain, the window length should be long relative to the
reverberation time to achieve accurate separation. At the
same time, too long a window degrades the separation
performance of IVA and ILRMA, as discussed in [30]. This
is because capturing the source activity and spectral pat-
terns becomes difficult for IVA and ILRMA as the time
resolution of the spectrograms becomes low due to a long
window. The robustness of [VA and ILRMA is also deteri-
orated by a long window because the effective number of
time segments is decreased. This trade-off of the separa-
tion performance caused by window length in STFT can
be easily confirmed from the results for both music (Fig. 8)
and speech (Fig. 9) mixtures, which is consistent with
the results in [30]. As shown in the figures, the perfor-
mance was poor for the shorter windows (< 128 ms), and
Kitamura and Yatabe EURASI/P Journal on Advances in Signal Processing

(2020) 2020:46 Page 11 of 35

 

EY )I2/ 1X lo

7 ™N
&
Y=’

IEC) 2/1Xllo

0 20 40

 

XX

the performance for the longer windows (> 768 ms) was
more varied than that of the shorter ones. The window
length best suited for these conditions (combinations of
source signals and impulse responses) seems to be around
256 ms or 512 ms. While the maximum achievable per-
formance becomes higher as the window length becomes
longer due to the mixing model (11), these results indi-
cate that the source modeling becomes difficult for both
IVA and ILRMA when the window length is too long. This
trade-off should be important for discussing the results
further.

By comparing the performances of the conventional
(IVA, Consistent IVA, and ILRMA) and proposed (Con-
sistent IVA+BP, Consistent ILRMA, and Consistent
ILRMA+BP) methods, we can see that the proposed
methods tend to outperform the conventional ones. Some
comparisons are made as follows:

ILRMA (Music 1 E2A)
ILRMA (Music 1 JR2)
= = =Consist. ILRMA+BP (Music 1 E2A)
—=== Consist. ILRMA+BP (Music 1 JR2)

 

60 80 100
Iteration

Window length: 256 ms, shift length: 32 ms

ILRMA (Music 1 E2A)
ILRMA (Music 1 JR2)

— — —Consist. IL_RMA+BP (Music 1 E2A)
—=== Consist. ILRMA+BP (Music 1 JR2)

 

60 80 100
Iteration

(b) Window length: 1024 ms, shift length: 512 ms

Fig. 6 Examples of normalized energy of inconsistent components (IEW) 51X15) of ILRMA and Consistent ILRMA+BP for music 1: a 256-ms-long
window and 32-ms shifting and b 1024-ms-long window and 512-ms shifting, where X = [X1,X2],Y =[Y1, Yo], and &€(-) is in (14)

e Conventional and proposed IVAs. The _ proposed
Consistent IVA+BP performed better than the con-
ventional IVAs (IVA and Consistent IVA) in Figs. 8b
and 9b when the window length was sufficiently long
(> 256 ms). In those cases, the conventional Consis-
tent IVA resulted in a worse performance than IVA,
which indicates that just using spectrogram con-
sistency cannot improve the performance of IVA.
This demonstrates the importance of the iterative
back projection when spectrogram consistency is
considered within determined BSS.

e Conventional and proposed ILRMAs. The pro-
posed Consistent ILRMA without BP performed
comparably to the conventional ILRMA. In Figs. 8a
and 9a, Consistent ILRMA _ performed better
than ILRMA when the window length was long
(> 768 ms). In contrast, in Figs. 8b and 9b, Consis-

 
Kitamura and Yatabe EURAS/P Journal on Advances in Signal Processing

(2020) 2020:46

Page 12 of 35

 

 

-1
49 x10

ILRMA (Speech 1 E2A)

ILRMA (Speech 1 JR2)
— = =Consist. ILRMA+BP (Speech 1 E2A)
===== (Consist. ILRMA+BP (Speech 1 JR2)

NEY) 2/ 1X lo

0) 20 40

——~
—”

a

x10"

—
oO)

 

60 80 100

Iteration
Window length: 256 ms, shift length: 32 ms

 

ILRMA (Speech 1 E2A)
ILRMA (Speech 1 JR2)

—
NO

NEY) 12/1IX lo

0 20 40

— = =Consist. ILRMA+BP (Speech 1 E2A)
=== = Consist. ILLRMA+BP (Speech 1 JR2)

 

60 80 100

Iteration

(b) Window length: 1024 ms, shift length: 512 ms

Fig. 7 Examples of normalized energy of inconsistent components (ECS / XI) of ILRMA and Consistent ILRMA+BP for speech 1: a
256-ms-long window and 32-ms shifting and b 1024-ms-long window and 512-ms shifting, where X = [X1,X2]1,Y =[Y 1, Yo], and &(-) is in (14)

 

 

tent ILRMA performed worse than ILRMA. This
is presumably because the scale ambiguity pre-
vented the spectrogram consistency from working
properly. By incorporating iterative back projection
into Consistent ILRMA, the proposed Consistent
ILRMA+BP performed better than the conventional
ILRMA. In the best situation (the top-left subfigure
of Fig. 8), Consistent ILRMA+BP performed 8 dB
better than ILRMA by bringing out the potential of
spectrogram consistency in determined BSS.

To further explain the experimental results, some
notable tendencies are summarized as follows:

e Short window. When the window length was short

(64 ms), all methods performed similarly in terms
of ASDR. This is because the achievable perfor-
mance was already limited by the window length that

was shorter than the reverberation time. This result
contradicted our expectation before performing the
experiment. Since enforcing the consistency spreads
the frequency components based on the main-lobe
of the window function, we expected that the ability
to solve the permutation problem would be higher
when the window length was shorter because of the
wider main-lobe. In reality, we found that the spec-
trogram consistency could assist IVA and ILRMA
except for the cases where the window length was
short (< 128 ms in this experiment) compared to the
reverberation time.

e Large window shift. When the shift length was 1/2

of the window length, the performance of ILRMA
significantly dropped compared to smaller shift
lengths (1/4, 1/8, and 1/16), especially when the
window length was long (e.g., 1024 ms). This is pre-
Kitamura and Yatabe EURASI/P Journal on Advances in Signal Processing

(2020) 2020:46 Page 13 of 35

 

Shift len.: 1/2 Shift len.: 1/4 Shift len.: 1/8 Shift len.: 1/16

 

Window len.: 1024 ms
ASDR [dB]
oa Oo Ga

-—Lai=}+—
+l +
-Cl__ +
List
CT}

 

 

|

Window len.: 768 ms
ASDR [aB]

 

 

uh
.
|

Window len.: 512 ms
ASDR [dB]
om oa
Set

 

 

Window len.: 256 ms
ASDR [dB]

 

Window len.: 128 ms
ASDR [cB]

 

 

Window len.: 64 ms
ASDR [dB]

 

 

 

 

 

 

 

 

 

IVA
Consis. IVA

IVA
Consis. IVA+BP }

Consis. IVA

IVA
Consis. IVA+BP

Consis. IVA

IVA
Consis. IVA+BP

Consis. IVA

Consis. IVA+BP
ILRMA

Consis. ILRMA

Consis. ILRMA+BP |
ILRMA

Consis. ILRMA

Consis. ILRMA+BP
ILRMA

Consis. ILRMA +

Consis. ILRMA+BP
ILRMA

Consis. ILRMA
Consis. ILRMA+BP

(a) E2A (300ms)

 

XX

sumably because the number of time segments was
small, i.e., NMF in ILRMA failed to model the source
signals from the given amount of data. In addition,
for a larger window, distinguishing spectral patterns
of the sources became difficult for IERMA due to the
time-directional blurring effect caused by a longer
window. Such performance degradation was alle-
viated for Consistent ILRMA+BP. This might be
because the smoothing process of the inverse STFT
provides some additional information for the source
modeling from the adjacent bins.

Window len.: 128 ms Window len.: 256 ms Window len.: 512 ms Window len.: 768 ms Window len.: 1024 ms

Window len.: 64 ms

Fig. 8 Average SDR improvements for synthesized music mixtures (music 1-10) with a E2A and b JR2, where Hann window is used in STFT

Shift len: 1/2 Shift len: 1/4 Shift len.: 1/8 Shift len.: 1/16

 

ASDR [dB]

 

 

ASDR [dB]

 

 

ASDR [dB]

 

 

ASDR [dB]

 

 

ASDR [dB]

 

 

ASDR [dB]

 

 

 

 

 

 

 

 

IVA
Consis. IVA

IVA
Consis. IVA+BP

Consis. IVA

IVA
Consis. IVA+BP

Consis. IVA +

IVA
Consis. IVA+BP

Consis. IVA

Consis. IVA+BP
ILRMA

Consis. ILRMA

Consis. ILRMA+BP
ILRMA

Consis. ILRMA

onsis. ILRMA+BP +
ILRMA

Consis. ILRMA

Consis. ILRMA+BP
ILRMA

Consis. ILRMA
Consis. ILRMA+BP +

(b) JR2 (470ms)

 

e Length of boxes. When the length of the box of
ILRMA was long, as in Figs. 8a and 9a, Consis-
tent ILRMA+BP was able to improve the perfor-
mance. Conversely, when the length of the box of
ILRMA was short, as in Figs. 8b and 9b, Consistent
ILRMA+BP was only able to slightly improve the
performance. Note that the vertical axes are differ-
ent. This result indicates that the achievable perfor-
mance decided by the mixing model (11) limits the
improvement obtained by spectrogram consistency.
Since consistency is the characteristic of a spectro-
Kitamura and Yatabe EURASI/P Journal on Advances in Signal Processing (2020) 2020:46 Page 14 of 35

 

Shift len.: 1/2 Shift len.: 1/4 Shift len: 1/8 Shift len.: 1/16 Shift len.: 1/2 Shift len.: 1/4 Shift len: 1/8 Shift len.: 1/16

 

 

 

20

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

IVA
IVA

Consis. VA} ZL
+. Ik
-O_}+—

IVA
Consis. IVA+BP

i iene AULA i ath
rarer rieriy
i avrg HG tui lit
uti ath Hilt
f ding-noalbee quale at Meath att

ILRMA
Consis. ILRMA

Consis. ILRMA+BP +—{_L}—

ILRMA

Consis. ILRMA} —{1L--—

Consis. IVA} —=—_L-—

-> Oh»

ILRMA-——CLL+—
Consis. ILRMA-——={LL-—
Consis. ILRMA+BP +—1_L +—

Consis. ILRMA+BP

Consis. VA}. {ZL
is. oo fh
——7{}+—
Consis. VA} “+L
is. +.
ILRMA;) —Zc}k—
Consis. ILRMA} LL

Consis. ILRMA+BP ——1_L+—

Consis. IVA+BP
Consis. IVA+BP
Consis. IVA+BP

(a) E2A (300ms)

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

IVA
Consis. IVA}. «
Consis. IVA+BP

IVA
Consis. IVA

IVA
Consis. IVA+BP

Consis. IVA

IVA
Consis. IVA+BP

Consis. IVA

ILRMA
Consis. IVA+BP

Consis. ILRMA

Consis. ILRMA+BP
ILRMA

Consis. ILRMA ¢

Consis. ILRMA+BP
ILRMA

Consis. ILRMA

Consis. ILRMA+BP
ILRMA

Consis. ILRMA
Consis. ILRMA+BP

(b) JR2 (470ms)

Fig. 9 Average SDR improvements for synthesized speech mixtures (speech 1-10) with a E2A and b JR2, where Hann window is used in STFT

 

 

gram, it cannot manage the mixing process. The
demixing-filter update of ILRMA, which is the same
for the conventional and proposed methods, man-
ages the mixing process. Hence, when the mixing
model has a mismatch with the observed condition,
there is less room for spectrogram consistency to
improve the performance.

e Improvement by consistency. The proposed method

tended to achieve a good performance when the
conventional ILRMA also worked well, e.g., Figs. 8a
and 9a. This tendency indicates that the spectro-

gram consistency effectively promotes the sepa-
ration when the estimated source Y, accurately
approaches the original source S, during the opti-
mization, as S, is naturally a consistent spectrogram.
This is the reason we feel that the consistency can be
an assistant of the frequency-domain BSS. An impor-
tant aspect is that the source model (e.g., NMF in
ILRMA) actually informs the separation cue, and the
spectrogram consistency enhances the separation
performance when the source modeling functions
correctly.
Kitamura and Yatabe EURASIP Journal on Advances in Signal Processing

4.2 BSS of real-recorded mixtures
4.2.1 Conditions
Next, we evaluated the conventional and proposed
methods using live-recorded music and speech mixtures
obtained from underdetermined separation
tasks in SiSEC2011 [60], where only two sources
were mixed to make the BSS problem determined
(M = N = 2). The signals used in this experiment are
listed in Table 3. The reverberation time of these signals
was 250 ms, and the microphone spacing was 1 m (see
[60]). Since these source signals were actually recorded
using a microphone array in an ordinary room with
ambient noise, the observed signals are more realistic
compared to those in Section 4.1.

For simplicity, in this experiment, we used STFT with
a fixed condition, the 512-ms-long Hann window with
1/4 shifting. The experimental conditions other than the
window were the same as those in Section 4.1.1.

4.2.2 Results and discussion

Figure 10 shows the results of live-recorded music
and speech mixtures. The absolute scores were lower
than those for the synthesized mixtures discussed in
Section 4.1.2 due to the existence of ambient noise. Still,
we can confirm the improvements of the proposed Con-
sistent [IVA+BP and Consistent ILZRMA+BP compared to
the conventional IVA and ILRMA, respectively, for both
the music (upper row) and speech (lower row) mixtures.
In particular, Consistent IVA+BP improved more than
4dB over IVA in terms of the median of the ASDR
of speech mixtures. Consistent ILRMA+BP achieved the
highest performance in terms of the median of the SDR
improvement for both music and speech mixtures. These
results confirm that the combination of spectrogram con-
sistency and iterative back projection can assist the sepa-
ration of determined BSS for a more realistic situation.

5 Conclusion

In this paper, we have proposed a new variant of the
state-of-the-art determined BSS algorithm called Con-
sistent ILRMA. It utilizes the smoothing effect of the
inverse STFT in order to assist the separation and enhance
the performance. Experimental results showed that the
proposed method can improve the separation perfor-
mance when the window length is sufficiently large (>
256 ms in the experimental condition of this paper). These
results demonstrate the potential of considering spectro-
gram consistency within the state-of-the-art determined
BSS algorithm. In addition, we experimentally confirmed
the importance of iterative back projection for consid-
ering spectrogram consistency within determined BSS.
It should be possible to construct a new source model
in consideration of the spectrogram consistency, which
can pave the way for the next direction of research on
determined BSS.

(2020) 2020:46 Page 15 of 35

Table 3 Live-recorded music and speech signals obtained from

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

SISEC201 1

Signal Source (1/2)

Music 1 dev1_nodrums_liverec_250ms_1m_sim_1/dev1_
nodrums_liverec_250ms_1m_sim_2

Music 2 dev1_nodrums_liverec_250ms_1m_sim_1/dev1_
nodrums_liverec_250ms_1m_sim_3

Music 3 dev1_nodrums_liverec_250ms_1m_sim_2/dev1_
nodrums_liverec_250ms_1m_sim_3

Music 4 dev1_wdrums_liverec_250ms_1m_sim_1/dev1_
nodrums_liverec_250ms_1m_sim_2

Music 5 dev1_wdrums_liverec_250ms_1m_sim_1/dev1_
nodrums_liverec_250ms_1m_sim_3

Music 6 dev1_wdrums_liverec_250ms_1m_sim_2/dev1_
nodrums_liverec_250ms_1m_sim_3

Music 7 dev2_nodrums_liverec_250ms_1m_sim_1/dev1_
nodrums_liverec_250ms_1m_sim_2

Music 8 dev2_nodrums_liverec_250ms_1m_sim_1/dev1_
nodrums_liverec_250ms_1m_sim_3

Music 9 dev2_nodrums_liverec_250ms_1m_sim_2/dev1_
nodrums_liverec_250ms_1m_sim_3

Music 10 dev2_wdrums_liverec_250ms_1m_sim_1/dev1_
nodrums_liverec_250ms_1m_sim_2

Music 11 dev2_wdrums_liverec_250ms_1m_sim_1/dev1_
nodrums_liverec_250ms_1m_sim_3

Music 12 dev2_wdrums_liverec_250ms_1m_sim_2/dev1_
nodrums_liverec_250ms_1m_sim_3

Speech 1 dev1_female4_liverec_250ms_1m_sim_1/dev1_
female4_liverec_250ms_1m_sim_2

Speech 2 dev1_female4_liverec_250ms_1lm_sim_3/dev1_
female4_liverec_250ms_1m_sim_4

Speech 3 dev1_male4_liverec_250ms_1m_sim_1/dev1_
male4_liverec_250ms_1m_sim_2

Speech 4 dev1_male4_liverec_250ms_1m_sim_3/dev1_
male4_liverec_250ms_1m_sim_4

Speech 5 dev1_female4_liverec_250ms_1lm_sim_1/dev1_
male4_liverec_250ms_1m_sim_2

Speech 6 dev2_female4_liverec_250ms_1lm_sim_3/dev1_
male4_liverec_250ms_1m_sim_4

Speech 7 dev2_female4_liverec_250ms_1lm_sim_1/dev1_
female4_liverec_250ms_1m_sim_2

Speech 8 dev2_female4_liverec_250ms_1lm_sim_3/dev1_
female4_liverec_250ms_1m_sim_4

Speech 9 dev2_male4_liverec_250ms_1m_sim_1/dev1_
male4_liverec_250ms_1m_sim_2

Speech 10 dev2_male4_liverec_250ms_1m_sim_3/dev1_
male4_liverec_250ms_1m_sim_4

Speech 11 dev2_male4_liverec_250ms_1m_sim_1/dev1_
female4_liverec_250ms_1m_sim_2

Speech 12 dev2_male4_liverec_250ms_1m_sim_3/dev1_

female4_liverec_250ms_1m_sim_4

 
Kitamura and Yatabe EURASI/P Journal on Advances in Signal Processing (2020) 2020:46

 

SDR imp. for music mixtures SIR imp. for music mixtures SAR for music signals

25 0
15
20 ° 15
10
_ _ 15 10
=, ©, a
x 5 a 10 ri
D 2 B
<J
5 0
0
0 -5
-5 *
5 -10
SDR imp. for speech mixtures 95 SIR imp. for speech mixtures 16 SAR for speech mixtures
15
14
20 ;
10 12
fra] 1 =
g @ 15 mS 10
a cc
n° D1 < 8
<] J ”
|. = 4 6
0 5 I
4
0 2

IVA
ILRMA
IVA
ILRMA
IVA
ILRMA

Page 16 of 35

Consis. IVA
Consis. IVA+BP
Consis. ILRMA

Consis. ILRMAt+BP

Consis. IVA
Consis. IVA+BP

Consis. ILRMA
Consis. ILRMAt+BP

Consis. IVA
Consis. IVA+BP

Consis. ILRMA

Consis. ILRMA+BP

Fig. 10 SDR improvements (left column), SIR improvements (center column), and SAR (right column) for live-recorded music and speech mixtures,

where STFT is performed using the 512-ms-long Hann window with 1/4 shifting. Top row shows the performances for music mixtures, and bottom
row shows the performances for speech mixtures

 

Appendix where q; and q2 are random variables, H (q,) and H (q2)
Independence between real and imaginary parts of are their entropy, and H (qj, q2) is the joint entropy of q1
spectrogram

and g2. Since the numerator of (35) corresponds to the
mutual information of gq; and q2, the symmetric uncer-
tainty coefficient can be interpreted as normalized mutual
information. When q; and q2 are mutually independent,
(35) becomes zero. In contrast, when qg; and qg2 are com-
pletely dependent, (35) becomes one.

We calculated the symmetric uncertainty coefficient
(35) between the real and imaginary parts of a time-
frequency bin obtained by applying STFT to music or
speech sources. Let s be a complex-valued time-frequency
bin of a source (the indexes of frequency and time are
omitted here). The independence between the real and
imaginary parts can be measured by C(Re(s), Im(s)),

The source generative model (15) assumes that the real
and imaginary parts of a source in the time-frequency
domain are mutually independent because the generative
model has a zero-mean and circularly symmetric shape in
the complex plane. The independence between real and
imaginary parts or amplitude and phase has been inves-
tigated, but its validity may depend on the parameters
of STFT. Independence can be measured by a symmetric
uncertainty coefficient [63-65]:

A(qi) + H(q2) — A(q1, q2)

C(q}, = 2 ;
(41 42) H(qy) + Hq)

(35)

 
Kitamura and Yatabe EURASI/P Journal on Advances in Signal Processing

(2020) 2020:46 Page 17 of 35

 

Symmetric uncertainty coefficient for music sources

 

1/2] 5.727e-05 | 5.9e-05 | 5.42e-05 | 6.559e-05 | 5.298e-05 | 8.842e-05

 

  
 
 

 

 

on

&) 1/4| 5.676e-05 | 5.755e-05 | 6.429e~05 | 6.788e-05 | 5.986e-05
5

© 1/8| 7.029e- -

€ 029e-05 5.992e-05

”Y

1/16 Onell S 4.336e-05 | 4.481e-05 | eheleley teres)

1024 768 512 256
Window length [ms]

128

64

. . 8 . -4
Symmetric uncertainty coefficient for music sources x10

 

4

1/2} 6.098e—05 | 5.592e—-05 | 3.459e—-05 | 4.811e-05 | 6.124e—05 | 9.318e-05

3.714e-05 | 4.355e-05 | 7.021e—-05 | 9.057e—-05 | 5.826e—05 | 0.0001514

1/4

   
  

Shift length

1/8 6.105e-05 | 3.98e-05 | WeeeKEZS |) 0.0001019 | 9.71e-05
1/16 eee RZ) 4.429e—-05 | 5.057e-05 0.0001619 | 0.0001001
768 128 64

1024 512 256
Window length [ms]

1

x10

Symmetric uncertainty coefficient for music sources
2

  
 

1/2| 6.665e—-05 | 8.833e—-05 | 7.133e—-05 | 8.318e—-05 | 5.264e-05
1/4 keel 5.302e-05 7.659e-05 | 6.278e-05
1/8} 4.544e-05 8.628e-05

1.5

Shift length

 

1/16 0.5

3.628e-05 | 4.79e—-05

1024 768 512 256

Window length [ms]

128 64

 

 

Shift length

(a) Hann window

Shift length

(b) Hamming window

Shift length

(c) Blackman window

Fig. 11 Symmetric uncertainty coefficient between real and imaginary parts for music and speech sources, where a Hann, b Hamming, or ¢
Blackman window is used in STFT. Left and right columns correspond to the music sources and speech sources, respectively

 

    
  
   

 

     

Symmetric uncertainty coefficient for speech sources x10
3
1/2| 6.449e—-05 | 9.839e-05 | 0.000119 | 7.71e-05 4.028e-05
2.5
1/4 7.317e—-05 | 8.726e-05 | 8.205e-05 | 7.674e—-05 | 2.863e-05 9
1/8| 8.012e-05 | 6.513e—-05 | 8.792e-05 | 9.485e-05 | 5.809e-05 | 8.69e—-05 15
1
1/16] 0.0001157 | 8.948e—-05 [MONK EI 3.303e—-05 | 8.972e-05 05
1024 768 512 256 128 64
Window length [ms]
Symmetric uncertainty coefficient for speech sources x104
1/2 5.912e-05 MMNOKGEN 3.35¢e-05 16
| 1.4
1/4 oleh Wek) 6.411e-05 ORT! 3.919e-05 1.2
1
1/8 |e) 5.594e-05 4.285e-05 | 7.62e-05 08
0.6
1/16 6.905e-05 4.658e-05 | 5.175e—-05 O4
1024 768 512 256 128 64
Window length [ms]
Symmetric uncertainty coefficient for speech sources x10
1/2 5.449e-05 | 7.591e-05
1.5
1/4 5.263e-05 | 7.9e-05 | 4.861e-05 5.222e-05
1/8| 7.777e—-05 | (ele /sv25 |) 7.899e-05 | 8.175e-05 | 7.216e—-05 | 6.983e-05 |
1/16 | 8.29e-05 | 6.379e-05 3.386e-05 | | 0.0001894 05
1024 768 512 256 128 64
Window length [ms]

 

 

where Re(-) and Im(-) return the real and imaginary
parts of an input complex value, respectively. Here,
H(Re(s)), H(Im(s)), and H(Re(s), Im(s)) were approxi-
mately obtained by calculating the histograms of Re(s) and
Im(s). The number of bins in the histograms was set to
10,000. We used the dry sources listed in Table 1: 15 music
(instrumental) and eight speech sources. The parameters
of STFT were the same as those in Section 4.

Figure 11 shows the symmetric uncertainty coeffi-
cients averaged over all bins and sources. Their values
C(Re(s), Im(s)) were almost zero for all STFT conditions
and source types (music or speech), and thus, the assump-
tion of independence between real and imaginary parts
is valid for music and speech sources. This fact leads

to the generative model assumed in ILRMA. Note that
those symmetric uncertainty coefficients validated the
independence of real and imaginary parts at each time-
frequency bin. That is, the inter-bin relation is not con-
sidered here. The proposed method captures such inter-
bin relations imposed by the spectrogram consistency,
which is not apparent in these bin-wise assessments of
independence.

Additional experimental results for synthesized mixtures

Figures 12-15, 16-21, and 22—27 show the SDR improve-
ments, SIR improvements, and SAR, respectively, for
synthesized music and speech mixtures. These figures
correspond to the results and discussions in Section 4.1.2.
Page 18 of 35

(2020) 2020:46

Kitamura and Yatabe EURAS/P Journal on Advances in Signal Processing

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

dda+VWUTl “s!suoD
VAT “S!S40D

VAY TI

dd+VAI ‘s!suop

VAI ‘S!SU0D

VAI

| da+VWUTI “sIsu0g

VIN TI “S!su0D
VAY TI

da+VAI s!suop
VAI ‘S!suod
VAI

dd+VWUTl ‘s!suoD
VA TI “S!S40D

VAY TI

dd+VAI ‘s!suod

VAI ‘S!SU0D

VAI

dé+VWUTl ‘S!suoD
VI TI “S!s4u0D

VU TI

da+VAl 's!suop

VAI 'S!SU0D

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

- = I

VAI

dd+VWUTl ‘s!suod
VIN TI “S!S40D

VAY TI

dd+VAI ‘s!suop

VAI ‘S!SU0D

VAI

dd+VWUTl ‘S!suog
VAT “S!s40D

jVANY TI

da+VAI ‘sisuog
VAI 's!suog
VAI

dd+VWUTl ‘Ss!suod
VINYTI “S!S40D

VAY TI

dd+VAI ‘S!suoD

VAI ‘S!SU0D

VAI

dd+VWUTl ‘Ss!suod
VA TI “S!S4u0D

VWI

dd+VAI ‘s!suoD
VAI ‘S!suoD
VAI

—

© —lo— —Lll-— ——cL-— — lL} —_L_-——» 1 -#—
> —Cor— “cl —cl + ol -—— -olK— + oh =
3 —Coe— —CL— + —_ + —L+-— —-——» oh -<
ol qT oH — — oie
£ HoH 4oIch oe 4L——}+— He - HoH
2} > —oe —ClLe— f—— + fot oe oe LL -—" + —-—
- —Cl —Coe — + —o+— Ho IK: *e
c —CoR— —CI + —LL-— —CLle— = += 4I--— +
= oo rh oH — Tr — —CIe
© Ick Ick oh 4+ ole . “ok
Opi eH Gi | ee GAB) Gs GM ey a AI ey
< —iLF —L —lL_-— Lene +L -—— +L
> —cole —ole I -— —o ++ —Cl-— (Ik - =
c —o — Te — oe —-— — + {oh—
2.0 oo qo oe — —o —ole
fe Hoc Hock ccoH ++ Hoh - HH
N —oLe ee — Ll -— ——L_-— lL -— + Le =
> —Coe —CI —I+-— — + CI +. HL oe
c —}+—: —_rF— + a a —I+-— HI +=
= Th IT oT r+ lor —Coe
fe —CIok coh —oe ++ — HH
7) —C —Ioh —I Hoe: ok - -Cik
2 GG se fo BP se SF BP SS Pp ese fF S oS Pp sek SF eB FS Bp se GF Pe CS Bp ese fF PF FS YS
I | | I | |
[ap] uasv [ap] uasV [ap] uasV [ap] uasV [ap] uasVv [ap] uasvV
SW ZO] “Ud] MOPUIM, SW gQ/ -Ud] MOPUIM SW ZIG ~Ud] MOpUIM SW QGZ ~Ud| MOpUIA, SW QZ] 7 Ud] MOPUIM, SU 7Q “Ud] MOPUI,
of oo + —_ 1 -— —_ + —_L + —lL —CLe
> oo lo —l + —ol —ClIo
en — — —r + — + —Coe—
3s —lo —lo —o —lo —Lo} Soc
£ — — —o T+ oo oe —CIe
a —{ 1 —o —__- — I ——I-— —ol
of a —_ + — — —lL_ —lL
=} oo lo — + —LL + + a
= —oo —lo ——l —lot —oole CIT
£ —___ a ee Sl Soo a —oie
“wa — I —oI —_ —C_ I —_I-— —oI
< —_ LF —_ —_ 1+ —_-— —rlL_ —lL oe
SF eo —loo — + —l + —c + — —Co-—
co ——_ + 4} —L— + — + —CI +
= —lo —L_ — —Lo —Co Hock
£ — 1 —— — a To —CIK
wv — 1 — — —C_T ——I-— —CI
9 | ee a el a — 1+} — —lL + —lL_-— —CL +
= oe — —_ + — + —- —oe
= —C_k ooo oT I 0k HCL
£ — 1k —le oo oe — oe —oIR
wa — To — —- —loe | Ie —CI-—
|

[ap] yasV
SW 7ZO| “Ud] MOpUI\

[ap] YasV
SW QQO/ -Ud| MOPUI\,

[ap] YasV
SW Z|G -Ud] MOPUI\,

[ap] YasV

SW 9GZ “U2a] MOpUIM

[ap] YasV

SW QZ]. Ud] MOpUIAA

[ap] YasV

SW 7Q -Ud]| MOPUIA,

(b) JR2 (470ms)

Fig. 12 Average SDR improvements for synthesized music mixtures (music 1-10) with a E2A and b JR2, where Hamming window is used in STFT

(a) E2A (300ms)

 

 
Page 19 of 35

(2020) 2020:46

Kitamura and Yatabe EURASI/P Journal on Advances in Signal Processing

 

 

 

Shift len.: 1/16

LE

)d8+VINU TI “SisuoD
VINTI “S!s4u0D

VAY TI

dd+VAI ‘s!suod

VAI ‘S!SU0D

VAI

 

dé+VWU TI ‘S!suoD
VAUTI “s!suod

VAY TI

dd+VAI ‘s!suop

VAI ‘S!SU0D

VAI

 

 

7) d8+VINU TI SisuoD
VIN TI “S!S40D

VAY TI

da+VAl 's!suoD

VAI ‘sisuog

VAI

 

 

 

 

 

 

 

 

 

 

 

 

 

dd+VWU TI “s!suod
VIUTI “S!su0D

VAY TI

dd+VAI ‘S!suop

VAI ‘S!SU0D

 

 

15 Shift len.: 1/2 Shift len.: 1/4 Shift len.: 1/8

o wo oO wo ow
I

[ap] YasV

Su ZO} Ue] MOpUl

Soe Se
[ap] YasV
SW QQ/ “Ud] MOPUIM

[ap] YasV
SW Z|G "Ud] MOpUIA,

10
5
0

-5

[ap] YasV
SW 9GZ “U2a] MOpUIM

[ap] YasV
SW QZ] “Ud] MOpUIA,

Oo wo oO Ww

[ap] YasV
SU fQ 7Ud] MOpUI\,

VAI
°

 

dd+VWU Tl “s!suog
VINYTI “S!S40D

VAY TI

7 d+VAI ‘s!suop

VAI ‘S!SU0D

VAI

 

 

dd+VWUu Tl “s!suod
7 VNU TI “S!suod

VAY TI

dd+VAI ‘s!suod

VAI “S!suod

VAI

 

 

dd+VWU Tl “s!suod
VIN TI “S!S40D

VAY TI

dd+VAI ‘s!suop

VAI ‘S!SU0D

VAI

 

 

Shift len. 1/2 Shift len.: 1/4 Shift len.: 1/8 Shift len.: 1/16

 

 

 

 

 

 

 

 

 

 

7 d8+VWNU TI “SisuoD
VIN TI “S!su0D

VAY TI

dd+VAI ‘s!suoD

VAI ‘S!suod

VAI

 

 

ow oO Wb oO

[ap] yasV
SW ZO} “U2] MopUIM

ow oOo WwW

[ap] YasV
SW QQ/ “Ud] MOpUIAA

ow Oo Ww

[ap] YasV
SW ZG 7Ud] MOpUIM

[aP] YaSV
SW 9GZ “U2a] MOpUIM

ow oO WwW

[ap] YasV
SW QZ] Ud] MOpUIAA

Ho oO WwW

[ap] YasV
SU 7Q “"Ud] MOpUIA,

oO

—

(b) JR2 (470ms)

Fig. 13 Average SDR improvements for synthesized music mixtures (music 1-10) with a E2A and b JR2, where Blackman window is used in STFT

(a) E2A (300ms)

 

 
 

Page 20 of 35

(2020) 2020:46

 

Kitamura and Yatabe EURAS/P Journal on Advances in Signal Processing

 

 

 

 

 

 

Shift len.: 1/2 Shift len: 1/4 Shift len: 1/8 Shift len.: 1/16

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

Shift len.: 1/2 Shift len: 1/4 = Shift len: 1/8 Shift len.: 1/16

 

 

 

 

 

 

 

 

 

 

 

 

 

20

. — foe _ —L + —LL-— — + —Eoore ~~ fj da+vwui ‘sisuog
. —o 0 + —LCI + —Coe - fle {va sisuog
—Co}— —l oR ——_ + —CI-+— — I} —ok- sf vw
—lor}+— — + —lor}— —CI +I} —ooH sf dg+VA‘sisuog
oH —lo To Io HH - Hoo | walsisuop
—oooe ee ee ee — Ll} —L + —CoH VAI
—LlLe 1 — LL -—— —CL + —_+— —Lo— = J dave “sisuog
a o_o — + —C + —LL + oo sf va 'sisuop
—ol-— ————T} —r}— —Co}— —ol}— —oo— sf yw
—lo}+— —}+— —1}— —Cl oe oo fdg+vAr'sisuog
oo} —I T+ ae 4Lr— HOI {Var‘sisuog
—oCooH a — + a —COh VAI
———— PO eae] OP ee FO ee ee Jaan sisuog
—Lro— | | —_ re + | | —I+— | | —r-— «| | —r— | | —To =f VNUTIsisuog
oo ——_T + —}— —l}+— —o}— —ooe sof wwe
+ a 1 . a — oo} oH = Jda+VAl'sisuog
I} — I oe a ol I Hoo | vaisisuog
—Clo 4 — ro —Ooo 40H VAI
- + ee eee —lL + —oL-— — Le fo — sd] da VNU “stsuog
.. —— TR —cCo —C —CloH —ClL + Co f yan 'sisuop
—o —Cr+— —I + — + —ooe sf wneT
I }+— — ——T—— : oo ooo oO = f daar ‘sisuog
oe —o +o CIT —o— Hoo: = {val sisuog
oe cree =e —Coe— Ih —Cl oe oh VAI
) lo °o o ° lo ° 6 ° lo ° io ° lo °o 6 ° lo ° ‘6 ° Lo °o o
[ap] uasV [ap] uasV [ap] uasV [ap] uasV [ap] yasV [ap] yasV
SW 7ZO] -Ud| MOpUI;, SW QQO/ -Ud]| MOPUI/[, SWI Z|G Ud] MOPUI/A SUI QGZ -Ud]| MOPUI/A SW QZ] -Ud] MOPUI/A SWI 7Q -“Ud] MOPUIAA
— —__L + —L —LCo_ —T toe |da+Vvwel “sisuog
—" + ——— + + —CI + —CL +4 oo Jynetsisuog
————————T}+— —————+— ————— + ——— + —oloH oe {ve
= a . CoH —Cob +o HH de+VAI ‘s!suog
——_ — ———— — io} MIE > |WAl'sisuog
————— ——— a —oo —l— SH lv
——_ — —_ + —lr —L_ —L J] dV “sisuog
—— +} —— ——I + —— —L —Ooe Jywetsisucg
——————T-— ————_ + ——_ + —l— — —ooe fe
. = . ore : oo —loH oo OH da+VAI ‘sisuog
—_ Tr} ——— ——o —oo —o} MIE + |WAl'sisuop
———— ee ee —— —o —o-— Io {val
— — —_ + —CLl — —toe J da+vwai “sisuog
———_ + —_ T+ —Cro + —C —lLoH Oe {VWUl‘sisuog
—_l_ 1} ———_l ——lIt}+— —ol a a oo {vw
th CoH : CoH —Cob oe HOH de+VAl s!suog
——_ ——— — —T —} MK | vaAl'sisuop
——$ ——$L —l —Cob —le— — {val
— Ly} —————_ + —L_ + —L —e oo |de+vWUull “sisuog
a —— T+ —— —Col —oloe LO J vet ‘sisuog
————+ ———————I+— —L—}— ——C-}— —oo —ooeK {ye
oI : 4H . CCH —Co— + + HED» Jdg+var'sisuog
—_ Te} —— ~I| — Te | | “Te; | ——re | | ok {Ar ‘sisuog
LT — T+ — Te oro —CoR— —o {val
19 °S fey ° oS 19 ° wo ° 2 Ss 9 ° fe) °o 6 9 19 ° wo ° 6 9 ° Lo °o 6 19 ° ite) o o
[ap] uasV [ap] uasV [ap] uasV [ap] yasV [ap] yasV [ap] yasV
SW ZO] “Ud] MOpUI, SW gO/ ~Ud] MOPUIA, SW ZIG ~Ud] MOpUIA, SW QGZ ~ Ud] MOPUIAA SW QZ] - Ud] MOpUIAA SW 7Q “Ud] MOPUIN,

 

(b) JR2 (470ms)

Fig. 14 Average SDR improvements for synthesized speech mixtures (soeech 1-10) with a E2A and b JR2, where Hamming window is used in STFT

(a) E2A (300ms)

 
Page 21 of 35

(2020) 2020:46

Kitamura and Yatabe EURASI/P Journal on Advances in Signal Processing

 

 

 

be

 

 

A

 

 

 

 

Shift len: 1/2 Shift len.: 1/4 Shift len.: 1/8 Shift len.: 1/16

 

if hl

 

 

 

 

 

 

 

 

 

 

 

10

LO Oo

[ap] yasV
SW ¥ZO} “US| MOpUI

-35

[ap] uasV
SW gQ/ 7Ud] MOpUIM

[ap] uasV
SW Z|G “US| MOpUIAA

[ap] uasV
SU 9GZ “Ud] MOpUIM

[ap] yasV
SW §Z| “Ud] MOpUIA,

dd+VWNU TI S!suog
VATI “S!S4U0D

VAY TI

dd+VAI ‘S!suop

VAI “S!suod

{VAI

daé+VWU TI “S!su0D
VA TI “S!ISu0D

VAY TI

da+VAI 's!suop

{WAI ‘sisuog

VAI

da+VWU TI “S!su0g
VIN TI “S!ISU0D

VAY TI

da+VAI ‘S!suop

VAI ‘s!suoD

VAI

da+VWU TI “S!suog
VANUTI “S!su0p

VAY

dd+VAI ‘S!suop
VAI ‘S!su0D
VAI

oO Ww oO oO

- |

[ap] uasV
SW pQ -U9] MOpUI\,

 

 

 

 

 

 

 

 

wl

 

 

 

 

 

 

 

 

 

 

 

 

20 Shift len.: 1/2 Shift len.: 1/4 Shift len: 1/8 Shift len.: 1/16

wo oO Ww oO Lo
- I

[ap] uasV
SW ZO] “ U2] MopUlA

oO
N

w o Ww Oo ?

[aP] YasV
SW gQ/ "Ud] MOpUIM

o
N

wo Oo w Oo

[ap] YasV
sw ZG 7U3a] MOpUIM

—

[ap] YasV
SW 9GZ “Ud] MOpUIM

wo o Lo Oo

[aP] YaSV
SW QZ] “U2a] MOpUIMY

[aP] YaSV
SW 7Q -"Ud] MOPUI\,

dd+VWU TI “S!suoD
VANTI “S!ISU0D

VAY TI

da+VAl 's!suop

VAI “s!suoD

VAI

dd+VWU TI “S!su0D
VINUTI “S!ISuoD

VNU TI

da+VAI ‘s!suop

VAI “s!suoD

VAI

da+VWU TI “S!suog
VANTI “S!ISU0D

VAY TI

° 1d€+VAl ‘s!Isuop

VAI “s!suoD
VAI

ddé+VWU TI “S!suoD
VAN TI “S!ISU9D

VAY TI

dd+VAI ‘S!suop

VAI ‘s!suoD

VAI

Ww oO Ww oO ad

(b) JR2 (470ms)

Fig. 15 Average SDR improvements for synthesized speech mixtures (speech 1-10) with a E2A and b JR2, where Blackman window is used in STFT

(a) E2A (300ms)

 

 
 

Page 22 of 35

(2020) 2020:46

 

Kitamura and Yatabe EURAS/P Journal on Advances in Signal Processing

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

© [Sa i REES cron ane Seeeee a ——l+——- «4 Hol da+ Ver “s!suog
> —_ T+ —— + —— + —l ROIS iw ons Ho J ww sisuog
2 —I + —_ + ——— — —cC + + oo] vw
8 SS So. aT. 1+ ——_ —COH  jda+var‘sisuog
£ oH oo a) I} — OST | yar ‘sisuog
a —L : oH : - oO “| a —ok—- —oe— + {VAI
@ — = SAREE op poanea Saeeeee o>} i -.4 HL ———_ | d+ Veil “sisuog
> — + — T+ — ———— —o+——_ | ODS | vt “sisuog
c —C oc —o+ SaaS on Donon ane = }__4 —CI=}—_——. . J oS + f Vn
= ——a cin] — SS safe See —$ oo —COH J da+var'sisuog
€ oH el oe + I OST | var 'sisuog
w —Cr : oe : :- Oo a ol oe: —o— + {val
< ee | — —— Ll + ee —_L_-—— HOLE — +» 4da+VWUll “sisuog
= —| | a a —+——; |} HI = +} VT “sisu0g
e —_ T+ ——— ro} —o + } SS} eo} vn
2 — T+ or So — ——T —COH | da+var‘sisuog
© —ooH 4 —o a — HOLST | var 'sisuog
a ——LI —I : + OD oe. oo} oo —o— + {val
x SH SE eee EE lt -— HELE ++ -+]da+VNUTl “s!su0g
> OH . +} | eet —}———— | Hoo =- | yw sisuog
c > CCH ————_T +4 — + — + + HER + +} vn
= —oC —l 1 —— TT — —— OH fda+val‘sisuog
£ 4ooH oH —oro}—4 —}—. —oo fo} var ‘sisuog
w | —CI—k : ook —_ re —cl oe Soo lvl
e@ gg #& SF ® SR GF ek FSF fF SK GF HK SF vw SK GF LK SF Kw SK GF LB SF vw SH GF Lx FS HS
[aP] HISV [ap] uISV [ap] YISV [aP] YISV [aP] YISV [aP] YISV

su 7ZO| “Ud] MOpUI, SW gO/ ~Ud] MOPUIA, SW ZIG -Ud] MOpUIA, SW QGZ “Ud] MOPUIAA SW QZ] “Ud] MOpUIAA SUI 7Q “Ud]| MOPUIA,
© ania fii Sa =e Lj d+ VN “s!su0g
> oT} — >} — a a OD] vw ’sisuog
oe a ee ee — —Co OS ve
Ss eS pasSSBMBeA! apron; [EEEEZEI | ee — a} —Co IH d+ WAl ‘sisuog
£ ————— r+ —————— 4} — —Toe— moe sf vAl'sisuog
Bt ——— ————— ———_—_ Tr} —— + —co Hoo oval
2 i] fe — Ll - —_ +4 — | dV! “SIsuog
= oo J — — OS yt sisuog
cg item | | eerie) Dh teem pRRARS! 553 raise] seeeeaeee) — + oo vn
= —_ ——$— ——_$_$ —_ + —o CH da+WAl ‘sisuog
& ————— T+ ——————T+— — ——roe— Mo sf VAI sisuog
Oho —_ ————$ oro}, —_ I} —oo .- <r lv
< —l |) EEE OEE SE Se Co} 4 dV “sisuog
2 op — + — —— + Oo] wwe ’sisuog
c ie | peepee ee a Hoo vw
= SEsBSANES! aunnaba EEaEs ©) esa RESOMBSS! E555] EEEZZE! | SesBBREBOSES prauny [EEE] Sones] Pea EES! usa EnEsl Sees] —ol IH da+WAl ‘sisuog
& ————— 1+ ——————_ + —l —loe— Mo sf VAI 'sisuog
Oho —— peaReeeORS prarezzalzszi ee’! panaSSSSESS8 roe nae nee i —ooe - ooo fw
0 nee Lime) ee ie —lL CL J d+ VNU Tl “sisuog
= — or | fp or ——l — OI J wat ’sisuog
-- ———— fp — >} —— + So] vv
= RaRBe! gpaesan ona) aie lela os os HOH da+val ‘sisuog
| —$ oT} |} ST fT I —— | I —re— |} | IK {VAl'sisuog
w —o — ———— —— —Sre | ooo otal

sR8egek evrveogeuggrevrvegsgeRegreervresgRegrervresgeegerevrvregeRegrerve

[aP] YISV [ap] yISV [aP] YISV [aP] YISV [aP] YISV [aP] YISV
SW ¥ZO| “Ud] MOpUIM SW g9Q/ “Ud] MOPUIA, SW Z|G “Ud] MOPUIA, SW QGZ “"Ud] MOPUIA, SW QZ] “Ud] MOpUIA, SW 7Q “Ud] MOPUIAA

 

(b) JR2 (470ms)

Fig. 16 Average SIR improvements for synthesized music mixtures (music 1-10) with a E2A and b JR2, where Hann window is used in STFT

(a) E2A (300ms)

 
Page 23 of 35

(2020) 2020:46

Kitamura and Yatabe EURASI/P Journal on Advances in Signal Processing

 

 

 

 

 

 

 

 

 

 

 

—CLe—
— I+
—_—  —
— or
oe
—C Lok
|
—CLor
— +4
—
—oH
—Cl
—_ 1. +
—TTo +4
—_ Tr
a
—ooe
—CL
—lLoH|
- — To H4
—COoH
lok
4 ITH
LOH

 

 

 

 

 

 

 

 

 

 

 

95 Shift len.: 1/2 Shift len.: 1/4 Shift len.: 1/8 Shift len.: 1/16

g 2£ ¢ » eo
[ap] uISV
SW ZO] “U2] MopuIN

N =- =
[aP] YISV
SW gQ/ 7Ud] MOpUIM

Lo oO wo oO LO oO
N

Oo uw oO LO oO

[aP] YISV
SW Z|G “Ud] MOpUI/A

oO uw oO LO oO

[ap] YISV
SW 9GZ 7 Ud] MOpUIA

N a =
[aP] YISV
SW Z| “Ud] MOpUIAA

wo oOo wo oO LO Oo
N

N - =—
[ap] YISV
SUI 7Q 7Ud] MOPUI\,

 

 

 

 

 

 

 

Shift len.: 1/2 Shift len.: 1/4 Shift len.: 1/8 Shift len.: 1/16

 

 

 

 

 

 

 

 

 

 

 

 

[ap] uISV
Sw ZO} “U2] MopUIM

Oo nN AN K-
[aP] YISV
SW gQ/ “Ud] MOpUIM

ao nN AN S-
[ap] YISV
sw ZG 7U3a] MOpUIM,

ao Nn AN K~
[ap] YISV
SW 9GZ “Ud] MOpUIA

ao Nn AN Kf
[ap] YISV
SW QZ] 7 U2] MOpUIMY

ao Nn AN K~-
[ap] YISV
SW 7Q -Ud] MOPUI\,

dd+VWNU TI S!suog
VA TI “s!ISU0D

co) VAY TI

dd+VAI ‘S!su0p
VAI “S!SUoD
VAI

| da+VNUTI “Sisuog

VAT “S!ISU0D
VAY TI
da+VAl 's!suop

{WAI ‘s!suog

VAI

da+VWU TI “S!su0D
VAT “S!ISU0D

VAY TI

da+VAI ‘S!suop

VAI “s!suoD

VAI

°} dg+VWU TI “S!Isuog

VAUTI “sIsu0D

4 WAY TI

dd+VAI ‘S!suod
VAI ‘S!SU0D
VAI

wo Oo Ww oO wo oO
N

dd+VWUTI “S!su0D
VAN TI “S!ISU0D

VAY TI

da+VAl 's!suop

VAI “s!suoD

VAI

dd+VWU TI “S!su0D
VAN TI “S!ISUoD

VY TI

dd+VAI ‘s!suop

VAI “s!SuoD

VAI

da+VWU TI “S!suog
VATI “S!SUu0D

VAY TI

dd+VAI ‘S!su0p

VAI “s!suoD

VAI

ddé+VWU TI “S!suoD
VI TI “s!ISU0D

VAY TI

dd+VAI ‘S!suop

VAI ‘s!suoD

VAI

(b) JR2 (470ms)

Fig. 17 Average SIR improvements for synthesized music mixtures (music 1-10) with a E2A and b JR2, where Hamming window is used in STFT

(a) E2A (300ms)

 

 
Page 24 of 35

(2020) 2020:46

Kitamura and Yatabe EURAS/P Journal on Advances in Signal Processing

 

 

 

;

S——

 

 

 

 

 

 

95 Shift len.: 1/2 Shift len.: 1/4 Shift len: 1/8 Shift len.: 1/16

———_
= +—
— I+
Tr
a
—
+
— +
—_LI-}+—_
oT
oH
—_
———+—
—_CIl-+—~+
I+
T+
—ooH
—r
Cir
TH
—LH
oH
IH
oor

 

 

 

 

 

 

 

 

 

 

 

 

 

Rg 2#£e
[ap] uISV
sw YZ} -Ua] MOpUlY

0

Oo Lo Oo LO Oo
N

[ap] YISV
SW gQ/ 7U9d] MOpUIM

Lo Oo Lo Oo LO oO
N N

[ap] YISV
SW Z|G “Us| MOpUIA,

25

[ap] YISV
SU 9GZ “U2s] MOpUI,

Oo LO Oo wo oO
N

LO oOo wo Oo wo Oo
N N

[ap] YISV
SW QZ] “Ud] MOpUIAA

ddé+VWUTI “S!suoD
VIN TI “S!ISU9D

VAY TI

dd+VAI ‘S!suop

VAI ‘s!suop

°| VAI
°} da+VWU II “SsuD

VAN TI “S!ISU0D
VAY TI

dd+VAI ‘s!suop
VAI “s!suoD

°4 VAL
=] de+VNUTI “SIsu0g
+ © 4 VINYL ‘sIsuog

«of VINE

dd+VAI ‘S!suoD
VAI ‘s!suop

{VAI
coe] dE+VINUTI “SISUOD
+e} WUT 'SISUOD

se VT

dd+VAI ‘S!suop
VAI “S!suod
VAI

LO Oo wo Oo re) oO
N N

[ap] YISV
SUI 7Q 7Ud] MOPUI\,

 

 

 

 

 

 

Shift len: 1/2 Shift len.: 1/4 Shift len.: 1/8 Shift len.: 1/16

 

 

 

 

 

 

 

 

 

 

 

 

[ap] uISV
SW ¥ZO] “U2] MopulM

ao N AN K-
[aP] YISV
SW gQ/ “Ud] MOpUIM

a N AN K-
[ap] YISV
sw ZG “Uu9a] MopuIM

a N AN Kf
[ap] YISV
SW 9GZ “Ud] MOpUIM

ao nN NN HK =
[aP] YISV
SW 8Z| “U2a] MOpUIM

ao Nn NN KF =
[ap] YISV
SW 7Q -"Ud] MOPUI|

ddé+VWUTI “S!suoD
VAT “S!ISUu0D

VAY TI

da+VAl 's!suop

VAI ‘s!suoD

VAI

da+VWU TI “S!suog
VINUTI “s!ISu0D

VAY TI

da+VAI ‘s!suop

VAI ‘S!SU0D

VAI

dd+VWU TI “S!suog
VANTI “S!ISUoD

VAY TI

dd+VAI ‘S!suop

VAI ‘s!suop

VAI

dd+VWUTI “S!suoD
VAT “S!ISU0D

VAY TI

da+VAl 's!suop

{WAI ‘s!suog

VAI

(b) JR2 (470ms)

Fig. 18 Average SIR improvements for synthesized music mixtures (music 1-10) with a E2A and b JR2, where Blackman window is used in STFT

(a) E2A (300ms)

 

 
 

Page 25 of 35

 

 

 

 

 

 

 

Shift len: 1/2 Shift len.: 1/4 Shift len.: 1/8 Shift len.: 1/16

 

 

 

 

 

 

 

 

 

 

 

 

(2020) 2020:46

da+VWNU TI S!suog
VI TI “S!ISUu0D

VAY TI

dd+VAI ‘S!suop

VAI “S!suod

VAI

da+VWU TI “S!su0D
VAUTI “s!suoD

VAY TI

da+VAl 's!suop

VAI “s!suoD

VAI

dd+VWU TI “S!su0g
VINUTI “S!ISu0D

VAY TI

da+VAI ‘S!suop

VAI “s!suoD

VAI

da+VWU TI “S!suog
VIAN TI “S!su0pD

VAY TI

dd+VAI ‘S!suoD

VAI 'S!suoD

VAI

— Sr —o}+— - oH

—_Cl ++ T+ ——}+—_ —CoH

1 a a a —I . OK

—L + —CoH Th HOC

. ———S po — + —CoK

—— + ————r-+— —co+— —COIH

— ——— + ———$o - OK

fot | | La —_T -e_ —LI -—— on } Tt

————— ro} ——_C LL} —Co+—- | -—Co

—l + —Clo+— | —CoH

—l oH as Ea 4oIh

——$_ + -  —Io ——————_$Ls —I— —ooe-

. HoH oI a a IH

ge 2@ fF eB SF FSF B FSF PB FS F LB FSF we 2 f° 2 Sf #98
[ap] uISV [aP] YISV [ap] uISV [aP] uISV [ap] uIsSV

SW YZ} “US| MOpUIM

SW gQ/ 7Ud] MOpUIM

SW Z|G “US| MOpUIAA

SW 9GZ 7Ud] MOpUIM

SW 7Q -U9] MOpUI\,

 

 

 

 

 

 

 

 

—————+— ———_ —— —_CL_ + CCH
1+ —————o + —_l I++ — re —COk
. —_ TH —_l_ 1 —__{_T— —+ <I
—————_ + —— ———— —_—CL + CCH
——L —_Ll + ————L iI} — or —CCH
. — IH —_—_ 1 —__{l 1 —Cr+ ce
——_—_ +} ————— + —————+— — T+ —COIH
2 ———L_ 1} —_CL}— —CL— —ICOCH
: HTH : —oo} : —Cooh —Coooh Hi»
: —_T ——————— ——_ To —lI +4 —<
———_ + — ——_ —r r+ —iH
——l a} —__oe| ————_ + —_LI}+— —CICH

. fo ——____ r+ ———I + —Cr +4 —CCH

. =i : oh ——————lo —oH —Cl—

—Cl Ih _—lone —C Ch —oo ce

 

 

 

 

 

 

 

 

 

 

 

 

30 Shift len.: 1/2 Shift len.: 1/4 Shift len: 1/8 Shift len.: 1/16

 

Kitamura and Yatabe EURASI/P Journal on Advances in Signal Processing

Lo
N

oO

N - —

[ap] uISV

SW ZO] “U2] MopUlA

Oo Oo WwW Oo

Oo oOo Oo Oo wf Oo

N N - =
[aP] YISV
SW gQ/ 7Ud] MOpUIM

LO
N

oOo Lo

N - —
[aP] YISV
sw ZG 7Uu3d] MOpUIM

ow} Oo

a 2-2" °
[ap] YISV
SW 9GZ “Ud] MOpUIM

daé+VWU TI “S!su0D
VANUTI “S!ISU0D

VAY TI

da+VAI 's!suop

VAI “s!suoD

VAI

da+VWU TI “S!suoD
VAN TI “S!ISuoD

VNU TI

da+VAI ‘s!suop

VAI “s!suoD

VAI

da+VWU TI “S!suog
VA TI “S!ISuoD

VAY II

dd+VAI ‘S!suop

VAI “s!SuoD

VAI

ddé+VWU TI “S!suoD
VIN TI “S!ISU9D

VAY TI

dd+VAl ‘s!suop

VAI ‘s!suoD

VAI

ono oO WhO

N - —
[ap] YISV
SW 7Q -"Ud] MOPUI\,

 

(b) JR2 (470ms)

Fig. 19 Average SIR improvements for synthesized speech mixtures (speech 1-10) with a E2A and b JR2, where Hann window is used in STFT

(a) E2A (300ms)

 
 

Page 26 of 35

(2020) 2020:46

 

Kitamura and Yatabe EURAS/P Journal on Advances in Signal Processing

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

© —rlL —LL_-—S 1 —_L-— —cL_ +S —LL | de+vnul “sisuog
> —$ —_ + ——+— —oe oO VT! ’s!su09
a —CI+— ———— T+ —lI-+— — + ° 4 vine
2s —l— — + —_CI Ic + oY da+val ‘sisuog
£ — — oo —— HOF val “sisuog
w —__ T+ sees == Se ++ oH oo vA
2 ——T LF +h —L - i —CL— devel “sisuog
= ——— — + ae a C+ OO vn ‘s!suo9
c —CT + ———l + —cl coe —Oo}— OO vw
= — ————_ + —_CI +4 4c} «DY ag+var‘sisuog
€ —__ Ts I+ oH —-— HOOK val ‘sisuog
“ —__T + eee 2 eS + —r4 HOH val
< ———_— ST + a} — +] —o + ~ LL d+ VNU “sIsuog
>} } —_T + —_+— | —_+—} | —c+—} | | Soe | yet 'sisuog
< —_I + —CI}+— —C i }— — LOH ve
2 + — ro Io} + 4 da+val ‘sisuog
© —_1—s — 4 I —— HOOK +4 VAr'sisuog
7) ——__ +4 | —l TH o- —Io—H HoH VAI
x Sao] Ess —o—- —S— OI d+ vu ‘s!suog
> - —_ —_CL+— —Cl— —Co}— -—COoF4 vine ‘sisuog
c SoH — T+ oT —CorS oH | ve
= ——— oo} ao cH — oc © HOOK da+val‘sisuog
£ . oo —CaIb a —o - HCO) val sisuog
“wa —__ | —_I-— _< och —oH HOI {val

ge 2 ee e©& eS EF 2B FSF PB SF GF 2B FSF ew SF GF Bf FSF fF SF GF BB FSF eB FS GF F FSF Fe

[aP] uISV [aP] YISV [aP] uISV [aP] uISV [ap] uISV [ap] uISV

SW PZO] -Ud| MOpUI;, SW QQO/ -Ud]| MOPUI/[, SWI Z|G Ud] MOPUI/A SUI QGZ -Ud]| MOPUI/A SW QZ] “Us| MOPUI/A SWI 7Q “Us| MOPUIAA
ee a —_ iF —T TH LH devil “sisuog
Spe oe or ——— + —+—_ + —_IH OTH Vel ‘sisuop
2p rr —————— + —_ ++ —COH OCH ve
St. 4H . —Ce . —CI ———S— Oh + Hk | da+vAl ‘sisuog
£ ——— ITH a ae ———— + or fo} wal ‘sisuop
B oo ——_ + —_oo —_ +c} CoH {val
o) SSS) EE —Ll + —L Le —LI1_H —DH d+VWUul ‘sisuog
=f} oor) yf oo ———L—+— —_ + LH ICH VU ‘s!suo9
c a a a ——L Ey —_L oo} —Cloo+— SoH OH ve
=} HIoh : —oe . Io —Ll Hoh + ek | da+vAl ‘sisuog
& To ————_—_Cot ——_Coro ro} —or}— Lo | war ‘sisuop
“a ——— —____ T+ —_L_T —— +o} CO {VAI
2 ees — — TL + —rL —rLH - DCH da+ VNU “sisuog
a a ed ————— + — T+ —lI CH VU “sisu09
of ————_ r+ ———_L + —C}— —CIoH OH vw
2. 4th . —Io . —CIoh —ooo oH 4 Hk | da+VAl ‘sisuog
& —— ————— —_L_T — or oe Lo | wal ‘sisuop
w $< —_—_ 1 + —_—__ Ts — ae a —COo I val
q) i ————_ 1. + ——— —— 1+ — | —LH da+vnui “sisuog
>} ———————_—_ r+ ——LL + — + —Co ICH VU “sisuo9
cg TT ——_C + LI} —_I— ++ ITH MOH VU
= : co . cM : —CoH —loH oh | —O | datvar sisuog
€ —————_Tr) | _— lo | — T+ | | — | —cie |} | LO} WAI ‘sisuop
“ ——— —_ —_ TH} +o Io | val
g88 e2® ew esgsgeReeeresgee”eereregseeerer#egReeeerevegegreres

[aP] YISV [aP] uISV [aP] uISV [aP] uISV [aP] uISV [aP] uISV
SW ZO] “Ud] MOpUIA, SW gO/ ~Ud] MOPUIA, SW ZIG ~Ud] MOpUIA, SW QGZ ~Ud| MOPUIAA SW QZ] 7 Ud] MOpUIAA SW 7Q 7Ud] MOPUI,

 

(b) JR2 (470ms)

Fig. 20 Average SIR improvements for synthesized speech mixtures (speech 1-10) with a E2A and b JR2, where Hamming window is used in STFT

(a) E2A (300ms)

 
Page 27 of 35

(2020) 2020:46

Kitamura and Yatabe EURASI/P Journal on Advances in Signal Processing

 

Shift len.: 1/2 Shift len.: 1/4 Shift len.: 1/8 Shift len.: 1/16

Shift len.: 1/2 Shift len.: 1/4 Shift len: 1/8 Shift len.: 1/16

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

gahehuenddonpestaalbesdde

 

 

oOo uw oO LO oO

x - =—
[aP] HISV
SW YZ} “US| MOpUIM

oO wo oO LO oO

N - —
[ap] uISV
SW gQ/ 7Ud] MOpUI\

oO wo Oo LO oO

N - -
[aP] YISV
SW Z|G "US| MOpUIAA

oOo w oO wo oO

J — =-
[aP] YISV
SW 9GZ “U2] MOpUIA

Oo uw Oo LO Oo

N - =
[aP] YISV
SW §Z| “Ud] MOpUIA,

dd+VWNU TI S!suog
VATI “S!ISUu9D

VAY TI

dd+VAI ‘S!suop

VAI “S!suod

VAI

daé+VWU TI “S!suoD
VA TI “S!ISUuoD

VAY TI

da+VAl 's!suop

VAI “s!Su9D

VAI

da+VWU TI “S!suog
VINUTI “s!ISU0D

VAY TI

da+VAI ‘S!suop

VAI ‘s!suoD

VAI

da+VWU TI “S!suog
VAUTI “S!su0p

VAY TI

dd+VAI ‘S!suop

VAI 'S!SU0D

VAI

Oo Ww oO LO Oo

NA - =—
[aP] YISV
SW 7Q -U9] MOPUI\,

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

sndpdbbeeddd Pes ddaleeeded

 

8 2 828 2
[ap] uISV
SW ZO] “U2] MopUlA

ao N NAN K-
[aP] YISV
SW gQ/ 7Ud]| MOpUIM

ao N AN KK
[ap] YISV
sw ZG 7Uu3d] MOpUIM

Oo N NAN KF =
[ap] YISV
SW 9GZ “Ud] MOpUIA

ao Nn AN Kf =
[aP] YISV
SW QZ] “U2a] MOpUIA,

oa N AN KF
[ap] YISV
SW 7Q -"Ud] MOPUI\,

dd+VWU TI “S!suoD
VANTI “S!ISU0D

VAY TI

da+VAl 's!suop

VAI “s!suoD

VAI

da+VWU TI “S!su0D
VANTI “S!ISuoD

VNU TI

dd+VAI ‘s!suop

VAI “s!SuoD

VAI

dd+VWNU TI “S!su0g
VA TI “S!Su0D
VAY II

dd+VAI ‘S!su0p

} VAI “sIsuog

VAI

ddé+VWU TI “S!suoD
VINUTI “S!ISU9D

VAY TI

dd+VAI ‘S!suop

VAI ‘s!suoD

VAI

(b) JR2 (470ms)

Fig. 21 Average SIR improvements for synthesized speech mixtures (speech 1-10) with a E2A and b JR2, where Blackman window is used in STFT

(a) E2A (300ms)

 

 
 

Kitamura and Yatabe EURAS/P Journal on Advances in Signal Processing

(2020) 2020:46

Page 28 of 35

 

25

Ro
Oo

n.: 1024 ms
a

SAR [dB]
So

Window le

So
ao oO a

Ro
oO

n.: 768 ms
a

SAR [dB]
So

Window le

S|
ao Oo oa

Ro
Oo

n.: 512 ms
a

SAR [dB]
So

Window le

|
a o Oo oa

Window len.: 256 ms
SAR [dB]

So!

Window len.: 128 ms

Shift len: 1/2 Shift len: 1/4 Shift len: 1/8 Shift len.: 1/16

 

olde

 

 

Window len.:

 

 

 

 

o

 

 

i}
4}
4

—
{TE
—_l
Tc
4
HIT
Cir
+E
| —Co
Fa an
4
4H
—_
—TE
—oo
| 4
4
4h
—_
—TCh
—Co

Window len.:

 

 

 

 

 

 

 

 

 

 

<a<atan <aatea t<faoden tnt ean
S>S>agosseog >S>assgn SSPassegn SSPassea
—~—~tHoeortet ~T[THFHOOrte “THEME Kt  “TEeKYs
6ftijlie 6xtidaie¢e 6ltlidie 6xtijdaie

a2z27"Fs o27-"*s o27"7 ss a2" {ss
$4 ga $4 2& $406 62 & $4 2G

OD en OG en Os a OG ea
5 84 5 S84 5 8a 8 8 ¢

o 2 ° 2 O 2 3 2

€ € € €

° 3° 3° 3°

3° ° 3° 3°

(a) E2A (300ms)

Shift len.: 1/2 Shift len.: 1/4 Shift len: 1/8 Shift len.: 1/16

 

sstoydastbadutdy

1024 ms
3

Window |
SAR [dB]
-—i
Hi oe
41H
ecco] te
+o

 

768 m
SAR [dB]
a oS
+
Hh
4
— |
—_\—
—it+—
Ih—
—
+l}
. -—Ci+—
CT 1
—Ci}+—
1I-—
i
+c}
-—Cit—
Cit
—_| +
1=I-—
—
+o}
-fl}+—
—_— —
—Cor

 

 

 

 

ditt tA
li tl tg

 

 

128 m
S
+0
—CEh
i
—T
Cir
li
ih
a
+CI}—
—iot
—or ||
—_—
e IH
+I
+I
—L
—it-
—L
JH
{1h
+CItF—
Oh
oH
oH

SAR [dB]
o

 

 

eagle Pedi Meath pe aith

 

 

 

 

 

 

 

 

 

oO
g
2e 5
ec
50
z
= 0
=
Saaaaecn tftfaoctca t<totctca <e<eaocca
S>>agassemgo >Srassag SSPassemn SSPassag
—~—~Foerere “~T[THOrte “THEO erte “TT EeOer st
6ftijdie 6xtijiie 6sltijdie 6x<idie
a2" {s a2" {s a2" ss a2" "s
$4 ¢& $4 8a $4 6 62 54 €&
oO «3 | OG | OG 2 Oo %@ |
5 8a 5 8 4 5 8a 5 8 4
° 3 Oo 2 3 2 ° 2
<€ <€ € €
3° ° 3°
3° 3°

(b) JR2 (470ms)

Fig. 22 Average SAR for synthesized music mixtures (music 1-10) with a E2A and b JR2, where Hann window is used in STFT

 

 
Kitamura and Yatabe EURASI/P Journal on Advances in Signal Processing

(2020) 2020:46

Page 29 of 35

 

95 Shift len.: 1/2 Shift len.: 1/4 Shift len.: 1/8 Shift len.: 1/16

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

ra ul uel
ell
ly Hla
rt
itl
Eayl

(a) E2A (300ms)

Window len.: 256 ms Window len.: 512 ms

Window len.: 128 ms

Shift len. 1/2 Shift len.: 1/4 Shift len.: 1/8 Shift len.: 1/16

stl

 

°
°

20h

 

 

 

 

SAR [dB]
o oO
Hie *
He
oe
ele —_ oe 4 bow
—lle
— oe

oO

 

 

=
oa

 

 

 

 

 

 

 

 

 

 

 

 

 

calif lt nell a
eHst HTP EDT PT PORT TT Peg ttt
a“eaariyeegtitpectiapeqty?

g s
(b) JR2 (470ms)

Fig. 23 Average SAR for synthesized music mixtures (music 1-10) with a E2A and b JR2, where Hamming window is used in STFT

 

X

 
 

Kitamura and Yatabe EURAS/P Journal on Advances in Signal Processing

(2020) 2020:46

Page 30 of 35

 

25

Shift len: 1/2 Shift len: 1/4 Shift len: 1/8 Shift len.: 1/16

 

n.: 1024 ms
8

mi

SAR [dB]
o.G
{lo}
4}
oh
+i}
t+

Window le

Ht
+
-Cit}—
TEE
Coit}
net
1024 m

Window len.:

 

So
ao oO a

 

Ro
oO

Window len.:

cr
+
Cia:
a
ea
—loSs—
768 m

Window len.:

 

S|
ao Oo oa

 

Ro
Oo

n.: 512 ms
a

SAR [dB]
So
fH EER ed
4+ 7 +
“fT
-—olt+—
—CCtr

Window le

768 m

SAR [dB]

oa
| EEE
ols 7 +
qi}

Pe {I eS} SEs

—it+
—ol+

-—Clclk—
Lack
4a}
+> iene}
f+
LE
Window len.: 512 m

 

|
a o Oo oa

 

RN
oO

Window len.: 256 m
SAR [dB]
So Ga
Cor
+} 7 7
+o
—Oet+—
—_—
—TE

-—}
oH
—Cl}
—Cl
—
ot
Window len.: 256 m

 

 

 

 

 

 

 

 

 

 

 

 

5
0
-5 1
25 ——
— 20 g
N N
yal =
2 e
eh 08 ne He §
se"U AG 5
BO 5 : 5
wT 7
&
= 9% if iI | | =
-5 1
25
g 20 :
S15 } i} | y S
79 4
ec <€
deen gGb aad pide g : baad s
2s 3
3? 3
= £
= 0 =
Saacacecn x<txatadtataatatatatgaaetatatta
SSEGSSaGg >SSHSsqg >SHssqa >Snssa
6<t GG 6<5Ge 6< Gz 6ctGGz
aZ27*s oZ27*s oZ27*s oZ27*s
5406 (8 $406 68 $4 «62 $4 6 68
OG 2 OG | Os 2 OG 2
§ 84 § S¢ s 84 § O¢
3 2 Oo 2 O 2 ° 2
€ € € €
3° 3° 3° [-)
o 5 3 3

(a) E2A (300ms)

SAR [dB]
a 3S
Cl
HH
Ih
=r}
o—_]e
+i
co}
Hi
++
—_l—
~ —ooH
—CIk—

SAR [dB]
a 3S

e_]} °

{IH
o4—
-— it
coe p eH

tt}

SAR [dB]
on oS a
+: -
eis
41+
—_ x4
—coo
Ctr
“CO: <
+I
Ci}
+t
—o | it
—Tor—

SAR [dB]
on 3
LTH
+
cs
——Ci
—_ Te
—_ |}

SAR [dB]
3
Ls
ook
emf] «
oH
oon
oh

Shift len: 1/2 Shift len.: 1/4 Shift len: 1/8 Shift len.: 1/16

 

=
oa

oO

I
a

 

 

=
o

oO

 

I
oa

 

oO

1
oa

 

 

=
ao

oO

 

|
ao

 

=
oa

ghlll

o

oO

 

 

 

 

 

 

 

 

 

 

'0 gat anf gy
g Peypradyy rn
2 7 2 o{{e eT 2] |. DT
x 5 coed
<x
a
Of 4h b
Szaanaeaen tenaeen <eneen enenn
S>>agosstm SSPassgo S>Srmassqo S>SPMsstan
—~—~Hoerore ~T[THEeOrte “THEO erte “TT EOeOr st
otijied 6xtijiie slide 6x<ilie¢e
a27"7Fs a2z27"s a2" *s a2z2"=s
$4 ¢& $4 @& $4 6 62 $4 €&
OG ea OG ea O@ | OG en
6 Og 6 Og & Og 6 68g
° 2 Oo 2 3 2 ° 2
<€ <€ € €
3° 3° 3°
Oo 3°

(b) JR2 (470ms)

Fig. 24 Average SAR for synthesized music mixtures (music 1-10) with a E2A and b JR2, where Blackman window is used in STFT

 

 
Page 31 of 35

(2020) 2020:46

Kitamura and Yatabe EURASI/P Journal on Advances in Signal Processing

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

VAY TI
dd+VAI ‘S!su0p

VAY TI
da+VAl 's!suop

VAN

dd+VAI ‘S!suop

© — Le = =o — Te — Ie —i
> oH : ~ oH it: I ol li
< —0 Te oo <I Ik ot
8) oH oe a Ik 4k The
£ Ih HT Ho Tk Ik Hike
Bt oH t oo so HM -0h oh
2 —oe —ooS —ooe ie -—ue —i
- el oo. —_|- —l— —_[ —l
=) oo —ore co —Ik Sk he
| Is ore —o -OTs i rls
w re — oH so HM 40 ok
< = se a —— = i
> —L. —oIe —r re - fH —LIe
2) oe a) ore Tk Hk oF
& HH oH ok Ik Hk ihe
w ore —ore oo “Ce 40 oh
af > os oo a re Le -—
> —h-- = —I: —I— —Oh —e ke:
= < Oe — Tx Hoe oh rs HH
& Ih “oh < —0h ch “Ok
a ico —e _ th Hs “Ik hk
° Lo °o ro ° Lo °o ° Lo °o wo ° lo ° wo ° lo ° ° lo °o rd
[ap] uvs [ap] uvs [ap] uvs [ap] uvs [ap] uvs [ap] uvs
SW 7ZO] “Ud]| MOpUIA, SW gQ/ 7Ud] MOPUIA, SW Z|G ~Ud] MOpUIM, SW QGZ “"Ud] MOPUIA, SW QZ] “Ud] MOpUIA, SW 7Q 7Ud] MOpUIM
°} or — a oo > =—UEF
>} —orne -— I iM -OoIs Is =~ DM
peo co Se De Ie “1H coor
So. ee : oe - 0k —k : I > ore
Bp sR — TH — Tk Io Hk “OTK
of-— p— —— —e —s i
=} = —cI-— —OTe I —Ik “=
¢) oo —OIH —ol4 Te = 0h
=) . ete - tk - ke : Satan > re
& on —— —oIH Tk IH Hh
Op —CoTh —oTh Io rth Ck
2} — —— or + —iLk = oe
=} ore —LI-— IK - oe ok cor
dp +o -—Ie Oe I Le -——Th
Go —cTh —cor Ik 40h OTs
gf > oo a r re ie “oT v= 1H
= —CoH —co —CI: —I— --——0TH — Oe
c —— +-— °. SDH He: rk - ‘oT -H
= . Ch : oe . —cre —C < qe —ooh
£ fon —Olk —Cok on +k Oh
OP ok —ok — HI Hoh rs
g 2 fg ©» © PE eB SF ew FS HPQ RK SF ew FS HE LK SF vw S HE f£ SF 6 FS HE gv S vw SH
[ap] uvs [ap] uvs [ap] uvs [ap] uvs [ap] uvs [ap] uvS

Sw ZO] “U2] MopUlAY

SW gQ/ 7Ud] MOpUI,

sw ZG 7Ua] MOpUIA

SU 9GZ “Ud] MOpUIM

SW QZ] 7 U2] MOpUIM

SUI 7Q :Ud] MOPUI,

(b) JR2 (470ms)

Fig. 25 Average SAR for synthesized speech mixtures (speech 1-10) with a E2A and b JR2, where Hann window is used in STFT

(a) E2A (300ms)

 

 
 

Kitamura and Yatabe EURAS/P Journal on Advances in Signal Processing

(2020) 2020:46

Page 32 of 35

 

 

20 Shift len: 1/2 Shift len.: 1/4 Shift len: 1/8 Shift len.: 1/16
T é
* a

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

a All al
Tn
lil
eg
oo selbdlegeldilesattd
ai ssdbgaleabeodk gadis

(a) E2A (300ms)

Fig. 26 Average SAR for synthesized speech mixtures (speech 1-10) with a E2A and b JR2, where Hamming window is used in STFT

n.: 768 ms

Window le

Window len.: 512 ms

Window len.: 256 ms

oagtogl ii sty stl

SAR [dB]
a
eli
+
Hi +—
++—
i
—Tit
—oo—
eh
—)
—Cot+—
oo =| |
ye ees
+I
Hh
—] +
+c}+—
HI
tit
+
-(h
—]
++—
+}—
—+—

SAR [dB]

SAR [dB]

Shift len.: 1/2 Shift len.: 1/4 Shift len: 1/8 Shift len.: 1/16

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

<<fatacao <teotea <eexeotean <eeotean
SS>Ussmo SFSassegH >SUsSsegH >SSUSsag
“tee “tee ~~ oe oe ~~
slais slougic 4fiaic slagis¢
a27"7Fs a27=s oa27"7"s a27"7=s
56 $f 8 2a 6 ge 8 2a
og 2a ° | ° = ° e =
§ 84 5 84 5 8a 5 8 4

Oo 3 Oo 2 3 2 ° 2

€ € € e

5 ° 3°

° °

(b) JR2 (470ms)

 

 
Kitamura and Yatabe EURASI/P Journal on Advances in Signal Processing

(2020) 2020:46

Page 33 of 35

 

Shift len.: 1/2 Shift len.: 1/4 Shift len: 1/8 Shift len.: 1/16

 

 

 

 

 

 

 

yal lav ituetiy
cgay
ett yende joe

=
o

 

 

 

 

 

 

 

 

 

 

 

 

E z
o . T
6 ; : :
@ 19 . : f au : H
25 of ! : :
3H 8 HT ; . .
o .
wT
0
=
-5
20
E 15
©0 eo . *
N 3 oh ay el §
7 M10 i &
Sa bid : Hae A d,ate age®
za °
wT
& 0
=
-5
20
w
£ 15 .
st . cep woh eben
on poly ]
N nadie bene ih g,0008
2a 5
EG 5 B A A A
=
= 0
Sazaxanaean <eneen eneen exanecn
SS8395 S56398 SS5358 528335
6£55e¢ «e<55e «e552 wehbe
22° GE «482° GE 82°52 82° Gz
é§ Of 6 C8 6 O° 8 é§ Of
i= e€ e€ <€
3° o ° °
5 6 } 5

(a) E2A (300ms)

 

X

Shift len.: 1/2 Shift len.: 1/4 Shift len.: 1/8 Shift len.: 1/16

 

f'n ly

 

 

 

 

SAR [dB]
o
IA
“Th
— Te
—T
—e
oh -

Window len.: 512 ms

 

 

a oS
4H
is
(
—
41H
Hib»
+o
40h
(I
-Ot—
—{i-
—l—

Window len.: 256 ms
SAR [dB]

 

 

 

 

 

 

 

 

 

 

 

 

 

”
E 10 — 3
eo
oo
3, Gagne ST Ate Siatie. &
2o By = = =
0
So
&
=
-5
0 * . ° .
—E 10 ° 3
s
ES sli i Bll A a A a a
So ‘eI i é $
5 03
- 0
=
Saaaaeaen <eneen teneen <enecn
>>OSSH >SHOSSH FSSHOSsSqH SSPasszaqg
Soyer e “SER Et HOLTER St KOE E +
4f5G4¢ alaic sluice slaisc
o27F=s o27=s o27={s o27Fs
cs G.6lCU 5s yg!lCU 5 g)6| CUO sg “8
Oo 3 22 Oo «3 2a OG | Oo «3 |
6 84 6 Sg 6 8¢ 6 84
Oo 3 Oo 3 3 3 ° 3
o ° [-)
3 Oo

(b) JR2 (470ms)

Fig. 27 Average SAR for synthesized speech mixtures (speech 1-10) with a E2A and b JR2, where Blackman window is used in STFT

 
Kitamura and Yatabe EURAS/P Journal on Advances in Signal Processing

Abbreviations

BSS: Blind source separation; ICA: Independent component analysis; STFT:
Short-time Fourier transform; FDICA: Frequency-domain independent
component analysis; IVA: Independent vector analysis; ILRMA: Independent
low-rank matrix analysis; NWF: Nonnegative matrix factorization; IS-NMF:
Nonnegative matrix factorization based on the Itakura—Saito divergence; SDR:
Source-to-distortion ratio; SIR: Source-to-interference ratio; SAR:
Source-to-artifact ratio

Acknowledgements

The authors would like to thank Nao Toshima for his support on the
experiment. Also, the authors would like to thank the anonymous reviewers
for their valuable comments and suggestions that helped improve the quality
of this manuscript.

Authors’ contributions

DK derived the algorithm, performed the experiment, drafted the manuscript
for initial submission, and revised the manuscript. KY proposed the main idea,
gave advice, mainly wrote the manuscript for initial submission, and corrected
the draft of revised manuscript. The authors read and approved the final
manuscript.

Funding
This work was partially supported by JSPS Grants-in-Aid for Scientific Research
19K20306 and 19H01116.

Availability of data and materials

The datasets used for the experiments in this paper are openly available: SISEC
2011 (http://sisec201 1 .wiki.irisa.fr/) and RWCP-SSD (http://research.nii.acjp/
src/en/RWCP-SSD.html). Our MATLAB implementation of the proposed
method is also openly available at the following site: https://github.com/d-
kitamura/ILRMA/blob/master/consistentILRMA.m

Competing interests
The authors declare that they have no competing interests.

Author details

'National Institute of Technology, Kagawa College, 355 Chokushi, Takamatsu,
Kagawa, 761-8058, Japan. *Waseda University, 3-4-1 Okubo, Shinjuku-ku,
Tokyo, 169-8555, Japan.

Received: 2 July 2020 Accepted: 29 October 2020
Published online: 16 November 2020

References

1. P. Comon, Independent component analysis, a new concept? Signal
Process. 36(3), 287-314 (1994)

2. P.Smaragdis, Blind separation of convolved mixtures in the frequency
domain. Neurocomputing. 22, 21-34 (1998)

3. S. Kurita, H. Saruwatari, S. Kajita, K. Takeda, F. Itakura, in Proc. ICASSP.
Evaluation of blind signal separation method using directivity pattern
under reverberant conditions, vol. 5 (IEEE, 2000), pp. 3140-3143

4. N. Murata, S. Ikeda, A. Ziehe, An approach to blind source separation
based on temporal structure of speech signals. Neurocomputing.
41(1-4), 1-24 (2001)

5. _H. Saruwatari, T. Kawamura, T. Nishikawa, A. Lee, K. Shikano, Blind source
separation based on a fast-convergence algorithm combining ICA and
beamforming. IEEE Trans. ASLP. 14(2), 666-678 (2006)

6. _H. Sawada, R. Mukai, S. Araki, S. Makino, A robust and precise method for
solving the permutation problem of frequency-domain blind source
separation. IEEE Trans. SAP. 12(5), 530-538 (2004)

7. A.Hiroe, in Proc. ICA. Solution of permutation problem in frequency
domain ICA using multivariate probability density functions (Springer,
Berlin, Heidelberg, 2006), pp. 601-608

8. T. Kim, T. Eltoft, T-W. Lee, in Proc. ICA. Independent vector analysis: an
extension of ICA to multivariate components (Springer, Berlin,
Heidelberg, 2006), pp. 165-172

9. TT. Kim, H.T. Attias, S.-Y. Lee, T.-W. Lee, Blind source separation exploiting
higher-order frequency dependencies. IEEE Trans. ASLP. 15(1), 70-79
(2007)

(2020) 2020:46

20.

21.

22.
23.

24.

25.

26.

2/.

28.

29,

30.

31.

32.

33.

Page 34 of 35

N. Ono, in Proc. WASPAA. Stable and fast update rules for independent
vector analysis based on auxiliary function technique (IEEE, 2011),

pp. 189-192

D. Kitamura, N. Ono, H. Sawada, H. Kameoka, H. Saruwatari, Determined
blind source separation unifying independent vector analysis and
nonnegative matrix factorization. IEEE/ACM Trans. ASLP. 24(9), 1626-1641
(2016)

D. Kitamura, N. Ono, H. Sawada, H. Kameoka, H. Saruwatari, in Audio Source
Separation, ed. by S. Makino. Determined blind source separation with
independent low-rank matrix analysis (Springer, Cham, 2018), pp. 125-155

. 1. Tachikawa, K. Yatabe, Y. Oikawa, in Proc. IWAENC. Underdetermined

source separation with simultaneous DOA estimation without initial
value dependency (IEEE, 2018), pp. 161-165

D.D. Lee, H.S. Seung, Learning the parts of objects by non-negative matrix
factorization. Nature. 401(6755), 788-791 (1999)

D.D. Lee, H.S. Seung, in Proc. NIPS. Algorithms for non-negative matrix
factorization, (2000), pp. 556-562

C. Févotte, N. Bertin, J.-L. Durrieu, Nonnegative matrix factorization with
the Itakura-Saito divergence. With application to music analysis. Neural
Comput. 21(3), 793-830 (2009)

Y. Mitsui, D. Kitamura, S. Takamichi, N. Ono, H. Saruwatari, in Proc. ICASSP.
Blind source separation based on independent low-rank matrix analysis
with sparse regularization for time-series activity (IEEE, 2017), pp. 21-25
H. Kagami, H. Kameoka, M. Yukawa, in Proc. ICASSP. Joint separation and
dereverberation of reverberant mixtures with determined multichannel
non-negative matrix factorization (IEEE, 2018), pp. 31-35

R. Ikeshita, Y. Kawaguchi, in Proc. ICASSP. Independent low-rank matrix
analysis based on multivariate complex exponential power distribution
(IEEE, 2018), pp. 741-745

D. Kitamura, S. Mogami, Y. Mitsui, N. Takamune, H. Saruwatari, N. Ono, Y.
Takahashi, K. Kondo, Generalized independent low-rank matrix analysis
using heavy-tailed distributions for blind source separation. EURASIP J.
Adv. Signal Process. 2018, 28 (2018)

K. Yoshii, K. Kitamura, Y. Bando, E. Nakamura, T. Kawahara, in EUS/PCO.
Independent low-rank tensor analysis for audio source separation (IEEE,
2018), pp. 1657-1661

R. Ikeshita, in EUS/PCO. Independent positive semidefinite tensor analysis
in blind source separation (IEEE, 2018), pp. 1652-1656

R. Ikeshita, N. Ito, T. Nakatani, H. Sawada, in WASPAA. Independent low-rank
matrix analysis with decorrelation learning (IEEE, 2019), pp. 288-292

N. Makishima, S. Mogami, N. Takamune, D. Kitamura, H. Sumino, S.
Takamichi, H. Saruwatari, N. Ono, Independent deeply learned matrix
analysis for determined audio source separation. IEEE/ACM Trans. ASLP.
27(10), 1601-1615 (2019)

K. Sekiguchi, Y. Bando, A.A. Nugraha, K. Yoshii, T. Kawahara,
Semi-supervised multichannel speech enhancement with a deep speech
prior. IEEE/ACM Trans. ASLP. 27(12), 2197-2212 (2019)

S. Mogami, N. Takamune, D. Kitamura, H. Saruwatari, Y. Takahashi, K.
Kondo, N. Ono, Independent low-rank matrix analysis based on
time-variant sub-Gaussian source model for determined blind source
separation. IEEE/ACM Trans. ASLP. 28, 503-518 (2019)

Y. Takahashi, D. Kitahara, K. Matsuura, A. Hirabayashi, in Proc. ICASSP.
Determined source separation using the sparsity of impulse responses
(IEEE, 2020), pp. 686-690

M. Togami, in Proc. ICASSP. Multi-channel speech source separation and
dereverberation with sequential integration of determined and
underdetermined models (IEEE, 2020), pp. 231-235

S. Kanoga, T. Hoshino, H. Asoh, Independent low-rank matrix
analysis-based automatic artifact reduction technique applied to three
BCI paradigms. Front. Hum. Neurosci. 14, 17 (2020)

D. Kitamura, N. Ono, H. Saruwatari, in Proc. EUSIPCO. Experimental analysis
of optimal window length for independent low-rank matrix analysis,
(2017), pp. 1210-1214

Y. Liang, S.M. Naqvi, J. Chambers, Overcoming block permutation
problem in frequency domain blind source separation when using
AuxlVA algorithm. Electron. Lett. 48(8), 460-462 (2012)

K. Yatabe, Consistent ICA: determined BSS meets spectrogram
consistency. IEEE Signal Process. Lett. 27, 870-874 (2020)

T. Gerkmann, M. Krawczyk-Becker, J. Le Roux, Phase processing for
single-channel speech enhancement: history and recent advances. IEEE
Signal Process. Mag. 32(2), 55-66 (2015)
Kitamura and Yatabe EURASI/P Journal on Advances in Signal Processing

34.

35.

36.

37.

38.

39.

 

42.

43.

Ad,

 

48.

49.

50.

51.

52.

53.

54,

55,

56.

5/.

58.

59.

60.

61.

P. Mowlaee, R. Saeidi, Y. Stylianou, Advances in phase-aware signal
processing in speech communication. Soeech Commun. 81, 1-29 (2016)
P. Mowlaee, J. Kulmer, J. Stahl, F. Mayer, Single channel phase-aware signal
processing in speech communication: theory and practice. (Wiley, 2016)

K. Yatabe, Y. Oikawa, in Proc. ICASSP. Phase corrected total variation for
audio signals (IEEE, 2018), pp. 656-660

K. Yatabe, Y. Masuyama, Y. Oikawa, in Proc. IWAENC. Rectified linear unit
can assist Griffin-Lim phase recovery (IEEE, 2018), pp. 555-559

Y. Masuyama, K. Yatabe, Y. Oikawa, in Proc. |WAENC. Model-based phase
recovery of spectrograms via optimization on Riemannian manifolds
(IEEE, 2018), pp. 126-130

Y. Masuyama, K. Yatabe, Y. Oikawa, Griffin-Lim like phase recovery via
alternating direction method of multipliers. IEEE Signal Process. Lett.
26(1), 184-188 (2019)

Y. Masuyama, K. Yatabe, Y. Koizumi, Y. Oikawa, N. Harada, in Proc. ICASSP.
Deep Griffin—Lim iteration (IEEE, 2019), pp. 61-65

Y. Masuyama, K. Yatabe, Y. Oikawa, in Proc. ICASSP. Phase-aware
harmonic/percussive source separation via convex optimization (IEEE,
2019), pp. 985-989

Y. Masuyama, K. Yatabe, Y. Oikawa, in Proc. ICASSP. Low-rankness of
complex-valued spectrogram and its application to phase-aware audio
processing (IEEE, 2019), pp. 855-859

Y. Masuyama, K. Yatabe, Y. Koizumi, Y. Oikawa, N. Harada, in Proc. ICASSP.
Phase reconstruction based on recurrent phase unwrapping with deep
neural networks (IEEE, 2020), pp. 826-830

J.L. Roux, H. Kameoka, N. Ono, S. Sagayama, in Proc. DAFx. Fast signal
reconstruction from magnitude STFT spectrogram based on spectrogram
consistency, (2010)

J. Le Roux, E. Vincent, Consistent Wiener filtering for audio source
separation. IEEE Signal Process. Lett. 20(3), 217-220 (2013)

N. Perraudin, P. Balazs, P.L. Sondergaard, in Proc. WASPAA. A fast
Griffin-Lim algorithm (IEEE, 2013), pp. 1-4

K. Yatabe, Y. Masuyama, T. Kusano, Y. Oikawa, Representation of complex
spectrogram via phase conversion. Acoust. Sci. Tech. 40(3), 170-177
(2019)

M. Kowalski, E. Vincent, R. Gribonval, Beyond the narrowband
approximation: wideband convex methods for under-determined
reverberant audio source separation. IEEE Trans. ASLP. 18(7), 1818-1829
(2010)

K. Matsuoka, S. Nakashima, in Proc. ICA. Minimal distortion principle for
blind source separation, (2001), pp. 722-727

K. Yatabe, D. Kitamura, in Proc. ICASSP. Determined blind source
separation via proximal splitting algorithm (IEEE, 2018), pp. 776-780

K. Yatabe, D. Kitamura, in Proc. ICASSP. Time-frequency-masking-based
determined BSS with application to sparse IVA (IEEE, 2019), pp. 715-719
K. Yatabe, D. Kitamura, Determined BSS based on time-frequency masking
and its application to harmonic vector analysis. arXiv:2004.14091 (2020)
M. Brandstein, D. Ward, Microphone arrays: signal processing techniques
and applications. (Springer Science & Business Media, 2013)

S. Araki, S. Makino, Y. Hinamoto, R. Mukai, T. Nishikawa, H. Saruwatari,
Equivalence between frequency-domain blind source separation and
frequency-domain adaptive beamforming for convolutive mixtures.
EURASIP J. Adv. Signal Process. 2003(11), 1157-1166 (2003)

D. Griffin, J. Lim, Signal estimation from modified short-time Fourier
transform. IEEE Trans. Acoust. Speech Signal Process. 32(2), 236-243
(1984)

D. Gunawan, D. Sen, Iterative phase estimation for the synthesis of
separated sources from single-channel mixtures. IEEE Signal Process. Lett.
17(5), 421-424 (2010)

N. Sturmel, L. Daudet, L. Girin, in Proc. DAFx. Phase-based informed source
separation of music, (2012)

M. Watanabe, P. Mowlaee, in Proc. INTERSPEECH. Iterative sinusoidal-based
partial phase reconstruction in single-channel source separation, (2013)
F. Mayer, D. Williamson, P. Mowlaee, D.L. Wang, Impact of phase
estimation on single-channel speech separation based on
time-frequency masking. J. Acoust. Soc. Am. 141, 4668-4679 (2017)

S. Araki, F. Nesta, E. Vincent, Z. Koldovsky, G. Nolte, A. Ziehe, A. Benichoux,
in Proc. LVA/ICA. The 2011 signal separation evaluation campaign
(SISEC2011): -Audio source separation, (2012), pp. 414-422

S. Nakamura, K. Hiyane, F. Asano, T. Nishiura, T. Yamada, in Proc. LREC.
Acoustical sound database in real environments for sound scene
understanding and hands-free speech recognition, (2000), pp. 965-968

(2020) 2020:46

62.

63.

64.

Page 35 of 35

E. Vincent, R. Gribonval, C. Févotte, Performance measurement in blind
audio source separation. IEEE Trans. ASLP. 14(4), 1462-1469 (2006)

W.H. Press, S.A. Teukolsky, W.T. Vetterling, B.P. Flannery, Numerical Recipes
in C: The Art of Scientific Computing. (Cambridge University Press, New
York, 1992)

|. Andrianakis, P. White, Soeech spectral amplitude estimators using
optimally shaped gamma and chi priors. Soeech Comm. 51(1), 1-14
(2009)

65. P.Mowlaee, J. Stahl, Single-channel speech enhancement with correlated
spectral components: limits-potential. Soeech Comm. 121, 58-69 (2020)
Publisher’s Note

Springer Nature remains neutral with regard to jurisdictional claims in
published maps and institutional affiliations.

 

 

 

 

S
Submit your manuscript to a SpringerOpen”®
journal and benefit from:
> Convenient online submission
> Rigorous peer review
> Open access: articles freely available online
> High visibility within the field
> Retaining the copyright to your article
Submit your next manuscript at > springeropen.com
)

 

 
