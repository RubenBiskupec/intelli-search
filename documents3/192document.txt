International Journal of Electrical and Computer Engineering (J ECE)
Vol. 10, No. 6, December 2020, pp. 5824~5831
ISSN: 2088-8708, DOI: 10.1159 1/ijece.v1016.pp5824-5831 O 5824

Q-learning vertical handover scheme
in two-tier LTE-A networks

Ammar Bathich!, Mohd Asri Mansor?, Saiful Izwan Suliman’, Sinan Ghassan Abid Ali*
'23Faculty of Electrical Engineering, Universiti Teknologi MARA, Malaysia
“Faculty of Computer Technologies Engineering, Iraq University College, Iraq

Article Info
Article history:

Received Apr 1, 2020
Revised Apr 11, 2020
Accepted May 1, 2020

ABSTRACT

Global mobile communication necessitates improved capacity and proper
quality assurance for services. To achieve these requirements, small cells
have been deployed intensively by long term evolution (LTE) networks
operators beside conventional base station structure to provide customers
with better service and capacity coverage. Accomplishment of seamless

handover between Macrocell layer (first tier) and Femtocell layer (second

tier) is one of the key challenges to attain the QoS requirements. Handover
Keywords: related information gathering becomes very hard in high dense femtocell

networks, effective handover decision techniques are important to minimize
LTE-A 1 >: ;

, unnecessary handovers occurred and avoid Ping-Pong effect. In this work,
Q-learning we proposed and implemented an efficient handover decision procedure
T'wo-tier networks based on users’ profiles using Q-learning technique in an LTE-A macrocell-
Vertical handover femtocell networks. New multi-criterion handover decision parameters are
proposed in typical/dense femtocells in microcells environment to estimate
the target cell for handover. The proposed handover algorithms are validated
using the LTE-Sim simulator under an urban environment. The simulation
results showed noteworthy reduction in the average number of handovers.

Copyright © 2020 Institute of Advanced Engineering and Science.
All rights reserved.

Corresponding Author:

Ammar Bathich,

Faculty of Electrical Engineering,
Universiti Teknologi MARA,

40450 Shah Alam, Selangor, Malaysia.
Email: ammarbat2003 @ gmail.com

1. INTRODUCTION

Dependency on using the handover procedure in long term evolution advanced (LTE-A) networks
for the User Equipment UE mobility results in the reduction in wireless network complexity [1]. In spite of
this advantage, the handover still experiences multifunction. For example, the handover decision is affected
by carrier interferences and inflexibility [2-4]. This keeps us with the QoS requirements in high delay and
loss during handover among cells [5]. The handover procedure will become more critical when the UE starts
moving from the serving station to the target station [6]. Furthermore, the smooth handover technique needs
to be periodic and fast, and the data transfer should not be lost and delayed. Even more, the increasing
demands for using wireless broadband has led to the mobile network operators deploying more wireless cells
of various types (macrocell (eNB) and femtocell (HeNB)) to fulfil the data traffic rate [7]. Thus, a handover
between the two-tier networks will cause an unnecessary handover effect, handover failure and a drop in
the performance of the wireless network. The Figure 1 shows eNB and HeNBs cells in E-UTRAN LTE-A
architecture.

The standard handover decision in LTE-A is based on the received signal strength (RSS) and
received signal quality (RSQ) parameters. Thus, the deployment of dense HeNBs inside the eNB cell would
increase the interference. This interference reduces the RSQ by decreasing the RSS ratio in comparison to
the Received Signal Strength Indicator RSSI. As a result, a degradation in handover performance is

Journal homepage: http://ijece.iaescore.com/index.php/IJ ECE
Int J Elec & Comp Eng ISSN: 2088-8708 O 5825

observed [8]. Moreover, the variation in transmitting power between the two types of wireless networks
(eNB and HeNB) is another issue. When the HeNB location is near the eNB tower, the RSS of the HeNB will
always be less than the eNB [9-12].

Many researches have worked on enhancing the handover procedure in the wireless networks in
LTE-A. This has been achieved by reducing packet loss and packet delay and simultaneously increasing
network throughput. LTE-A promises improvement in handover performance and guarantee of a satisfactory
QoS for real time applications. However, there are still many concerns regarding the capability of adopting
these schemes in real environments. This real environment deployment issue can be solved by minimizing
the extra overhead of corresponding mechanisms and thus minimize calculation time.

The drawbacks that must be addressed in LTE-A handover technique could be summarized in three
points: Firstly, current selection of handover decision parameters is based on RSS and RSQ parameters,
which are inappropriate for high-density HeNB deployment in LTE-A networks. Secondly, long searching
time/frequent handovers due to presence of multiple target cells which cause degradation of handover
performance. Thirdly, inefficient in the standard handover scheme in the presence of HeNB cells yields to
unnecessary handovers, handover failure and dropping the network performance.

Various works in the handover decision were proposed in [13-16] to find out the target station.
In [15, 16], the mobility forecast of a user equipment is based on keep tracking of its previous three locations.
Nevertheless, the researchers did not explain their methodologies for choosing the locations of UE as well as
the distances among them, they did not take into consideration macrocell load. Furthermore, in [13, 14],
the target station was selected based on the probability of the UE movement activity in systematic directions
with fixed speed, nevertheless, this suggested method cannot be realized in real conditions. In this work,
a novel handover decision structure is proposed for choosing the target station based on UE mobility history
by applying a Q-learning based technique that takes a handover decision according to the current and past
history of the environment. We compared our handover proposed algorithm with Suman work [17] in terms
of average number of handovers. LTE-Sim simulator has been developed to evaluate the system
performance. The remainder of the paper is structured as follows: Section 2 shows and discusses
the Q-learning environment used. The proposed model has been discussed in section 3. Section 4 condenses
the performance evaluation of the proposed work. Finally, section 5 summaries the paper.

bh 6 \

MME / /SGw MME / S-GW MME /S-GW
eee HN Aten a >
OUP 81S i |
~ fe ~
(9) “of SP Ww g
nN! ‘ ;
I Q ? PAR ‘ HeNB GW
NBN fen ‘ \ E-UTRAN

SIO xf .

(( «) (( .)
eNB ———e\
—x2—

HeNB HeNB

 

 

Figure 1. HeNBs in E-UTRAN architecture

2. Q-LEARNING ALGORITHM

Q-Learning is a type of machine learning technique where an agent attempts to find an ideal strategy
from its history of movement inside a dynamic framework [18]. In Q-learning technique, an agent studies
ideal activities/actions via experimentation communication with its surrounding. On each progress, the agent
picks an activity that modifies the condition of the framework via a progress stage, at that point it gets
a reward showing how positive or negative the activity was. The agent objective is to strengthen this reward
by calculating the ideal approach and picking the best activity for each condition of the framework.
The objective of Q-Learning is to gain proficiency with an approach that advises an agent which
activity/actions to make under which conditions.

Definition: In Q-learning procedure, an agent attempts to discover the strategy that maximizes
the Q-value function which offers the expected utility of choosing an action a in an existing state s.

Q-learning vertical handover scheme in two-tier LTE-A networks (Ammar Bathich)
5826 O ISSN: 2088-8708

Formulation: The objective of a Q-learning process is to discover the best strategy [op that
maximizes the cumulative expected reward (over many trials) in the learning process (n is the number
of trials):

[[ opt (E [xea0 VR (Sk - ax) (1)

y which is (0 < y < 1) represents a discount factor. At learning trial k, with an action a, taken in state s;,
the received reward is represented as R(s, —a,). For y = 0 upcoming rewards have no effect on
the state value, whereas for y close to 1, upcoming actions are considered as important as the immediate
rewards. A Q-function is defined for a given policy IT as:

Q(s, a) = R(s, a) + Y dives Psy (a)Q(u,b) (2)

where:
R(s, a) is the expected reward of the current pair of state-action, which represents an action a taken in state
environment s.

P; y (a) is the probability of transition from the current state s to the next state v as an outcome of action a.
Q(v, b) is the new state-action pairs Q-function value.

To ensure that there is at least one optimal strategy II* in a single agent environment, we apply
Bellman’s optimality [19]. Q-function maximum value which indicates the optimal action b for every
possible next pair (vu, b) is denoted as Q*(s,a) .

Q*(s,a) = R(s,a) + Moves Poy (A) Maxye, Q*(u,b) (3)

In an iterative procedure, Q-learning determines the optimal Q*(s,a). At each stage during the learning
procedure, the Q-value function should be updated using the (4):

Q,(s,a) = (1 — a)Q;-1(S, a) + a(R,(s, a) +ymaxy Qr_i(, b)) (4)

where o represent the learning rate.

3. RESEARCH METHOD

All parameters related to handover decision phase based on Q-learning technique are defined
as follows:
a. Environment: involves all components besides the agent

In our framework, it contains the macrocell eNB and all femtocells HeNBs in the UEenp’s
neighboring cell list (NCL). We consider that the environment is a discrete-time, finite-state and stochastic
dynamic system.
b. Agent: is the decision maker

In our case, the agent involves the macrocell mobile user UEeng executing a handover process from
its serving cell to another neighboring cell that provide better performance.
c. State: is the environment’s current state

In our framework, it involves the current UEeng serving cell, which is the macrocell eNB. The state
set S is defined as S = {s = 1,2,..., Nyc, +1} where Nyc, is the number of neighboring femtocells. (s = 1)
refers to the initial state where the mobile user UEeNB is connected to the macrocell eNB. To select
the target cell in a short time we have to short-list the neighboring femtocells, to optimize the candidate
neighboring cell list we propose Distance and moving Direction Q-learning based technique (D’Q technique).
The UE direction assists the handover decision through avoiding signaling measurement controls with
neighbor cells that are not ahead of the UE trajectory as well as in selecting the neighbor cell that fits as
the target cell. The distance between UE and target cell is important, which should not exceed the cell radius,
in order that cells which are far away from the mobile user are not involved in the candidate neighboring list.

Neighbor cells location and each user equipment UE position are determined using GPS [20].
|+6,,°| is the range that all nominee cells should be situated ahead of the user equipment UE direction,
and each cell that is located inside this zone will have the priority to be combined into the candidate cell
list [20]. Assume that a UE is moving from location P; to location P2 as shown in Figure 2, P3 is the neighbor
cell location. Every neighbor cell of the user equipment is tested via calculating the angle 0 of ZP3, P,, P3
as following:

Int J Elec & Comp Eng, Vol. 10, No. 6, December 2020 : 5824 - 5831
Int J Elec & Comp Eng ISSN: 2088-8708 O 5827

1 (P3—P1 ).(P2-P1 )
0 = cos ++ ++ > 5
P2>-P1, D3 |P3—-P4 ||P2—-P3 | ( )

where P, , P, and P3 are P, (x, , V1), Po (%2, 2 ) and P3 (x3, y3 ) respectively.

The distance between the user equipment and the neighbor cell is applied, which should not exceed
the neighbor cell radius, in order that cells which are far away from the user equipment are not involved in
the candidate cell list [21-23]. The distance between the user equipment at position P, and the cell at
location P; is calculated by (6):

Anan, = ¥ (X%3 — X2)* + (V3 — 2)? (6)

For UE moves from position P, towards neighbor cell located at P3; , we consider the neighbour cell
to be a candidate cell if(@ < |+0,,°|) and(d,,,, < neighbor cell radius dj, ). The next stage contains
selecting the target cell from the nominee candidate list by utilizing the Weight Adjustment algorithm [20].
In our work, the shortest distance to the user equipment’s current position and the narrowest 8 from
the candidate cell list would be the most appropriate target cell. The Weight Adjustment algorithm is shown
in Algorithm 1.

Algorithm 1. Weight adjustment
1: Input Op,p,p, and dp,p,

> Output: Whorm

_ 9P2,P1P3

> Onorm = 1 a

> dporm = 1 — e382
° norm 2r

oO B® W NY

Onorm + dnorm

° Wnorm

Wnorm 18 used for choosing the target cell. Furthermore, normalization is also implemented for both
distance and angle, in order that both will be according to standard integration. For normalization we use @ as
the angle value. @n6;m involves the result of angle normalization as all angles of the candidate cells are less
than or equal |+6,,°|, this angle (@) is used for normalization procedure. dyo,-m involves the result of
distance normalization which is normalized via cell transmission range (27r) to enhance the priority of
the angle value, as the distance of all nominee cell list is less or equal to r. These methodologies for choosing
the candidate cell list and selecting the target cell are illustrated in Algorithm 2.

Algorithm 2. Choosing the candidate cell list and selecting the target cell
Input: Py (%1,¥1),P2(%2,y¥2) and P3(x3,y3)

Output: Cellrarget

N is an empty array which will include the candidate cell list

1: for each neighbor cell do
P3—P,).(P2—-P
- Ppaps,ps = COS DePiliPaps
3: 1£ (Op, ps SIFOin°|) then
4: add cell to N
5: end if // line 3
6: end for // line 1
7: if N is not empty then
8: for each cell CNdo
9Q: dyap, = V (X3 — X2)* + (V3 —¥2)* // cell position is (X%3—Yys)
10: Weell = Weell + Wrorm(9 norm + dnorm)
11: end for // for line 8
12: Celliargee = The cell with the maximum Wei,
13: rest Wee of all cells by 0
14: else // line 7
15: Cellrarger = 0
16: end if //line 7

17: return Cellrarget

d. Action: is the agent decision result

In our framework, it refers to the handover decision results: the UEeNB may keep its
connection with the serving macrocell eNB (action1) or select one of the femtocells HeNBs from its NCL
(action 2, ..., action Nycy, + 1). In our proposal algorithm, we use the e-Greedy technique with an adaptive e€
scheme by presenting RSRQ-dependent exploration instead of a fixed or a hand-tuning e€ parameter
(RSRQ Q-learning based technique (Q2 technique)) [24, 25]. Unlike the traditional «-Greedy method,

Q-learning vertical handover scheme in two-tier LTE-A networks (Ammar Bathich)
5828 O ISSN: 2088-8708

which use a fixed € parameter, the required action of Q2 technique is to make the agent more explorative
in circumstances when the information about the environment is unclear. Q2 technique algorithm is
shown in Algorithm 3.

Algorithm 3. Q* technique

Ae: the amount of decrease or increase of €, 0<e< 1
Stage 1: Set Ae to 0.01 and € to 0.1

Stage 2: At each trail, we compare RSRQ;:-; and RSRQ:.

-if RSRQ:-; < RSROQ:, then € = e€ - Ae

-else € = E+ Ae

e. Reward: It indicates the quality or goodness of the action a in the state s, considered as a utility function
and denoted by R

In our framework, the reward is the earned capacity after connecting to the target cell (eNB or
HeNB). Our objective is to maintain and maximize the capacity of UE.ng connecting to a new cell after
a handover process (Capacity Q-learning based technique (CQ technique)). Thus, if UEenp selects
the macrocell eNB as a serving cell, the utility function R which is a perceived reward (capacity) of the target
cell is expressed as 1. Else if UEeng selects to connect to one of the femtocells HeNBs in its NCL, the utility
function R is expressed as 2 [26, 27].

Let Peyg be the transmitted power by the macrocell eNB and hyg, the gain of the channel between
the macrocell eNB and its serving kin macrocell user UEeng. Similarly, hi; represents the gain of the channel
between the in, femtocell HeNB and the jm femtocell user UExens. Lastly, Pi represents the transmit power of
the itn femtocell HeNB. An Additive White Gaussian Noise (AWGN) is considered at macrocell user UEenp
with o* power. Macrocell user UEens k capacity from its serving macrocell eNB is calculated by (7):

 

2
C, = B log, (1 4 Hewuc| Pent) (7)

N UEengp o7+I

where B is the available bandwidth, J = Yi HeNBl hy |"P, is the interference from neighboring femtocells
HeNBs, and Nyeng is the number of neighboring femtocells HeNBs. We consider that the bandwidth is
equally allocated to all users (UEenp and UEnens). The capacity at femtocell user } (UEnenp) j from femtocell
(HeNB) 1 is given by (8):

2
C; = —“— log, (: + =f) (8)

N UEyenp o*+lenB+ IHeNB

2 . . . .
where Ipvg = lhene, j | Peng is the interference from macrocell eNB, heyg; is the gain of the channel

between macrocell eNB and user j. Also, Iyeyg = Yisil hy, j \"P, is the interference from other femtocells
HeNBs and h, ; is the gain of the channel between HeNB, , transmitting with power P, , and user j.

  
   

fr, s\
HeNB 4\((»)))
(9) AP. cdo)

Figure 2. User equipment distance and moving direction

Int J Elec & Comp Eng, Vol. 10, No. 6, December 2020 : 5824 - 5831
Int J Elec & Comp Eng ISSN: 2088-8708 O 5829

4. RESULTS AND DISCUSSION

The LTE-Sim simulator [28] is used to evaluate the performance of the proposed algorithm
depending on the number of the handovers with compare to the algorithm introduced by Suman [17].
The topology consists of two macrocells (eNB) with a radius of 1km each and various femtocells (HeNBs)
density, the femtocell number is configured as 30, 50, 70 and 90 in each macrocell, and all femtocells are
covered by open access type to allow the user equipment UE to handover to each femtocell. Each femtocell
radius covers 30 meters. The UE number is configured as 15, 30, 45 and 60. The UEs are distributed
randomly in each macrocell coverage area and each UE starts moving from the center of its serving eNB
based on random mobility.

The handover decision in the proposed topology will cover three vertical handover types: Hand-in,
Hand-between and Hand-out handovers based on the availability of each vertical handover type.
Each femtocell will be randomly located between 50 meters to 1000 meters from the macrocell location in
three dependent scenarios: close, middle and at the edge. Concerning femtocells distribution scenarios:
close, middle and at the edge, femtocells are distributed in four different groups: 30, 50, 70 and 90 in each
scenario. Figure 3 presents the average number of handovers for the proposed algorithm in each scenario for
30 UEs. As shown in Figure 3, the relationship between the average number of handovers and femtocells
density is positive relationship, which means that the average number of handovers increase when femtocells
density increase. While it has the lowest average when the femtocells distribution is at the edge. This is
because the mobile users start to move from the location of macrocell tower. In addition, the average of
handovers number increases as the number of femtocells in all distribution scenarios increases.

Furthermore, the results of the average number of handovers for the proposed algorithm and Suman
handover algorithm were discussed in terms of femtocells that are distributed to groups of 30,50,70 and 90
per each macrocell, and two groups of UEs (15 and 30) as presented in Figure 4. Based on each result,
it is evident that by increasing the femtocells number, both algorithms show an increment in the average
handovers number, because mobile users make additional handovers with respect to their movements in each
mobile user group.

The results emphasize that the best performance was achieved by our algorithm in all distributions
of femtocells and all densities. This is because of utilizing Q-learning methodology which allow the mobile
user to learn from his previous history, in addition to other supporting methodologies which do not allow
the mobile user to connect to femtocells that are only close to the it, but to connect to those located in front of
or approximately ahead of current mobile user position in order to avoid the redundant handover.

The user equipment only nominates the femtocell whose tower location is less than 1+25] and
the distance between the UE and the candidate femtocell is less than or equal 28 meters. On the contrary,
in the case of Suman handover decision the handover procedure is triggered when the RSS between the UE
and its neighbor femtocells is higher than the RSS between the UE and its serving cell without any
consideration of how long the target femtocell will serve the UE and its usefulness to do handover or not.

AVERAGE NUMBER OF HANDOVEF
_ ff
—S

Figure 3. Comparison of average number of handovers of the proposed algorithm in three scenarios:
close, middle and at the edge

Q-learning vertical handover scheme in two-tier LTE-A networks (Ammar Bathich)
5830 O ISSN: 2088-8708

7.800
mwiee

600

9,500
) 400
3300
9200
: 30 femtocells

Ch) fay
rv c

AVERAGE NUMBER OF HANDOVERS

 

ntocells 70 femtocells 90 femtocells

G Proposed algorithm - 15 MUs 0.029 0,087 0.116 0151
G Proposed algorithm - 30 MUs 0,087 0,159 0,224 0,383
OSuman algorithm (2017)- 15 MUs 0,066 0,149 0.340 0.365
GO Suman algorithm (2017) - 30 MUs 0,140 0,399 0,523 0,730

Figure 4. Comparison of average number of handovers for both algorithms

Finally, regarding the total average number of handovers for each UE group, it is reduced in
the proposed algorithm by (55.63%) compared to Suman handover algorithm for all various femtocells
densities when the number of UE is 15. Moreover, the proposed algorithm reduces the total average number
of handovers by (41.74%) compared to Suman handover algorithm for all various femtocells densities when
the UEs number is 30.

5. CONCLUSION AND FUTURE WORK

The simulation results show that the proposed algorithm performs well in enhancing the handover
decision in LTE-A networks. The simulation results examined the proposed algorithm for femtocells of
the open access type in order to enhance the target femtocell selection in the vertical handover decision.
The selection of suitable parameters to improve the handover decision still encompasses a wide area research.
Therefore, the recommendation for further research in this field can be as follows: Firstly, is to investigate
different parameters of user performance in light of handover and load balancing in the wireless system over
horizontal and vertical networks. Secondly, to investigate different parameters of user performance on both
femtocell types: the close and hybrid. Finally, in regard to implementation, UE velocity should be taken into
account in the handover decision as the main behavior. Thus, by monitoring the three main behaviors at UE
which are the UE mobility, acceleration, and deceleration as the frequent line changes, the suitability of
the proposed algorithm for the VE behavior can be ensured.

ACKNOWLEDGEMENTS

The authors would like to express the gratitude to the Ministry of Education, Malaysia and
Universiti Teknologi MARA, Selangor, Malaysia for the financial support given for this project (Geran
Bestari Perdana) [File No: 600-IRMI/PERDANA 5/3 BESTARI (095/2018).

REFERENCES

[1] B. Ma, et al., “Modeling and Analysis for Vertical Handoff Based on the Decision Tree in a Heterogeneous Vehicle
Network,” IEEE Access, vol. 5, pp. 8812-8824, 2017.

[2] T. Zahir, et al., “Interference Management in Femtocells,’ IEEE Communications Surveys & Tutorials, vol. 15,
no. 1, pp. 293-311, 2013.

[3] G.Godor, et al., “A Survey of Handover Management in Lte-Based Multi-Tier Femtocell Networks: Requirements,
Challenges and Solutions,” Computer Networks, vol. 76, pp. 17-41, 2015.

Int J Elec & Comp Eng, Vol. 10, No. 6, December 2020 : 5824 - 5831
Int J Elec & Comp Eng ISSN: 2088-8708 OO 5831

[4]

[5]
[6]
[7]

[8]

[9]

[10]
[11]
[12]
[13]
[14]
[15]

[16]

[17]
[18]
[19]
[20]
[21]

[22]

[23]

[24]
[25]

[26]

[27]

[28]

S. Bhosale and R. Daruwala., “Multi-criteria Vertical Handoff Decision Algorithm Using Hierarchy Modeling and
Additive Weighting in an Integrated WLAN/WiMAX/UMTS Environment-A Case Study,” KSI Transactions on
Internet & Information Systems, vol. 8, no. 1, pp. 35-57, 2014.

N. Rajule, et al., “Survey of vertical handover decision algorithms,” International Journal of Innovations in
Engineering and Technology (IJIET), vol. 2, no. 1, pp. 362-368, 2013.

H. Kwak, et al., “Mobility management survey for home-eNB based 3GPP LTE systems,” Journal of Information
Processing Systems, vol. 4, no. 4, pp. 145-152, 2008.

S. Neeraja, et al., “Analysis of Adaptive Hysteresis Based Horizontal Handoff Algorithm for GSM,” International
Journal of Innovative Research in Electrical, Electronics, Instrumentation and Control Engineering, vol. 1,
no. 9, pp. 433-437, 2013.

X. Yan, et al., “A survey of vertical handover decision algorithms in fourth generation heterogeneous wireless
networks,” Computer Networks, vol. 54, no. 11, pp. 1848-1863, 2010.

A. Gharsallah, et al., “Network Selection in Heterogeneous Wireless System Environments,” Journal of Networks,
vol. 10, no. 12, pp. 633-641, 2015.

S. Ciochina, et al., “An Optimized Nlms Algorithm for System Identification,” Signal Processing, vol. 118,
pp. 115-121, 2016.

Y.C. Wang and C. A. Chuang, “Efficient Enb Deployment Strategy for Heterogeneous Cells in 4G LTE Systems,”
Computer Networks, vol. 79, pp. 297-312, 2015.

M. H. Hachemi, et al., “Predicting the Probability of Spectrum Sensing with Lms Process in Heterogeneous LTE
Networks,” Radioengineering, vol. 25, no. 4, pp. 808-820, 2016.

H. Ge, et al., “A history-based handover prediction for LTE systems,” 2009 International Symposium on Computer
Network and Multimedia Technology, pp. 1-4, 2009.

Y. H. Wang, et al., “A handover prediction mechanism based on LTE-A UE history information,” 2014
International Conference on Computer, Information and Telecommunication Systems (CITS), pp. 1-5, 2014.

X. Chen, et al., “Efficient and prompt handover in LTE-based systems by predicting the target eNodeBs,” 2014
International Conference on Cyber-Enabled Distributed Computing and Knowledge Discovery, pp. 406-413, 2014.
F. M. Chang, et al., “An efficient handover mechanism by adopting direction prediction and adaptive time-to-
trigger in LTE networks,” International Conference on Computational Science and Its Applications, vol. 7975,
pp. 270-280, 2013.

S. Deswal and A. Singhrova, “A Vertical Handover Algorithm in Integrated Macrocell Femtocell Networks,”
International Journal of Electrical and Computer Engineering (IJECE), vol. 7, no. 1, pp. 299-308, 2017.

E. Alpaydin, “Introduction to machine learning,” MIT press, 2nd edition, 2010.

C. J. C. H. Watkins and P. Dayan, “Technical note: Q-learning,” Machine Learning, vol. 8, pp. 279-292, 1992.
Y.S. Huang, et al., “A Handover Scheme for LTE Wireless Networks under the Assistance of GPS,” Proceeding
2013 8th International Conference on Broadband and Wireless Computing, Communication and Applications,
BWCCA, pp. 399-403, 2013.

A. Bogdanov, “Location identification and handover in new-generation mobile networks,” 2020 Moscow Workshop
on Electronic and Networking Technologies (MWENT), Moscow, Russia, pp. 1-4, 2020.

M. A. Wong, J. A. J Alsayaydeh, S. M. Idrus, N. Zulkifli, and M. Elshaikh, “Efficient P2P data dissemination in
integrated optical and wireless networks with Taguchi method,” TELKOMNIKA Telecommunication, Computing,
Electronics and Control, vol. 17, no. 4, pp. 1642-1647, 2019.

K. Ahuja, et al., “Network Selection Based on Weight Estimation of QoS Parameters in Heterogeneous
Wireless Multimedia Networks,” International Journal of Wireless Personal Communications, vol. 77, no. 4,
pp. 3027-3040, 2014.

H. A. Mahmoud, et al., “Performance of Open Access Femtocell Networks with Different Cell-Selection Methods,”
in 2010 IEEE Vehicular Technology Conference, pp. 1-5, 2010.

C. Dhahri and T. Ohtsuki, “Learning-based Cell Selection Method for Femtocell Networks,” IEEE Vehicular
Technology Conference, pp. 1-5, 2012.

B. Liu, et al., “AHP and Game Theory based Approach for Network Selection in Heterogeneous Wireless
Networks,” IEEE Consumer Communications and Networking Conference (CCNC), Las Vegas, Nevada, USA,
pp. 501-506, 2014.

V. A. Narayanan, et al., “An Intelligent Vertical Handover Decision Algorithm for Wireless Heterogeneous
Networks,” American Journal of Applied Sciences, vol. 11, no. 5, pp. 732-739, 2014.

G. Piro, et al., “Simulating LTE cellular systems: an open source framework,” [EEE Transactions on Vehicular
Technology, vol. 60, no. 2, pp. 498-513, 2011.

Q-learning vertical handover scheme in two-tier LTE-A networks (Ammar Bathich)
