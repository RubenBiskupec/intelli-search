Reddy et al. J Big Data (2020) 7:35
https://doi.org/10.1186/s40537-020-0031 1-y

© Journal of Big Data

RESEARCH Oy oT-Ta waa -55 4

®

Analyzing MRI scans to detect glioblastoma
tumor using hybrid deep belief networks

Annapareddy V. N. Reddy!, Ch. Phani Krishna, Pradeep Kumar Mallick?, Sandeep Kumar Satapathy’,
Prayag Tiwari*, Mikhail Zymbler? and Sachin Kumar? ®

 

*Correspondence:
sachinagnihotril 6@gmail.com
> Department of Computer
Science, South Ural State
University, Chelyabinsk, Russian
Federation

Full list of author information

is available at the end of the
article

o) Springer Open

Abstract

Glioblastoma (GBM) is a stage 4 malignant tumor in which a large portion of tumor
cells are reproducing and dividing at any moment. These tumors are life threaten-

ing and may result in partial or complete mental and physical disability. In this study,
we have proposed a classification model using hybrid deep belief networks (DBN)

to classify magnetic resonance imaging (MRI) for GBM tumor. DBN is composed of
stacked restricted Boltzmann machines (RBM). DBN often requires a large number of
hidden layers that consists of large number of neurons to learn the best features from
the raw image data. Hence, computational and space complexity is high and requires
a lot of training time. The proposed approach combines DTW with DBN to improve
the efficiency of existing DBN model. The results are validated using several statistical
parameters. Statistical validation verifies that the combination of DTW and DBN outper-
formed the other classifiers in terms of training time, soace complexity and classifica-
tion accuracy.

Keywords: Discrete wavelet transform, Deep belief network, Glioblastoma tumor,
Magnetic resonance imaging

 

Introduction
Glioblastoma (GBM) is a stage IV aggressive malignant brain tumor, which is generally
found in the cerebral hemispheres of the brain [1]. The treatment of GBM tumor is very
difficult and cure is not possible in most of the cases. The treatment can only slow down
the progress of the cancer and may reduce the symptoms and discomfort. The diagno-
sis of GBM contains neurological exams, imaging tests i.e. MRI and biopsy. The GBM
tumor may occur at any age; however, the high majority of the patients are adults. The
symptoms of GBM may include worse headache, nausea, vomiting and seizures (Fig. 1).
Medical science is equipped with advanced devices and technology. MRI machines
are able to capture high contrast images of the brain and other parts of the body.
These MRI scans are very useful to diagnose and detect tumors and other defected
cells. However, sufficient knowledge and experience is desirable in order to read and
understand these MRI scans. Sometimes, unavailability of such trained people may
delay the diagnosis process. Therefore, in order to automate the process, a classifi-
cation model can be developed using machine learning methods. Artificial neural

© The Author(s) 2020. This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing,
adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and
the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material
in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material
is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the
permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http://creativeco
mmons.org/licenses/by/4.0/.
Reddy et al. J Big Data (2020) 7:35 Page 2 of 17

 

  

M@ fore. Glioblastoma
4 t 2 4 . ; .

     

 

 

Fig. 1 Glioblastoma brain tumor
X

network (ANN) is one of the powerful approaches in machine learning which are
able to handle large amounts of data with desirable accuracy. Advancement in ANN
came up with deep neural architectures i.e. convolutional neural network (CNN) and
recurrent neural network (RNN). Deep neural network [2] allows us to understand
the hidden patterns from the complex data and images. Deep belief networks (DBN)
is a class of deep neural networks with multiple layers of hidden units in which con-
nections are established between layers rather than units within each layer. Each layer
in DBN is a restricted Boltzmann machine (RBM) stacked against each other to con-
struct the DBN. Deep learning approaches are able to automatically extract the fea-
tures from the large data sets, however the correctness of the extracted features are
not guaranteed [3-5]. In order to overcome this issue, this article proposed a DTW
based DBN approach for image classification.

The rest of the article is organized as follows: In “Literature review section’, state of art
literature review is presented. “Materials and methods” section discusses the materials
and methods that consist of the description of the data set and methodology used in the
study. “Results and discussion” section presents results and discussion and “Conclusion
and future scope” section concludes the article with limitation and future scope of the
article.

Literature review

Deep learning approaches have gained a lot of attention in the last decade in the medical
domain. Deep learning methods are capable of extracting complex features from the raw
data and able to construct new features from the existing one. Affonso et al. [6] argued
that human inspection is a time consuming process in several industries to check the
quality of materials. Automatization could improve this process through digital image
processing. However, accuracy and computational cost are very important and therefore
there should be a balance between the two. The authors used convolutional neural net-
works (CNN) with feature descriptors to analyze real world data of woods samples from
industries. They concluded that CNN along with the feature descriptor provides a better
accuracy in classification of the image data. Qayyum et al. [7] proposed a CNN based
approach for content-based image retrieval system for medical image classification.
They used a rich data set of medical images with twenty-four classes for analysis. They
proposed that learning discriminative features directly from the images may reduce the
Reddy et al. J Big Data (2020) 7:35 Page 3 of 17

semantic gaps and would improve the classification. They achieved a classification accu-
racy of 99.77% with deep CNN.

Jaiswal et al. [2], used CNN to classify the pneumonia using chest X-ray. They used
publically available chest x-ray dataset from RSNA (Radiological Society of North Amer-
ica). They evaluated several deep learning models and found that Mask-RNN is able to
achieve better accuracy among others. In [8], Litjen et al. conducted a comprehensive
state of art survey on various methods, applications of deep learning approaches in
medical image analysis, segmentation and object detection. They illustrated how deep
learning is facilitating several aspects of the medical domain. Khatami et al. [3] proposed
an image classification approach for radiography images. They applied Kolmogorov—
Smirnov test to find the most discriminative features from the radiography images. They
argue that DTW can slightly improve the classification performance using deep net-
works. Another study [9] extended the deep convolutional neural network to classify the
echocardiography video images to assist in the diagnosis of heart disease. Data-driven
learning frameworks by incorporating both spatial and temporal information from video
images have been given as input to the CNN in this study and they have achieved 92.1%
accuracy. They also mentioned that incorporating feature extraction helps to improve
the classification performance of deep neural networks. Gao et al. [5] proposed a deep
learning based model to diagnose Alzheimer disease using CT scans of the brain. They
mentioned that CNN provides desirable accuracy that helps in early diagnosis of Alz-
heimer disease. They developed an advanced CNN incorporating both 2D and 3D CNN
networks. The stated that the modified CNN was able to achieve better accuracy and
classification in comparison to other 2D CNN models. Sharma et al. [10] used a deep
learning framework to diagnose cancer cells. They developed a CNN model to classify
the cancer image data and compared with other traditional approaches. They also found
that CNN performs better than other methods. Al-Rahhal et al. [11] developed a deep
learning framework to classify the electrocardiogram signals (ECG) to detect the heart
disease. The extracted suitable features from the ECG data using stacked auto-encoders.
Next, a softmax regression layer is added on the top of the hidden layers in the deep neu-
ral network. Moreover, expert recommendations are considered to label the ECG sig-
nals. They mentioned that the proposed approach achieved better accuracy than other
state of the art approaches.

In another study [12], Tang et al. used multi-scale representation to capture and
represent features from the medical images. Further, extracted features were encoded
using Fisher vector technique. The authors claimed that the proposed approach dem-
onstrated a superior performance on the data set. Zhong et al. [13] stated that the deep
learning model specifically CNN needs a sufficiently large number of labeled samples
to train the model. However, real world hyper spectral labeled images are limited in the
amount. Therefore, deep learning may not be suitable for such kind of data. They sug-
gested that DBN is able to deal with this issue as it provides unsupervised pre-training
to the unlabeled samples but may result in several dead hidden units. They proposed an
approach to deal with this problem and obtained better performance than the original
DBN. Zhao et al. [14] proposed a feature learning method known as discriminant DBN
for learning high-level features for image classification. These discriminant features are

learned by ensemble learning mechanism with DBN in an unsupervised manner. Wang
Reddy et al. J Big Data (2020) 7:35 Page 4 of 17

et al. [15] suggested a semi supervised DBN based on Boltzmann machine by introduc-
ing the relevant constraint and the supervised information are equivalently integrated
into the learning process of this restricted Boltzmann machine and then, this model is
constructed to improve the classification accuracy. Shi and Chi [16] proposed a hyper-
spectral image classification method. This method has exploited the 3D spectral-spatial
information using 3D deep neural networks. They constructed a super pixel to gener-
ate the spatial image to increase the spectral-spatial similarity and diversity. Next, a
3D super pixel based sample filling method has been applied to solve the misclassifica-
tion issue and finally, a 3D recurrent CNN had been used for classification of images.
Similarly, Paoletti et al. [17] proposed a deep CNN based image classification model for
hyper-spectral images by presenting a 3D network based CNN that uses both spatial and
spectral information. They have also implemented mirroring strategy to effectively pro-
cess border areas in the images. The development of computational models for medi-
cal image diagnosis raised a new level of interventional treatment. Therefore, medical
image processing is now one of the most effective ways to quickly diagnose the diseases
and assist the medical staff in quick decision making. As a solution, machine learning
techniques are being used to automate the diagnosis process since last decade. However,
traditional machine learning methods are not sufficient to deal with complex problems.
Therefore, deep learning methods are trying to resolve the limitations of machine learn-
ing based techniques. In this work, an attempt has been made to show a clear cut differ-
entiation between deep learning based methods and non-deep learning based methods
for image classification.

Materials and methods

Data set description

The dataset obtained from cancer imaging archive repository collections of Rider Neuro
MRI images [18]. Rider Neuro MRI images consist of a data set of 19 patients with recur-
rent GBM. The 19 patients had repeat dynamic contrast-enhanced MRI (DCE-MRI)
datasets on the same 1.5T imaging magnet. The total number of high contrast images
is 70,220 for 19 patients. The total size of the data set was 7.3 Gigabytes. The image data
contains two classes: images with the presence of GBM tumor and images without GBM.
Figure 2 illustrates the two classes (with or without presence of GBM tumor) in the data
set.

Proposed approach

In this study, a novel approach is proposed to classify the MRI images using a deep
learning framework. Figure 3 illustrates the proposed framework for image classifica-
tion in three stages. The first stage performs the data preprocessing that consists of fea-
ture extraction using DWT, vectorization and construction of additional features for
processing. The second stage deals with dimensionality reduction of the images using
principal component analysis (PCA) and provides reduced dimensional feature vectors
for smooth image classification. Third stage consists of a stack of RBN that forms a DBN
network with hidden layers.
Reddy et al. J Big Data (2020) 7:35 Page 5 of 17

 

 

 

 

Fig. 2 a Represents a normal brain. b—-h represents brain with GBM tumour
\

Data preprocessing

DWT is a powerful approach for feature extraction from non-stationary signals and
image data. DWT is considered the most suitable for image decomposition and feature
extraction as it can analyze the image resolution on different scales. In this study, bi-
orthogonal wavelet function in which the wavelet function is not necessarily orthogonal
but invertible, has been used. In such case, two scaling functions $(*) are used that are

associated with two different wavelet functions W(x) as given in Eqs. (1)—(4).

P(x) = 2 » h(n) (2x — n) (1)
P(x) = 2 y h(n) (2x — n) (2)
W(x) = 2 Yemen —n) (3)
w(x) = 2d amd — n) (4)

In above equations, x represents input signals (in terms of wavelet transform), g rep-
resents wavelet sequence or scaling mask. The images are decomposed using above
approach up to three levels and each level consists of 4 sub-band images. Each level con-
sists of approximation coefficient, horizontal details, vertical details and diagonal details.

After extracting the features from the data, Principal component analysis (PCA) is
used to reduce the dimension of the data. PCA maps high dimensional data into lower
dimensional without affecting the quality of the data.

As the raw image is processed by DWT there is a decomposition of images and expan-
sion of data as well as feature extractions. But as we go on extracting features with
the above technique the dimension goes on increasing. Hence PCA has been used to
Reddy et al. J Big Data (2020) 7:35 Page 6 of 17

 

  

Dimensionality
Reduction

    
  

 

Data Pre-processing

 

Extracted Construct
onstruction
Feature Feature Vector
of Feature

Extraction Corresponding based ima
using 2D-DWT to Each Image —

Bi-orthogonal
1.3 Wavelet

DBN Based Classification

 

 

 

Fig. 3 Proposed framework for image classification using deep belief network
\

properly deal with the dimension of extracted data. Principal components are the pro-
jection of the original features onto the Eigen vectors and correspond to the largest

Eigen values of the covariance matrix of the original feature set.

Deep belief network (DBN)

Deep belief network (DBN) can be think as a neural network with stacked Recurrent
Boltzmann Machines (RBMs) which are generative auto-encoders. To deal with image
classification problem, DBN may have many layers, which are trained in a greedy layer
wise strategy. DBN consists of two type of neural networks: belief network and RBMs.
RBM is a stochastic recurrent neural network with stochastic binary units and undirected
Reddy et al. J Big Data (2020) 7:35 Page 7 of 17

edges between them. RBM also has one layer of hidden units in which connections are
restricted between them and results in a more efficient learning algorithm. The probabil-
ity distributions over hidden and visible units can be defined in terms of energy function
[Eqs. (5) and (6)].

P(v,h) = ~exp(-E (v, h)) (5)
where
z=) exp(—E(v,h)) 6)
VA

V and h represents visible and hidden units respectively and z is the partition func-
tion. E is energy function (an energy based model that can be learnt by performing
(stochastic gradient decent on the empirical negative log-likelihood of the training
data). In case of unlabeled image set in the training data, DBN first performs unsu-
pervised training to label the unlabeled images for the training of the model. Further,
the model can be used using deep neural networks over the set of image data.

The parameters needs to be carefully setup for the proposed approach. Deep learn-
ing DBN consists of a stack of RBMs that accomplish the task of DBN collectively.
The values set for the various parameters selected for three RBMs i.e. RBM1, RBM2,
RBMsB3 are shown in Table 1.

The algorithm 1 illustrates the RBM procedure for sigmoidal units and algorithm 2

illustrates the process of DBN learning.

Algorithm 1: RBM procedure
Parameters x: sample from training distribution, ¢: learning rate, w: weight matrix (hxn),
b: bias vector for hidden units, c: bias vector for input units
Procedure:
Begin: RBM (x, €, w, b, c);
For all hidden units 1:
Compute Q(h[0][i] = 1/(1 + exp(x[0]))
#for Gaussian units, Sigmoid (b[i] + sum, (w[i]L/] x x[0]L/]))
Sample h[0][i] from Q(h[0][i] = 1/(1 + exp(x[0]))
End for
For all visible units j:
Compute P(v[1][j] = 1/(1 + exp(h[0]))
#for Gaussian units, Sigmoid (c[j] + sum;(w[i][j] x h[0][i]))
Sample v[1][j] from P(v[1][j] = 1/1 + exp(h[0]))
End for
For all hidden units 1:
compute Q(h[1][i] = 1/(1 + exp(x[1]))
#for binomial units, Sigmoid(b[i] + sum,(w[i][/] x x[1][/]))
End for
W+= e x (h[0] x x[0]” — QCALIL] = 1]@[1) x x[1]"
b+= ex (h[0] — Q(ALLIL] = 11x[1]))
C+= ex (x[0] — x[1]$

 
Reddy et al. J Big Data (2020) 7:35

Table 1 Parameter setup for proposed approach

 

 

 

Parameters DBN architecture

RBM1 RBM2 RBM3
Visible units 40,000 1000 500
Latent units Binary Binary Binary
No. of latent units 1000 500 300
Performance Free energy Free energy Free energy
Max epoch 100 100 100
Learning rate 0.1 0.1 0.1
Model Generative Generative Generative

 

Algorithm 2: DBN Learning Procedure
Parameters: Z: Supervised training distribution for DBN with input samples (x,y)
C: Training criterion function that takes a network output f(x) and target y and returns a scalar
differentiable in f(x)
Epsilon_C: learning rate for the stochastic gradient decent on supervised cost C
L: Number of layers, 1,2...,L b[i]: bias vector for level i where I = 1,2,.....L
V: weight matrix for the supervised O/P layer __c: bias vector for supervised output layer
Procedure:
1. DBN(Z, C, epsilon_C, L, n, W, b, V, c)
2. Recursively define mean-field propagation:
muli](x) = Expectation(g|i]|g[i — 1] = mu[i — 1](x))
Where,
mu|i|(x) = x and
Expectation(g[ilg[i — 1] = mu[i-—1]) is the expected value of g[i] under the RBN
conditional distribution Q(g[i]g[i — 1]
3. When the values of g[i — 1] are replaced by the mean field values mu[i — 1](x)
In case, if g[i] has Gaussian units:
Expectation(g[i][j]|g[i — 1] = Sigmoid(b[i][j] + sum, W[i][j][k]mu[i — 1][k](x)
4 Define the network output function:
f(x) =V xX mul[L](@)' +c
5 Iteratively minimize the expected value of C(f (x), y)

Learning has been done by using stochastic gradient descent with learning rate
epsilon_C (values 0 to 1), using and appropriate stopping criterion based on validation
set.

In this study, several other classifiers are used to evaluate the performance of the pro-
posed approach. Multi-layer Perceptron Neural Network (MLPNN) with back propa-
gation, Recurrent Neural Network (RNN), Radial Basis Function Network (RBFNN),
Extreme Learning Machines (ELM), Probabilistic Neural Network (PNN) and Time
Delay Neural Network (TDNN).

Results and discussion
Experiments have been performed to evaluate the performance of DWT-PCA-DBN
based classifiers. All the experiments have been carried out using Python programming

environment. Since, the size of the data was very huge, we have used a local cloud server

Page 8 of 17
Reddy et al. J Big Data

(2020) 7:35

with high-end configurations along with GPU support. To compare the performances

among several settings, we have trained DBN with various parameters and structures

and computed the results of training and testing errors for each scenario. To compare

the performance with other classification techniques, various performance criterion

such as classification accuracy, specificity, sensitivity and F-score are considered. The

total experimentation process can be compiled in various stages as detailed below.

a. Deep vs. non deep learning methods: For the comparison purpose, in the first fold,

the performance comparison between deep learning based proposed DW'T-PCA-
DBN approach and non-deep learning based methods i.e. MLPNN, RNN, RBEN, ELM,
PNN, TDNN have been done based on classification accuracy, specificity, sensitivity
and F-score as shown in Table 2. From Table 2, it can be understood that proposed
deep learning based proposed DW'T-PCA-DBN image classification model is showing
significantly improved result over non-deep learning based methods. Then, in second
fold of validation gain the performance comparison has been established among tradi-
tional DBN, DW'T-DBN and DW'T-PCA-DBWN as detailed in Table 3. It is evident that
proposed model outperformed the other existing models (Table 2 and 3).

Number of epochs for training of RBN: In this work, the DBN consists of three lay-
ers of RBN such as RBN1, RBN2 and RBN3 and training of RBN algorithms require
certain number of iterations or epochs to converge into an optimal value. A failure to
obtain an optimal value for each RBM results in poor performance of overall system
since RBM is a basic building block of the proposed DWT-PCA-DBN image classi-
fier. It seems that the model training for high iterations yields better results, but in
fact, it takes long time to train and also over-fitting the data may arise, therefore, it is
advisable to stop before the over-fitting occurs. The error graphs shows the perfor-
mance in the form of convergence with respect to number of epochs in Figs. 4, 5 and
6 for three different layers (RMB 1: layer 1, RBM 2: layer 2 and RBM 3: layer 3) for
DBM, PCA-DBM and DWT-PCA-DBM respectively. From Fig. 2, it can be clearly
seen that, layer 3 gradually decreases from 40 till 100 numbers of epochs showing
much better performance and layer 1 and layer 2 shows zig-zag movement from 30
to 100 number of epochs which is a sign of over fitting for traditional DBN network.
From this, it can be concluded that 40 epochs is the best setting for DBN image clas-
sifier in our case. Similarly, Figs. 5 and 6, it can be seen that, layer 3 converges at 50
epochs and 70 epochs for PCA-DBN and DW'T-PCA-DBN image classifiers respec-

Table 2 Performance comparison between deep learning vs. non-deep learning based

 

 

approaches

Classification techniques Accuracy Specificity Sensitivity F-score
MLP 0.85 £0.33 0.83 £0.26 0.87 £0.22 0.84 + 0.30
RNN 0.87 £0.23 0.88 + 0.31 0.85+0.21 0.84 + 0.29
RBFNN 0.79+0.22 0.75 £0.23 0.74 + 0.34 0.7440.21
ELM 0.90+0.15 0.87 £0.32 0.91 +£0.22 0.89+0.25
PNN 0.89+0.18 0.90 £0.28 0.87 £0.29 0.88 + 0.32
TDNN 0.86 + 0.32 0.85 £0.25 0.88 £0.23 0.86 £0.29
DWT-PCA-DBN 0.95+0.14 0.94+ 0.16 0.97 £0.26 0.95+0.15

 

Page 9 of 17
Reddy et al. J Big Data

Table 3 Performance comparison between traditional DBN, DWT-DBN and proposed DWT-

(2020) 7:35

 

 

PCA-DBN

Classification techniques Accuracy Specificity Sensitivity F-score
DBN 0.89+0.18 0.88 + 0.26 0.91+0.19 0.90 £0.22
DWT-DBN 0.91 40.19 0.90 £0.24 0.92 +0.18 0.91 +£0.23
DWT-PCA-DBN 0.95 £0.14 0.94+0.16 0.97 £0.26 0.95+0.15

 

 

 

Fig. 4 Error graph for different number of layers for DBN
Ne

Error Graph for Different Number of Layers for DBN

—@ l-Layer
—t- 2-Layer
“he Slayer

 

20 40 60 & 100

Number of Epochs

tively. While comparing the convergence of all three networks with respect to num-
ber of epochs and errors occurred, it can be concluded that proposed DWT-PCA-
DBM is showing best setting with optimal value of error and epochs.

. Weight initialization: Weights initialization is one of the most effective approaches

in speeding up the training of a neural network. In fact, it influences not only the
speed of convergence, but also the probability of convergence and the generalization.
Using too small or too large values could speed the learning, but at the same time,
it may end up performing worse. In addition, the number of iterations of the train-
ing algorithm and the convergence time would vary depending on the initialized val-
ues. In this phase of performance validation, considering weight initialization for all
three individual deep learning based networks and other methods have been meas-
ured and given in Figs. 7, 8, 8 and 9. Three different initialization methods have been
applied during the training of 100 epochs such as (a) small weights between 0 and 1
(b) large weights between 1 and 10 and (c) initializing with zero weights. For DBN
network from Fig. 7, it can be seen that, initializing the weights of DBN network with

 

Page 10 of 17
Reddy et al. J Big Data (2020) 7:35 Page 11 of 17

 

Error Graph for Different Number of Layers for PCA-DBN

10

Log of Error

 

2 40 et) & 100
Number of Epochs

 

 

Fig.5 Error graph for different number of layers for PCA-DBN
\

 

 

 

 

J
cr >)
Error Graph for Different Number of Layers for WT-PCA-DBN
10
—@ )-Layer
—t- 2-Layer
“wk Layer
8
6
a)
4
2
0
2 40 ei & 100
Number of Epochs
Fig.6 Error graph for different number of layers for proposed DWT-PCA-DBN
\ J

 

 

all the types of random values results in converging from 40 epochs but experiment-
ing with small random weights results in least error. PCA-DBN network as shown

in Fig. 8 also shows better convergence and less error with respect to initializing the
Reddy et al. J Big Data

(2020) 7:35

network with small weights. Similarly, in proposed DW T-PCA-DBN network shown
in Fig. 9, experimenting with small values for weight initialization helps the network
with least error, though, it converges at 70 epochs. While comparing among all three
networks from Fig. 10, it can be concluded that, proposed DWT-PCA-DBN net-
work for image classification is showing outstanding performance with respect to the
number of epochs and error. DBN network is converging at 40 epochs, while PCA-
DBN is at 100 epochs and DW'T-PCA-DBN is 70 epochs with least error in compari-
son to other two networks.

Statistical analysis

Two level statistical analysis such as McMemar’s test along with overall accuracy,
average accuracy, and Kappa statistics for training sets and testing sets have been
conducted for DBN, DWT-PCA and DW T-PCA-DBN as detailed below.

a. The McNemar’s test, which is based upon the standardized normal test statistic,
is used to demonstrate whether the two methods perform differently in the sta-
tistical sense. The statistic is computed using (7).

mniy —_ MNnji
,/mni + mnji (7)

where, mn denotes number of samples misclassified by J classifier but not by

MNij =

j classifier. Similarly mnj;; denotes number of samples misclassified by 7 classifier
but not by J classifier. This is basically derived from the Chi squared distribution

using (8).

 

 

Fig. 7 Error graph for different weight initialization methods for DBN
\

Error Graph for Different Weight Initializers for DBN

 

20 40 60 80 100

Number of Epochs

 

Page 12 of 17
Reddy et al. J Big Data (2020) 7:35 Page 13 of 17

 

Error Graph for Different Weight Initializers for PCA-DBN

~@ Zero Weight
—t- Large Weight
Kk Smal! Weight

Log of Error

0 20 40
Number of Epochs

Fig.8 Error graph for different number of layers for PCA-DBN

 

Error Graph for Different Weight Initializers for WT-PCA-DBN

@ Zero Weight
—t#- Large Weight
“Kk Small Weight

Log of Error

0 2 40 a
Number of Epochs

 

Fig.9 Error graph for different number of layers for proposed DWT-PCA-DBN

»  (b-c)*
~ (b+c) 8)

Under the null hypothesis mnj is equal to mnj;;. That is equivalent to the number

of counts for (9).
Reddy et al. J Big Data (2020) 7:35 Page 14 of 17

 

Error Graph for Different Number of Epochs

 

2 40 & & 100

Number of Epochs

Fig. 10 Error graph for different techniques such as; DBN, PCA-DBN and proposed DWT-PCA-DBN
\

 

 

mn = Mn = (mnij + mnji)/ (9)

At 95% level of confidence, the difference of accuracies between the two methods
(DBN and DWT-PCA-DBN) is significant as | mnjy |=3.841 which is greater than
1.96. Hence the null hypothesis can be rejected. Similarly at 95% level of confidence
the difference of accuracies between the two methods (DW T-DBN and DW T-PCA-
DBN) is significant as | mnjj |=2.147 which is greater than 1.96. Hence, the null
hypothesis can be rejected and the alternative hypothesis can be accepted that states
there is a significant difference between the corresponding two different classifiers.
b. Measuring the overall accuracies (OAs), average accuracies (AAs), and Kappa statis-
tics (Kappa) of ten run of trainings and tests of DWT, PCA-DBN and DWT-PCA-
DBN (Table 4).

The following are few observations of the current study that makes it challenging
and interesting for image classification.

a. In this study, RIDER Neuro MRI data which contains imaging data on 19 patients
with recurrent glioblastoma who underwent repeat imaging sets have been exten-
sively used and experimented.

b. To deal with the large dataset, a local cloud server with high end configurations and
also with GPU support and Python has been used for experimentation.

c. To compare the performances among several settings, the DBN has been trained
with various parameters and structures and computed the results of training and

testing errors for each scenario.
Reddy et al. J Big Data

(2020) 7:35

Table 4 Performance comparison based on overall accuracies, average accuracies,
and Kappa statistics for DBN, DWT-DBN and proposed DWT-PCA-DBN

 

 

 

 

Classifiers Overall accuracies (%) Average accuracies (%) Kappa statistics
DBN 9] 89 0.4811
DWT-DBN 93 9] 0.5732
DWT-PCA-DBN 97 95 0.6522

d. To compare the performance with other classification techniques, various perfor-

k.

mance measurement metrics such as classification accuracy, specificity, sensitivity
and F-score are being measured.

A comparative result has been obtained between deep learning and non-deep learn-
ing based strategies and from Table 2, it can be observed that, proposed deep learn-
ing based proposed DW'T-PCA-DBN image classification model is showing signifi-
cantly improved result over non deep learning based methods.

The performance comparison has also been established among traditional DBN,
DWT-DBN and DWT-PCA-DBN and it can be concluded from Table 3 that, the
performance of DW'T-PCA-DBN is more as compared to other techniques as deep
learning approach is more efficient for image classification task and also the DWT-
PCA-DBN technique outperforms the general DBN as there are more streamlining
of feature selection has been done through DW'T-PCA approach.

. Considering the number of epochs required for training the RBN network, from

Fig. 4 it can be observed that, layer 3 gradually decreases from 40 till 100 numbers
of epochs showing much better performance, similarly, from Figs. 5 and 6, it is seen
that, layer 3 converges at 50 epochs and 70 epochs for PCA-DBN and DWT-PCA-
DEN image classifiers, respectively.

. Therefore, while comparing the convergence of all three networks with respect to

number of epochs and errors occurred, it can be concluded that proposed DWT-
PCA-DBM is showing best setting with optimal value of error and epochs.

As the weight initialization is one of the important factor considered during network
initialization and tuning, in this work, three weight initialization ranges have been
considered for all three deep learning based networks.

For DBN network as shown in Fig. 7, it can be seen that, initializing the weights
of DBN network with all the types of random values results in converging from 40
epochs but experimenting with small random weights results in least error.
PCA-DBN network as shown in Fig. 8 also shows better convergence and less error
with respect to initializing the network with small weights.

Similarly, in proposed DWT-PCA-DBN network shown in Fig. 9, experimenting
with small values for weight initialization helps the network with least error, though,

it converges at 70 epochs.

. While comparing among all three networks from Fig. 10, it can be concluded that,

proposed DWT-PCA-DBN network for image classification is showing outstanding
performance with respect to the number epochs and error. DBN network is con-

Page 15 of 17
Reddy et al. J Big Data (2020) 7:35 Page 16 of 17

verging at 40 epochs, while PCA-DBN is at 100 epochs and DW'T-PCA-DBN is 70
epochs with least error in comparison to other two networks.

n. Additionally, statistical performance measures have been performed using McNe-
mar’s test to validate the significant differences between the different existing and
proposed classifier models.

Conclusion and future scope

Deep learning is well known approach for image classification as it is able to automati-
cally extract the features from image data for further processing. However, the cor-
rectness of the extracted features is not guaranteed because there is no mathematical
validation available for the correctness of those extracted features. To address this issue,
this study proposed an improved DWT-PCA-DBN image classifier based image clas-
sification model by combining DWT for feature extraction and PCA to get optimized
features with DBN. The DBN is composed of stacked RBMs to extract the more signif-
icant features from the reduced datasets layer by layer. Generally, DBN requires huge
and multiple hidden layers with huge number of hidden units to learn the best fea-
tures from the raw pixels of image data. This actually increases the complexity as well
as training time for the model. Therefore, by integrating DBN with wavelet transform
techniques both complexity as well as training time has been reduced. Except using raw
images, the extracted low resolution images from DWT are used for training the pro-
posed image classifier. The proposed model has been experimented with deep learning
based approaches such as traditional DBN, PCA-DBN with non-deep learning based
approaches of variants of ANN and also the performance of the proposed classifier has
been evaluated based on number of epochs for training of RBN and weight initializa-
tion. Finally, the statistical validation justifies the efficiency of this method. The work can
be extended to improve the computation efficiency of the model with respect to large
amount of dataset with occlusion kind of patterns. Occlusion generally refers the block-
age of blood flow into the brain. This type of pattern may occur in a tumor spot. This is
also a kind of abnormality which may need attention for proper diagnosis. In this work
we have not experimented our model for tumors with occlusion kind of pattern due to
the unavailability of such patterns in the data. However, the work can be extended upon
the availability of data with occlusion patterns using deep learning methods.

Abbreviations
DBN: Deep belief networks; GBM: Glioblastoma; RBM: Recurrent Boltzman machine; DWT: Discrete wavelet transform;
PCA: Principal component analysis.

Acknowledgements
Prayag Tiwari has received funding from the European Union's Horizon 2020 research and innovation program under the
Marie Sklodowska-Curie Grant Agreement No 721321.

This work is financially supported by the Ministry of Science and Higher Education of the Russian Federation (Gov-
ernment Order FENU-2020-0022).

Authors’ contributions

AVNR, CPK, PKM, SKS and PT prepared the draft and Idea. AVNR, CPK performed the programming. PKM, SKS and PT ana-
lyzed the results. SK and MZ wrote the manuscript prepared the tables, references and checked the English. All authors
read and approved the final manuscript.

Funding
The research received no external funding.
Reddy et al. J Big Data (2020) 7:35 Page 17 of 17

Availability of data and materials
Data is publically available.

Competing interests
The author declare no competing interests in publication of this article.

Author details

Department of Computer Science, Koneru Lakshmaiah Education Foundation (K L Deemed to be University), Vad-
deswaram, Guntur, India. Department of Computer Science, Teegala Krishna Reddy Engineering College, Hyderabad,
Telangana, India. ? School of Computer Engineering, Kalinga Institute of Industrial Technology (KIIT) Deemed-to-be
University, Bhubaneswar, Odisha, India. * Department of Information Engineering, University of Padova, Padua, Italy.

° Department of Computer Science, South Ural State University, Chelyabinsk, Russian Federation.

 

Received: 3 December 2019 Accepted: 25 May 2020
Published online: 01 June 2020

References

1. Glioblastoma Tumor: https://www.abta.org/tumor_types/glioblastoma-gbm/. Accessed 08 Nov 2019.

2. Jaiswal AK, Tiwari P, Kumar S, Gupta D, Khanna A, Rodrigues JPC. Identifying pneumonia in chest X-rays: a deep
learning approach. Measurement. 2019;145:511-8.

3. Khatami A, Khosravi A, Nguyen T, Lim CP, Nahavandi S. Medical image analysis using wavelet transform and deep
belief networks. Expert Syst Appl. 2017;86:190-8.

4. Gao X, LiW, Loomes M, Wang L. A fused deep learning architecture for viewpoint classification of echocardiography.
Inf Fus. 2017;36:103-13.

5. Gao XW, Hui R, Tian Z. Classification of CT brain images based on deep learning networks. Comput Methods Pro-
grams Biomed. 2017;138:49-56.

6. Affonso C, Rossi ALD, Vieira FHA, Carvalho AC. Deep learning for biological image classification. Expert Syst Appl.
2017;85:1 14-22.

7. Qayyum A, Anwar SM, Awais M, Majid M. Medical image retrieval using deep convolutional neural network. Neuro-
computing. 2017;266:8-20.

8. Litjens G, Kooi T, Bejnordi BE, Setio A, Ciompi F, Ghafoorian M, Laak J, Ginneken B, Sanchez C. A survey on deep learn-
ing in medical image analysis. Med Image Anal. 2017;42:60-88.

9. Gao X, LiW, Loomes M, Wang L. A fused deep learning architecture for viewpoint classification of echocardiography.
Information Fusion. 2017;36:103-13.

10. Sharma H, Zerbe N, Klempert |, Hellwich O, Hufnag! P. Deep convolutional neural networks for automatic
classification of gastric carcinoma using whole slide images in digital histopathology. Comput Med Imaging
Graph. 2017;61:2-13.

11. Rahhal M, Bazi Y, AlHichri H, Alajlan N, Melgani F, Yager RR. Deep learning approach for active classification of elec-
trocardiogram signals. Inf Sci. 2016;345:340-54.

12. Tang Q, Liu Y, Liu H. Medical image classification via multiscale representation learning. Artif Intell Med.
2017;79:71-8.

13. Zhong P Gong Z, Li S, Schonlieb C. Learning to diversify deep belief networks for hyperspectral image classification.
IEEE Trans Geosci Remote Sens. 2017;55:3516-30.

14, Zhao Z, Jiao L, Zhao J, Gu J, Zhao J. Discriminant deep belief network for high-resolution SAR image classification.
Pattern Recogn. 2017;61:686-701.

15. Wang G, Qiao J, Li X, Wang L, Qian X. Improved classification with semi-supervised deep belief network. IFAC-Paper-
sOnLine. 201 7;50(1):41 74-9.

16. Shi C, Pun C. Super pixel-based 3D deep neural networks for hyperspectral image classification. Pattern Recogn.
2018;74:600-16.

17. Paoletti ME, Haut JM, Plaza J, Plaza A. A new deep convolutional neural network for fast hyperspectral image clas-
sification. ISPRS J Photogramm Remote Sens. 2018;145(A):1 20-47.

18. Barboriak D. Data from RIDER_NEURO_MRI. The Cancer Imaging Archive. 2015. http://doi.org/10.7937/K9/TCIA.2015.
VOSN3HN1.

Publisher’s Note

Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.
