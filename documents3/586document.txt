 

Theoretical Computer Science

Theoretical Computer Science 848 (2020) 1-27

Contents lists available at ScienceDirect

 

www.elsevier.com/locate/tcs

 

Conditional probability logic, lifted Bayesian networks, and
almost sure quantifier elimination ie

Vera Koponen

Department of Mathematics, Uppsala University, Box 480, 75106 Uppsala, Sweden

ARTICLE INFO

Article history:

Received 8 April 2020

Received in revised form 28 July 2020
Accepted 8 August 2020

Available online 12 August 2020
Communicated by A. Avron

Keywords:

Logic

Finite model theory

Almost sure elimination of quantifiers
Artificial intelligence

Machine learning

Graphical models

ABSTRACT

We introduce a formal logical language, called conditional probability logic (CPL), which
extends first-order logic and which can express probabilities, conditional probabilities
and which can compare conditional probabilities. Intuitively speaking, although formal
details are different, CPL can express the same kind of statements as some languages
which have been considered in the artificial intelligence community. We also consider
a way of making precise the notion of lifted Bayesian network, where this notion is a
type of (lifted) probabilistic graphical model used in machine learning, data mining and
artificial intelligence. A lifted Bayesian network (in the sense defined here) determines,
in a natural way, a probability distribution on the set of all structures (in the sense of
first-order logic) with a common finite domain D. Our main result (Theorem 3.14) is that
for every “noncritical” CPL-formula g(x) there is a quantifier-free formula g*(x) which is
“almost surely” equivalent to g(x) as the cardinality of D tends towards infinity. This is

relevant for the problem of making probabilistic inferences on large domains D, because
(a) the problem of evaluating, by “brute force”, the probability of g(x) being true for some
sequence d of elements from D has, in general, (highly) exponential time complexity in
the cardinality of D, and (b) the corresponding probability for the quantifier-free @*(x)
depends only on the lifted Bayesian network and not on D. Some conclusions regarding
the computational complexity of finding y* are given in Remark 3.17. The main result has
two corollaries, one of which is a convergence law (and zero-one law) for noncritial CPL-
formulas.
© 2020 The Author. Published by Elsevier B.V. This is an open access article under the CC
BY license (http://creativecommons.org/licenses/by/4.0/).

 

1. Introduction

We consider an extension of first-order logic which we call conditional probability logic (Definition 3.1), abbreviated CPL,
with which it is possible to express statements about probabilities, conditional probabilities, and to compare conditional
probabilities which makes it possible to express statements about the (conditional) independence (or dependence) of events
or random variables. Remarks 3.4, 3.6 and Example 3.5 below illustrate this. The semantics of CPL deal only with finite
structures and assumes that all elements in a structure are equally likely, so (conditional) probabilities correspond to pro-
portions. Quite similar formal languages, which aim at expressing the same sort of statements, have been studied within
the field of artificial intelligence by Halpern [11, Section 2] and Bacchus et al. [2, Definition 4.1]. CPL is more expressive
than the probability logic £,,p considered by Keisler and Lotfallah in [16] (which cannot express conditional probabilities)

E-mail address: vera.koponen@math.uu.se.

https: //doi.org/10.1016/j.tcs.2020.08.006
0304-3975/© 2020 The Author. Published by Elsevier B.V. This is an open access article under the CC BY license
(http://creativecommons.org/licenses/by/4.0/).
2 V. Koponen / Theoretical Computer Science 848 (2020) 1-27

and our first theorem (Theorem 3.14) is a generalization of their main result [16, Theorem 4.9], both in the sense that the
language considered here is more expressive and that we consider a wider range of probability distributions.

A graphical model for a probability distribution and a set of random variables is a “graphical” way of describing the
conditional dependencies and independencies between the random variables. In such a probabilistic model the random
variables are also viewed as the vertices of a directed or undirected graph where edges indicate conditional dependencies
and independencies [3,23]. The notion of a Bayesian network is one of the most well-known graphical models. A Bayesian
network 6 for a probability space (S, 4) and random binary variables X;,..., Xj is determined by the following data where,
for any distinct i;,..., ix, € {1,...,m} and values x1,...,X% that X;,,..., X;, can take, the tuple (x;,...,x,) denotes the event
that Xj, =%1,..., Xi, = Xx:

(1) A (not necessarily connected) directed acyclic graph (DAG), also denoted 6, with vertex set V = {Xj,..., Xn} such that
if there is an arrow (directed arc) from X; to X; then i < j.

(2) To each vertex X; € V, if Xj,,...,Xj, are the parents of X; (in the DAG) and 4j,xj,,...,xj, are values that
Xi, Xj,,-.-, Xj,» respectively, can take, then the conditional probability P(x; | xj,,...,Xj,) is specified’ in such a way
that the following holds:

(a) For each j, the set of parents of X;, denoted par(X;), is minimal (with respect to set inclusion) with the property
that for every i < j, X; and Xj; are conditionally independent over par(X;). The conditional independence means
that if par(X;) = {X1,,..., X1,}, then for all possible values x;,xj,x1,...,X Of Xi, Xj, Xi,,..., X1,, respectively, we
have

P (Xj | Xj.X1,---, Xe) = P(X | X1,.--, Xk)

whenever both sides are defined.”

(b) The joint probability distribution on X1,..., Xn is determined by the conditional probabilities associated with the
vertices of 6. More precisely: The event (x1,...,X,) can be computed recursively by repeatedly using the following
identities which hold for any choice of distinct i1,...,i, € {1,...,n}:

P(X, ..+5Xi,) = P(X, | Xi, 5 +5 Xi, 4) -P(QXi,, ey Xia)
P (Xi, | Xi, 5 Xi, 5) = P(X, | Xj, ey Xin)

if ji,.--,Jm € {i1,..-, tea} and par(Xj,) = {Xj,,..., Xjq}-
If 6 is a Bayesian network as defined above, then it follows (from e.g. [23, Definition 1.2.1 and Theorems 1.2.6, 1.2.7]) that

(i) For every X; € V, Xj; and the set of all predecessors of X; are conditionally independent over par(X/j).
(ii) For every X; ¢ V, Xj; and the set of all nondescendants of Xj; (except Xj; itself) are conditionally independent over

par(X;).

Moreover: if condition (i) or condition (ii) holds, then {X;,..., X,} can be ordered so that conditions (a) and (b) above hold
without changing the arrows of the DAG.

Graphical models are used in machine learning, data mining and artificial intelligence in (probability based) learning
and inference making. To illustrate this by a very simple example, suppose that we have a finite set A of some kind of
objects and properties P,Q and R which objects in A may, or may not, have. We can view A as a “training set”. The
training set can be formalized as a o-structure with domain A where o = {P,Q,R} and P,Q and R are also viewed as
unary relation symbols. Let jz be a probability distribution on A and let binary random variables X,Y, Z:A— {0,1} be
defined by X(a) = 1 if a has the property P and X(a) =O otherwise (for every a € A); Y(a) = 1 if a has the property Q and
Y(a) = O otherwise; and analogously for Z and R. Suppose that, after some “learning”, we have found a Bayesian network
6 for (A, ) and X,Y, Z such that its DAG is as illustrated

yx ey

and the (conditional) probabilities w(X =1), w(Y =1| X=1), wW(Y =1 | X =0), w(Z =1 | X =1) and w(Z =1 | X =0) are
specified. (In real applications, it is unlikely that a relatively simple probabilistic model, which is desirable for computational
efficiency, fits the training data completely and usually this is not even the goal because one wants to avoid so-called
“overfitting”; so one can view the Bayesian network as a reasonable approximation of the training data.) An application of

1 The expression P(x; | Xjpreees X;,) denotes the conditional probability that X; =x; given that Xj, =xj,,..., X j, =X jy.
Or equivalently, we could require that P(x%j,Xj | X1,.--, Xp) = P(X | X4,..., Xx) P (xj | X1,---, Xx) whenever all factors are defined.
V. Koponen / Theoretical Computer Science 848 (2020) 1-27 3

the Bayesian network 6 is to make predictions about probabilities on some other finite domain B. Let us now make the
following assumptions, partly based on 6 but where the independency assumptions between different objects are imposed.
Every b € B has the probability 44(X = 1) of having property P, independently of what the case is for other b’ € B. For every
b € B, if b has the property P then the probability that b also has the property Q (R) is w(Y =1 | X =1) (u(Z =1 | X =1)),
independently of what the case is for other elements in B, and if b does not have the property P then the probability that
b has Q (R) is “w(Y =1 | X =O) (u(Z =1 | X =0)), independently of what the case is for other elements. Based on this
we can define a probability distribution (as in Definition 3.11) on the set Wg of all o-structures with domain B, where
each member of Wg, represents a “possible scenario” or “possible world”. For every formula ~(xj,..., Xx) of conditional
probability logic and any choice of b;,...,bx € B we can now ask what the probability is that @(x1,..., Xx) is satisfied by
by,..., Dr.

When using a Bayesian network 6 for prediction as in the example we have “lifted” it from its original context (the set
A) and used it on a new domain of objects. Also when moving from the fixed domain A to an arbitrary domain B we have,
in a sense, “lifted” our reasoning from propositional logic to first-order logic, or some extension of it. Perhaps this is the
reason why the term “lifted graphical model” is used by some authors when a graphical model is used to describe or predict
(conditional) probabilities of events on an arbitrary or unknown domain; see [18] for a survey of lifted graphical models.
In the subfield of machine learning, data mining and artificial intelligence called statistical relational learning (or sometimes
probabilistic logic learning) the “lifted” perspective is central as one here considers general domains of objects and properties
and relations that may, or may not, hold for, or between, the objects. (See for example [6,9].) There is no consensus regarding
what, exactly, a lifted Bayesian network (let alone lifted graphical model) is or how it determines a probability distribution
on a set of “possible worlds”. Different approaches have been considered. A key question is how the probability that a
random variable takes a particular value is influenced by its parents in the DAG of the Bayesian network. The above example
uses the most simple form of aggregation/combination rules. Another approach is to use aggregation/combination functions.
Some explanation of these notions is found in e.g. [6, p. 31, 54], [18, p. 18], [13]. I have not seen any definition of the
notions of aggregation rule and aggregation function, but aggregation rules tend to be mainly linguistic descriptions (think
of formal logic) of how the value of a random variable depends on the values of other random variables in the network,
while aggregation functions are specifications of the dependence mainly in terms of functions. From a practical point of view
it probably makes sense to have the freedom to adapt one’s lifted graphical model to the application at hand, so uniformity
may not be a primary concern for practicians. But to prove mathematical theorems about lifted graphical models, and the
probability distributions that they induce, we need (of course) to make precise what we mean, which is done in Section 3.

In this article we use aggregation rules expressed by formulas of conditional probability logic (CPL). The idea is that for
any relation symbol R, of arity k say, there are an integer vr, numbers ar; € [0,1], and CPL-formulas xp j(x1,...,Xx) for
i=1,...,Vpr such that if xr j(x1,...,Xx) holds, then the probability that R(x1,..., xx) holds is wr j. This formalism is strong
enough to express, for example, aggregation rules of the following kind for arbitrary m, any CPL-formula w(x1,...,X,) and
any a; € [0,1], i=0,...,m: For all i=0O,...,m, if the proportion of k-tuples that satisfy w(x1,...,x,) is in the interval
[i/m, (i+ 1)/m], then the probability that R(x1,...,xX,) holds is aj.

Once we have made precise (as in Definition 3.8) what we mean by a lifted Bayesian network © for a finite relational
signature o (i.e. a finite set of relation symbols, possibly of different arities) and also made precise (as in Definition 3.11)
how © determines a probability distribution Pp on the set of all o-structures with domain D (for some finite set D),
then we can ask questions like this: Given a CPL-formula, @(x1,..., Xx) and d;,...,dx € D what is the probability that
~(X1,...,Xk) is satisfied by the sequence dj,...,d,%? Or more formally, what is Pp ({D EWp: DE g(d, ...5dk)})? It is
computationally very expensive to answer the question by analyzing all members of Wp, since, in general, the cardinality of
Wp is in the order of 2!2! where r is the maximal arity of relation symbols in o and |D| is the cardinality of D. However,
our first theorem (Theorem 3.14) says that if g is “noncritical” in the sense that its conditional probability quantifiers (if any)
avoid “talking about” certain finitely many critical numbers, then there is a quantifier-free formula m*(x1,...,X,) such that,
with probability approaching 1 as |D| > o, @ and @” are equivalent. If we are given such g* then we can easily compute
the probability w@* = Pp ({D EWp:DE¢*(d, .. +, dk)}) by using only the lifted Bayesian network 6, so in particular this
computation is independent of the cardinality of D. Moreover, w* only depends on the quantifier-free formula g* and not
on the choice of elements d1,...,d,. We also get that, as |D| > oo, Pp ({D EWp:DEQG(q,..., dx)}) >a"*.

But of course, given a noncritical gy, we have to first find a quantifier-free g* which is “almost surely” equivalent to 9.
The proof of Theorem 3.14 produces an algorithm for doing this. At one step in the algorithm one may need to transform a
quantifier-free formula into an equivalent disjunctive normal form and this computational task is, in general, NP-hard. But
if one assumes that all quantifier-free subformulas of @ are disjunctive normal forms, then the algorithm that produces g*
works in quadratic time in the length of g if we assume that an arithmetic operation, a comparison of two numbers and a
comparison of two literals is completed in one time step (more details in Remark 3.17).

The proof of Theorem 3.14 gives some by-products such as a “logical limit/convergence law” (Theorem 3.15) and a result
(Theorem 3.16) saying that for every lifted Bayesian network as in Definition 3.8 there is an “almost surely equivalent” lifted
Bayesian network in which all aggregation formulas (as in Definition 3.8) are quantifier-free. The original zero-one law
for first-order logic, independently of Glebskii et al. [10] and Fagin [8], becomes a special case of Theorem 3.15 when we
restrict attention to first-order sentences and the DAG of the lifted Bayesian network has no edges and all the probabilities
associated to the vertices are 1/2.
4 V. Koponen / Theoretical Computer Science 848 (2020) 1-27

A couple of earlier results exist which are similar to the results of this article. Jaeger [13] has considered another sort
of lifted Bayesian network which he calls relational Bayesian network. Instead of using aggregation/combination rules (as we
do in this article) relational Bayesian networks use aggregation/combination functions. Theorem 3.9 in [13] is as analogoue
of Theorem 3.15 below for first-order formulas in the setting of relational Bayesian networks which use only “exponentially
convergent” combination functions. Theorem 4.7 in [14] has a similar flavor as Theorem 3.16 below, but [14] considers
“admissible” relational Bayesian networks and a probability measure defined by such on the set of structures with a common
infinite countable domain.

The results of this article are mainly motivated by concepts and methods in machine learning, data mining and artificial
intelligence, but if the results are seen from the perspective of finite model theory and random discrete structures, then they
join a long tradition of results concerning logical limit laws and almost sure elimination of quantifiers. For a very small and
eclectic selection of work in this field, ranging from the first to some of the last, see for example [8,10,12,15,19,21,22,24,25].

The organization of this article is as follows. Section 2 introduces the basic conventions used in this article as well as
some basic definitions. Section 3 defines the main notions of the article and states the main results. Section 4 gives the
proofs of these results. The last section is a brief discussion about further research in the topics of formal logic, probabilistic
graphical models, almost sure elimination of quantifiers and convergence laws.

2. Preliminaries

Basic knowledge of first-order logic and first-order structures is expected and there are many sources in which the
reader can find this background, for example [20]. In this section we clarify and define some basic notation and terminology
concerning logic and graph theory. Formulas of a formal logic will usually be denoted by g, w, @ or x, possibly with sub-
or superscripts. Logical variables will be denoted x, y, z,u,v, w possibly with sub- or superscripts. Finite sequences/tuples
of variables are similarly denoted x, y, Z, etc. If a formula is denoted by g(x) then it is, as usual, assumed that all free
variables of @ occur in the sequence x (but we do not insist that every variable in x occurs in the formula denoted by
~(x)); moreover in this context we will assume that all variables in x are different although this is occasionally restated. In
general, finite sequences/tuples of elements are denoted by a, b,c, etc. For a sequence a, rng(a) denotes the set of elements
occurring in a. For a sequence 4, |a| denotes its length. For a set A, |A| denotes its cardinality. In particular, if g is a formula
of some formal logic (so @ is a sequence of symbols), then |g| denotes its length. Sometimes we abuse notation by writing
‘a € A’ when we actually mean that rng(a) C A.

By a signature (or vocabulary) we mean a Set of relation symbols, function symbols and constant symbols. A signature
o is Called finite relational if it is finite as a set and all symbols in it are relation symbols. We use the terminology ‘o-
structure’, or just structure if we omit mentioning the signature, in the sense of first-order logic. Structures in this sense
will be denoted by calligraphic letters A, 6, C, etc. The domain (or universe) of a structure A will often be denoted by
the corresponding non-calligraphic letter A. A structure is called finite if its domain is finite. If o’ Co are signatures and
A is o-structure, then Alo’ denotes the reduct of A to the signature o’. We let [n] denote the set {1,...,n}. We use the
terminology atomic (o -)formula in the sense of first-order logic with equality, so in particular, the expression ‘x = y’ is an
atomic o-formula for every signature o, including the empty signature o = @. It will also be convenient to have a special
symbol T which is viewed as an atomic o-formula for every signature o; the formula T is interpreted as being true in
every structure.

Definition 2.1. Let o be a finite relational signature and x a sequence of different variables.

(i) If p(X) is an atomic o-formula, then g(x) and —@(X) are called o-literals.

(ii) A consistent set of o-literals is called an atomic o-type. When denoting an atomic o-type by p(x) it is assumed (as for
formulas) that if a variable occurs in a formula in p(x), then it belongs to the sequence x.

(iii) If p(X) is an atomic o-type, then the identity fragment of p(x) is the set of formulas of the form x; =x; or x; #x; that
belong to p(x).

(iv) If p(x) denotes an atomic o-type and for every o-literal g(x), either @(X) € p(X) or =P(X) € p(X), then p(x) is called a
complete atomic o -type (with respect to o ). An atomic o-type which is not complete is sometimes called partial.

(v) Let p(x, y) be an atomic o-type. The y-dimension of p(x, y), denoted dim;(p(x, y)), is the maximal d € N such that
there are a o-structure A and a,b A such that A — p(@, b) and |rng(b) \ rng(@)| > d.

(vi) Let o’ Co and let p be an atomic o-type. Then plo’ ={g € p:@ is a o’-formula} and p[x={@g € p: all free variables
of g occur in x}.

Remark 2.2. Note that if p(x) is complete atomic o-type where x = (X1,..., Xm), then this implies that for all 1 <i, j <m,

either x; = x; or x; # xj; belongs to p(x). (Also observe that if p(x, y) is a complete atomic o-type and dim j(p(x, y)) =d,
then for every o-structure A and for all a,b such that A — p(G, b), we have |rng(b \ rng(a@)| = d.

Notation 2.3. Let o be a signature, X a sequence of different variables, A a o-structure with domain A and @e A”!
V. Koponen / Theoretical Computer Science 848 (2020) 1-27 5

(i) If p(x) is an atomic o-type, then the notation ‘A — p(a)’ means that A | g(a) for every formula (x) € p(x), or in
other words that a satisfies every formula in p(x) with respect to the structure A, or (to use model theoretic language)
that a realizes p(x) with respect to the structure A.

(ii) If y is a sequence of different variables (such that no variable occurs in both x and y) and q(x, y) is an atomic o-type,
then q(a, A) = {be Al: AE q@G, b)}.

By a directed graph we mean a pair (V, E) where V is a (vertex) set and E C V x V. A directed acyclic graph, abbreviated
DAG, is a directed graph (V, EF) such that (v, v) ¢ E for all v € V and such that there do not exist distinct vg,..., vp, EV
for any k>1 such that (vj, vj,1) € E for all i=0O,...,k —1 and (ax,dg) € E. A directed path in a directed graph (V,E) isa
sequence of distinct vertices vo,..., Vex € V such that (vj, vi+1) for alli=O,...,k—1; the length of this path is the number
of edges in it, in other words, the length is k.

Definition 2.4. (About directed acyclic graphs) Suppose that 6 is a DAG with nonempty and finite vertex set V. Letae V.

(i) A vertex b € V is a parent of a if (b,a) is a directed edge of 6. We let par(a) denote the set of parents of a.

(ii) We define the maximal path rank of a, or just mp-rank of a, denoted mpr(a), to be the length of the longest directed path
having a as its first vertex (i.e. the length of the longest path dg, qaj,...,a, where a=do and (qj, qj) is a directed
edge for each i=O,...,k —1).

(iii) The maximal path rank of 6, or just mp-rank of 6, denoted mpr(6) is defined as mpr(G) = max{mpr(a) :ae€ V}.

Observe that if 6 is a DAG with vertex set V and mpr(6) =r and @’ is the induced subgraph of 6 with vertex set
V’={aeV:mpr(a) <r}, then, for every a < V’, the mp-rank of a is the same no matter if we compute it with respect to
®’ or with respect to 6; it follows that mpr(6’) =r —1.

We call a random variable binary if it can only take the value O or 1. The following is a direct consequence of [1,
Corollary A.1.14] which in turn follows from the Chernoff bound [4]:

Lemma 2.5. Let Z be the sum om n independent binary random variables, each one with probability p of having the value 1. For every
€ > 0 there is c, > 0, depending only on €, such that the probability that |Z — pn| > epn is less than 2e~“eP",

3. Conditional probability logic and lifted Bayesian networks

In this section we define the main concepts of this article and state the main results.

Definition 3.1. (Conditional probability logic) Suppose that o is a signature. Then the set of conditional probability formulas
overo, denoted CPL(o), is defined inductively as follows:

(1) Every atomic o-formula belongs to CPL(o’) (where ‘atomic’ has the same meaning as in first-order logic with equality).

(2) If pg, YW € CPL(o) then (-9), (PAW), (@V VW), (~> wv), (@ << Ww), (xg) € CPL(o) where x is a variable. (As usual, in
practice we do not necessarily write out all parentheses.) We consider Vx@ to be an abbreviation of —Ax-9@.

(3) If r>0 is a real number, yg, w,0,t € CPL(o) and y is a sequence of distinct variables, then

("+l | Wily = I@I tly) €CPL@) and

(lig | wily = 0 | tly +r) €CPL(O).

In both these new formulas all variables of g, ¥,@ and Tt that appear in the sequence y become bound. So this con-
struction can be seen as a sort of quantification, which may become more clear by the provided semantics below.

A formula g € CPL(o) is called quantifier-free if it contains no quantifier, that is, if it is constructed from atomic formulas
by using only connectives —, A, V,>,<.

Definition 3.2. (Semantics)
(1) The interpretations of -=, A, Vv, >, < and 4 are as in first-order logic. ;
(2) Suppose that A is a finite o-structure and let g(x, y), W(X, y), A(X, y), T(X, y) € CPL(o). Let Ge Al,

(a) We define g(a, A) = {be Al: AE gG,b)}.
(b) The expression

Ak (r+ 9G 1V@ Dlly = 1G.) 17@ Dily)
6 V. Koponen / Theoretical Computer Science 848 (2020) 1-27

means that w(a, A) 4¥, t(a, A) 4M and
lp@, A)N WG, A)| . Joa, A) TG, A)|
|W (a, A)| — |z (a, A)|
and in this case we say that (r+ lgaawlvGaywllly = loay|tG Wily) is true (or holds) in A. If w(a, A) =@
or tT(a, A) = or

eG, ANwG,A)|  |aG@A)NtG,A)|
he eee A eee
| (a, A)| |z (a, A)|

then we write
AK (r+ 9G 1V@ lly = 6G.) 17@ Hily)

and say that (r+ 9@, 9) | ¥@Wly = 6G) | TG, Dlly) is false in A.
(c) The meaning of

Ak (lig@. WIVGHY|y = OGY 1G, lly +1)

is defined similarly.

Remark 3.3. (A warning) Observe that with the given semantics,

AK (r+ 119G1V@ Dlly = 1G.) 17@ Dily)

does not necessarily imply

AK (r+119@D1V@ lly < 6G.) 17@ Dily)

because the first formula may fail to be true for a because w(a,.A) = % or t(a,.A) = @ in which case the corresponding
fraction is undefined and then also the other formula is false for a.

Remark 3.4. (Expressing conditional probabilities, or just probabilities) Let x = (x1,...,x,) and y = (y1,..., y). If T(x, y)
denotes the formula y; = y; and 6(x, y) denotes the formula y; ¥ y1, then

(iP D1 VR ily = OR 1 TR lly +7) (311)

expresses that the proportion of tuples y that satisfy g(x, y) among those y that satisfy w(x, y) is at least r. Thus the
formula expresses a conditional probability if we assume that all [-tuples have the same probability. Under the stated
assumptions, let us abbreviate (3.1) by

(iP 1 WR Diy = 1). (3.2)

If we assume, in addition, that w(x, y) is the formula y; = y;, then each of (3.1) and (3.2) expresses that the proportion of
l-tuples y that satisfy g(x, y) is at least r.

Example 3.5. Suppose that M is a unary relation symbol and F a binary relation symbol. Consider the statement “For
at least half of all persons x, if at least one third of the friends of x are mathematicians, then x is a mathematician”. If
M(x) expresses that “x is a mathematician” and F(x, y) expresses that “x and y are friends”, then this statement can be
formulated in CPL, using the abbreviation (3.2), as

(\|(IM(y) | F@% Wily = 1/3) > MOO |x =x], > 1/2),

Remark 3.6. (Expressing independence) Suppose that A is a finite o-structure, 6(x, y) is the formula y; = y; and ae A”,
If r=0O and

AR(r+ 9G HIVE Hlly = IGG) 0G, DIly) A

(PG, I) 10 ily = VEN 1WE Dy +r),
V. Koponen / Theoretical Computer Science 848 (2020) 1-27 7

then the event X= {be AVI: AE g(a, b)} is independent from the event Y = {he AVI: AE w (a, b)} if all |y|-tuples have
the same probability.

If A represents a database from the real world, then it is unlikely that events of interest are (conditionally) independent
according the precise mathematical definition. Instead one may look for “approximate (conditional) independencies”. If r is
changed to be a small positive number and if

/\

AE(r+ 9G HIVE Hip = IG 16G, ly) A
(r+ 1194.) 10G Wily = lOGHI VE Hlly

(r+ 1V@D1GE lly = WEN 16G, lly) A

(r+ IVE 1G Diy = WE 1G@, lly)

then the dependency between X and Y is weak, or one could say that they are “approximately independent up to an error
of r”. The reason for the more complicated formula is to make “r-approximate independence” symmetric.

Definition 3.7. The quantifier rank, qr(g), of formulas g € CPL(o) is defined inductively as follows:

(1) For atomic g, qr(g) = 0.

(2) qr(-g) = qr(@), qr(g * v) = max{qr(¢), qr(W)} if * is one of A, V, > or <.

(3) qr(axg) = qr(g) +1.

(4) ar((r+ lg | wily = 61 tly) = ar((lp | wily = 11 tip +r)) =
max{qr(p), qr(y), qr(@), qr(T)} + | YI.

Definition 3.8. (Lifted Bayesian network) Let o be a finite relational signature. In this article we define a lifted Bayesian
network for o to consist of the following components:

(a) An acyclic directed graph (DAG) © with vertex set o.

(b) For each Reo, a number vr Ee N*, formulas xp j(X) € CPL(par(R)), for i=1,..., vr, where |X| equals the arity of R,
such that ¥x(\/;", Xr,i()) is valid (i.e. true in all par(R)-structures) and if i 4 j then 4x(xri(X) A Xr,j(X)) is unsatisfi-
able. Each xr; will be called an aggregation formula (of 6).

(c) For each R €o and each 1 <i < vp, a number denoted m(R | xr ji) (or MCR(X) | XR,i(X))) in the interval [0, 1].

We will use the same symbol (for example 6) to denote a lifted Bayesian network and its underlying DAG. The intuitive
meaning of (R | Xr i) in part (c) is that if a is a sequence of elements from a structure and a satisfies xp i(xX), then the
probability that a satisfies R(x) is W(R | XR.i)-

Remark 3.9. (Subnetworks) Let © denote a lifted Bayesian network for o. Suppose that o’ Co is such that if Reo’ then
par(R) Co’. Then it is easy to see that o’ determines a lifted Bayesian network 6’ for o’ such that

e the vertex set of the underlying DAG of 6’ is o’,
e for every R €o’, the number vr and the formulas xz ;, i=1,..., Vg, are the same as those for 6,
e for every R €o’ and every 1 <i < vp, the numbers (R | xRj) are the same as those for 6.

We call the so defined lifted Bayesian network 6’ for o’ the subnetwork (of 6) induced by o’.

Definition 3.10. (The case of an empty signature) (i) As a technical convenience we will also consider a lifted Bayesian
network, denoted 6%, for the empty signature %. According to Definition 3.8 the vertex set of the underlying DAG of 6” is
0, the empty set. It follows that no formulas or numbers as in parts (b) and (c) of Definition 3.8 need to be specified for
6".

(ii) For every n € N™, let w denote the set of all @-structures with domain [n] and note that every w has only one
member which is just the set [n].

(iii) For every n € Nt, let P? be the unique probability distribution on W’.

Definition 3.11. (The probability distribution in the general case) Let o be a finite nonempty relational signature and let
6 denote a lifted Bayesian network for o. Suppose that the underlying DAG of © has mp-rank p. For each 0 <r < ¢ let
6, be the subnetwork (in the sense of Remark 3.9) induced by o; = {R €o : mpr(R) <r} and note that 6, = 6. Also let
o_1 =%, 6_; = ©" and let P,! be the unique probability distribution on W,! = Ww". By induction on r we define, for
8 V. Koponen / Theoretical Computer Science 848 (2020) 1-27

every r=0,1,..., 0, a probability distribution P* on the set W/, of all o,-structures with domain [n] as follows: For every
AeéeW,,

PA=Pr'Alo-1) |T] JT] [J] 24aria

Reo;\o;7-1 i=1 aexri(Alor-1)

where
LCR | XR,i) if AE xXri(a) A R@),
MA, R,i,d4)=41—W(R| XRi) if AE xrRi@) A -R@),
0 otherwise.

Finally we let W, =W? and P, =P’, so P, is a probability distribution on the set of all o-structures with domain [n].

Remark 3.12. ((Ir)reflexive and/or symmetric relations) Let A be a set and let R C AX be a k-ary relation on A. We call
R reflexive if for all ac A the k-tuple containing a in each coordinate belongs to R. We call R irreflexive if for every
(d1,...,dx) € R we have aj £a; if i¢ j. We call R symmetric if for every (a,...,a,%) € R, every permutation of (a1,..., dx)
also belongs to R. Consider Definition 3.11 and let R €o. We can make sure that P,(A) > 0 only if the interpretation
of R in A is reflexive (respectively irreflexive) by choosing the formulas xr; and associated (conditional) probabilities in
an appropriate way. To achieve that P,(A) > 0 only if the interpretation of R in A is symmetric we can do like this: In
the definition of A(A, R,i,a) (in Definition 3.11) we interpret R(a) as meaning that R is satisfied by every permutation of
a and we interpret —R(a) as meaning that R is not satisfied by any permutation of a. We also need to assume that for
every k-tuple a, either every permutation of a satisfies xp ;(X) or no permutation of a satisfies 7p ;(X). Then the proof of
Theorems 3.14 - 3.16 still works out with very small modifications.

Definition 3.13. Let 0, W, and P,, be as in Definition 3.11.
(i) If p(X) € CPL(o) and Ge [n]"*!, then we define P,(y(@)) = Pn({A € Wn: AE 9@)}).
(ii) If ¢ € CPL(o) has no free variables (i.e. is a sentence), then we define P;(~) = Ph ({A EW,:AE (}).

Now we can state the main results. They use the notion of noncritical formula which depends on the lifted Bayesian
network under consideration. Since this notion is quite technical and relies on some technical results (concerning the con-
vergence of the probability that an atomic type is realized) which will be proved later, we give the precise definition later
in Definition 4.30; in that context it will be more evident why the definition of noncritical formula looks as it looks. For
now I only say this: For every m € N* there are finitely many numbers (depending only on 6) which are called m-critical
(according to Definition 4.29). Roughly speaking, a formula @(X) € CPL(o) is noncritical (details in Definition 4.30) if for
every subformula (of g(x)) of the form

(r+ Ix Ivy = ll ely) or (x1 Wily = II clly +r)

the number r is not the difference of two m-critical numbers where m = |x| + qr(@). It follows that every first-order formula
is noncritical. For a longer discussion on the topics of critical formulas and (non)convergence see Remark 3.18.

Theorem 3.14. (Almost sure elimination of quantifiers for noncritical formulas) Let o be a finite relational signature, let 6 be a
lifted Bayesian network and, for each n € N*, let P;, be the probability distribution induced by & (according to Definition 3.11) on
the set W,, of all o -structures with domain [n]. Suppose that every aggregation formula xp; of © is noncritical. If p(x) € CPL(o) is
noncritical, then there are a quantifier free formula g*(x) € CPL(o) and c > 0, which depend only on (x) and ©, such that for all
sufficiently large n

Pn(¥X(p(X) = p*(x))) = 1-e™.

Theorem 3.15. (Convergence for noncritical formulas) Let 0, 6, Wy and P» be as in Theorem 3.14. For every noncritical p(x) €
CPL(o) there are c > 0 and 0 <d <1, depending only on @(x) and ©, such that for every m €« N* and every a € [m]"*",

[Pn(@@@)—d| < 1-—e"™ forall sufficiently large n > m.
The number d is always critical (i.e. l-critical for some |). Moreover, if @ has no free variable (i.e. is a sentence), then P,(~) converges

to either 0 or 1.

Theorem 3.16. (An asymptotically equivalent “quantifier-free” network) Let o, 6, W, and P, be as in Theorem 3.14. Then for
every aggregation formula Xp ,i(x) of & there is a quantifier-free formula xj ,(X) containing only relation symbols that occur in xR i
such that if 6* is the lifted Bayesian network
V. Koponen / Theoretical Computer Science 848 (2020) 1-27 9

e with the same underlying DAG as 6,
e where, for every R eo and every 1 <i < vp, the aggregation formula xp ; is replaced by XR i and
e where u*(R | XRD = LL(R | Xri) for every R Eo and every 1 <i < vp,

then for every noncritical p(y) € CPL(c) there is d > 0, depending only on ~(y) and ©, such that for every m ¢ N* and every

\Pn(P@) — P*(@@)| < e~“", for all sufficiently large n > m,
where P~ is the probability distribution on W, according to Definition 3.11 if 6 is replaced by 6* and P» is replaced by P*.

Remark 3.17. (Computational complexity) The proof of Theorem 3.14 indicates an algorithm for finding the quantifier-free
gy* from @. Suppose that we fix the lifted Bayesian network (so o is also fixed) and try to understand how efficient the
algorithm is with respect to the length of g. The crucial step is Definition 4.35 and Lemma 4.37 which together show how
to eliminate a quantifier of the form constructed in part (3) of Definition 3.1 in a satisfiable formula. However, at this step
in the proof we assume that the formulas inside the latest quantification are written as disjunctions of complete atomic
types. The problem of transforming an arbitrary quantifier-free formula into an equivalent disjunctive normal form is NP-
hard so the algorithm is not efficient in general (given the current state of affairs in computational complexity theory). But
if we assume that every quantifier-free subformula of @ is a disjunctive normal form, then the number “steps” that the
indicated algorithm needs to find y* is O(\y|*) if |p| denotes the length of gy and “step” means an arithmetic operation,’ a
comparison of two numbers or a comparison of two literals. This essentially follows from Remark 4.36 because the number
of times that a quantifier needs to be eliminated is bounded by |g}.

Remark 3.18. (Necessity of noncriticality) It follows from Remark 3.4 that for every sentence w of the language Ly p
considered in [16] there is a sentence of CPL which has exactly the same finite models as yw. Therefore it follows from
[16, Proposition 3.1] that the assumption that @ is noncritical in Theorems 3.14 and 3.15 is necessary. More precisely,
let o contain one binary relation symbol R and no other symbols and let 6 be a lifted Bayesian network for o where
[L(R(x, y) | X=xX) = 1/2 and ‘x =x’ is the only aggregation formula associated to R. Then, according to [16, Proposition 3.1]
interpreted in the present context, there is a (“critical”) sentence yy ¢€ CPL(o) such that P,(y) does not converge.

We now generalize the idea of [16, Proposition 3.1] to show that nonconvergence for at least some “critical” formu-
las is the case for many (if not all) lifted Bayesian networks. Let o be a finite relational signature, let 6 be a lifted
Bayesian network for o such that every aggregation formula of 6 is noncritical. Let g(x) € CPL(o) be a noncritical for-
mula where X = (x1,...,X,) and k > 2. By Theorem 3.15 there is 0 <d <1 such that for every np ¢ Nt and every @€ [no]*,
liMn—>oo Pn(g(a)) =d. By the same theorem, d is a “critical” number, that is, |-critical for some | according to Definition 4.29.
Suppose that 0 <d <1 (which would typically be the case if g(x) is atomic). Furthermore, suppose that all numbers of the
form (4(R | Xri) associated with 6 (as in Definition 3.8) are rational. It then follows (from Definition 4.29 and results and
definitions preceeding it) that d is rational. Now suppose that for all n and any choice of distinct a;,...,@m € [n], the binary
random variables X1,...,Xm with domain W,, are independent, where X;(A) =1 if AE (aj) and X;(A) =0 otherwise.
From item (b) of Remark 4.7 one can derive that if g(x) is atomic then this independence assumption holds.

Now we consider the following formula, denoted w(x1,..., X_1):

(NP(x1,--- Xe VLY=Vily = d) A (ear, Xe. Y) LY =Vily = 1-4).

In structures in W, it expresses that “there are exactly dn elements y such that @(x’, y) is satisfied” where x’ =
(X1,...,Xp—1). We will show that P,, (Ax’w(x’)) does not converge as n — oo.

If dn is not an integer and A € Wy, then A  3x’¢(x’), so Pp (Ax’ yr (X’)) = 0. Note that as d is rational there are infinitely
many n such that dn is an integer and infinitely many n such that dn is not an integer. Hence it suffices to show that
P, (ax (x’)) gets arbitrarily close to 1 for sufficiently large n such that dn is an integer. Fix a large n such that dn is an
integer and a [n]‘—!. Then, for every b € [n], P,, (y(a, b)) is very close to d. By the assumption about independence above,
it follows that the probability that “there are exactly dn elements b such that y(@, b) holds” is close to (7 )dn(1 — d)9-".
Thus the probability of the negation of this statement is close to 1 — (;')dn(1 — d)—®" and, using the assumption about
independence again, it follows that P;,(—-Jx'g(x’)) is close to

nk-1 n
(: _ (;, Jana - aa) < (: _ (;, Jana - aan)
dn dn

1 ” c \"
~ {1 — —— = {1—-— — by Stirling’s approximation
( Jada =) ( va) (Py SuNg's APP

3 More precisely, adding, multiplying or dividing two numbers.
10 V. Koponen / Theoretical Computer Science 848 (2020) 1-27

~ eV" _5 Q asn— oo (where c = 1/./27d(1 — d)).

Finally let us take a broader look at a formula of the form

r+ laMleaMlly 2 les | gaMlly- (3.3)

Suppose that gj is noncritical for every i. By Theorem 3.15, there are numbers d;,d2,d3,dq such that for any no, every
a €[no]!”! and every i, limp—so0 Pn(gi(@)) = dj. Suppose that r is chosen so that r+ d;/dz =d3/dq. Then the formula (3.3)
is critical (see Definition 4.30). The intuition is now that for all large enough n and almost all A € W,, the numbers
r+ |Q1(A) N @2(A)|/|G2(A)| and |g3(A) MN g4(A)|/|@4(A)| are very close to each other, but this does not exclude the
possibility that for infinitely many n the first number is at least as large as the second and for infinitely many n the second
number is larger. In this case the truth value of the formula (3.3) will alternate between true and false infinitely many times
as n tends to infinity in typical (or “almost all”) members of Wy.

One may also ask if it is necessary in the above theorems that all aggregation formulas xrj are noncritical. | do not
currently know but I assume that the answer is yes.

4. Proof of Theorems 3.14, 3.15 and 3.16

Let o be a finite relational signature and © a lifted Bayesian network for o. The proof proceeds by induction on the
mp-rank of the underlying DAG of 6. The base case will not be when the mp-rank of © is 0. Instead the base case will
be the “empty” lifted Bayesian network for the empty signature @, as described in Definition 3.10. In the case of an empty
signature (and consequently empty lifted Bayesian network) Theorems 3.14 - 3.16 are a direct consequence of Lemma 4.13
below.

The rest of the proof concerns the induction step. The induction step is proved by Proposition 4.41 and Corollary 4.42
which rely (only) on Assumption 4.1 below which states the general assumptions related to the lifted Bayesian network
and Assumption 4.10 below which states the induction hypothesis. Theorems 3.14 - 3.16 follow from the arguments in this
section, in particular Proposition 4.41 and Corollary 4.42, because

e k <¢ N®™ can be chosen arbitrarily large in Lemma 4.13 and in Assumption 4.10,
e €’>0can be chosen arbitrarily small in Lemma 4.13 and in Assumption 4.10, and
e because we can choose 8’(n) =e“ for any d > 0 in Lemma 4.13 and because of the lower bound in Lemma 4.28.

For the rest of this section we assume the following:

Assumption 4.1. (Relationship to a lifted Bayesian network)

e o is a finite relational signature and o’ is a proper subset of o.

e For each Reo \o’, of arity m say, there are a number vr € N, a sequence of variables x = (x1,...,X%m) and formulas
Xri(X) € CPL(o’), for i=1,..., vp, such that Vx(\Vi8, Xr, i(X)) is valid (i.e. true in all o’-structures) and if i~ j then
AX(XR,i(X) A Xr,j(X)) is unsatisfiable.

e For every Reo \o’ and every 1 <i < vp, (R | Xr,i) denotes a real number in the interval [0, 1]. (Sometimes we write
[L(R(X) | XR,i(X)) where xX is a sequence of variables the length of which equals the arity of R.)

e For every o-structure A, every R€o \o’, every 1 <i< vp and every a¢A’ where r is the arity of R, let

LCR | XR, i) if AF Xr,i(a) A R@),
MA, R,1,4)= 41—W(R| XRi) ifAE XRi(@ AAR),
0 otherwise.
e For every ne N*, W, is the set of all o’-structures with domain [n] = {1,...,n} and P’ is a probability distribution

on W,..
e For every n € N*™, W, is the set of all o-structures with domain [n].

Recall that, according to Definition 3.2, if w(x) € CPL(o’) and A€W, then y(Alo’) = {b: Afo’ FE w(b)}.

Definition 4.2. For every n<¢ N and every A € W, we define

P(A =PiAlo’) [] J] [] 44 io.

Reo\o’ i=1 aexri(Afo’)

Then P,, is a probability distribution on W, which we may call the P;,-conditional probability distribution on Wy.
V. Koponen / Theoretical Computer Science 848 (2020) 1-27 11

Notation 4.3. The notation in this section will follow the following pattern: o’-structures, in particular members of W,, will
be denoted A’, 6’, etcetera; subsets of W,, will be denoted X’ (or X/,), Y’ (or Yj,), etcetera; o-structures and subsets of W,
will be denoted similarly but without the (symbol for) “prime”.

In the proofs that follow we will consider “restrictions” of P, to some subsets of W, according to the next definition.

Definition 4.4. (i) If Y’ CW, then we define

={AeEW,: Alo’ <Y} and
' P (Alo .-
pY (A) = oe I] I I] A(A, R, 1, a).
Reo\o' i=1 aexri(A)

(ii) If A’ ¢ Wi, then we let
n

w” =w'*! | and, for every Ace w*,

Pp“ (A) = PM) (4) = I] I] I] A(A, R, 1, a).

Reo\o’ i=1 aexri(A)

Then PY and P“' are probability distributions on W" and Ww”, respectively; if this is not clear see Remark 4.7 below.
Note also that if Y’ CW), A’ eY’ and Ae Ww’ then

Pi(A’)

A’
pay A) (4.1)

PY (A) =

 

and in particular, taking Y’ = W,,, we have, for every A € W,,

P,(A) = Pi(Afo’)PA!? (A). (4.2)

We now state a few basic lemmas which will be useful.
Lemma 4.5. For every n, if Y’ C W, then P, (W” ) = P/(Y’).

Proof. By using (4.2) in the first line below we get

PW) = S> Yo RA = D> SD BUPA (A =

A’eY’ Acw’ A’eY’ Acw’
> PA) SO PAA = DOA) = BY). 0
A’eY’ Acw*’ A’eY’

Lemma 4.6. For every n,
(i) if X CW, and A’ € Wi, then P,(X |W) = P* (Xn W*), and
(ii) if X C Wy and Y' C Wi, then P,(X |W) = PY (XN WY’).

Proof. Let X C W,.
(i) Let A’ € W,. Using Lemma 4.5 in the first line below and (4.2)) in the second line below, we get

P(XNW4%) = PB(xXnWw’)

Px | Wt) = 8 ___* =

nXiwe) P»(W~’) Pr(A’)

FA) 2 aexcwe FO Pe _ pnw’.
P(A’)

(ii) Let Y’ C W.,. Using that XN W" is the disjoint union of all XN W~' such that 4’ € Y’, Lemma 4.5, part (i) of this
lemma and (4.1), we get
12 V. Koponen / Theoretical Computer Science 848 (2020) 1-27

 

P,(XNWY ) P,(XNW*)
Py(X|WY) = 4~—___ = }° “—___ =
P(WY) 4, Py(WY)
P,(w“’ P(A)»
» ne Prk|W") = ) 1 P4 xn) =
A’eyY’ n( ) A’eyY’ n( )
S> PY(XNW) = PY (KNW). o
A’eyY’

Remark 4.7. (About P“’) Fix any n and any A’ e W,,. For every R Eo \o’, every 1 <i< vp and every dé xrj(A’), let
Q(R, i, a) = {0,1} and let Pr jg be the probability distribution on Q(R,i,a) with Praja) = UCR | Xr). Then let Po be
the product measure on

Q= I] Q(R,i,a).

Reo\o'
- 1<i<vpr
de xR i(A’)

Consider the map which sends A « W“ to the finite sequence
KA = (k(R,i,a):REO\o',1<i<vr,de xri(A))

where K(R,i,a) =1 if A/_ R(a) and x(R,i, a) =0 otherwise. This map is clearly a bijection from Ww’ to Q and, for every

Aew, P4(A) = Polk 4). .
For every a € {0,1}, every Reo \o’ and every ae¢ [n] (having the same length as the arity of R), let Ep, ={A«€ w :

A — R“(a)} where R®° and R! denote —R and R, respectively. From the connection to the product measure it follows that

(a) for every Reo \o’, every 1 <i< vp and every GE xri(A), PA ER «) = (R | Xr), and
if @1,...,Q@m € {0,1}, Ri,...,Rm€oO\o' and dj,...,dm are tuples where |a;| is the arity of R; for each i, and for a
(b) if {0,1}, R R ' and les where |a;| is th f R; for each i, and for all
1<i<j<m, Ri #R; or aj 44a,;, then the events ER, ayeee ER 4,, are independent.

The next lemma is a direct consequence of (b) of Remark 4.7.

Lemma 4.8. Suppose that p(x1,...,Xm) and q(x1,...,Xm) are (possibly partial) atomic (o \ o’)-types. Also assume that if g is an
atomic o -formula which does not have the form x = x or the form T and g € p or —=@ € p, then neither ~ nor —@ belongs to q. Then,
for every n, every A’ € W,, and all distinct a,,..., dm € [n], the event {A € WwW” : AE p(ai,...,dm)} is independent from the event

{Ae Ww’ .A EL q(d1,...,@m)} in the probability space (we, Pp’.

Definition 4.9. (Saturation and unsaturation) Let x and y be sequences of different variables such that rng(X) Nrng(y) = @
and let p(x, y) and q(x) be atomic o-types such that q C p. Let also O<a@ <1 and d=dim;(p).

(a) A finite o-structure A is called (p,q, a)-saturated if, whenever a ¢ A! and A q(a), then |{b¢ A'”!: AE p@,b)}| =
alAl?. _ _ _

(b) A finite o-structure A is called (p,q, @)-unsaturated if, whenever a € A! and A q(@), then |{b € Al’! : AE pG, b)}| <
aA?

If p’(x, y) and q’(xX) are atomic o’-types and q’ C p’, then the notions of (p’, q’, a)-saturated and (p’, q’,«)-unsaturated are
defined in the same way, but considering finite o’-structures instead.

Assumption 4.10. (Induction hypothesis) Suppose that k ¢ N*, e’ > 0, 6’: Nt > R#° and Y}, CW, for n< N*, are such
that the following hold:

(1) limps 6’(n) = 0.

(2) P/(¥,,) => 1—64’(n) for all sufficiently large n.

(3) For every complete atomic o’-type p’(xX) with |x| <k there is a number which we denote P’(p’(x)), or just P’(p’), such
that for all sufficiently large n and all a € [n] which realize the identity fragment of p’,

IP, ({A’ e Wh: A’ & p’@}) — P'(p'®)| < 8'(n).
V. Koponen / Theoretical Computer Science 848 (2020) 1-27 13

(4) For every complete atomic o’-type p’(x, y) with |xy| <k and 0 < dimj(p’(x, y)) = |yl, if q’(x) = p’[x and P’(q’) > 0,
then for all sufficiently large n, every A’ €Y, is (p’,q’,a/(1 + €’))-saturated and (p’, q’,a(1 + e’))-unsaturated if a =
P’(p'(x, y))/P'(q'(X)).

(5) For every Xpr,i(X) as in Assumption 4.1 there is a quantifier-free o’-formula xj ,(X) such that for all sufficiently large n
and all A’ € Yj, A’ E Vx(xR i) > XR ;)).

Remark 4.11. (Some special cases) (i) As a technical convenience we allow empty types (and this does not contradict our
definition of an atomic type). For example, in Definition 4.9, we allow the possibility that x is an empty sequence and
consequently q(x) =@ and p(x, y) is really just p(y).

(ii) For an empty atomic o’-type p’ we let P’(p’) =1 and in this case we also interpret the set {A’ €¢ W,: A’ — p’(a)} as
being equal to W,,. Then part (3) of Assumption 4.10 makes sense also for a empty type p’.

(iii) If p’(y) is a complete atomic o’-type and P’(p’) =0, then for all sufficiently large n and all A’ €Y’, p’ is not realized
in A’ (i.e. p’(A’) = %). The reason is this: Let x denote an empty sequence and let q’(x) be the empty atomic o’-type, so
q’ C p’. For large enough n, every A’ € W, is (p’,q’, P’(p’)(1 + ’))-unsaturated by part (4) of Assumption 4.10. If P’(p’) =0
this implies that p’ has no realization in A.

Lemma 4.12. Suppose that p’(x) is a complete atomic o'-type and that p(X) D p’(X) is a (possibly partial) atomic o -type. There is a
number which we denote P(p(X) | p’(X)), or just P(p | p’), such that for all sufficiently large n, all a € [n] and all A’ € Y}, such that

A’ p'(a),
PA ({AeW* : AE p(@}) =P(pR |p’).
Moreover, the number P(p(x) | p’(x)) is a product of numbers of the form (R | Xr,ij) or 1 — WR | XR).

Proof. Suppose that a,b € [n] and A’, B’ « Y,, are such that A’ — p’(a@) and B’ —& p’'(b). Let R Eo \ o’. By part (5) of
Assumption 4.10, for each 1 <i < vg, there is a quantifier free formula x; ; such that (if n is large enough) XR; is equivalent

to Xp; in every structure in Y,,- It follows that if c’ and d’ are subsequences of a and b, respectively, of length equal to the

arity of R, then either A’ E xp ;(C) and B’ E xpj(d), or A’ K xxi and B’ ~ xp j(d). The conclusion of the lemma now
follows from (a) and (b) of Remark 4.7. O

Lemma 4.13. (The base case) For every k ¢ N* and every «’ > 0, if 0’ = 9, P,, is the uniform probability distribution* on Wi, for
alln and 6’: N* > R#° is any function such that lim,_,.0 4’(n) = 0, then there are Y/, C W), forn <¢ N*, such that (1)-(4) in
Assumption 4.10 hold. Moreover, for every €'-noncritical? p(X) € C PL(@) with |x| + qr(p) <k there is a quantifier-free formula ~* (x)
such that for all sufficiently large n and all A’ € Yj, A’ = ¥x(p(%) = ¢*()).

Proof. Suppose that 0’ = G and let ke N* and ¢’ > 0 be given. Then, for every n, W,, contains a unique structure which is
just the set [n] which has probability 1. Let 5’: N+ — R=° be any function such that limp_.oo 6’(n) = 0. For every complete
atomic o’-type p’(x) let P’(p’(x)) = 1. Observe that, for every n, if a € [n] and a realizes the identity fragment of p’(x), then
a realizes p’(x) in the unique A’ of W’,. Hence, for trivial reasons we have (3).

For every n let Y), be the set of all A’ © W, such that for every complete atomic o’-type p’(x, y) with |xy| <k and
0 < dimj(p’(x, y)) = |y|, if q(x) = px, then for all sufficiently large n, every A’ <Y, is (p’,q’,1/(1 + €’))-saturated and
(p’,q’, (1 + €’))-unsaturated. Suppose that p’(x, y) is a complete atomic o’-type with |xy| <k and 0 < dim; (p’(x, y)) =I.
Let q’(X) = p’|X and suppose that A’ — q’(@) where A’ ¢ W.. Then A’ — p’(G,b) for every b € [n] consisting of different
elements no one of which occurs in d. There are n!¥! — Cn!¥I-! such b for some constant C. So if n!¥! — cnl¥l-1 = st then
A’ is (p’,q’, 1/(1 +é’))-saturated. For trivial reasons, A’ is also (p’, q’, (1 + ’))-unsaturated. Hence, we have proved (4). The
last claim of the lemma follows from Proposition 4.32 the proof of which works out in exactly the same way if o and Y, (in
that proof) is replaced by o’ and Y’, respectively, and we assume (4). In other words, the almost everywhere elimination of
quantifiers follows from the saturation and unsaturation properties stated in (4). O

Lemma 4.14. Suppose that X, © Wp. Then for all sufficiently large n, Py (Xn) < Pa(Xn AW") 4+ 8/(n).

Proof. We have

Pr (Xn) = Pn(Xn awn) + Pn(Xn \ w'n)

4 In fact the uniform probability distribution is the only probability distribution on W;, since W, is a singleton if o’ = @ (which we assume in this
lemma).
> In the sense of Definition 4.30.
14 V. Koponen / Theoretical Computer Science 848 (2020) 1-27

and, using Lemma 4.5, we have
Py (Wh \ W*") = 1 — P,(W"") = 1— P/(¥,) < 5'(n).
Hence Py, (Xn) < Pa(Xn NW) +8/(n). oO

Lemma 4.15. Suppose that p’(x) is a complete atomic o'-type and that p(x) > p’(x) is an (possibly partial) atomic o -type. Letting n
be sufficiently large, then for all a € [n] and letting Z;, be the set of all A’ € Y}, such that A’ — p’(a) we have

Pn({A © Wn: AK p(@} | W" {Ae Wn: AE p'(@)}) =
P2n({A € W :.A E p(@)}) =
P(p(x) | p’(X))

where P(p(x) | p’(x)) is like in Lemma 4.12.

Proof. For every A&W, we have AE p’(a) if and only if Afo’ E p’(@). Therefore W¥: 1 {Ae W,: AE p’(@)} = W. By
Lemma 4.6 we have

Pn({A€ Wn: AE p(@} |W" 1 {Ae Wn: AE p’'@}) =
Pp’ ({A €W"" | AE p(@)}).
Then, using (4.1) and Lemma 4.12, we get

Pn({A € W : AE p(a)}) = » P*(AcW* : AE p@) =

 

 

A'€Z;,
P(A) A’ A’. _ _ _
» signe (Ae W* : AE P@)) =
A’e€Z,,
P’ A’ _ _ - -
» sp De |p’) = PIPE | p'®). o
wea, ben)

Lemma 4.16. Suppose that p’(x) is a complete atomic o’-type and that p(X) D p’(x) is a (possibly partial) atomic o -type. Then for all
sufficiently large n and all a € [n] which realize the identity fragment of p’(x) (and hence of p) we have

|Pn({A € Wh: AE p(@} | Ww") — P(p(Xx | p’(%)) - P’(p'(®)|_ < 35’(n).
Proof. Let a <€ [n] realize the identity fragment of p’(x). Furthermore,
let X, be the set of all Ae W, such that AE p(a),
let X’, be the set of all A’ € Wy, such that A’ — p’(a), and
let Z, be the set of all A’ © Y), such that A’ — p’(a).
From parts (2) and (3) of Assumption 4.10 it easily follows that (for large enough n)
P.(Z,)/P;(¥;,) differs from P/(Z;,) by at most 6’(n),
P,(Z,,) differs from P/(X;,) by at most 6’(n) and
P.(X;,) differs from P’(p’(x)) by at most 6’(n).
By Lemma 4.6, Py (Xp | W%:) = P¥n(X MW"), Then, using (4.1) and Lemma 4.12, we have

P¥(xow')= 5° P%*(X,NW4)= >> P(x, W*) =

 

 

A’eY;, A’€Z;,
P’(A’))_
Yooqy Alo qy —
dX dL PMM= DD BrP =
A’eZh AeX, WA’ A’eZy AeX,nw*’
P/(A) Al PAD A
y* ns y P — y p+ (x, NW“ ) =
Pi(Yn) ad Bry )

A'eLh AeX,0WA' Ney,
V. Koponen / Theoretical Computer Science 848 (2020) 1-27 15

 

 

 

PHA) oo) ray — pemyay | alg Pr(A’)
a PY) P(p(X) | p’(%)) = P(p(X) | p ) Py) =
_ 1 P'(Z,)
P(p(X) | p'(X)) PI)’
where
P/ (Zi)

P'(p’(x)) — 38’(n) < P/Y!) <P'(p'(x)) + 36(n). Oo

 

Lemma 4.17. Suppose that p’(x) is a complete atomic o'-type and that p(X) D p(X) is an (possibly partial) atomic o -type. Then for
all sufficiently large n and all a € [n] which realize the identity fragment of p'(x) we have

[Pn({A € Wh: AE p@}) — Pp | p’(x)) - P’(p'(x))| < 58/(n).

Proof. Let a € [n] realize the identity fragment of p’(x). Let X,; be the set of all A <¢ W, such that A; p(a). We have
Pa(Xn) = Pn (Xn | W"") Pp (W*") + Pa(X | Wh \ WY") Pp (Wh \ W").

By the use of Lemma 4.5 and by part (2) of Assumption 4.10, we also have
P,(W, \ W*") = 1 — P, (W*) = 1— P/(Y)) < 8'(n).

It follows that P(X | Wp \W*r)P, (W, \W*n) < 6/(n). By Lemma 4.5 and part (2) of Assumption 4.10, P,(W*:) = P’(y/,) >
1 —6’(n). It now follows from Lemma 4.16 that P, (Xn) differs from P(p(x | p’(x))-P’(p’(x)) by at most 56’(n) (for sufficiently
large n). O

Definition 4.18. For every (possibly partial) o-type p(x) such that p’(x) = pfo’ is a complete atomic o’-type, we define
P(p(x)) = P’(p’(X)) - P(p() | p’(x)).

With this definition we can reformulate Lemma 4.17 as follows:

Corollary 4.19. If p(x) is an (possibly partial) atomic o-type such that p{o’ is a complete atomic o'-type, then, for all sufficiently
large n and alla € [n] which realize the identity fragment of p(x) we have

|Pn({A € Wh: AE p(@)}) — P(p®)| < 58’(n).

Lemma 4.20. Suppose that p(X, y) is a complete atomic o-type. Let p’(X, y) = plo’, q(X) = p|xand let pY (x, y) include p’(X, y) and
all formulas in p in which at least one variable from y occurs. Then

P(p(x, y) | p'(%, y)) = P(p? (, ¥) | p’(%, ¥)) - P(Q@) | p', y)).
Proof. By Lemma 4.12, for any sufficiently large n, any G, b € [n] and any A’ € Y;, such that A’ — p’(q, b), we have
P(p(x, ¥) | p’(%, y)) = P4* ({AeW* : AE pG@,b)}),
P(p’ (x, y) | p'(x, y)) =P4 ({AeW* : AE p’G,b)}) and
P(q(x) | p'(x, y)) =P4 ({AewW* : AE q@)}).

Note that p(x, y) = p’(x, y) U p’(%, y) Uq(%). By Lemma 4.8, the event {4 «¢ W“” : AE p’(a,b)} is independent, in
(Ww, P“’), from the event {A ¢W~% : A q(a@)}. Therefore,

PA ({AeW* : AK pG,b)}) =
P+ ({Ae Ww : AE p’(G,b)}) -P4 ({AeW* : AE q@)})

and from this the lemma follows. O

Lemma 4.21. Let p'(x, y) be a complete atomic o’-type, q'(X) = p’|x and suppose that q(x) is a complete atomic o -type such that
q > q'. Then P(q(X) | p’(X, ¥)) = P(x) | q’(X)).
16 V. Koponen / Theoretical Computer Science 848 (2020) 1-27

Proof. Since q’(x) C p’(x, y) it follows from Lemma 4.12 that for any sufficiently large n, any a, b €[n] and any A’e Y,, such
that A’ — p’(a, b), we have
P(q(X) | p'(®, y)) =P“ ({Ae we : AF q(@}) and
P(q(x) |q/(®) =P4 ({Ae ws : AE q@)}).
Hence P(q(x) | p’(x, y)) =P(q(X) | q’(%)). O
In Lemma 4.12 we defined the notation P(p(x) | p’(x)) when the atomic o-type p has no more variables than the
complete atomic o’-type p’. From Definition 4.18 of P(p(x)) it follows that P(p(x) | p’(x)) = P(p(x))/P’(p’(x)). Now we
extend this notation to pairs of (p(X, y), q(x)) where p(x, y) is a complete atomic o-type and q(x) = p[x.
Definition 4.22. Suppose that p(x, y) is a complete atomic o-type and let q(x) = p|x. We define
P(p(x, y))
P(q(x)) |
In the same way, if p’(x, y) is a complete atomic o’-type and q’(x) = p’[x, then we define
P’(p’(x, y))
P’(q’(x))

P(p(x, y) | q(x) =

P'(p'(x, ) | q'(X)) =

Lemma 4.23. Suppose that p(x, y) is a complete atomic o -type, let q(x) = p[x and let p’ (X, y) be defined as in Lemma 4.20. Then
P(p(x, ¥) | q(X)) = P’(p'(X, y) | q’(x)) - P(p” (X, y) | p’(®, Y)).
Proof. Using Definition 4.18 and Lemmas 4.20 and 4.21 we get
—_ - P(p(x, y)) — P’(p'(X, y)) -P(pe, y) |p’, Y))
P(p(x, Y) | dQ) = Sa OF oo
P(q(x)) P'(q’(x)) - P(q(X) | g'(x))
P’(p'(x, y)) - P(p? (X, y) | p’(%, ¥)) - P(q(®) | p'(, y)) _
P’(q’(x)) - P(q(X) | q(x)
P’(p'(x, y)) - P(p? (X, y) | p’(%, ¥)) - P(q(®) | g(%)) _
P’(q’(X)) - P(q(X) | q/(X))

P’(p'(x, y) | q’(x)) -P(p? (x,y) |p’ y)). O
Lemma 4.24. Suppose that n is large enough that part (4) of Assumption 4.10 holds. Suppose that p(x, y) and q(x) are complete atomic
o -types such that |xy| <k, dimy(p) = 1 and q C p. Let y = P(p(x, y) | q(x)) and A’ €Y},. Then

PA ({A ew : Ais (p.q,vy/A+ e’)*)-saturated

and (p,q, y+ e')*)-unsaturated})

is at least 1 — 2n'*le—‘e’Y" where the constant c-, > 0 depends only on ¢’.

Proof. Suppose that p(x, y) and q(x) are complete atomic o-types such that |xy| <k, dimy(p) =1 and q C p. Let p’=p|o
and q’ =q/o’. Moreover, let p(x, y) include p’(x, y) and all (o \o’)-formulas in p(x, y) which contain the variable y. Also,
let

a = P'(p'(x, y) | q'(X)),

B =P'(p” (x, y) | p'(x, y)) and

y =P'(p(x, y) | q(x).
By Lemma 4.23 we have y = af.

Let A’ < Y,. By (4) of Assumption 4.10 A’ is (p’,q’,a@/(1 + €’))-saturated and (p’, q’, #(1 + @))-unsaturated if n is large

enough. For every ae [n]*! let

Bi = {be[n]: A’ E p'G,b)}.

By the mentioned (un)saturation property, if A’ / q’(@) then an/(1 +e’) <|B4| < an(1 +’). For every Ge [n]*! and every
Aew" let
V. Koponen / Theoretical Computer Science 848 (2020) 1-27 17

Baa = {be[n]: AE p’G,b)}
and note that Bg,4 © Bi for every a and every Ac w-’. Let
X; = {Aew": either AK q@ ory/(1 +e’)? <|Baal<yd+e)’}.

Observe that if de W, AE q(a@) and AE p’(G,b), then AE p(a,b). Hence every Ac Oaetnx Xa is (p.9, v/0 + g/)*)-
saturated and (p,q, y(1 + €’)*)-unsaturated.

Fix any a such that A’ — q’(a) (and note that A q(a) implies A’  q’(a)). By Lemma 4.8, for all distinct b,c € BZ, the
events

E, —{Acw : AK p’G,b)} and E. ={Ac WwW : AK p'G,0)}

are independent. Moreover, by Lemma 4.12, for each b € B-, P, (Ep) = B. Let Z -W“’ _, N be the random variable defined
by

Z(A) = |{be BE: AE p’G,b)}}.
Let € =e€’/(1+ 6’) and note that ¢ < e’ and 1 —e¢ = 1/(1+ 6’). By Lemma 2.5,

PA (|Z — B|Bi|| > ©B|BS|) < 2exp (—ceB|Bi))
where c, depends only on € and hence only on é’. Recall that a6 = y and an/(1 + €’) < |B-| <an(1 + €’). From this it
follows that (1+¢’)*yn> (1 + ¢')B|B-| and yn/(1 +e) < B|BZ|/( +é’). Therefore, if Z > (1 +e')*yn or Z <yn/(1+e’)?,
then |Z — B|B4|| > eB|BL|. Hence, if ce, =ce/(1 + €’),

p+ (w~ \ xa) < 2exp(—ceB|Bal) < 2exp(—ceyn).

Since the argument works for all a € [n]'*! such that A’ K q’(a) it follows that

pa ( CO) Xa) > 1 — 2n'Xlencervn

ae[n]|*!

and this proves the lemma. O
The next lemma generalizes the previous one to types p(x, y) where the length of y is greater than one.

Lemma 4.25. Suppose that n is large enough that part (4) of Assumption 4.10 holds. Suppose that p(x, y) and q(x) are complete atomic
o -types such that |xy| <k, dimy(p) =|y| and q C p. Let y = P(p(X, y) | q(x)) and A’ € Y,,. Then
PA ({A ew : Ais (p.q,y/A+ e’)7'Vl)-saturated
and (p,q, yd+ e')?|¥!)-unsaturated})

is at least 1 — 2/¥|n!xl+l¥l-le—ce’¥" where the constant c, > 0 depends only on ’.

Proof. We prove the lemma by induction on m = |y|. The base case m = 1 is given by Lemma 4.24. Let p(x, y) and q(x) be
as assumed in the lemma where y = (yq,..., ¥m41). Let Dm(X, ¥1,---, Ym) be the restriction of p to formulas with variables
among x, yj,..., Ym. Furthermore, let a = P(pm | q), B=P(p | Pm) and y =P(p | q). Observe that by Definition 4.22 we
have
Pp) PW) Pm) |
”*P@ Pm P@

Let A’ €Y,. By the induction hypothesis, the probability (with the distribution P~’) that

 

 

(a) Aj W is (pm, g,a/(1 +6’)?")-saturated and (pm, q,a(1 + &’)2”)-unsaturated

is at least 1 — 2'n!Xl+m—le—ceon where the constant c, depends only on ¢’. By the induction hypothesis again, the
probability that

(b) AeW™ is (p, pm. B/( + ’)2)-saturated and (p, pm, BC + e’)*)-unsaturated
18 V. Koponen / Theoretical Computer Science 848 (2020) 1-27

is at least 1 — 2n/*l+™e—ce’n where ce is the same constant as above (since it depends only on ¢’). It is straightforward
to check that if A © W™' satisfies both (a) and (b) then J is (p,q, y/(1 + €’)?t)-saturated and (p,q, y(1 + €’)2™)-
unsaturated. Since y = af < min{a, B} it follows that the probability that A¢W~ is (p,q, y/(1 +8’)2+)-saturated and
(p,q, v1 +e')?+))-unsaturated is at least 1 — 2™+1n/*l+me-ceyn

Definition 4.26. For every n, let Y, be the set of all A ¢ W" such that whenever p(x, y) and q(x) are complete atomic o-
types with |xy| <k, dimy(p) = |y|, q C p and y =P(p | q), then A is (p,q, y/(1+¢’)*'¥!)-saturated and (p,q, y(1 +6’)7!7!)-
unsaturated.

The following corollary follows directly from the definition of Y, and Lemma 4.25.

Corollary 4.27. Let p(x, y) and q(x) are complete atomic o -types such that |xy| < k, d =dimy(p) > 0,q € p and y = P(p | q). For
every n, every A€Yy is (p,q, y/(1 + €’)*4)-saturated and (p,q, y(1 + €’)*")-unsaturated.

Lemma 4.28. There is a constant c > 0 such that for all sufficiently large n, Pn(Yn) => (1 —e~)(1 — 5’(n)).

Proof. There are, up to changing variables, only finitely many atomic o-types p(x) such that |x| <k. It follows from
Lemma 4.25 that there is a constant c > 0 such that for all large enough n and all A’ €Y,,

PA (Yn NW) >1—e°™.

Note that Pr(¥n) = Pa(Yn | W")P,;(W*), By Lemma 4.5, Py(W*:) = P/(¥/) and by Lemma 4.6 we have P,(¥}, | W*) =
P¥n(¥, 1W*n). Hence Py(¥n) = PY (¥, VW*")P’ (Y’,). Then, reasoning similarly as in the proof of Lemma 4.16 (using (4.1)),
we get

PY¥(¥, Ww) = S* P&(¥,nW*)= S> So PX (A)=

 

 

 

 

A’eyY), A’eY¥n AcY, WA’
P’ A’ , P’ A’ ,

~ LD eeMw-Lee LY Pew-
1 -yl ! Pr (Yn) ) ) Pa(Yn) ,
A’eYn AcY, WA A’eyY;, AeYy,nw4

P’(A’ ' ' P(A’
yr awe) = yo eer) =
2 Bip 2 PAY)
EY), A’eY;,

(1-e").
Using part (2) of Assumption 4.10 we know get

Pan) = PY(¥, NW")Pi(¥,) > (1—e"")(1-8'(n)). O

Definition 4.29. A real number is called critical if it is m-critical for some positive integer m. We say that a real number a
is m-critical if at least one of the following holds:

(a) There are a complete atomic o-type q(x), distinct complete atomic o-types p(x, y), ..., pj(X, y) and a number 1 <I <!
such that |xy| <m, q C p; for all 1 <i <I and

y= Dizi P(Pi | 4)

== .
izt P(p; | q)

(b) a =I'/l where 0 <I’ <1 are integers and | is, for any choice of distinct variables x;,...,Xm, less or equal to the number

of pairs (p(xX1,..., Xm’), G(X1,.-.,Xq)) where d < m’ <m, p and gq are complete atomic o-types such that g € p and

dim (x, genes x) (P) = 0.

From the definition it follows that (for every m <€ N) there are only finitely many m-critical numbers. It also follows
(from part (b)) that, for every m, 0 and 1 are m-critical. In part (a) above we allow x to be empty in which case the type
q(x) is omitted and P(p; | q) is replaced by P(pj).

Definition 4.30. Let g(x) € CPL(o) and let | = |x| + qr(@).
(1) We call g(X) noncritical if the following holds:
V. Koponen / Theoretical Computer Science 848 (2020) 1-27 19

(r+IVEH OB Dy = WZ H1O*E Willy) or

(llvZ, I) 10, ily = WE) 16°, Dilly +1)

is a subformula of g(x) (where w,0, w* and 6* denote formulas in CPL(o) and z and y may have variables in common
with x) then, for all /-critical numbers aw and 6, r4a — B.

(ii) Let ¢ > 0. We say that @(X) is €-noncritical if

e (x) is noncritical and
e whenever r appears in a subformula as in part (i) and @ and £ are [-critical numbers, then the following implications
hold:
Ifr+a>B thenr+a/(1+2e)? > B(1+2e)2, and
ifa > B+r then w/(1+2e)* > B(14+2e)? +r.

Since, for every | € N, there are only finitely many I-critical numbers it follows that for every noncritical g(x) € CPL(o),
if one just chooses ¢ > 0 sufficiently small, then g(x) is ¢-noncritical. Definition 4.26 and Lemma 4.28 motivate the next
definition.

Definition 4.31. Let ¢ > 0 be such that 1 +¢ =(1 +e’)?*.

It follows from Definition 4.31 and Lemma 4.27 that if p(x, y) and q(x) are complete atomic o-types such that |xy| <k,
d=dimy(p) > 0, gC p, P(q) > 0, and y = P(p | q), then for every n, every A€Y, is (p,q, y/(1 + &))-saturated and
(p,q, y(1 + €))-unsaturated. By an analogous argument as in Remark 4.11 (iii), it now follows that if p(x) is a complete
atomic o-type such that |x| <k and P(p) =0, then for all sufficiently large n, p is not realized in any member of Y;.

In the proof of the proposition below we will sometimes abuse notation by treating an atomic type p(x) as the formula
obtained by taking the conjunction of all formulas in p(x). So when writing, for example, Vi Ving pi,j(X, y)’ in the proof
below we view pj, ;(X, y) in this expression as the conjunction of all formulas in the complete atomic type pj, ;(x, y).

Proposition 4.32. (Elimination of quantifiers) Suppose that g(x) € CPL(o) is €-noncritical and |x| + qr(g) < k. Then there is a
quantifier-free formula ~* (x) such that for all sufficiently large n and every A € Yn, A E VxX(@(X) — y*(x)).

Proof. Let an ¢-noncritical g(x) € CPL(o) be given with |x| + qr(g) < k. We will assume that x is nonempty (i.e. that @
has free variables). In Remark 4.39 it is indicated which changes we need to make in the simpler case when ¢ has no free
variable. The proof proceeds by induction on quantifier-rank. Suppose that qr(g~) > O since otherwise we can just let y* be
y and then we are done. If for all sufficiently large n, for all A €Y, and for all a € [n]| we have A | y(@) then we can let
y* (x) be the formula x; 4x; and then AE Vx(@(X) = y*(x)) for all sufficiently large n and all A€Y,. So from now on we
assume that, for arbitrarily large n, there are A €Y, and a such that AE g(Q).

Suppose that g(x) is dyw(x, y) for some w(x, y). Then we have |xy|+ qr(w) <k and qr(w) < qr(@) so, by the induction
hypothesis, we may assume that y(x, y) is quantifier-free. By assumption there are n, A € Y,, a and b such that AE w(a, Db).
Then there are m > 1, different complete atomic o-types qj(x), i=1,...,m, and, for each i, mj > 1 and different complete
atomic o-types pi,j(X, y), j=1,...,mj, such that qi C pj;,; for all j and w(x, y) is equivalent to \/7", Ving pi,j(X, y). If, for
some i, P(qj(x)) =0, then gq; is not realized in any A€/Y, (for large enough n) and can be removed. So we may assume
that all P(q;) > O for all i. If, for some i and j, P(pi,j | q) =0 then P(pj,;) =0 so pj,; is not realized in any A €Y, for large
enough n. So we may also assume that P(p;,; | gi) > 0 for all i and j. If dimy,(p;,;) =1 then, by the definitions of Y, and
€, it follows that for all sufficiently large n and all A€ Yj, if A qj(a) then A — Jypj;,j(@, y). If dimy(p;,;) =0 then, for
all n and all A © Wh, if A qi(a) then A — pj;,j(a,b) for some b € rng(a). It follows that for all sufficiently large n and all
AE Yn, AE VR(Ay W(X Y) <> Viti Gi ®).

Now we consider the case when @(x) has the form

(r+ IVE 1OR lly = IWR 1O*R Wily) oF (4.3)

(IVR) [OR ily = IWR 16°R ily +1), (4.4)

Since the second case (4.4) is treated by straightforward variations of the arguments for taking care of the first case (4.3)
we only consider the first case (4.3). Observe that |xy|+qr(w) <k (because qr(g) = |y| + max{qr(v), qr(9), qr(w*), qr(@*)})
and similarly for 6, w* and 6%. Since all the formulas w, 0, w* and 6* have smaller quantifier-rank than g@ we may, by the
induction hypothesis, assume that w(x, y), 0(x, y), w*(x, y) and 6*(x, y) are quantifier-free formulas.
20 V. Koponen / Theoretical Computer Science 848 (2020) 1-27

If (x, y) or O0*(x, y) is unsatisfiable, then, by the provided semantics, we have A g(a) for every o-structure A and
every sequence of elements a from the domain of A. In this case g(x) is equivalent to any contradictory quantifier-free
formula with free variables among x, for example the formula x; 4 x1. So from now on we assume that 6(x, y) and 0*(x, y)
are Satisfiable.

Until further notice, assume also that w(x, y) A 6(x, y) and w*(x, y) A 6*(x, y) are satisfiable. Then there are distinct
complete atomic o-types qj(X), pi,j(X, y), for i=1,...,m and j =1,...,mj, and distinct complete atomic o-types (;(x),
Si,j(X, y), fori=1,...,l and j=1,...,1;, such that the following conditions hold:

qi(X) © pi,j(X, y) for all i=1,...,m and all j=1,...,mj.
W(X, ¥) A(X, y) is equivalent to \Vj24 Vj, pij(, ¥).
ti(x) C $j, ;(xX, y) for alli=1,...,] and all j=1,...,]j.

e 0(x, y) is equivalent to Vig Vi Si, j(%, Y).

Since Viet Vi 5i,j(X, Y) is a consequence of \/7_, Ving pi,j(X, y) it follows that m <1 and m; <1; for all i <m. Moreover,
for every i <m there is i’ such that q; = tj, and for all i<m and all j <m; there are i’, j’ such that pj;,; = sj, ;. Therefore
we may assume in addition (by reordering if necessary) that

qi =t; for alli < mand p;,; = 5;,; for alli < mand all j < mj. (4.5)

For the same reasons as in the previous case we may assume that all of P(qi), P(pi,;), P(ti) and P(s;,;) are positive for all i
and j. Next we define

dj; =dimj(p;,;) foralli=1,...,mandj=1,...,mij,
e;,; =dimy(s;,;) foralli=1,...,Jand j=1,..., |,
dj = max{dj1,...,di,m,;} foralli=1,...,m,

ej =max{ej1,...,ei1,} foralli=1,...,l,

Qi; =P(pi,j(X, y) | qi(X)) foralli=1,...,mandj=1,...,mj,
a; = the sum of all aj, ; such that dj, ; = dj,

Bi,j = P(Si,j(X, y) | i(X)) for alli=1,...,Jandj=1,...,l,

6; = the sum of all 6;,; such that e;, ; = e;.

It follows that for all i=1,...,m we have dj; < e; and a; < fj.

Definition 4.33. For all i=1,...,1 we define a number 7; as follows:

(1) If i<m and dj =e; > 0 then we define yj; = a; /f;.
(2) If i<m and dj =e; =O then we define y; = m;/lj.
(3) If i<m and d; < e; then we define j; = 0.

(4) If m <i <I then we define y; = 0.

Now we can reason in exactly the same way with regard to the formulas w*(x, y) and 9*(x, y). So there are numbers
m*,I*,m; and I? and complete atomic o-types q;(x) for i=1,...,m*, Dj ,(%, y) for i<m* and j =1,...,m-, t*(x) for
i=1,...,I* and Sj y) fori </I* and j =1,...,/7 such that all which has been said about y, @, qi, pi,j, tj and s;,; holds
if these formulas and types are replaced by y*, 6*, q;, D; ; etcetera, and the numbers m, I, mj, |; are replaced by m*, I*, m;
and I*. Moreover, we define numbers d; e; d=, e*, Ql; a, Be B; and y,* in the same way as above, using the types
q; 5 Pj t* and Si j instead of qi, pi,j, tj and 5;,;.

So far we have assumed that w(x, y) A@(x, y) and w*(x, y) A0*(X, y) are satisfiable. If w(x, y) A@(x, y) is not satisfiable,
then we let m=0 and we view the disjunction \/¥_, Vint pi,j(X, y) as “empty” and hence always false. In this case we
always have i>™m so it follows that yj =0 for all i=1,...,1. Similar conventions apply if w*(x, y) A 6*(X, y) is not satisfi-
able. With these conventions the case when any one of the mentioned formulas is unsatisfiable is taken care of by the rest
of the proof.

Lemma 4.34. Let i ¢ {1,..., mb}.
(a) For all sufficiently large n and all A € Yn,
V. Koponen / Theoretical Computer Science 848 (2020) 1-27 21

Vy; Ui pi.i@, A)|
a
2—- lj _ .
(b) If dj = e; then, for all sufficiently large n and all A € Yn,
[Uy Pii@ A)|
I; _
| ja SiG A)|
(c) If dj < e; then, for all sufficiently large n and all A € Yn,
LUT PLGA] ¢
a
I - —
Ul siGA]"

where the constant C > 0 depends only on the types p;,; and sj, ;.
arts (a), (b) and (c) hold ifm, mj, |;, Vj, di, ej, pj,; and s;,; are replaced by m*, m=, I*, y,*, d*, e*, p; . and s* ., respectively.
(d) Parts (a), (b) and (c) hold if li. Vir d jand si, j laced by m*, m;, I, Yj", dj, e;, B; ; and s; vel

< (1+ 2e)77.

Proof. We split the argument into cases corresponding to the three first cases of Definition 4.33. Let A €Yp.
First suppose that dj = e; > 0 and hence yj, = a; /;. Since A is assumed to be (pj,;, qi, (1 + €)aj,;)-unsaturated if dj, ; > 0
it follows that
\pi,j(@, A)| <1 + e)a%, jn" if d;,; > 0.

If dj; =O then Di, ja, A)| = 1 and each member of the unique tuple realizing pj;,;(a, y) belongs to a. It follows that

mj
LJ pij(,A)| < A+ 2e)ajn" for all sufficiently large n. (4.6)

j=l

 

 

By similar reasoning (and since we assume dj; = e;) we get

li
LJ Si,j (a, A)

j=l

< (14 2¢) pin". (4.7)

 

 

Since A is assumed to be (pj,j,qi, ai,;/(1 + €))-saturated if dj; > 0 and (5;,;, tj, 6j,;/(1 + €))-saturated if e;,; > 0 it
follows that |pj;,;(@,.A)| > oj, jn“i/(1 +e) if dj,j > 0 and |s;,;@,A)| = B;,jn*i/(1 +) if e;,; > 0. This (and d; = e;) implies
that

 

 

 

 

 

 

mi a;nti li Bini
- 1 - 1
U Pi.j@, A)| = ihe and Usij@A) > the (4.8)
j=l j=1
From (4.6), (4.7) and (4.8) we get
Li, pij@ A)

lig = ating = Umut «a ezott <0 “
(1 + 2e) (1 + 2€)*B; UL, si,j(@, A)| Bi

Now suppose that dj = ej; = 0. Then yj, =m;/l;. Also, each p;,j(a, y) and each s;,;(a, y) has a unique realization in A. Since
we assume that pj; 4 pi; if j Aj’ and s;,; As;,7 if j Aj’ we get

— my — [Up Pis@ A]
di Ui 5i,j(@, A)

and now the inequalities of (a) and (b) follow trivially.
Next, suppose that dj < e;. Then y; = 0. By similar reasoning as before,

Yi

’

 

pine \
<
1+ 2¢é

 

<

 

Si,j(, A) for sufficiently large n.
j=l
22 V. Koponen / Theoretical Computer Science 848 (2020) 1-27

It follows that

 

aap? = toakoo oe a
(1 + 2€) | Uja1 Si,j(d, A)|
Since e; > O we can argue as we did to get (4.8), so we have
i pine
si,j@, A)| > ——.
U ij@,A)| =

 

 

Depending on whether d; > 0 or dj = 0 we get, by arguing as in previous cases,

< (1 + 2e)a;n"i or

mj
_) pi.5@. A)

mj
LJ pi,j (a, A) = mj.
j=l

j=l

 

 

 

Since d; < e; we get, in either case,

Uj PLGA]
— < 7 for sufficiently large n
[Ul 51.5 A)|

where C > 0 is a constant that depends only on the types p;,; and 5;,;.
The proof of part (d) is, of course, exactly the same (besides the relevant replacements of symbols). O

Definition 4.35. Let | be the set of all i ¢ {1,...,1} such that there exists some i’ € {1,...,/*} such that t}; =t7 andr+y >
Vir

Remark 4.36. (The computational problem of finding !) The number a;,; is obtained from numbers given by Assump-
tions 4.1 and 4.10 and applying a number of arithmetic operations which is linear in |pj;,;|. It follows that the number of
arithmetic operations needed to compute qj; is linear in jet |pi,j], where by an arithmetic operation I mean addition,
multiplication or division. The case is similar for 6;, a;* and £*. The number of comparisons of literals needed to check if
t; =t;, is |t;| if we assume that we use some uniform way of listing the literals in complete atomic o -types. So to decide if
i€ I we need to perform a number of arithmetic operations, comparisons of literals and comparisons of numbers which is

linear in

Do IPisl+ Dosis + Do IPE + DIF jl:
j=l j= j=1 j=1

Consequently the number of arithmetic operations, comparisons of literals and comparisons of numbers that are needed to
create J is linear in

m om Lol m* m; eG
DD IP t+ Dy Dd Wilt Dy Dd IPE lt DoD |S:
i=1 j=1 i=1 j=1 i=1 j=1 i=1 j=1

Lemmas 4.37 and 4.38 below show that (x) is equivalent, in every A € W, for all large enough n, to a quantifier-free
formula which depends only on @(x) and the lifted Bayesian network 6. As noted after Definition 4.29, 0 is a ¢-critical
number for every ¢, so r > 0 (since ¢ is noncritical). Observe that it follows from Definitions 4.29 and 4.33 that y; and y;*
are (|x| + qr(@))-critical numbers for all i.

Lemma 4.37. Suppose that I 4 9. Then for all sufficiently large n, all A € Y, and alla € [n]'*!,
AE (r+ v9) 10, Dily = WGI) 16*G lly)
if and only if AE \/j-; ti(@.

V

Proof. Suppose that

A= (r+ VGH) 16G Dlly = IW*@)16*G Dily).

V
V. Koponen / Theoretical Computer Science 848 (2020) 1-27 23

Then both ||W(@, y) | 6G, y)\l5 and |lv*, y) | @*G, y) |p are defined in A and

l(a, A) NAG, A)| . |v* (a, A) N6*(G, A)|
|0(a, A)| (a, A)|

’

   

SO
SS ee
l l, a - [* It = ,

Now 4 realizes exactly one of t;(x),...,t1(%) and exactly one of t7(X),...,t}(X) so there are 1 <i <I and 1 <i’ </* such
that A tj(a@) At; (@) and hence tj = tf. Ifr+yj = vy, theni eI and hence A E Vie ti(@) so we are done. Hence it remains
to prove that r 4 Vi = y;7. We divide the argument into cases.

Case 1: Suppose that i >m and i’ > m*. Then, by the definition of yj and y;* (Definition 4.33), we have y; = y,* =0 so we
getr+Vi=y;-

Case 2: Suppose that i < mand i’ > m*. Then y,;* =0 and as yj is always nonnegative we get r+ yj > y;7.

Case 3: Suppose that i > m and i’ < m*. By Lemma 4.34 (a), assuming that n is sufficiently large,

r+ (4.10)

ye User PP @ A]
14+2¢e)2 —
(1 +2¢) ~ Us (@,A)|
Since i >m we have p,,j(a, A) =% for every 1 <i <m and every 1 < j <m, so
[Um Ups Pi@ A)
lo dk : ~
in Uhr 5.1 4)|
This together with (4.10) implies that
= 4262" (411)
TE ak Gea aa)

If r < y,* then, since p(x) is €-noncritical, we get r < y;/(1 + 2e)* which contradicts (4.11). Hence r > y,, and since yj; =0
(because i > m) we get r+ yj > y;".
Case 4: Suppose that i < m and i’ < m*. Then (4.10) reduces to

rr - (4.12)
i si@ a] ie 1 5j7_ 4, ‘aa
Towards a contradiction, suppose that r+ yj < y;;. Since g(x) is assumed to be €-noncritical we get
2 Vir
r+(14+28)*yj< 4 2e)2" (4.13)

Recall, from the definition of dj and e;, that dj < e;. We now consider two subcases and in each subcase we will derive a
contradiction to (4.12).
Subcase 4(a): Suppose that dj = e;. By parts (a) and (b) of Lemma 4.34,

[Ui pi. @, A)| ui re oa .

From (4.13) and (4.14) we get

(4.14)

[Ut , Di,j(@, A)| 5
r+ — ert (1 428) Vi <
[Ut 1 5i,j (4, A)|

m*, _
yp _ [User Pi. 4)
1+2¢°)2 — l', _
(1 + 2e) [pL sf @ |
24 V. Koponen / Theoretical Computer Science 848 (2020) 1-27

which contradicts (4.12).
Subcase 4(b): Suppose that d; < e;. Then Lemma 4.34 (c) gives

LUT PiiGA| — ¢
ne
lj - —
| ja SiG A)|
where the constant C > 0 depends only on the involved types. Lemma 4.34 (a) gives
Uy 1 Pir, (qd, A)| . Vr
142¢)2°
Uist (a, A)| (1 + 2¢€)

Since d; < e; implies that y; = 0 it follows from (4.13) that r< y/(1 + 2e)*. Note that the right hand term in (4.15) tends
to 0 as n tends to infinity. So for all sufficiently large n we have

(4.15)

r+ jks Pi.i@ A) <rpoe- Vir _ |e 1 Pi j(@ A)
Unnsu@al 7 TH Es al

and this contradicts (4.12).

Now suppose that AE \/;.,ti(a@), so A ti(a) for some i € I. By Definition 4.35 of J there is i’ € {1,...,/*} such that
tj =t; andr+yj = y,;. Since g(x) is an €-noncritical formula it is, in particular, noncritical which implies that r+ yj 4 y,
and hence r+ yj > y,;. Since g(x) is €-noncritical it follows that

r+yi/(+2e)? > yx 426)’. (4.16)

It suffices to prove that
1 = * ) my; =
| ier Uj Pui A)| | VE U jan Pr jG, A)|
So
l l, = — I Ir =
| Uia1 Uj S,,j(G, A)| | U1 Uj sp jG, A)|

Again we divide the proof into cases.

Case 1: Suppose that i’ > m*. Then the term to the right of ‘>’ in (4.17) is zero, so (4.17) holds.

Case 2: Suppose that i > mand i’ < m*. Then the term immediately to the left of ‘>’ in (4.17) is zero, so we need to prove
that

(4.17)

* my _
Um Uys pry @ A]
r= (4.18)
[UL Uj st )@ A)
From i >m we get yj = 0 so (4.16) reduces to
r>yr(1+2e)?. (4.19)
Recall that from the definition it follows that di, < e%.
Subcase 2(a): Suppose that di, = e;,. Then using parts (d) and (b) of Lemma 4.34 we get
m*, _ x * _
— [UP G@ A] [UR UF P74]
- [* Ir -
~ Jus 1 Sir j (a, A)| Ula Uji Sj ;

which together with (4.19) gives (4.18).
Subcase 2(b): Suppose that dj, < e;,. Then parts (d) and (c) of Lemma 4.34 imply that

yi +28)?

      

* * _ m* -
[Ur U Vin Fi A) [Ur PF @ | _¢
l* _ — n>
LULU st) @ A] [UL sf @ 4)

for some constant C > 0 depending only on the involved types. Since r > O it follows that (4.18) holds for all sufficiently
large n.
V. Koponen / Theoretical Computer Science 848 (2020) 1-27 25

Case 3: Suppose that i < m and i’ < m*. Now (4.17) is equivalent to

_ m*, _
| Ung Pi,j (a, A)| | U jet Pi ; (4, A)|
a

r+ - > - (4.20)
Uj sis@ A] |UL ys @ a)
So it remains to prove (4.20). By Lemma 4.34 and (4.16) we have
| Ur, pig G, A)| ;
r+ oo or Fs 14-20)? y7. (4.21)
| Ul, i,j (@, A)| (1 + 2e)
If d; =e, then, by Lemma 4.34,
m*, _
Us pi @.A)|
(1+2e)*y; > ————_.
LU st )@ A
which together with (4.21) gives (4.20).
Now suppose that d*, <e*. Then y,; =0 and (4.21) reduces to
[Uys pii@, A) |
r+ ,» wees. >r+ eee > 0 (4.22)
JUjarsisG@a] O42)

Lemma 4.34 gives
m*, _
[UF PGA]
Te < —
[Ufa sh j@ A)
This together with (4.22) gives (4.20) for all sufficiently large n. This completes the proof of Lemma 4.37. O

Lemma 4.38. Suppose that I = Y. Then for all sufficiently large n, all A € Yn and alla € [n]"*",
AF (7 + IVGWIOGWIy = IWaylerG Vlly).

Hence the formula (4.3) is equivalent, in every such A, to any contradictory quantifier-free formula.

Proof. Suppose that I = 4. Suppose towards a contradiction that there are arbitrarily large n, A © Y, and @€ [n]'*! such that

AE (r+ WG.) 10, Dily = WG I) 16*@ lly),

Then we argue just as we did in the beginning of the proof of Lemma 4.37 to get (4.10) and find 1 <i<I and 1 <i’ <I*
such that t; =t;,. Since 1 = we must have i ¢ I and therefore r+ yj < y,;;. Now we can continue to argue exactly as in the
proof of Lemma 4.37 to get a contradiction in each one of the cases 1-4 in that proof. O

Remark 4.39. (The case when x is empty) Suppose now that x is empty, so the formula (4.3) becomes

(r+ IV) ODly = IVD 1 O*Wly), (4.23)
where we can assume that w, 6, w* and 6* are quantifier-free. Then there are distinct types pj(y), i=1,...,m and distinct
types sj(y), i=1,...,1. We can now define numbers y and y* similarly as each yj (and y;*) was defined above. We now

get an analogoue of Lemma 4.34 which gives the same kind of upper and lower bounds of |i", pi(A)| / | jer Si(A)| in

terms of y. If r+ y > y* then, by the noncriticality of (4.23), we get r+ y > y* and by the e-noncriticality of the same
formula we get r+ y/(1 + 2e)? > y*(1 + 2e)*. Now we can argue similarly as in the “converse direction” in the proof of
Lemma 4.37 and conclude that (4.23) is true in all A¢/Y, for all sufficiently large n; hence (4.23) is equivalent to T in all
such A. Now suppose that r+ y < y* and suppose, towards a contradiction, that there are arbitrarily large n and A€Y, in
which (4.23) holds. Then we can argue as in the first part of the proof of Lemma 4.37 and get a contradiction. Hence, for
all sufficiently large n, (4.23) is false in all A €Y,; consequently, (4.23) is equivalent to —T in all such A. (The case when
gy has the form dyy(y) is easier and analogous to the argument in the beginning of the proof of Proposition 4.32 so this
part is left to the reader.)
26 V. Koponen / Theoretical Computer Science 848 (2020) 1-27

Now the proof of Proposition 4.32 is completed. O
Definition 4.40. Define a function 6: N+ > R=® by 8(n) =5- max{6’(n),e~“} where c > 0 is like in Lemma 4.28.

Proposition 4.41. (Completion of the induction step) Let Y, C Wn, € > 0 and 6(n) be as in Definitions 4.26, 4.31 and 4.40, respec-
tively. Then:

(1) limp+o 6(n) = 0.

(2) Pa(¥n) = 1 — 6(n) for all sufficiently large n.

(3) For every complete atomic o -type p(X) with |x| < k there is a number which we denote P(p(x)) such that for all sufficiently large
n and alla € [n] which realize the identity fragment of p,

|Pn({A € Wh: AE p(@)}) — P(p®)| < 5).

(4) For every complete atomic o -type p(x, y) with |xy| < k and 0 < dim; (p(x, y)) = | yl, if q(x) = p[x and P(q) > 0, then for all
sufficiently large n, every A € Yp is (p,g,a/(1 + €))-saturated and (p,q, a(1 + €))-unsaturated if ~w = P(p(x, y)) | P(q(X)).

(5) For every €-noncritical p(x) € CPL(o) with |x| + qr(@) <k, there is a quantifier-free o -formula p* (x) such that for all sufficiently
large n and all A € Yn, AF Vx(p(X) <= *(X)).

Proof. Parts (1) and (2) follow from the definition of 5(n), Assumption 4.10 and Lemma 4.28. Part (3) follows from Corol-
lary 4.19. Part (4) follows from Corollary 4.27 and the definition of ¢. Part (5) follows from Proposition 4.32. O

Corollary 4.42. Let ¢ > 0 be as in Definition 4.31.

(a) If p(X) € CPL(o) is €-noncritical and |x| + qr(~) <k, then there are c > 0 and 0 <d <1 which is a sum of numbers of the form
P(p), where p is a complete atomic o-type, such that for every m € N* and every a € [m]'*! such that A — g(a) for some A € Wm,
\Pn (p(a)) —d | < Cé(n) for all sufficiently large n where the constant C depends only on @. Moreover, d is I-critical for some I.

(b) If @ € CPL(o) has no free variable, is e-noncritical and qr(~) < k, then either P,(@~) < 6(n) for all sufficiently large n, or Pn(~) =
1 — 6(n) for all sufficiently large n.

(c) Suppose that for every R € o \o", if x is the sequence of free variables of xp ; then |x| ++ qr(Xr,i) < k. Let P* be defined as Py, except
that we replace xr,j by x Ri in Definition 4.2 where x Ri is a quantifier-free formula which his equivalent to xp ; in every structure in
Y,, for all large enough n. If (x) € CPL(o) is €-noncritical, |x| + qr(g) < k and A — g(a) for some A € Wy and some m, then

IPr(@@) — Pr(y(@))| < 6(n) forall sufficiently large n.

Proof. (a) Suppose that g(x) € CPL(o) is €-noncritical and |x|+qr(g) <k. By part (5) of Proposition 4.41 g(x) is equivalent,
in every A €Y, (for large enough n), to a quantifier-free formula y* (x). Then @*(X) is equivalent to a disjunction of complete
atomic o-types Vig pi(x) where we assume that p; 4 p; if iA j. Suppose that A — g(a) for some A € Wy, and some m.
Let I be the set of indices i such that A — p;(a) for some A € W, and some n. By assumption, | 4M. Let d= )0;., P(pi). By
part (3) of Proposition 4.41, we have \Pn (p* (a)) —d| < |J|6(n) for all sufficiently large n, and now (a) follows from part (2)
of Proposition 4.41. It now follows from Definition 4.29 that d is |-critical for some I.

(b) Suppose that @ € CPL(o) has no free variable, is ¢-noncritical and qr(g) < k. By Proposition 4.41 (5), there is a
quantifier-free sentence g* such that for all sufficiently large n and all AG Y;, AE @ < g”*. Then g* must be equivalent
to | or T. The conclusion of part (b) now follows from parts (1) and (2) of Proposition 4.41.

(c) Since xr; is equivalent to XR i in every A €Y, it follows from the definitions of P, and P* that if A ¢Y, then
P(A) = P(A). It follows that if X, CY, then P*(X,) = Pn(Xn) and in particular P* (Yn) = Pn(¥n). Since P* (Wh \ Yn) =
1 — Pt(¥n), and similarly for Py, it follows that P (Wr \ Yn) = Pa(Wn \ Yn). From part (2) of Proposition 4.41 we get
P* (Wp \ Yn) = Pn(Wh \ Yn) < 5(n). Let X, = {A € Wy: A= G(@}. Then

Pr (Xn) < Py (Xn | ¥n)Py Wn) +6(2) = Py Xn NYn) + 5) =
Pn(Xn Yn) +6(n) < Pa(Xn) + 6(n),
and by similar reasoning Pn(Xn) < P*(Xn)+46(n). O

5. Concluding remarks

The results of this article consider one particular formal logic and one type of lifted graphical model. Also, given these
two things, choices have been made for example regarding exactly how to define a probability distribution on the set of
structures with a common finite domain. From the point of view machine learning and artificial intelligence, as well as
mathematical curiosity, one could ask a number of questions, of which I suggest a few below.
V. Koponen / Theoretical Computer Science 848 (2020) 1-27 27

In finite model theory, theoretical computer science and linguistics a number of extensions of first-order logic have been
considered [20]. For example, a generic way of extending first-order logic is by adding one or more so-called generalized
quantifiers [15,17]. In machine learning, data mining and artificial intelligence a number of different (lifted) graphical mod-
els, including the popular Markov networks [7,18] have been considered. For which combinations of formal logical language
and lifted graphical model do we get “almost sure elimination of quantifiers” and/or “logical limit laws”? Do we get more
expressive formalisms by using aggregation functions than if we use aggregation rules, or vice versa? How do different com-
binations of formal language and graphical model relate to each other? In what sense is a combination (formal language 1,
graphical model 1) “better” than a combination (formal language 2, graphical model 2)? What are reasonable candidates for
the relation “A is better/stronger than B”? Some thoughts in this direction appear in the last part of [5].

One can consider conditional probabilities which are not constant, but depend on the size of the set of elements (or
tuples) satisfying the condition in question. As a special case we have probabilities that depend on the size of the whole
domain, as in previous work on logical zero-one laws in random graphs [24,25]. -

What if the probability of a tuple a satisfying a relation is dependent on whether another tuple Db satisfies the same
relation (as in [19,21] for example)?

A situation that seems natural in the context of artificial intelligence is to have an underlying fixed structure and on top
of it relations that are “governed” by some probabilistic graphical model. The underlying fixed structure could be represented
by a t-structure A for some signature Tt. For another signature o (disjoint from t) we could consider the set of expansions
of A to (t Uao)-structures where the probabilities of these extensions are governed by some probabilistic model and the
underlying structure A. To formalize this using the set up of this article, one can modify w? in Definition 3.10 to contain
exactly one t-structure with domain [n] and W, will be the set of all (tc Uo)-structures that expand the unique structure
in w . The definition of the probability distribution P, on W, can now depend not only on the lifted Bayesian network 6
but also on the unique structure in w . It seems obvious that, in order to get similar results as in this article, one needs to
assume some sort of uniformity regarding the unique structure in w? for cofinitely many n.

References

[1] N. Alon, J.H. Spencer, The Probabilistic Method, second edition, John Wiley & Sons, 2000.
[2] F. Bacchus, A.J. Grove, J.Y. Halpern, D. Koller, From statistical knowledge bases to degrees of belief, Artif. Intell. 87 (1996) 75-143.
[3] C. Borgelt, R. Kruse, Graphical Models: Methods for Data Analysis and Mining, John Wiley & Sons, 2002.
[4] H. Chernoff, A measure of the asymptotic efficiency for tests of a hypothesis based on the sum of observations, Ann. Math. Stat. 23 (1952) 493-509.
[5] L. De Raedt, P. Frasconi, K. Kersting, S. Muggleton (Eds.), Probabilistic Inductive Logic Programming: Theory and Applications, Lecture Notes in Artificial
Intelligence, vol. 4911, Springer-Verlag, Berlin, Heidelberg, 2008.
[6] L. De Raedt, K. Kersting, S. Natarajan, D. Poole, Statistical Relational Artificial Intelligence: Logic, Probability, and Computation, Synthesis Lectures on
Artificial Intelligence and Machine Learning, vol. 32, Morgan & Claypool Publishers, 2016.
[7] P. Domingos, D. Lowd, Unifying logical and statistical Al with Markov logic, Commun. ACM 62 (2019) 74-83.
[8] R. Fagin, Probabilities on finite models, J. Symb. Log. 41 (1976) 50-58.
[9] Lise Getoor, Ben Taskar (Eds.), Introduction to Statistical Relational Learning, The MIT Press, 2007.
[10] Y.V. Glebskii, D.I. Kogan, M.I. Liogonkii, V.A. Talanov, Volume and fraction of satisfiability of formulas of the lower predicate calculus, Kibernetyka 2
(1969) 17-27.
[11] J.Y. Halpern, An analysis of first-order logics of probability, Artif. Intell. 46 (1990) 311-350.
[12] C.D. Hill, On 0, 1-laws and asymptotics of definable sets in geometric Fraissé classes, Fundam. Math. 239 (2017) 201-219.
[13] M. Jaeger, Convergence results for relational Bayesian networks, in: Proceedings of the 13th Annual IEEE Symposium on Logic in Computer Science,
LICS 98, 1998.
[14] M. Jaeger, Reasoning about infinite random structures with relational Bayesian networks, in: Proceedings of the Sixth International Conference on
Principles of Knowledge Representation and Reasoning, KR 98, 1998.
[15] R. Kaila, On probabilistic elimination of generalized quantifiers, Random Struct. Algorithms 19 (2001) 1-36.
[16] H.J. Keisler, W.B. Lotfallah, Almost everywhere elimination of probability quantifiers, J. Symb. Log. 74 (2009) 1121-1142.
[17] E. Keenan, D. Westerstahl, Generalized quantifiers in linguistics and logic, in: J. van Benthem, A. ter Meulen (Eds.), Handbook of Logic and Language,
second edition, Elsevier, 2011, pp. 859-910.
[18] A. Kimmig, L. Mihalkova, L. Getoor, Lifted graphical models: a survey, Mach. Learn. 99 (2015) 1-45.
[19] Ph.G. Kolaitis, H.J. Prémel, B.L. Rothschild, K,,;-free graphs: asymptotic structure and a 0-1 law, Trans. Am. Math. Soc. 303 (1987) 637-671.
[20] L. Libkin, Elements of Finite Model Theory, Springer-Verlag, Berlin, Heidelberg, New York, 2004.
[21] J.F. Lynch, Convergence law for random graphs with specified degree sequence, ACM Trans. Comput. Log. 6 (2005) 727-748.
[22] D. Mubayi, C. Terry, Discrete metric spaces: structure, enumeration, and 0-1 laws, J. Symb. Log. 84 (2019) 1293-1324.
[23] J. Pearl, Causality: Models, Reasoning, and Inference, second edition, Cambridge University Press, 2009.
[24] S. Shelah, J. Spencer, Zero-one laws for sparse random graphs, J. Am. Math. Soc. 1 (1988) 97-115.
[25] J. Spencer, The Strange Logic of Random Graphs, Springer-Verlag, Berlin, Heidelberg, New York, 2001.
