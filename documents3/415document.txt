Collazos-Huertas et al. Brain Inf. (2020) 7:8
https://doi.org/10.1186/s40708-020-001 10-4

Brain Informatics

RESEARCH Open Access

CNN-based framework using spatial

-)

Check for
updates

dropping for enhanced interpretation of neural
activity in motor imagery classification

D. F. Collazos-Huertas!’®, A. M. Alvarez-Meza!, C. D. Acosta-Medina', G. A. Castafto-Duque

and G. Castellanos-Dominguez'

Abstract

Interpretation of brain activity responses using motor imagery (MI) paradigms is vital for medical diagnosis and
monitoring. Assessed by machine learning techniques, identification of imagined actions is hindered by substantial
intra- and inter-subject variability. Here, we develop an architecture of Convolutional Neural Networks (CNN) with an
enhanced interpretation of the spatial brain neural patterns that mainly contribute to the classification of MI tasks.
Two methods of 2D-feature extraction from EEG data are contrasted: Power Spectral Density and Continuous Wave-

let Transform. For preserving the spatial interpretation of extracting EEG patterns, we project the multi-channel data
using a topographic interpolation. Besides, we include a spatial dropping algorithm to remove the learned weights
that reflect the localities not engaged with the elicited brain response. We evaluate two labeled scenarios of MI tasks:
bi-class and three-class. Obtained results in an MI database show that the thresholding strategy combined with
Continuous Wavelet Transform improves the accuracy and enhances the interpretability of CNN architecture, showing
that the highest contribution clusters over the sensorimotor cortex with a differentiated behavior of rhythms wand B.

Keywords: Motor imagery, Convolutional Neural Networks, Spatial dropping

1 Introduction

The motor imagery (MI) paradigm is a form of brain—
computer interface (BCI) that performs the imagination
of a motor action without real execution, relying on the
similarities between imagined and executed actions at
the neural level. MI is usually measured with electro-
encephalography (EEG) to register brain activity on the
scalp surface. Thus, assessment and interpretation of MI
brain dynamics in the sensorimotor cortex may contrib-
ute to applications ranging from evaluation of pathologi-
cal conditions and rehabilitation of motor functions [1,
2], motor learning and performance [3], improving the
learning of different abilities [4], among others. In edu-
cation scenarios, the Media and Information Literacy

 

*Correspondence: dfcollazosh@unal.edu.co

' Signal Processing and Recognition Group, Universidad Nacional de
Colombia, Manizales, Colombia

Full list of author information is available at the end of the article

Q) Springer Open

 

methodology proposed by the UNESCO covers several
competencies that are vital for people to be effectively
engaged in all aspects of human development [5]. Nev-
ertheless, one of the main challenges in implementing
MI practice is recognizing and identifying the imagined
actions since EEG signals have substantial intra- and
inter-subject variability [6].

Currently, there is an increasing interest in deep
learning models that are composed of multiple process-
ing layers of inference using data representations with
multiple levels of abstraction. In discriminating physio-
logical signals, Convolutional Neural Networks (CNN)
become the leading deep learning architectures due to
their regularization structure and degree of transla-
tion invariance [7], yielding an outstanding ability in
transferring knowledge between apparently different
tasks of classification [8, 9]. Thus, CNN models are use-
ful in learning features related to brain imaging and

© The Author(s) 2020. This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing,
adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and
the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material

in this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material
is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the
permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http://creativeco

mmons.org/licenses/by/4.0/.
Collazos-Huertas et al. Brain Inf. (2020) 7:8

neuroscience discovery [10]. Nevertheless, for appli-
cations in MI tasks, designing an available end-to-end
CNN architecture remains a challenge due to several
restrictions: their large number of hyperparameters to
be learned increase the computational burden (being
unsuitable for online processing [11]), and complicated
multilayer integration to encode relevant features at
every abstraction level of the input EEG data [12].

Another unresolved issue is the interpretability of
results provided by CNN models [13]. That is, along
with the improved accuracy, the learned features can
be hard to understand within the context of the original
MI paradigm. The value of neural activity interpreta-
tion becomes evident in purposes like a medical diag-
nosis, monitoring, and computer-aided learning [14].
As a tool in image processing, CNN architecture has
been discussed for enhancing the physiological expla-
nation of MI paradigms represented by multiple
time-series (time dimension), which reflect the brain
responses across the sensorimotor cortex (spatial
dimension), and commonly related to wz and £ rhythms
(spectral dimension). For representing local and global
structures in CNN models, therefore, the extraction of
time-series features is increasingly realized as a multi-
dimensional tensor that retains the EEG data structure
throughout the learning process, by adequately encod-
ing the spatio/spectro-temporal relationships of the
measured MI responses [15]. Nevertheless, CNN mod-
els should extract the structure of multi-dimensional
images properly to preserve the domain information of
interest. Intending to make the learned features more
interpretable in MI tasks, two main aspects are to be
considered to retain the spatial locality of CNN mod-
els: (i) improving the 2D-feature extraction from EEG
data for feeding the CNN models, and (ii) enhancing
the image-based EEG representation to integrate spa-
tial domain knowledge with the extracted 2D spectro-
temporal features.

For building 2D-maps in discrimination of MI tasks,
several algorithms of feature extraction are employed in
CNN models, including the following: common spatial
patterns due to the high recognition rate and compu-
tational simplicity [16]; event-related synchronization
to capture the channel-wise temporal dynamics of the
power signal [17]; empirical mode decomposition to deal
with EEG nonstationarity [18, 19]; and time-frequency
planes using the Fourier and wavelet transforms are fre-
quently extracted because they allow a more straightfor-
ward interpretation [20-23], the latter decomposition
being better suited to deal with sudden changes in EEG
signals. Nonetheless, the extracted 2D images tend to
have substantial variability in patterns across trials due to
inherent nonstationarity, artifacts, a poor signal-to-noise

Page 2 of 13

ratio of EEG signals, individual differences in cortical
functioning (like subjects exhibiting activity in different
frequency bands).

Concerning the integration of electrode montages with
the extracted 2D features, topographical representations
are applied, involving either local or global spline tech-
niques to interpolate the spatial distribution of the poten-
tial field on the scalp from distributed electrode arrays.
For low electrodes distributions, adequate mapping is the
spherical spline interpolation [24]. One strategy of inte-
gration is to incorporate prior knowledge to optimize
the neural network structure for handling the lack of
significant samples in smaller datasets. For instance, pre-
trained networks are used, but assuming a substantial
similarity between pre-training and target sets [25-27].
Otherwise, some ambiguity may remain in the foolproof
nature of the pre-trained network methodology [28]. In
the case of MI tasks, there are very few accessible data-
sets having some differences in implementing the para-
digm. Another integration approach is to have some
form of spatial dropping algorithm to remove candidate
localities known to be not engaged with the elicited
brain response. Relying on the fact that motor imagery
responses are directly related to electrocortical activity
over the sensorimotor area, the spatial dropping can be
performed either subject-independent by excluding all
electrodes out of the motor cortex before training and
validation [29-31], or by thresholding the electrode con-
tribution after training and validation for each subject.

Here, we develop a CNN architecture with an enhanced
interpretation of the spatial activity of brain neural pat-
terns that mainly contribute to the classification of MI
tasks (left, right hand, and foot). Following the approach
developed by [32], the CNN framework is designed, for
which we validate two commonly used techniques of fea-
ture extraction from EEG data: power spectral density
and continuous wavelet transform. For preserving the
spatial interpretation of extracting EEG patterns, we pro-
ject the multi-channel data using a topographic interpo-
lation. Besides, we include a spatial dropping algorithm
to remove the learned weights that reflect the localities
not engaged with the elicited brain response. Obtained
results in a MI database show that the thresholding strat-
egy is desirable since the highest contribution clusters
over the sensorimotor area with differentiated behav-
ior between yz and f bands. The present paper’s agenda
is as follows: Section 2 describes the collection of MI
data used for validation. Besides, it presents the funda-
mentals of feature extraction of time-frequency (t-/)
EEG patterns and describes the design of Convolutional
Neural Networks, including the spatial dropping strate-
gies for motor imagery classification. Further, Section 3
provides a summary of the classifier accuracy performed
Collazos-Huertas et al. Brain Inf. (2020) 7:8

by the extracted t-f vectors and evaluates the interpret-
ability of learning weights for distinguishing between MI
tasks. Lastly, Section 5 gives critical insights into the per-
formed interpretation and accuracy, and address some
limitations and possibilities of the presented CNN-based
framework.

2 Materials and methods

Description of MI database and preprocessing. We per-
form experimental validation with nine subjects (Ns = 9)
of Dataset 2a’, holding EEG signals acquired from the
scalp by a C-channels montage (C = 22). Each raw EEG
channel x°<R/! was sampled at 250 Hz (ie., at sample
rate At=0.004 s) and passed through a five-order band-
pass Butterworth filter within {2 = [8,30] Hz. Since
earlier works have shown that electrical brain activi-
ties prompted by motor tasks are frequently related to
jw and 6 rhythms [33], the spectral range is split into
the following bandwidths of interest: Afe {we [8-12],
Biow€ [16-20], Bmea€ [20-24], Bhigh€ [24—28]} Hz.

For performing an MI task, each trial began with an
acoustic cue “beep” (at 0 s), and along with a fixation
cross appeared on the black screen. After 2 s (at 2 s), an
arrow cue appeared for 1.25 s on the screen, pointing
in one direction according to the evaluated MI task: the
left (left hand), right (right hand), or down (foot). The
subjects were then instructed to image the correspond-
ing imaginary movement between 3 s and 6s. At 6 s, the
screen was black again, allowing the subjects to relax.
Then, each subject performed a run of each MI task while
the cross re-appeared within the time interval, starting
from 3.25 to the recording end, T's. The recordings were
collected in six runs separated by short breaks, perform-
ing N, = 72 trials per class and each one lasting T = 7
s. We validated two labeled scenarios: bi-class (left hand
and right hand), and three-class (left hand, right hand,
and foot). Testing is carried out using only the labeled tri-
als with the removed artifacts.

Feature extraction of t-f EEG patterns. In the first case,
the feature set is extracted from the Fourier decom-
position method. So, provided the EEG sample fre-
quency F,€R™, the power spectral density (PSD) vector
s = {sfER* : fENzg}, with Ng =I1|F;/2], is estimated
through the nonparametric Welch’s method that calcu-
lates the fast Fourier transform (FFT) algorithm on a set
of MEN overlapping segments, which are split from the
preprocessed EEG data vector x°. Due to the non-station-
ary nature of EEG data, the piecewise stationary analysis
is carried out over the set of the extracted overlapping
segments that are windowed by a smooth-time weighting

 

' BCI Competition IV, publicly available at www.bbci.de/competition/iv/.

Page 3 of 13

window we’ that lasts t—eN (t < T), yielding a set of
the time segments {v’” eR* : meEM}, where vi" ER (ter) is
tth element of v”. So, the t-f patterns are extracted from
EEG signals through the modified periodogram vector,
u = {ur ER*}, weR2, computed as follows:

wp =2{ |e exp)? vm eat (1)

fet

Thus, the resulting PSD vector is computed with spec-
tral components defined as s¢ =uy¢/(Mv), being
v= E{ laz|? : Vteth, and E{-}—the expectation operator.

In the second case, the feature set is extracted from
Continuous Wavelet Transform (CWT) that quantifies
similarity between a given equally sampled time-series
at time spacing 6;¢€/R and a previously fixed base func-
tion (7), termed mother wavelet ruled by a dimension-
less parameter vector n€R. Namely, each time element of
the CWT vector ¢£eC! is extracted from the preproc-
essed EEG time-series z€IR* at scale geIR by accomplish-
ing their convolution with the scaled and shifted mother
wavelet in the form:

st = law *((t—Od,f); (2)

teT

where notation (*) stands for the complex conjugate.

To build a picture showing amplitude variations
through time in Eq. (2), both procedures of wavelet scal-
ing g and translating through the localized time index
teT are used. As a result, the extracted wavelet coeff-
cients provide a compact representation pinpointing EEG
data’s energy distribution in time and frequency domains.
Therefore, the resulting CWT vector is computed with
spectral components defined as s¢ = EY of : WEET \

Having extracted the feature set, we further compute a
real-valued representative vector, p”’4/ ER for each trial
reR, with electrode elements that accumulate the spec-
tral contribution as follows:

po" _ Ss” se, f EC Af, (3)

"min <f <Nmax

where the frequencies Nmin and Nmax determine each one
of the bandwidths of interest fe Af, respectively, within
the most discriminating MI information is assumed to be
concentrated.

Then, we map the multi-channel data per patient on a
2D surface, aiming to preserve the spatial interpretation
of the extracted t-f patterns. In order to preserve the dis-
tance between electrodes in the 3D plane, we compute
the topographic interpolation matrix across all trials,
{S(p” AP) ERS * Ss. VreR}, through the projecting matrix
that maps each EEG trial field, p”4/, as a 2-D circular
Collazos-Huertas et al. Brain Inf. (2020) 7:8

view (looking down at the head top) using spherical
splines that sizes (S x S’)’, as detailed in [34].

Motor imagery classification using Convolutional Neu-
ral Networks. The proposed CNN architecture contains
three learning stages: (i) convolutional layer that holds a
set of kernel filters, {K;¢R* ** : icZ} (J is the number of
used kernel filters), together with the corresponding bias
vectors {bj€R* }, which are applied by a sliding window
across each topographic map S(p” Af), yielding the con-
volution feature map as below:

mrLAf —_— V1 (K; ® S(p’) + bi), EMbAL ops x SU
(4)

where y;(-) is a non-linear activation function, and ®
denotes the convolution operator. Of note, a zero-pad-
ding method is adopted to prevent losing the feature
dimension, so that the output and input sizes of convo-
lution mapping can be the same after the zero-padding
procedure.

(ii) Pooling layer that is a down-sampling stage to
reduce the dimension of output neurons in 2”'4f
through a pool operator matrix KeR* **’, with K’ < K,
aiming at decreasing the computational burden and
the over-fitting issue. Then, each down-sampled map
BA is rearranged into a vector form & “EROON (with
G <S,G’ < S’) by concatenating all matrix rows across
Af and i domains.

(iii) A fully connected stage that includes a neural net-
work with all neurons h’ (q)<¢RN® connected directly to
the outputs of preceding layer g—1 as follows:

h'(q) = y2(Wi@h' (q-1)+BO),¢4=2,Q (5)

where hi’ (1) = é W, sizing GG'IN¢xNj,(q), is the
weighting matrix that contains the connection weights
between the preceding neurons and the hidden units Nj,
of layer q, B(q)<€R*™ is the bias neuron, and y2(-) is an
activation function.

As a result, we obtain the output vector set
{y” = h"(Q)}, with y” €[0, 1]%4, representing Nj, mutually
exclusive classes, so that the last layer is tied to the out-
put dimension (Nj, = N)).

Due to the CNN-model training back-propagates the
discriminating information, through the tied weights,
from the hidden spaces in the input data, we propose to
assess the relevance of input feature mappings, employ-
ing the matrix W(q)<€R?** that holds the row vectors
w4 eRe with D=GG'IN;y. Based on the fact that each
w7, measures the contribution of input features to build
the hidden space h’(q), the relevance of d-th feature is

 

? function topoplot () in EEGLAB toolbox.

Page 4 of 13

assessed as the generalized mean of its corresponding
reverse projection vector, that is, 0% = wll p yielding
the vector 04 = {ofeR*; VdeD}, where notation || - |lp
stands for /,-norm. The obtained relevance vector 04
is reshaped into an estimated feature mapping matrix
Oe€R*** that is computed for each Af as follows:

6 = o(E{z, viel}), (6)

where 5;€R°*@ is the reconstructed feature mapping
for i-th kernel filter, and #(-) is an extrapolation operator
that maps from Gx G’ > SxS’. In this way, the obtained
O highlights the spatial discriminative information pro-
jected from topographic maps.

3 Experiments

We validate the proposed CNN-based MI classification
framework by appraising the following procedures: (i)
preprocessing and extraction of t-f planes, evaluating the
extraction methods of power spectral density and con-
tinuous wavelet transform, for which the correspond-
ing parameter tuning is carried out; (ii) tuning of CNN
architecture for MI discrimination, evaluating the spatial
dropping algorithm proposed for preserving the inter-
pretation of the extracted 2-D features. Two approaches
for dropping are appraised: removing all electrodes out
of the sensorimotor area before training and validation,
and thresholding the electrode contribution after train-
ing and validation.

Extraction of t-f feature patterns. Each chan-
nel recording, x°cR’, is split into N; =5 segments,
{x°eIR', t < T}, using a sliding window approach with
a segment length t = 2 s with overlap dt = 1 s. Within
each segment x°, PSD estimates are computed, fixing the
following parameters: tT = 256,56, = 0.9t. Likewise, we
compute the CWT vector ¢%, selecting the Morlet wave-
let as y that is frequently used in spectral analysis of EEG
signals [35]. So, we extract the continuous wavelet coef-
ficients within each time segment using a complex Mor-
let wavelet, adjusting the scaling value to g = 16 and the
sampling period to 1/At.

For either method of feature extraction, we perform
validation in four different scenarios for spectral band-
widths of interest feAr: A) uw, B) B, C) wUB, and D)
LeU Blow U Bmea U Phigh:

Proposed CNN architecture for MI discrimination.
The adopted multiple input CNN model is based on the
non-sequential Wide&Deep neural network [36] that
performs learning of deep patterns (using the deep path)
under simple rules (through the short path), having the
following units (Fig. 1):
Collazos-Huertas et al. Brain Inf. (2020) 7:8

 

OU9

BN8

    

FC7

 

 

Fig. 1 The proposed CNN structure that is based on Wide&Deep
neural network handling multiple inputs. The first layer (IN1) is

the input, the second (CN2) and third layers (MP3) are hidden and
accomplish the feature mapping generation, while the next block
(ranging from the output of layer CT4 to the OU9 layer) comprises the
classification stage

 

 

— IN1: Input layer that holds an image set sizing 42 x 56.

— CN2: Convolutional layer (first hidden layer). We use
two spatial filters that perform two resulting feature
maps, sizing 42 x 56. Each convolution kernel has a
size of 3 x 3, using a stride of one sample. In addition,
this layer incorporates a rectified linear unit ReLU
through the activation function yj (-) [37].

— MP3: Max-pooling layer (second hidden layer). This
layer sub-samples the resulting mapping that picks
up the maximum value of each feature map to reduce
the number of output neurons, also using a stride of
one sample. Thus, each feature mapping in CN2 is
down-sampled using a pool size of 2 x 2, resulting in
a matrix of size 21 x 28.

— CT4: Concatenate layer, linking together of all result-
ing MP3 feature maps into a single block.

— FI5: Flatten layer that arranges the set of concate-
nated feature maps from CT4 into a single 1D array.
So, the map is vectorized into a one-dimensional
array of size (21)(28)(2)(4) = 1176 points, resulting
from 2 spatial filters, and 4 bandwidths of interest.

— Batch normalization (BN) layers (BN6 and BN8)
that address the vanishing and exploding gradient
problems presented in fully connected networks.
To cope with this issue, all inputs of the previ-
ous layer at each batch are zero-scored, holding

Page 5 of 13

the mean activation close to 0 and the activation
standard deviation close to 1.
— FC7: Fully connected layer (third hidden layer) that
is linked to each neuron of OU9, holding h, neu-
rons for which the weight values are regularized
through the parameters (/), /2) using the Elastic
Net regularization. According to [38], Elastic Net
is used for preventing over-fitting by penalizing a
model having large weights, and can be used more
naively, e.g., when little prior knowledge is available
about the dataset. This layer uses a rectified linear
unit ReLU as the activation function y2(-). The fol-
lowing parameter setting of FC7 is fixed:
¢ Number of neurons are fixed through an exhaus-
tive grid search within h, = [50, 100,..., 550).

¢ The learning rate is fixed at /r = exp(—3).

¢ The optimizer used is the Adam algorithm and
the loss function used is the mean squared error
(MSE).

¢ The regularization parameters /; and Jz are tuned
by a grid search around [0.001, 0.01, 0.1].

— QOU9: Output layer having two or three neurons,
each one representing either task label (left hand,
right hand or foot). This layer is fully connected to
FC7 and uses the softmax procedure as the activa-
tion function y2(-).

Evaluating metrics of classifier performance. As a meas-
ure of performance, the classifier accuracy a,-€R[0, 1] is
computed as follows:

Tp + Tn

Ae = ——__—_,
“Tp + Tn + Fp + En

(7)
where Tp, Ty, Fp and Fy are true-positives, true-nega-
tives, false-positives, and false-negatives, respectively.

Besides, the kappa value, «ER[0,1], is computed to
evaluate the accuracy performance when removing the
impact of random classification as follows [39]:

K = (dc — pe)/(1 — pe); (8)

where pe = 0.5 for bi-label problems.

A cross-validation scheme is performed to evalu-
ate CNN-based classifier performance. Thus, the set of
training trials per subject is randomly partitioned using
a stratified tenfold cross-validation to generate the set
of validation trials. This procedure is repeated ten times
by shifting the test and training dataset.

4 Results

Performed bi-class accuracy of extracted t-f planes. Ini-
tially, we discuss the classifier performance of the com-
puted PSD vectors of contribution, p”“/. In each one
Collazos-Huertas et al. Brain Inf.

(2020) 7:8

Table 1 Performed bi-class accuracy within the MI
segment using the whole electrode montage (C=22)

 

 

 

 

Subject bh B wUB wU3B
PSD

A08T 97.1 + 3.5 84.9 + 6.9 93.3 — 3.9 96.8 + 3.9
AO9T 92.1 +48 89.0 + 6.1 96.5 + 4.3 96.6 + 4.1
AQ3T 91.145. 775 +64 91.2+65 91.3442
AOQ6T 80.0 + 6.9 81.6455 82.5 + 6.1 86.7 + 5.8
AQ7T 83.8 + 87 78.9 + 4.3 82.0449 85.1 + 8.6
AO5T 76.2 + 5.2 79.0 + 6.9 80.8 + 6.6 84.0 + 4.5
AO4T 84.7 + 6.2 79.347. 80.7 + 7.5 83.7454
AO1T 826+ 34 80.5 +54 82.6 + 5.6 83.5 + 7.0
AQ2T 804+ 68 778+ 6.2 81.1453 82.5 + 6.4
Average hy 200 350 350 300
Average dc 85.3 5.7 80.9 + 6.1 85.6 + 5.6 87.8 + 5.5
CWT

A037 96.4 + 3.6 95.0 + 4.6 95.0 + 4.6 94.2 + 2.9
A08T 96.3 £49 954+ 5.1 94.0 + 4.6 94.0 + 5.6
AO9T 940+54 94.8 + 5.6 94.8 + 4.2 92.3+5.9
AQ7T 85.7 +79 834+ 68 86.4 + 6.7 874454
AOQ6T 83.9+5.6 84.1 + 5.1 86.7 + 7.2 86.7 + 7.2
AO4T 86.9 + 7.7 84.6 + 84 854473 85.3 47.2
AO1T 83.2 +67 825+ 5.1 83.44 5.5 82.5 + 3.9
AOST 798 + 6.3 76.8 + 9.0 79.1 +48 822+ 4.9
AQ2T 818472 84.0 + 8.2 83.8+6.5 81.7472
Average hy 350 400 250 250
Average ac 87.5 + 6.1 86.7 = 6.4 87.6 + 5.7 8744 5.6

 

The best figure achieved by each individual is marked in italics

of the tested scenarios for spectral bandwidths of inter-
est, parameter tuning is carried out to reach the maxi-
mum accuracy within the MI interval [3—5] s. As seen
in Table 1, the use of only one rhythm (y or 8) is not

Page 6 of 13

sufficient to reach the best values of accuracy. Moreo-
ver, the 6 waveform drops to 80%. Their combination
pu U B barely helps the classifier rule. Thus, the last vali-
dating scenario (i.e., D) reaches the best performance
on average across all subjects, meaning that the inclu-
sion of more detailed information of 6 sub-bands allows
improving the accuracy of PSD vectors. Concerning
the individual performance, the subjects AO2T, AOLT,
AO4T, and AO5T achieve the lowest values, while AO8T,
AO9T, and AO3T accomplish the best results. Regarding
the CWT-based contribution vectors, the bottom part
of Table 1 shows that the use of every spectral band-
width scenario allows enhancing the performed results,
but without statistical difference between them when
averaging across the subject set. Furthermore, the bi-
class accuracy of CWT-based vectors is comparable
to that obtained by the best case of PSD-based extrac-
tion vectors, having a very similar ranking of individual
performance.

In terms of the tuned CNN parameters, their values
averaged across the subject set show that the training sce-
nario, achieving the best accuracy (WUPjowUBmeaUBhigh),
demands from the PSD-based vectors more hidden
units /,, than in the case of CWT planes. A similar situ-
ation holds in the scenario wU8 that also performs high
accuracy. When extracting the t-f vectors from a single
rhythm (jw or 6), the PDS-based representation demands
less hidden units but achieves lower accuracy.

Figure 2 displays the dependency of CNN hidden
units on the obtained bi-class accuracy. Compared
to the best score achieved by the individually tuned
value of i,, the deterioration in performance is notice-
able (nearly 5%) when decreasing the number of units
in every trained CNN model. At the same time, the
computational burden can reduce, on average, about a

 

 

 

 

 

 

 

 

 

—— Optimal |]
65
1 2 3 4 5 6 7 8 9
Subjects
PSD

 

 

100

95

90

85

Ac

80

75

   

 

   

—-- 100 hu |]
—-- 150 hu |4
—-— 200 hu |]
—— Optimal |}

6 7 8 9

70

 

 

 

 

 

4 5
Subjects
CWT

Fig. 2 Dependence of CNN hidden units and the individual bi-class accuracy. Label “optimal” is the individually tuned CNN model
XX

 
Collazos-Huertas et al. Brain Inf. (2020) 7:8

Page 7 of 13

 

is- 3s 2s- 4s 3s- 5s 4s- 6s 5s- 7s 1s- 3s 2s- 4s 3s- 5s 4s- 6s 5s- 7s

A02T AO8T

 
 
 
 

 
 
 

Fig. 3 Reconstructed topographic maps for the bi-class experiment D including all bandwidths across the time domain in the best (AO8T) and the

worst (AQ2T) subjects, left and right column, respectively

quarter time. Moreover, the variations in accuracy by
changing the amount of 1, indicate a similar complex-
ity for both measured extraction approaches.

Interpretability of brain areas activated by MI tasks.
Intending to give the interpretability of the extracted
input ¢-f vectors, we represent the feature mapping
graphically (topoplot) to highlight the spatial distribu-
tion of the assessed discriminative ability. Each topop-
lot depicts the proposed assessment O(p"4S) computed
in Eq. (6) in which we reconstruct the input feature
image from the trained CNN weights to estimate the
contribution of the electrodes, under the assumption
that the higher the reconstructed weight, the more crit-
ical the discriminating strength between the electrodes.
Of note, the interpolated values falling out of the elec-
trode space are assumed as meaningless. This situation
may arise because the network initializes the weight set
with random values, including the background pixels.
Therefore, the variability and reduced signal-to-noise
rate result in false augmentation of background locali-
ties, as subjects reach low discrimination ability.

The top row of Fig. 3 displays the PSD-based spatial
distribution reconstructed for the best training sce-
nario (D) within each time segment. As seen, the topop-
lots of AO2T (the worst individual) present the spectral
bandwidths contributing much alike with values mainly

 

spread all over space, including places outside of the elec-
trode space. In addition, the contribution estimates are
low and tend to be noisy. Another fact to mention is that
brain activity notably increases within the last time seg-
ment, for which the MI activity is thought to have already
vanished. By contrast, the best-achieving subject AO8T
has some relevant localities, which gather in places of
either brain hemisphere and within the MI interval, fad-
ing at the time window [4—6] s.

In turn, the bottom row depicts the CWT-based
topoplots assessed by the same training scenario (i.e., D),
showing that the obtained spatial distribution of AO2T
still presents the spectral bandwidths that contribute
similarly. However, several spatial clusters appear, and
the amount of meaningless estimates decreases. Never-
theless, a notably enhanced topographic representation
is performed by AO8T, for which the CW'T-based vec-
tors result in values adequately accommodated within
the electrode space, regardless of the window time. Fur-
thermore, the contribution concentrates on the electrode
neighborhoods clearly defined, changing over time. Thus,
the rhythm shows that the sensorimotor electrodes
contribute the most, being more evident their impor-
tance at the window [3—5]s, right at the MI period.

Figure 4 (left column) displays the topoplots individu-
ally computed for the CWT-based feature extraction
Collazos-Huertas et al. Brain Inf. (2020) 7:8

Page 8 of 13

 

A03T

 

A03T

 

A08T

 
   
   

AO02T

      

   

1s-3s 2s-4s 3s-5sS

A05T

4s-6s 5s-7s 1s-3s 2s-4s

(right column)

under the scenario C (i.e., w~U), showing that the brain
activity tends to gather over some electrodes in most of
the subjects. Also, the brain activity between neighbor-
ing time windows changes smoothly, at least in subjects
performing high accuracy (i.e., AO3T and AO8T). As the
discrimination ability of individuals decreases, the topo-
graphic representations become more blurred, meaning
that the learned weights are still severely affected by the
variability captured by EEG data. This situation is more
visible in AO5T (performing the worst) with much learn-
ing weights out of the scalp area, evidencing that the
CNN model is likely to be overtrained.

Performance of spatial dropping strategies. Two
approaches are evaluated—(i) removing all electrodes out
of the sensorimotor area before training and validation,
and (ii) thresholding the electrode contribution after
training and validation.

The first spatial dropping strategy is implemented by
simply including all electrodes belonging to the motor
cortex region (that is, C3,9,10,11,C4,14,15,16,17,18), fol-
lowing the spatial electrode distribution reported by [40].
Figure 4 (middle column) depicts the estimated topoplots
of the two best and worst-performing subjects, showing
that the brain activity gathers more prominently over
some lateral sensorimotor electrodes in most of the sub-
jects. Moreover, the brain activity between neighbor-
ing time-windows changes smoothly with the highest

AO08T

1s-3s 2s-4s 3s-5s 4s-6s 5s-7s Sere. rio

AO02T

00) Se
3s-5s
AOD5T

Fig. 4 Individual relevance weights performed by the tuned CWT feature extraction for the bi-class scenario C: Without spatial dropping (left
column), spatial dropping by removing all sensorimotor electrodes out (middle column), spatial dropping by excluding nonrelevant electrodes

A03T

AO08T

A02T

      

4s-6s 5s-7S 1s-3s 2s-4s 3s-5s

AO5T

4s-6s 5s-7S

 

contribution within the segments of MI ([2—4] and [3—5]
s). In the first couple of subjects (AO8T and AO3T), the
contribution of either rhythm (wu or #) differs. Besides,
the number of learning values out of the scalp is consid-
erably smaller than in the previous case. Still, the topo-
graphic representations of the subjects with the worst
accuracy (A02T and AO5T) remain blurred.

Concerning the second dropping strategy, Fig. 4 (right
column) represents the thresholded values, showing the
presence of several electrodes with a relevant contri-
bution. Thus, the top pair of subjects holds the learned
weights located on the lateral zones, having the highest
contribution near the sensorimotor area with differenti-
ated behavior between yz and 6 rhythms. As expected, the
central localities near the longitudinal fissure have zero-
valued weights. However, as the individual performance
decreases, the number of relevant electrodes increases
due to the increased variability. Moreover, the variance of
the captured EEG data for the worst-performing subjects
is so strong that they have a distorted topoplot with val-
ues out of the scalp. Still, these subjects present relevant
electrodes, unlike the previous approaches achieved.

Table 2 summarizes the bi-class performance achieved
by each evaluated CNN-based framework, showing that
every subject reaches a performance above ~ 75%. All
achieved accuracy scores are competitive with other
values performed by CNN-based approaches recently
Collazos-Huertas et al. Brain Inf. (2020) 7:8

Page 9 of 13

Table 2 Bi-class accuracy of evaluated CNN training strategies, using the CWT-extracted vectors and either dropping
strategy: CWT* with sensorimotor electrodes and CWT** with thresholding. In all compared cases, both sub-bands (ju
and £) are included and the CNN parameters are tuned individually

 

 

 

Subjects [41] [42] CWT K CWT* K CWwT** K

AQ3T 88.2 91.7 95.0 + 4.6 0.67 96.4 + 4.8 0.92 95.0 + 4.6 0.90
AQ9T 82.7 90.9 94.8 + 4.2 0.68 93.1465 0.86 940463 0.88
AQ8T 91.8 92.3 94.0 +46 0.90 97.043.6 0.94 94.7 44.9 0.89
AQ6T 65.7 785 86.7 + 7.2 0.71 84.9 + 9.0 0.69 86.7 + 7.2 0.73
AQ7T 51.7 86.5 86.4 + 6.7 0.58 81.9462 0.64 85.6 + 9.3 0.71
AQ4T 53.9 80.4 854473 0.73 86.1 47.5 0.72 87.6 + 5.0 0.75
AQ2T 63.9 68.4 83.6 + 6.5 0.73 80.3 + 6.2 0.61 81.7448 0.63
AQIT 79.4 87.8 83.4 + 5.5 0.88 81.1 + 5.0 0.62 83.2 + 3.9 0.66
AOST 54.9 88.9 79.1448 0.90 78.3474 0.57 76.7 + 6.9 0.53
Average 70.2 85.0474 87.6 + 5.7 0.75 86.6 + 6.2 0.73 874457 0.74

 

Table 3 Three-class accuracy of evaluated CNN training strategies using the CWT-extracted vectors for the considered
strategies: without spatial dropping (CWT), spatial dropping by removing all sensorimotor electrodes out (CWT*), spatial

dropping by excluding nonrelevant electrodes (CWT**)

 

 

 

Subjects [43] [44] CWT K CWT* K CWwT** K

AQ3T 86. ] 76.7 83.6 + 6.6 0.75 84.6 + 83 0.76 82.0 + 5.6 0.73
AQ7T 83.6 82.8 73.5495 0.59 73.947.5 0.60 750474 0.63
AO8T 63.1 78.2 73.0 + 9.0 0.59 76.0 + 9.5 0.64 75.14 104 0.63
AOIT 80.8 84.1 73.0 + 6.6 0.59 7344 6.1 0.60 75.7 5.5 0.63
AO9T 54.3 75.2 72.2456 0.58 69.4 + 5.7 0.58 73.0476 0.60
AQ4T 54.0 624 69.7 + 5.4 0.47 69.7 + 6.9 0.47 69.9 + 5.6 0.47
AQ6T 51.3 51.8 68.3 + 6.7 0.49 68.8 + 8.5 0.52 68.4 + 6.8 0.52
AQ2T 71.2 57.7 65.0 + 5.5 0.44 58.9 + 6.5 0.46 624 + 88 0.46
AQST 52.2 48.1 59.1 + 4.2 0.37 58.5 + 5.6 0.36 57.5 + 6.0 0.34
Average 66.2 68.5 70.8 + 6.5 0.54 70.3 + 7.0 0.55 71.2 7.0 0.56

 

presented for motor imagery classification (left and right
hand). It is worth noting that the use of either spatial
dropping strategy results in small degradation of classi-
flier accuracy or xk value.

Performance of three-class MI tasks. Further, we evalu-
ate the proposal in a more complicated classification
scenario, conducting testing for the following three-
class discrimination framework of motor imagery tasks:
left hand, right hand, and foot. Table 3 summarizes the
classifier performance reported by two state-of-the-art
approaches to the three-class discrimination, showing
that the proposed approach provides very competitive
outcomes (above 71%) and enhancing the accuracy of the
low-performing subjects. One aspect to remark is that
the values of multi-class accuracy and « tend to fall, com-
pared to the bi-class scenario, partially because of the
small database evaluated.

As in the binary classification task, we analyze the
interpretability of brain areas activated by each MI task
based on the reconstruction of the learned CNN weights.

When assessed by the CWT-based feature extraction,
Fig. 5 displays the reconstructed topoplots of scenario C,
having a more distinct electrode contribution than in the
bi-class case. If not using the spatial dropping, the dyad
of the best-performing subjects shows an increase in
neural activity within the motor imagery interval ([3—5]
s). However, this behavior is not evident in the worst-
performing pair. Moreover, subject AO2T has a response
postponed to the segment ([4—6]s).

In the next case of sensorimotor dropping, the mid-
dle column shows that the better the accuracy, the
more compact the electrode contribution. Thus, the
method assesses the motor cortex’s regular contribu-
tion through the whole record, regardless of the evoked
activity. This kind of scattered representation implies
high intrasubject variability. Then, the spatial drop-
ping by excluding nonrelevant electrodes (right col-
umn) enhances the interpretation of the learned CNN
weights, yielding a lower number of contributing elec-
trodes, but more meaningful.
Collazos-Huertas et al. Brain Inf. (2020) 7:8

Page 10 of 13

 

A03T

A08T

A02T

:

1s-3s 2s-4s 3s-5s

A05T

4s-6s 5s-7s 1s-3s 2s-4s

 

NS

Lastly, we evaluate the significance of learning CNN
weights in terms of the disagreement of performing the
individual accuracy, using the considered dropping strat-
egies: spatial dropping by weighing only all sensorimotor
electrodes (CWT*) and spatial dropping by excluding
nonrelevant electrodes (CW T**). To this, we conduct the
paired Welch’s t-test, employing the scores achieved on
the cross-validation folds and holding a significant level
of a p-value< 0.05. In this case, the non-rejection of the
null hypothesis (identical average scores) is the desired
behavior to prove that our relevance approaches (CWT*
and CWT**) do not differ from CWT (without spatial
dropping). Table 2 shows that only a couple of subjects
(namely, AO8T with p = 0.159 and AO7T with p = 0.133)
that are underlined are close to p < 0.15. In turn, Table 3
presents a confident difference in performance for sub-
ject AO2T (underlined subject) with a p = 0.039. This
result may be explained since A0O2T reports a low-per-
formance with high variability along the folds. Hence, the
sensorimotor region is not sufficient to code discriminant
information about this subject.

5 Discussion and concluding remarks

We present an approach using CNN models to improve
the interpretability of spatial contribution in discrimi-
nating between MI tasks, preserving an adequate clas-
sification accuracy. The results obtained for BCI Dataset
2a prove that the proposed deep learning framework

 

A03T

 

AO08T

 

A02T

    

3s-5s
AOS5T
Fig.5 Relevance weights computed for representative individuals (best-performing AO3T and AO8T and worst-performing AO2T and AO5T) in
terms of performed three-class accuracy for scenario C: without spatial dropping (left column), spatial dropping by weighing only all sensorimotor
electrodes (middle column), spatial dropping by excluding nonrelevant electrodes (right column)

A03T

AO8T

A02T

   

1s-3s 2s-4s 3s-5s

A05T

4s-6s 5s-7S 4s-6s 5s-75S

 

allows improving accuracy along with revealing the elec-
trodes with higher spatial relevance. Nevertheless, the
following aspects are to be regarded in the framework
implementation:

Feature extraction of t-f vectors. For each estimated
source, the t-f sets are extracted within each time win-
dow, generating an image containing temporal, spec-
tral, and spatial information. Intending to deal with the
nonstationary EEG nature, we evaluate the extraction of
t-f patterns from the FFT-based periodogram and con-
tinuous wavelet transform. Then, all extracted t-f feature
patterns are further interpolated to obtain the spatial dis-
tribution of activated brain areas through topographic
maps. We obtain that both approaches are similar in
terms of providing classifier performance and the com-
plexity of implementing CNN models. Besides, we evalu-
ate four combining scenarios of uw and f rhythms, which
differently influence the achieved accuracy. In the case of
PSD estimates, only the inclusion of detailed information
from three 6 sub-bands together with jz waveform pro-
vides the best system accuracy. By contrast, the CWT-
based feature set gives high accuracy scores regardless of
the evaluated sub-band combination. This result may be
explained by the fact that CWT is more suitable for the
decomposition of nonstationary data.

Nonetheless, the CWT-based vectors are preferable
for interpretation purposes because the learned weights
gather around electrode neighborhoods, forming more
Collazos-Huertas et al. Brain Inf. (2020) 7:8

clearly defined spatialities with relevant neural activity.
Moreover, the CWT-based weights smoothly change
over time following the implemented MI paradigm tim-
ing. One more aspect of highlighting is that the learned
weights are less sensitive to the overtraining effect.

Spatial interpretability of activated MI responses.
Another aspect to remark is the dropout algorithm that
CNN models include. Their high number of parameters
makes them particularly prone to over-fitting, demand-
ing the use of regularization methods. In addition, neu-
ral network training or inference can involve randomly
modifying parameters [45]. To cope with this issue, the
spatial dropout algorithm can withdraw an entire feature
map across a channel since adjacent pixels are highly cor-
related to the dropped pixels [46, 47].

Relying on the fact that the interpretation of evoked
brain zones can be performed by preserving spatial
information in input multi-spectral images, we evaluate
two spatial dropping strategies to promote discarding of
irrelevant image details: including just the sensorimotor
electrodes, and thresholding of the electrode contribu-
tion. Although the number learned values out the scalp
decreases considerably in the former strategy, the topo-
graphic representations of subjects having low accuracy
are still blurred, hindering the interpretation of analyzed
brain activity. The use of full-set EEG electrodes has
been already reported as difficult to achieve in practi-
cal MI applications, suggesting that the performance of
CNN models can improve with fewer electrodes, which
cover the motor cortex and sensorimotor cortex [48]. The
obtained results show that the thresholding strategy is
desirable since the highest contribution clusters over the
sensorimotor area with differentiated behavior between ju
and 6 bands. However, the high EEG data variability cap-
tured by the worst-performing subjects may still produce
distorted topoplots with values out of the scalp, making
difficult their understanding.

Evaluated CNN architecture for MI discrimination.
The first design consideration is the number of convolu-
tional layers, together with the type of end classifier. In
MI tasks, 70% of CNN models use a rectified linear unit
(ReLU) as the layer’s activation function, while the vast
majority of classifier fully connected layers employ a
softmax activation function [49]. The proposed network
relies on the Wide&Deep architecture for handling multi-
ple inputs to learn deep patterns under simple rules. With
the purpose of increasing the neurophysiological reliabil-
ity of feature interpretation, the Classifier Block includes
batch normalization applied to the convolutional outputs
before and after the fully connected layer FC7, improv-
ing the performance on unseen examples [50]. We also
use the Elastic Net regularization technique through the

Page 11 of 13

parameters (/j, /2) for preventing over-fitting by penaliz-
ing a model with large weights.

Spatial dropping of multi-class settings. The spa-
tial dropping algorithm is evaluated in two labeled sce-
narios of MI tasks: bi-class and three-class, resulting in
meaningful topographic representations and perform-
ing values of accuracy very competitive with the results
reported by similar CNN-based architectures. However,
the achieved values of multi-class accuracy and x tend
to fall, compared to the bi-class scenario. This behavior
can be partially explained by the small database evaluated
and the reduced set of scalp electrodes.

However, some restrictions are to be mentioned: the
first limitation to enhance the performance of the evalu-
ated CNN architecture is the small size of the examined
dataset that holds just nine subjects with very differ-
ent variability [51]. As a result, the deterioration in per-
formance is noticeable (nearly 5%) when decreasing the
number of units in each individual trained CNN model.
Moreover, the small data issue restricts the application of
robust approaches in deep learning like augmentation or
transfer learning, causing over-fitting. Another concern
is the adequate sampling of the potential scalp field for
the topographic analysis that requires a large number of
electrodes [52].

As future work, to enhance the impact of tested Deep
Learning models, we plan to employ datasets that hold
more labeled MI tasks, fusing CNNs with different char-
acteristics and architectures is also to be considered to
learn more complex relationships between spatial pat-
terns and extracted t-f representations, making the
learned CNN weights more accessible to interpret [53,
54].

Acknowledgements

This research manuscript is developed within “Programa de Investigacion
Reconstruccidn del Tejido Social en Zonas de Posconflicto en Colombia" COD-

SIGP 57579 under project “Fortalecimiento docente desde la alfabetizacion
medidtica Informacional y la CTel, como estrategia diddctico-pedagégica y
soporte para la recuperacion de la confianza del tejido social afectado por el
conflicto" COD-SIGP 58950, funded by Convocatoria Colombia Cientifica,
Contrato No. FP44842-213-2018 and Convocatoria Doctorados Nacionales 2017
COLCIENCIAS conv. 785.

Authors’ contributions

DFC-H, AMA-M, GC-D conceived of the presented idea. DFC-H and AMA-M
developed the theory based on EEG feature representation and Convolutional
neural networks and performed the computations. GC-D, CDA-M and GAC-D
verified the analytical methods. DFC-H and AMA-M investigated the influence
of the spatial dropout on the topographic map for improving the interpret-
ability of brain patterns and supervised the findings of this work. All authors
discussed the results and contributed to the final manuscript. All authors read
and approved the final manuscript.

Data availability
Publicly available datasets were analyzed in this study. This data can be found
here:http://www.bbci.de/competition/iv/#download.
Collazos-Huertas et al. Brain Inf.

(2020) 7:8

Competing interests
The authors declare that they have no competing interests.

Author details

' Signal Processing and Recognition Group, Universidad Nacional de Colom-
bia, Manizales, Colombia. * Cultura de la Calidad en la Educacién Research
Group, Universidad Nacional de Colombia, Manizales, Colombia.

Received: 7 May 2020 Accepted: 18 August 2020
Published online: 03 September 2020

References

1,

Cannard C, Brandmeyer T, Wahbeh H, Delorme A (2020) Chapter 16-Self-
health monitoring and wearable neurotechnologies. In: Ramsey NF, Mil-
lan JDR (eds) Brain-Computer Interfaces. Handbook of Clinical Neurology,
vol.168. Elsevier, pp 207-232

Xu M, Wei Z, Ming D (2020) Research advancements of motor imagery
for motor function recovery after stroke. Sheng wu yi xue Gong Cheng
xue za zhi= Journal of Biomedical Engineering= Shengwu Yixue
Gongchengxue Zazhi 37(1):169-173

Guillot A, Debarnot U (2019) Benefits of motor imagery for human space
flight: a brief review of current knowledge and future applications. Front
Physiol 10:396

Pillette L, Jeunet C, Nkambou R, N’Kaoua B, Lotte F (2019) Towards
artificial learning companions for mental imagery-based brain-computer
interfaces. CORR, arXiv:abs/1905.09658

Frau-Meigs D (2007) Media Education. A Kit for Teachers, Students, Par-
ents and Professionals. UNESCO

Marchesotti S, Bassolino M, Serino A, Bleuler H, Blanke O (2016) Quan-
tifying the role of motor imagery in brain-machine interfaces. Sci Rep
6:24076

Rim B, Sung N, Min S, Hong M (2020) Deep learning in physiological
signal data: a survey. Sensors 20(4):969

Sakhavi S, Guan C, Yan S (2018) Learning temporal information for brain-
computer interface using convolutional neural networks. IEEE Transac-
tions on Neural Networks and Learning Systems 29(11):5619-5629
Zemouri R, Zerhouni N, Racoceanu D (2019) Deep learning in the bio-
medical applications: recent and future status. Appl Sci 9(8):1526

Plis S, Hjelm D, Salakhutdinov R, Allen E, Bockholt H, Long J, Johnson H,
Paulsen J, Turner J, Calhoun V (2014) Deep learning for neuroimaging: a
validation study. Front Neurosci 8:229

. WuH, Niu, LiF, LiY, Fu B, Shi G, Dong M (2019) A parallel multiscale filter

bank convolutional neural networks for motor imagery EEG classification.
Front Neurosci 13:1275

Amin S, Alsulaiman M, Muhammad G, Bencherif M, Hossain M (2019)
Multilevel weighted feature fusion using convolutional neural networks
for EEG motor imagery classification. IEEE Access 7:18940-18950
Ortiz-Echeverri CJ, Salazar-Colores S, Rodri-quez-Reséndiz J, Gdmez-
Loenzo R (2019) A new approach for motor imagery classification based
on sorted blind source separation, continuous wavelet transform, and
convolutional neural network. Sensors 19(20):4541

Guan C, Tih-Shih L, Cuntai G, Fung S, Shuen D, Cheung Y, Teng S, Zhang
H, Krishnan K (2010) Effectiveness of a brain-computer interface based
programme for the treatment of adhd: a pilot study. Psychopharmacol
Bull 43(1):73-82

Doborjeh M, Kasabov N, Doborjeh Z (2017) Evolving, dynamic clustering
of spatio/spectro-temporal data in 3d spiking neural network models
and a case study on EEG data. Evolv Syst 9:04

Yang H, Sakhavi S, Ang KK, Guan C (2015) On the use of convolutional
neural networks and augmented csp features for multi-class motor
imagery of EEG signals classification. In: 2015 37th Annual International
Conference of the IEEE Engineering in Medicine and Biology Society
(EMBC), pp 2620-2623

Sakhavi S, Guan C, Yan S (2015) Parallel convolutional-linear neural
network for motor imagery classification. In 2015 23rd European Signal
Processing Conference (EUSIPCO), pp 2736-2740

Taheri M, Ezoji S, Sakhaei SM, (2020) Convolutional neural network based
features for motor imagery EEG signals classification in brain-computer
interface system. SN Appl Sci 2(555):1

20.

21,

22.

23.

24,

25.

26.

2/.

28.

29.

30.

31.

32.

33.

34.

35.

36.

37.

38.

39.

40.

41.

Page 12 of 13

Tang X, LiW, Li X, Ma W, Dang X (2020) Motor imagery EEG recognition
based on conditional optimization empirical mode decomposition and
multi-scale convolutional neural network. Expert Syst Appl 149:113285
Zhang J, Yan C, Gong X (2017) Deep convolutional neural network for
decoding motor imagery based brain computer interface. In 2017 IEEE
International Conference on Signal Processing, Communications and
Computing (ICSPCC), pp 1-5

Uktveris T, Jusas V (2017) Application of convolutional neural networks to
four-class motor imagery classification problem. ITC 46:260—273

Lee HK, Choi Y (2018) A convolution neural networks scheme for clas-
sification of motor imagery EEG based on wavelet time-frequecy image.
In: 2018 International Conference on Information Networking (ICOIN), pp
906-909

Yang J, Yao S, Wang J (2018) Deep fusion feature learning network for
MI-EEG classification. IEEE Access 6:79050-79059

Petrichella S, Vollere L, Ferreri F, Guerra A, Maatta S, Kononen M, Di Laz-
zaro V, lannello G (2016) Channel interpolation in tms-EEG: a quantitative
study towards an accurate topographical representation. Conference
proceedings: Annual International Conference of the IEEE Engineering in
Medicine and Biology Society. IEEE Engineering in Medicine and Biology
Society. Annual Conference, 2016:989-992

Tabar Y, Halici U (2017) A novel deep learning approach for classification
of EEG motor imagery signals. J Neural Eng 14(1):016003

Thodoroff P, Pineau J, Lim A (2016) Learning robust features using deep
learning for automatic seizure detection. CoRR. arXiv:1608.00220

Xu G, Shen X, Chen S, Zong Y, Zhang C, Yue H, Liu M, Chen F, Che W
(2019) A deep transfer convolutional neural network framework for EEG
signal classification. IEEE Access 7:112767-112776

D'Souza RN, Huang P-Y, Yeh F-C (2020) Structural analysis and optimiza-
tion of convolutional neural networks with a small sample size. Sci Rep
10(1):1-13

Dai M, Zheng D, Na R, Wang S, Zhang S (2019) EEG classification of motor
imagery using a novel deep learning framework. Sensors 19(3):551

Rong Y, Wu X, Zhang Y (2020) Classification of motor imagery electro-
encephalography signals using continuous small convolutional neural
network. Int J Imaging Syst Technol 30(3):653-659

Zhao X, Zhang H, Zhu G, You F, Kuang S, Sun L (2019) A multi-branch 3d
convolutional neural network for EEG-based motor imagery classification.
IEEE Trans Neural Syst Rehab Eng 27:2164-2177

Bashivan P Rish I, Yeasin M, Codella N (2016) Learning representations
from EEG with deep recurrent-convolutional neural networks. CoRR, arXiv
‘abs/1511.06448

McFarland D, Miner L, Vaughan T, Wolpaw J (2004) Mu and beta rhythm
topographies during motor imagery and actual movements. Brain
Topogr 12:177-186

Delorme A, Makeig S (2004) EEGLAB: an open source toolbox for analysis
of single-trial EEG dynamics including independent component analysis.
J Neurosci Methods 134(1):9-21

Alvarez-Meza AM, Velasquez-Martinez LF, Castellanos-Dominguez G
(2015) Time-series discrimination using feature relevance analysis in
motor imagery classification. Neurocomputing 151:122-129

Cheng H, Koc L, Harmsen J, Shaked T, Chandra T, Aradhye H, Anderson G,
Corrado G, Chai W, Ispir M, Anil R, Haque Z, Hong L, Jain V, Liu X, Shah H
(2016) Wide & deep learning for recommender systems. Association for
Computing Machinery, New York, p 7-10

Ide H, Kurita T (2017) Improvement of learning for CNN with ReLU activa-
tion by sparse regularization. In: 2017 International Joint Conference on
Neural Networks (CNN), pp 2684-2691

Lawhern V, Solon A, Waytowich N, Gordon S, Hung C, Lance B (2018)
EEGNet: a compact convolutional neural network for EEG-based brain—
computer interfaces. J Neural Eng 15(5):056013

Li F, He F, Wang F, Zhang D, Xia Y, Li X (2020) A novel simplified convo-
lutional neural network classification algorithm of motor imagery EEG
signals based on deep learning. Appl Sci 10(5):1605

Brunner C, Leeb R, Miller-Putz G, Schlégl A, Pfurtscheller G (2008) BCI
competition 2008-graz data set A. Institute for Knowledge Discovery
(Laboratory of Brain-Computer Interfaces), Graz University of Technology,
vol 16

Shahtalebi S, Asif A, Mohammadi A (2020) Siamese neural networks for
EEG-based brain-computer interfaces. ArXiv. arXiv:2002.00904

 
Collazos-Huertas et al. Brain Inf.

42.

43,

Ad,

 

48.

49.

(2020) 7:8

Olivas-Padilla B, Chacon-Murguia M (2019) Classification of multiple
motor imagery using deep convolutional neural networks and spatial
filters. Appl Soft Comput 75:461-472

Zhou B, Wu X, Zhang L, Lv Z (2014) Guo X (2014) Robust spatial filters

on three-class motor imagery EEG data using independent component
analysis. J Biosci Med 02:43-49

Li B, Yang B, Guan C, Hu C (2019) Three-class motor imagery classification
based on focsp combined with voting mechanism. In: 2019 IEEE Interna-
tional Conference on Computational Intelligence and Virtual Environ-
ments for Measurement Systems and Applications (CIVEMSA), pp 1-4
Labach A, Salehinejad H, Valaee S (2019) Survey of dropout methods for
deep neural networks. CoRR. arXiv:1904.13310

Thompson M (2019) Critiquing the concept of bci illiteracy. Sci Eng Ethics
25(4):1217-1233

Park S, Kwak N (2017) Analysis on the dropout effect in convolutional
neural networks. In: Lai S-H, Lepetit V, Nishino K, Sato Y (eds) Computer
Vision — ACCV 2016, Springer International Publishing, Cham, pp 189-204
Zhao X, Zhang H, Zhu G, You F, Kuang S, Sun L (2019) A multi-branch 3d

convolutional neural network for EEG-based motor imagery classification.

IEEE Trans Neural Syst Rehab Eng 27(10):2164-2177

Craik A, Kilicarslan A, Contreras-Vidal JL (2019) Classification and transfer
learning of EEG during a kinesthetic motor imagery task using deep
convolutional neural networks. In: 2019 41st Annual International Confer-
ence of the IEEE Engineering in Medicine and Biology Society (EMBC), pp
3046-3049

50.

51.

52.

53.

54.

Page 13 of 13

Borra D, Fantozzi S, Magosso E (2020) Interpretable and lightweight con-
volutional neural network for EEG decoding: application to movement
execution and imagination. Neural Netw 129:55-74

Collazos-Huertas D, Caicedo-Acosta J, Castaho-Duque G, Acosta-Medina
C (2020) Enhanced multiple instance representation using time-fre-
quency atoms in motor imagery classification. Front Neurosci 14:155
Michel C (2019) Chapter 12 - high-resolution EEG. In Kerry H. Levin and
Patrick Chauvel, editors, Clinical Neurophysiology: Basis and Technical
Aspects, volume 160 of Handbook of Clinical Neurology, pp 185 — 201.
Elsevier

Amin S, Alsulaiman M, Muhammad G, Mekhtiche M, Hossain M (2019)
Deep learning for EEG motor imagery classification based on multi-layer
CNNS feature fusion. Future Gener Comput Syst 101:542-554

Wang Z, Cao L, Zhang Z, Gong X, Sun Y, Wang H (2018) Short time Fourier
transformation and deep neural networks for motor imagery brain com-
puter interface recognition. Concurr Comput 30(23):e4413

Publisher’s Note
Springer Nature remains neutral with regard to jurisdictional claims in pub-
lished maps and institutional affiliations.

 

 

Submit your manuscript to a SpringerOpen”®
journal and benefit from:

> Convenient online submission

> Rigorous peer review

> Open access: articles freely available online
> High visibility within the field

> Retaining the copyright to your article

 

Submit your next manuscript at > springeropen.com

 

 
